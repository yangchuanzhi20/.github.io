

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.jpg">
  <link rel="icon" href="/img/favicon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ç™½è‰²å¾ˆå“‡å¡">
  <meta name="keywords" content="å‘ç–¯ï¼Œç”Ÿæ´»">
  
    <meta name="description" content="pytorchåŸºç¡€çŸ¥è¯†æ¢³ç†ğŸ§">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorchåŸºç¡€!ğŸ§">
<meta property="og:url" content="https://yangchuanzhi20.github.io/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="å°æ¨çš„ç²¾ç¥ä¸–ç•Œãƒ½( àº¶â–® àº¶)ï¾‰">
<meta property="og:description" content="pytorchåŸºç¡€çŸ¥è¯†æ¢³ç†ğŸ§">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yangchuanzhi20.github.io/img/39.jpg">
<meta property="article:published_time" content="2024-01-24T06:34:19.000Z">
<meta property="article:modified_time" content="2024-02-14T10:33:16.809Z">
<meta property="article:author" content="ç™½è‰²å¾ˆå“‡å¡">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Pytorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://yangchuanzhi20.github.io/img/39.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>pytorchåŸºç¡€!ğŸ§ Ë™Ï–Ë™ å°æ¨çš„ç²¾ç¥ä¸–ç•Œãƒ½( àº¶â–® àº¶)ï¾‰</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yangchuanzhi20.github.io","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"â™¡","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 100vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ç™½è‰²å¾ˆå“‡å¡à¸…Õâ€¢ï»Œâ€¢Õà¸…</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/game/">
                <i class="iconfont icon-switch-fill"></i>
                <span>æ¸¸æˆ</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/39.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">pytorchåŸºç¡€!ğŸ§</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-01-24 14:34" pubdate>
          2024å¹´1æœˆ24æ—¥ ä¸‹åˆ
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          17k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          138 åˆ†é’Ÿ
        
      </span>
    

    
    
  </div>


        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">pytorchåŸºç¡€!ğŸ§</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="PytorchåŸºç¡€"><a href="#PytorchåŸºç¡€" class="headerlink" title="PytorchåŸºç¡€"></a>PytorchåŸºç¡€</h1><h2 id="1-Tensorså¼ é‡"><a href="#1-Tensorså¼ é‡" class="headerlink" title="1.Tensorså¼ é‡"></a>1.Tensorså¼ é‡</h2><p>å¼ é‡æ˜¯ä¸€ç§ä¸“é—¨çš„æ•°æ®ç»“æ„ï¼Œä¸æ•°ç»„å’ŒçŸ©é˜µéå¸¸ç›¸ä¼¼ã€‚åœ¨ PyTorch ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å¼ é‡å¯¹æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºä»¥åŠæ¨¡å‹çš„å‚æ•°è¿›è¡Œç¼–ç ã€‚</p>
<p>å¼ é‡ç±»ä¼¼äº NumPy çš„ ndarraysï¼Œä¸åŒä¹‹å¤„åœ¨äºå¼ é‡å¯ä»¥åœ¨ GPU æˆ–å…¶ä»–ç¡¬ä»¶åŠ é€Ÿå™¨ä¸Šè¿è¡Œã€‚äº‹å®ä¸Šï¼Œå¼ é‡å’Œ NumPy æ•°ç»„é€šå¸¸å¯ä»¥å…±äº«ç›¸åŒçš„åº•å±‚å†…å­˜ï¼Œä»è€Œæ¶ˆé™¤äº†å¤åˆ¶æ•°æ®çš„éœ€è¦ã€‚</p>
<h3 id="1-1-åˆå§‹åŒ–å¼ é‡"><a href="#1-1-åˆå§‹åŒ–å¼ é‡" class="headerlink" title="1.1 åˆå§‹åŒ–å¼ é‡"></a>1.1 åˆå§‹åŒ–å¼ é‡</h3><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure>

<p>å¼ é‡å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è¿›è¡Œåˆå§‹åŒ–ã€‚</p>
<blockquote>
<p><strong>ç›´æ¥æ¥è‡ªæ•°æ®</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]<br>x_data = torch.tensor(data)<br></code></pre></td></tr></table></figure>

<blockquote>
<p><strong>ä» NumPy æ•°ç»„</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)<br></code></pre></td></tr></table></figure>

<blockquote>
<p><strong>ä»å¦ä¸€ä¸ªå¼ é‡</strong></p>
</blockquote>
<p>æ–°å¼ é‡ä¿ç•™å‚æ•°å¼ é‡çš„å±æ€§ï¼ˆå½¢çŠ¶ã€æ•°æ®ç±»å‹ï¼‰ï¼Œé™¤éæ˜¾å¼è¦†ç›–ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">x_ones = torch.ones_like(x_data) <span class="hljs-comment"># retains the properties of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Ones Tensor: \n <span class="hljs-subst">&#123;x_ones&#125;</span> \n&quot;</span>)<br><br>x_rand = torch.rand_like(x_data, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># overrides the datatype of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Random Tensor: \n <span class="hljs-subst">&#123;x_rand&#125;</span> \n&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Ones Tensor:<br> tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><br>Random Tensor:<br> tensor([[<span class="hljs-number">0.8823</span>, <span class="hljs-number">0.9150</span>],<br>        [<span class="hljs-number">0.3829</span>, <span class="hljs-number">0.9593</span>]])<br></code></pre></td></tr></table></figure>

<blockquote>
<p><strong>ä½¿ç”¨éšæœºå€¼æˆ–å¸¸é‡å€¼</strong></p>
</blockquote>
<p><code>shape</code> æ˜¯å¼ é‡ç»´åº¦çš„å…ƒç»„ã€‚åœ¨ä¸‹é¢çš„å‡½æ•°ä¸­ï¼Œå®ƒå†³å®šäº†è¾“å‡ºå¼ é‡çš„ç»´æ•°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">shape = (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,)<br>rand_tensor = torch.rand(shape)<br>ones_tensor = torch.ones(shape)<br>zeros_tensor = torch.zeros(shape)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Random Tensor: \n <span class="hljs-subst">&#123;rand_tensor&#125;</span> \n&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Ones Tensor: \n <span class="hljs-subst">&#123;ones_tensor&#125;</span> \n&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Zeros Tensor: \n <span class="hljs-subst">&#123;zeros_tensor&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong>åœ¨ç»™å®šå½¢çŠ¶ï¼ˆshapeï¼‰æ—¶ï¼Œé€—å·åœ¨ Python ä¸­é€šå¸¸ç”¨äºè¡¨ç¤ºå…ƒç»„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ<code>shape = (2, 3,)</code> ä¸­çš„é€—å·å®é™…ä¸Šæ˜¯ä¸€ä¸ªå…ƒç»„çš„æ ‡å¿—ï¼Œå³ä½¿åœ¨æ²¡æœ‰é€—å·çš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿæ˜¯ä¸€ä¸ªåˆæ³•çš„å…ƒç»„ã€‚</p>
<p>è¿™ç§å†™æ³•æ˜¯ä¸ºäº†ç¡®ä¿åœ¨å®šä¹‰å…ƒç»„æ—¶å³ä½¿åªæœ‰ä¸€ä¸ªå…ƒç´ ä¹Ÿä½¿ç”¨é€—å·ï¼Œä»¥<strong>é¿å…ä¸æ™®é€šçš„æ‹¬å·è¿ç®—ç¬¦äº§ç”Ÿæ­§ä¹‰</strong>ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå†™æˆ <code>shape = (2, 3)</code>ï¼Œå®ƒå°†è¢«è§£é‡Šä¸ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªæ•´æ•°çš„è¡¨è¾¾å¼ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªåŒ…å«ä¸€ä¸ªå…ƒç»„çš„è¡¨è¾¾å¼ã€‚</p>
<p>åœ¨ Python ä¸­ï¼Œå•ä¸ªå…ƒç´ çš„å…ƒç»„éœ€è¦åœ¨å…ƒç´ åé¢æ·»åŠ é€—å·ï¼Œä»¥æ˜ç¡®è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå…ƒç»„ã€‚è¿™æ˜¯ä¸ºäº†åŒºåˆ†å…ƒç»„å’Œæ‹¬å·å†…çš„è¡¨è¾¾å¼ã€‚æ‰€ä»¥ï¼Œ<code>(2, 3,)</code> å’Œ <code>(2, 3)</code> <strong>åœ¨è¿™é‡Œæ˜¯ç­‰ä»·</strong>çš„ï¼Œéƒ½è¡¨ç¤ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªæ•´æ•°çš„å…ƒç»„ã€‚</p>
<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">Random Tensor:<br> tensor([[<span class="hljs-number">0.3904</span>, <span class="hljs-number">0.6009</span>, <span class="hljs-number">0.2566</span>],<br>        [<span class="hljs-number">0.7936</span>, <span class="hljs-number">0.9408</span>, <span class="hljs-number">0.1332</span>]])<br><br>Ones Tensor:<br> tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br>Zeros Tensor:<br> tensor([[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]])<br></code></pre></td></tr></table></figure>

<h3 id="1-2-å¼ é‡çš„å±æ€§"><a href="#1-2-å¼ é‡çš„å±æ€§" class="headerlink" title="1.2 å¼ é‡çš„å±æ€§"></a>1.2 å¼ é‡çš„å±æ€§</h3><p>å¼ é‡å±æ€§æè¿°å®ƒä»¬çš„å½¢çŠ¶ã€æ•°æ®ç±»å‹å’Œå­˜å‚¨å®ƒä»¬çš„è®¾å¤‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Shape of tensor: <span class="hljs-subst">&#123;tensor.shape&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Datatype of tensor: <span class="hljs-subst">&#123;tensor.dtype&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Shape of tensor: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>Datatype of tensor: torch.float32<br>Device tensor <span class="hljs-keyword">is</span> stored on: cpu<br></code></pre></td></tr></table></figure>

<h3 id="1-3-å¼ é‡æ“ä½œ"><a href="#1-3-å¼ é‡æ“ä½œ" class="headerlink" title="1.3 å¼ é‡æ“ä½œ"></a>1.3 å¼ é‡æ“ä½œ</h3><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/torch.html">https://pytorch.org/docs/stable/torch.html</a></p>
<p>è¿™é‡Œå…¨é¢æè¿°äº† 100 å¤šç§å¼ é‡è¿ç®—ï¼ŒåŒ…æ‹¬ç®—æœ¯ã€çº¿æ€§ä»£æ•°ã€çŸ©é˜µæ“ä½œï¼ˆè½¬ç½®ã€ç´¢å¼•ã€åˆ‡ç‰‡ï¼‰ã€é‡‡æ ·ç­‰ã€‚è¿™äº›æ“ä½œä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥åœ¨ GPU ä¸Šè¿è¡Œï¼ˆé€Ÿåº¦é€šå¸¸é«˜äºåœ¨ CPU ä¸Šï¼‰ã€‚</p>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œå¼ é‡æ˜¯åœ¨ CPU ä¸Šåˆ›å»ºçš„ã€‚æˆ‘ä»¬éœ€è¦æ˜¾å¼åœ°å°†å¼ é‡ç§»åŠ¨åˆ° GPU using <code>.to</code> æ–¹æ³•ï¼ˆåœ¨æ£€æŸ¥ GPU å¯ç”¨æ€§ä¹‹åï¼‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We move our tensor to the GPU if available</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    tensor = tensor.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br></code></pre></td></tr></table></figure>

<blockquote>
<p><strong>ç´¢å¼•å’Œåˆ‡ç‰‡</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.ones(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First row: <span class="hljs-subst">&#123;tensor[<span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First column: <span class="hljs-subst">&#123;tensor[:, <span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Last column: <span class="hljs-subst">&#123;tensor[..., -<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br>tensor[:,<span class="hljs-number">1</span>] = <span class="hljs-number">0</span><br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">First row: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>First column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>Last column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong>çœç•¥ç¬¦å·çš„ä½œç”¨æ˜¯<strong>çœç•¥æ‰å…¶ä½™çš„ç»´åº¦</strong>ã€‚ä¾‹å¦‚ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor[:,:,:,<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor[..., <span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p><code>...</code>ç­‰ä»·äº<code>:,:,:</code></p>
<p>è¿æ¥å¼ é‡ å¯ç”¨äº <code>torch.cat</code> æ²¿ç»™å®šç»´åº¦è¿æ¥ä¸€ç³»åˆ—å¼ é‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(t1)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong>dimè¡¨ç¤ºè¿æ¥çš„ç»´åº¦ã€‚</p>
<blockquote>
<p><strong>ç®—æœ¯è¿ç®—</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value</span><br><span class="hljs-comment"># ``tensor.T`` returns the transpose of a tensor è½¬ç½®çŸ©é˜µ</span><br>y1 = tensor @ tensor.T<br>y2 = tensor.matmul(tensor.T)<br><br>y3 = torch.rand_like(y1)<br>torch.matmul(tensor, tensor.T, out=y3)<br><br><br><span class="hljs-comment"># This computes the element-wise product. z1, z2, z3 will have the same value</span><br>z1 = tensor * tensor<br>z2 = tensor.mul(tensor)<br><br>z3 = torch.rand_like(tensor)<br>torch.mul(tensor, tensor, out=z3)<br></code></pre></td></tr></table></figure>

<ol>
<li><strong>çŸ©é˜µä¹˜æ³•ï¼ˆMatrix Multiplicationï¼‰</strong>ï¼š<ul>
<li><code>y1 = tensor @ tensor.T</code>ï¼šè¿™æ˜¯Pythonä¸­ä½¿ç”¨<code>@</code>è¿ç®—ç¬¦è¿›è¡Œ<strong>çŸ©é˜µä¹˜æ³•</strong>çš„ç®€æ´å†™æ³•ï¼Œå®ƒè®¡ç®—äº†<code>tensor</code>ä¸å…¶è½¬ç½®çš„çŸ©é˜µç›¸ä¹˜ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨<code>y1</code>ä¸­ã€‚</li>
<li><code>y2 = tensor.matmul(tensor.T)</code>ï¼šè¿™æ˜¯<code>torch.Tensor</code>ç±»çš„<code>matmul</code>æ–¹æ³•çš„è°ƒç”¨æ–¹å¼ï¼Œå®ç°äº†ä¸<code>@</code>è¿ç®—ç¬¦ç›¸åŒçš„åŠŸèƒ½ï¼Œå°†ä¸¤ä¸ªå¼ é‡ç›¸ä¹˜ã€‚</li>
<li><code>y3 = torch.rand_like(y1)</code>å’Œ<code>torch.matmul(tensor, tensor.T, out=y3)</code>ï¼šè¿™ä¸¤è¡Œä»£ç å°†çŸ©é˜µä¹˜æ³•çš„ç»“æœå­˜å‚¨åœ¨é¢„å…ˆåˆ†é…çš„å¼ é‡<code>y3</code>ä¸­ã€‚</li>
</ul>
</li>
<li><strong>å…ƒç´ çº§ä¹˜æ³•ï¼ˆElement-wise Multiplicationï¼‰</strong>ï¼š<ul>
<li><code>z1 = tensor * tensor</code>ï¼šè¿™æ˜¯Pythonä¸­è¿›è¡Œå…ƒç´ çº§ä¹˜æ³•çš„ç®€æ´å†™æ³•ï¼Œå®ƒå°†<code>tensor</code>ä¸­çš„æ¯ä¸ªå…ƒç´ ä¸å¦ä¸€ä¸ª<code>tensor</code>ä¸­<strong>å¯¹åº”ä½ç½®çš„å…ƒç´ ç›¸ä¹˜</strong>ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨<code>z1</code>ä¸­ã€‚</li>
<li><code>z2 = tensor.mul(tensor)</code>ï¼šè¿™æ˜¯<code>torch.Tensor</code>ç±»çš„<code>mul</code>æ–¹æ³•çš„è°ƒç”¨æ–¹å¼ï¼Œå®ç°äº†ä¸<code>*</code>è¿ç®—ç¬¦ç›¸åŒçš„åŠŸèƒ½ï¼Œè¿›è¡Œå…ƒç´ çº§ä¹˜æ³•ã€‚</li>
<li><code>z3 = torch.rand_like(tensor)</code>å’Œ<code>torch.mul(tensor, tensor, out=z3)</code>ï¼šè¿™ä¸¤è¡Œä»£ç å°†å…ƒç´ çº§ä¹˜æ³•çš„ç»“æœå­˜å‚¨åœ¨é¢„å…ˆåˆ†é…çš„å¼ é‡<code>z3</code>ä¸­ã€‚</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>å•å…ƒç´ å¼ é‡</strong></p>
</blockquote>
<p>å¦‚æœä½ æœ‰ä¸€ä¸ªå•å…ƒç´ å¼ é‡ï¼Œä¾‹å¦‚é€šè¿‡å°†å¼ é‡çš„æ‰€æœ‰å€¼èšåˆä¸ºä¸€ä¸ªå€¼ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ <code>item()</code> å°†å…¶è½¬æ¢ä¸º Python æ•°å€¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">agg = tensor.<span class="hljs-built_in">sum</span>()<br>agg_item = agg.item()<br><span class="hljs-built_in">print</span>(agg_item, <span class="hljs-built_in">type</span>(agg_item))<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">12.0</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;float&#x27;</span>&gt;<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong>aggä¹Ÿæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œä¸ºå•å…ƒç´ å¼ é‡ã€‚</p>
<blockquote>
<p><strong>å°±åœ°æ“ä½œ</strong></p>
</blockquote>
<p>å°†ç»“æœå­˜å‚¨åˆ°æ“ä½œæ•°ä¸­çš„æ“ä½œç§°ä¸ºå°±åœ°æ“ä½œã€‚å®ƒä»¬ç”± <code>_</code> åç¼€è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼š <code>x.copy_(y)</code> ã€ã€ <code>x.t_()</code> å°†æ›´æ”¹ <code>x</code> ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor&#125;</span> \n&quot;</span>)<br>tensor.add_(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br>tensor([[<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>]])<br></code></pre></td></tr></table></figure>

<p>å¸¸è§çš„PyTorchå°±åœ°æ“ä½œï¼š</p>
<ol>
<li>**add_ã€sub_ã€mul_ã€div_**ï¼š<ul>
<li><code>add_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„åŠ æ³•ã€‚</li>
<li><code>sub_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„å‡æ³•ã€‚</li>
<li><code>mul_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„ä¹˜æ³•ã€‚</li>
<li><code>div_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„é™¤æ³•ã€‚</li>
</ul>
</li>
<li><strong>å…¶ä»–æ•°å­¦å‡½æ•°</strong>ï¼š<ul>
<li><code>abs_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„ç»å¯¹å€¼æ“ä½œã€‚</li>
<li><code>neg_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„å–è´Ÿæ“ä½œã€‚</li>
<li><code>pow_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„æŒ‡æ•°æ“ä½œã€‚</li>
<li><code>clamp_()</code>ï¼šå°±åœ°æ‰§è¡Œå¼ é‡çš„æˆªæ–­æ“ä½œã€‚</li>
</ul>
</li>
<li><strong>å½’çº¦æ“ä½œ</strong>ï¼š<ul>
<li><code>sum_()</code>ï¼šå°±åœ°è®¡ç®—å¼ é‡çš„å…ƒç´ ä¹‹å’Œã€‚</li>
<li><code>mean_()</code>ï¼šå°±åœ°è®¡ç®—å¼ é‡çš„å¹³å‡å€¼ã€‚</li>
<li><code>max_()</code>ï¼šå°±åœ°è®¡ç®—å¼ é‡çš„æœ€å¤§å€¼ã€‚</li>
<li><code>min_()</code>ï¼šå°±åœ°è®¡ç®—å¼ é‡çš„æœ€å°å€¼ã€‚</li>
</ul>
</li>
<li><strong>å…¶ä»–æ“ä½œ</strong>ï¼š<ul>
<li><code>fill_()</code>ï¼šç”¨æŒ‡å®šçš„æ ‡é‡å€¼å¡«å……å¼ é‡ã€‚</li>
<li><code>zero_()</code>ï¼šå°†å¼ é‡çš„æ‰€æœ‰å…ƒç´ è®¾ç½®ä¸º0ã€‚</li>
<li><code>fill_diagonal_()</code>ï¼šå°†å¼ é‡çš„å¯¹è§’çº¿å…ƒç´ å¡«å……ä¸ºæŒ‡å®šå€¼ã€‚</li>
</ul>
</li>
</ol>
<p>è¿™äº›å°±åœ°æ“ä½œéƒ½æ˜¯åœ¨å‡½æ•°ååé¢æ·»åŠ ä¸‹åˆ’çº¿<code>_</code>æ¥è¡¨ç¤ºçš„ï¼Œä¾‹å¦‚<code>add_()</code>ã€<code>mul_()</code>ç­‰ã€‚åœ¨ä½¿ç”¨æ—¶éœ€è¦å°å¿ƒï¼Œå› ä¸ºå®ƒä»¬ä¼šç›´æ¥ä¿®æ”¹åŸå§‹çš„å¼ é‡ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸å¯é¢„æµ‹çš„ç»“æœæˆ–éš¾ä»¥è°ƒè¯•çš„é”™è¯¯ã€‚</p>
<h3 id="1-4-ä½¿ç”¨-NumPy-æ¡¥æ¥"><a href="#1-4-ä½¿ç”¨-NumPy-æ¡¥æ¥" class="headerlink" title="1.4 ä½¿ç”¨ NumPy æ¡¥æ¥"></a>1.4 ä½¿ç”¨ NumPy æ¡¥æ¥</h3><p>CPU ä¸Šçš„å¼ é‡å’Œ NumPy æ•°ç»„å¯ä»¥å…±äº«å…¶åº•å±‚å†…å­˜ä½ç½®ï¼Œæ›´æ”¹ä¸€ä¸ªå°†æ›´æ”¹å¦ä¸€ä¸ªã€‚</p>
<blockquote>
<h3 id="Tensor-åˆ°-NumPy-æ•°ç»„"><a href="#Tensor-åˆ°-NumPy-æ•°ç»„" class="headerlink" title="Tensor åˆ° NumPy æ•°ç»„"></a>Tensor åˆ° NumPy æ•°ç»„</h3></blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">t = torch.ones(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br>n = t.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>n: [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br></code></pre></td></tr></table></figure>

<p>å¼ é‡çš„å˜åŒ–åæ˜ åœ¨ NumPy æ•°ç»„ä¸­ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">t.add_(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>])<br>n: [<span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span>]<br></code></pre></td></tr></table></figure>

<blockquote>
<h3 id="NumPy-æ•°ç»„è½¬-Tensor"><a href="#NumPy-æ•°ç»„è½¬-Tensor" class="headerlink" title="NumPy æ•°ç»„è½¬ Tensor"></a>NumPy æ•°ç»„è½¬ Tensor</h3></blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">n = np.ones(<span class="hljs-number">5</span>)<br>t = torch.from_numpy(n)<br></code></pre></td></tr></table></figure>

<p>NumPy æ•°ç»„ä¸­çš„æ›´æ”¹ä¼šåæ˜ åœ¨å¼ é‡ä¸­ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">np.add(n, <span class="hljs-number">1</span>, out=n)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>], dtype=torch.float64)<br>n: [<span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span>]<br></code></pre></td></tr></table></figure>

<h2 id="2-Datasets-DataLoaders-æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨"><a href="#2-Datasets-DataLoaders-æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨" class="headerlink" title="2.Datasets &amp; DataLoaders æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨"></a>2.<strong>Datasets &amp; DataLoaders</strong> æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨</h2><p>ç”¨äºå¤„ç†æ•°æ®æ ·æœ¬çš„ä»£ç å¯èƒ½ä¼šå˜å¾—æ··ä¹±ä¸”éš¾ä»¥ç»´æŠ¤;ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„<strong>æ•°æ®é›†ä»£ç ä¸æ¨¡å‹è®­ç»ƒä»£ç è§£è€¦</strong>ï¼Œä»¥è·å¾—æ›´å¥½çš„å¯è¯»æ€§å’Œæ¨¡å—åŒ–ã€‚PyTorch æä¾›äº†ä¸¤ä¸ªæ•°æ®åŸè¯­ï¼š <code>torch.utils.data.DataLoader</code>å’Œ<code>torch.utils.data.Dataset</code> å…è®¸ä½ ä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®é›†ä»¥åŠä½ è‡ªå·±çš„æ•°æ®ã€‚</p>
<p>Dataset å­˜å‚¨æ ·æœ¬åŠå…¶ç›¸åº”çš„æ ‡ç­¾ï¼Œè€Œ DataLoader åˆ™åœ¨ Dataset å‘¨å›´å°è£…äº†ä¸€ä¸ªå¯è¿­ä»£å™¨ï¼Œä»¥æ–¹ä¾¿è®¿é—®æ ·æœ¬ã€‚</p>
<h3 id="2-1-åŠ è½½æ•°æ®é›†"><a href="#2-1-åŠ è½½æ•°æ®é›†" class="headerlink" title="2.1 åŠ è½½æ•°æ®é›†"></a>2.1 åŠ è½½æ•°æ®é›†</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br>training_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">True</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor()<br>)<br><br>test_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">False</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor()<br>)<br></code></pre></td></tr></table></figure>

<ul>
<li><code>root</code> æ˜¯å­˜å‚¨è®­ç»ƒ&#x2F;æµ‹è¯•æ•°æ®çš„è·¯å¾„ï¼Œ</li>
<li><code>train</code> æŒ‡å®šè®­ç»ƒæˆ–æµ‹è¯•æ•°æ®é›†ï¼Œ</li>
<li><code>download=True</code> å¦‚æœæ•°æ®åœ¨ ä¸Šä¸å¯ç”¨ <code>root</code> ï¼Œåˆ™ä» Internet ä¸‹è½½æ•°æ®ã€‚</li>
<li><code>transform</code> å’Œ <code>target_transform</code> æŒ‡å®šè¦ç´ å’Œæ ‡æ³¨è½¬æ¢</li>
</ul>
<h3 id="2-2-æ•°æ®åŠ è½½å™¨"><a href="#2-2-æ•°æ®åŠ è½½å™¨" class="headerlink" title="2.2 æ•°æ®åŠ è½½å™¨"></a>2.2 æ•°æ®åŠ è½½å™¨</h3><p>æ£€ç´¢ <code>Dataset</code> æ•°æ®é›†çš„ç‰¹å¾ï¼Œå¹¶ä¸€æ¬¡æ ‡è®°ä¸€ä¸ªæ ·æœ¬ã€‚åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›ä»¥â€œå°æ‰¹é‡â€çš„æ–¹å¼ä¼ é€’æ ·æœ¬ï¼Œåœ¨æ¯ä¸ªæ—¶æœŸé‡æ–°æ´—ç‰Œæ•°æ®ä»¥å‡å°‘æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå¹¶ä½¿ç”¨ Python <code>multiprocessing</code> æ¥åŠ å¿«æ•°æ®æ£€ç´¢é€Ÿåº¦ã€‚</p>
<p><code>DataLoader</code> æ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„å¯¹è±¡ï¼Œå®ƒé€šè¿‡ä¸€ä¸ªç®€å•çš„ API ä¸ºæˆ‘ä»¬æŠ½è±¡äº†è¿™ç§å¤æ‚æ€§ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(training_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br>test_dataloader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>æˆ‘ä»¬å·²å°†è¯¥æ•°æ®é›†åŠ è½½åˆ°<code>DataLoader</code>ä¸­ï¼Œå¹¶å¯ä»¥æ ¹æ®éœ€è¦éå†è¯¥æ•°æ®é›†ã€‚ä¸‹é¢çš„æ¯æ¬¡è¿­ä»£éƒ½ä¼šè¿”å›ä¸€æ‰¹ <code>train_features</code> and <code>train_labels</code> ï¼ˆåˆ†åˆ«åŒ…å« <code>batch_size=64</code> ç‰¹å¾å’Œæ ‡ç­¾ï¼‰ã€‚å› ä¸ºæˆ‘ä»¬æŒ‡å®š <code>shuffle=True</code> äº† ï¼Œåœ¨æˆ‘ä»¬éå†æ‰€æœ‰æ‰¹æ¬¡åï¼Œæ•°æ®ä¼šè¢«æ´—ç‰Œã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Display image and label.</span><br>train_features, train_labels = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(train_dataloader))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Feature batch shape: <span class="hljs-subst">&#123;train_features.size()&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Labels batch shape: <span class="hljs-subst">&#123;train_labels.size()&#125;</span>&quot;</span>)<br>img = train_features[<span class="hljs-number">0</span>].squeeze()<br>label = train_labels[<span class="hljs-number">0</span>]<br>plt.imshow(img, cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Label: <span class="hljs-subst">&#123;label&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong>tensor.shapeå’Œtensor.size()è·å–åˆ°çš„å†…å®¹ç›¸åŒï¼Œä½†ä¸€ä¸ªæ˜¯å±æ€§ï¼Œä¸€ä¸ªæ˜¯æ–¹æ³•ã€‚å¯ä»¥æŠŠtensorçœ‹æˆæ˜¯ä¸€ä¸ªç±»ã€‚</p>
<h2 id="3-æ„å»ºç¥ç»ç½‘ç»œ"><a href="#3-æ„å»ºç¥ç»ç½‘ç»œ" class="headerlink" title="3.æ„å»ºç¥ç»ç½‘ç»œ"></a>3.æ„å»ºç¥ç»ç½‘ç»œ</h2><p>ç¥ç»ç½‘ç»œç”±å¯¹æ•°æ®æ‰§è¡Œæ“ä½œçš„å±‚&#x2F;æ¨¡å—ç»„æˆã€‚torch.nn å‘½åç©ºé—´æä¾›äº†æ„å»ºè‡ªå·±çš„ç¥ç»ç½‘ç»œæ‰€éœ€çš„æ‰€æœ‰æ„å»ºå—ã€‚PyTorch ä¸­çš„æ¯ä¸ªæ¨¡å—éƒ½å¯¹ nn.æ¨¡å—ã€‚ç¥ç»ç½‘ç»œæœ¬èº«æ˜¯ç”±å…¶ä»–æ¨¡å—ï¼ˆå±‚ï¼‰ç»„æˆçš„æ¨¡å—ã€‚è¿™ç§åµŒå¥—ç»“æ„å…è®¸è½»æ¾æ„å»ºå’Œç®¡ç†å¤æ‚çš„æ¶æ„ã€‚</p>
<h3 id="3-1-è·å–ç”¨äºè®­ç»ƒçš„è®¾å¤‡"><a href="#3-1-è·å–ç”¨äºè®­ç»ƒçš„è®¾å¤‡" class="headerlink" title="3.1 è·å–ç”¨äºè®­ç»ƒçš„è®¾å¤‡"></a>3.1 è·å–ç”¨äºè®­ç»ƒçš„è®¾å¤‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">device = (<br>    <span class="hljs-string">&quot;cuda&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;mps&quot;</span><br>    <span class="hljs-keyword">if</span> torch.backends.mps.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;device&#125;</span> device&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="3-2-å®šä¹‰ç±»"><a href="#3-2-å®šä¹‰ç±»" class="headerlink" title="3.2 å®šä¹‰ç±»"></a>3.2 å®šä¹‰ç±»</h3><p>æˆ‘ä»¬é€šè¿‡å­ç±»åŒ–æ¥å®šä¹‰æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œ <code>nn.Module</code> ï¼Œå¹¶åœ¨ <code>__init__</code> ä¸­åˆå§‹åŒ–ç¥ç»ç½‘ç»œå±‚ã€‚æ¯ä¸ª <code>nn.Module</code> å­ç±»éƒ½å®ç°å¯¹æ–¹æ³•ä¸­è¾“å…¥æ•°æ®çš„ <code>forward</code> æ“ä½œã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.flatten = nn.Flatten()<br>        self.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.flatten(x)<br>        logits = self.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> logits<br></code></pre></td></tr></table></figure>

<p>æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª <code>NeuralNetwork</code> çš„å®ä¾‹ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ° <code>device</code> ä¸­ï¼Œå¹¶æ‰“å°å…¶ç»“æ„ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = NeuralNetwork().to(device)<br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">NeuralNetwork(<br>  (flatten): Flatten(start_dim=<span class="hljs-number">1</span>, end_dim=-<span class="hljs-number">1</span>)<br>  (linear_relu_stack): Sequential(<br>    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">784</span>, out_features=<span class="hljs-number">512</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">1</span>): ReLU()<br>    (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">3</span>): ReLU()<br>    (<span class="hljs-number">4</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">10</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br>)<br></code></pre></td></tr></table></figure>

<p>ä¸ºäº†ä½¿ç”¨æ¨¡å‹ï¼Œæˆ‘ä»¬å°†è¾“å…¥æ•°æ®ä¼ é€’ç»™å®ƒã€‚è¿™å°†æ‰§è¡Œæ¨¡å‹çš„ <code>forward</code> ï¼Œä»¥åŠä¸€äº›åå°æ“ä½œã€‚ä¸è¦ç›´æ¥è°ƒç”¨<code>model.forward()</code> ï¼</p>
<p><strong>tipsï¼š</strong></p>
<ul>
<li>åœ¨ PyTorch ä¸­ï¼Œå®ç°äº† <code>nn.Module</code> çš„å­ç±»ä¸­çš„ <code>forward</code> æ–¹æ³•æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„çº¦å®šã€‚å½“æ‚¨è°ƒç”¨æ¨¡å‹çš„å®ä¾‹ï¼ˆä¾‹å¦‚ <code>model</code>ï¼‰æ—¶ï¼ŒPyTorch ä¼šè‡ªåŠ¨è°ƒç”¨ <code>forward</code> æ–¹æ³•ï¼Œè€Œä¸éœ€è¦æ˜¾å¼åœ°è°ƒç”¨ <code>model.forward()</code>ã€‚</li>
<li>è¿™æ˜¯å› ä¸º<code>torch.nn.Module</code>ç±»ä¸­å·²ç»å®šä¹‰äº†<code>__call__</code>æ–¹æ³•ï¼Œè€Œè¯¥æ–¹æ³•å†…éƒ¨å®é™…ä¸Šä¼šè°ƒç”¨<code>forward()</code>æ–¹æ³•ã€‚</li>
<li>åœ¨Pythonä¸­ï¼Œ<code>__call__</code>æ˜¯ä¸€ä¸ªç‰¹æ®Šæ–¹æ³•ï¼Œå…è®¸ç±»çš„å®ä¾‹åƒå‡½æ•°ä¸€æ ·è¢«è°ƒç”¨ã€‚</li>
</ul>
<p>ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œæ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨<code>__call__</code>æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Multiplier</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, factor</span>):<br>        self.factor = factor<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.factor * x<br><br><span class="hljs-comment"># åˆ›å»ºä¸€ä¸ªMultiplierå®ä¾‹</span><br>double = Multiplier(<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># ä½¿ç”¨__call__æ–¹æ³•è°ƒç”¨å®ä¾‹ï¼Œå®é™…ä¸Šå°±åƒè°ƒç”¨ä¸€ä¸ªå‡½æ•°ä¸€æ ·</span><br>result = double(<span class="hljs-number">5</span>)  <span class="hljs-comment"># ç›¸å½“äºè°ƒç”¨äº†double.__call__(5)</span><br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># è¾“å‡º 10</span><br></code></pre></td></tr></table></figure>

<p>åœ¨è¾“å…¥ä¸Šè°ƒç”¨æ¨¡å‹å°†è¿”å›ä¸€ä¸ªäºŒç»´å¼ é‡ï¼Œå…¶ä¸­ dim&#x3D;0 å¯¹åº”äºæ¯ä¸ªç±»çš„ 10 ä¸ªåŸå§‹é¢„æµ‹å€¼çš„æ¯ä¸ªè¾“å‡ºï¼Œdim&#x3D;1 å¯¹åº”äºæ¯ä¸ªè¾“å‡ºçš„å•ä¸ªå€¼ã€‚æˆ‘ä»¬é€šè¿‡ä¼ é€’æ¨¡å—çš„ <code>nn.Softmax</code> å®ä¾‹æ¥è·å–é¢„æµ‹æ¦‚ç‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, device=device)<br>logits = model(X)<br>pred_probab = nn.Softmax(dim=<span class="hljs-number">1</span>)(logits)<br>y_pred = pred_probab.argmax(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted class: <span class="hljs-subst">&#123;y_pred&#125;</span>&quot;</span>)[]()<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Predicted <span class="hljs-keyword">class</span>: tensor([<span class="hljs-number">7</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong></p>
<ol>
<li><code>tensor.argmax(1)</code> æ˜¯å¯¹ PyTorch å¼ é‡è¿›è¡Œæ“ä½œï¼Œç”¨äºæ²¿æŒ‡å®šç»´åº¦æ‰¾åˆ°å¼ é‡ä¸­æœ€å¤§å€¼çš„ç´¢å¼•ã€‚å‚æ•°æ˜¯0è¡¨ç¤ºæ²¿ç€åˆ—æ‰¾æœ€å¤§å€¼ï¼Œ1è¡¨ç¤ºæ²¿ç€è¡Œæ‰¾æœ€å¤§å€¼ã€‚</li>
<li><code>nn.Softmax(dim=1)</code> æ˜¯PyTorchç­‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­å¸¸ç”¨çš„å‡½æ•°ã€‚è¯¥å‡½æ•°ç”¨äºæ²¿ç€æŒ‡å®šçš„ç»´åº¦è®¡ç®—å¼ é‡çš„ softmax æ¿€æ´»ã€‚åœ¨è¿™é‡Œï¼Œ<code>dim=1</code> è¡¨ç¤º softmax æ²¿ç€è¾“å…¥å¼ é‡çš„ç¬¬äºŒä¸ªç»´åº¦ï¼ˆä» 0 å¼€å§‹ç´¢å¼•ï¼‰è¿›è¡Œæ“ä½œã€‚</li>
</ol>
<h3 id="3-2-æ¨¡å‹å±‚"><a href="#3-2-æ¨¡å‹å±‚" class="headerlink" title="3.2 æ¨¡å‹å±‚"></a>3.2 æ¨¡å‹å±‚</h3><h4 id="nn-Flatten"><a href="#nn-Flatten" class="headerlink" title="nn.Flatten"></a>nn.Flatten</h4><p><code>nn.Flatten</code> æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªå±‚ï¼ˆLayerï¼‰ï¼Œç”¨äºå°†è¾“å…¥çš„å¤šç»´å¼ é‡ï¼ˆä¾‹å¦‚ï¼Œå…·æœ‰å¤šä¸ªè½´æˆ–ç»´åº¦çš„å¼ é‡ï¼‰è½¬æ¢ä¸ºä¸€ä¸ªå…·æœ‰å•ä¸ªè½´çš„å¼ é‡ï¼ˆé€šå¸¸æ˜¯ä¸€ç»´å¼ é‡ï¼‰ã€‚å…¶ä½œç”¨æ˜¯å°†è¾“å…¥çš„æ•°æ®â€œå±•å¹³â€æˆä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿äºåç»­çš„ç¥ç»ç½‘ç»œå±‚ï¼ˆå¦‚å…¨è¿æ¥å±‚ï¼‰å¤„ç†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br>input_tensor = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(input_tensor)<br><span class="hljs-comment"># å®šä¹‰ä¸€ä¸ª Flatten å±‚</span><br>flatten_layer = nn.Flatten()<br><br><span class="hljs-comment"># ä½¿ç”¨ Flatten å±‚å°†è¾“å…¥å¼ é‡å±•å¹³</span><br>output = flatten_layer(input_tensor)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/1.png" srcset="/img/loading.gif" lazyload></p>
<p>åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå½“å°†å·ç§¯å±‚çš„è¾“å‡ºä¼ é€’ç»™å…¨è¿æ¥å±‚æ—¶ï¼Œéœ€è¦ä½¿ç”¨ <code>nn.Flatten</code> æ¥å°†å·ç§¯å±‚çš„è¾“å‡ºå±•å¹³ä¸ºä¸€ç»´å¼ é‡ï¼Œä»¥ä¾¿äºåç»­çš„å…¨è¿æ¥å±‚å¤„ç†ã€‚</p>
<h4 id="nn-Linear"><a href="#nn-Linear" class="headerlink" title="nn.Linear"></a>nn.Linear</h4><p><code>nn.Linear</code> æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆLinear Layerï¼‰ï¼Œä¹Ÿç§°ä¸ºå…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰æˆ–ä»¿å°„å±‚ï¼ˆAffine Layerï¼‰ã€‚è¿™ä¸ªå±‚<strong>å°†è¾“å…¥å¼ é‡ä¸æƒé‡çŸ©é˜µç›¸ä¹˜ï¼Œç„¶ååŠ ä¸Šåç½®å‘é‡</strong>ï¼ˆå¯é€‰ï¼‰ï¼Œæœ€ååº”ç”¨æ¿€æ´»å‡½æ•°ï¼ˆä¹Ÿå¯é€‰ï¼‰ã€‚</p>
<p>åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œå…¨è¿æ¥å±‚é€šå¸¸ç”¨äºå°†è¾“å…¥æ•°æ®ä¸æƒé‡ç›¸ä¹˜ï¼Œå¹¶åŠ ä¸Šåç½®ï¼Œä»è€Œäº§ç”Ÿæ–°çš„ç‰¹å¾è¡¨ç¤ºï¼Œè¿™äº›ç‰¹å¾è¡¨ç¤ºè¢«ä¼ é€’ç»™ä¸‹ä¸€å±‚ã€‚å…¨è¿æ¥å±‚çš„ä½œç”¨æ˜¯å°†è¾“å…¥æ•°æ®æ˜ å°„åˆ°è¾“å‡ºç©ºé—´ä¸­ã€‚</p>
<p>ä»¥ä¸‹æ˜¯ <code>nn.Linear</code> çš„åŸºæœ¬ç”¨æ³•ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">linear_layer = nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>)<br>output = linear_layer(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/2.png" srcset="/img/loading.gif" lazyload></p>
<p>åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæƒé‡çŸ©é˜µå’Œåç½®å‘é‡æ˜¯å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬ä¼šæ ¹æ®åå‘ä¼ æ’­ç®—æ³•è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚</p>
<p><strong>tipsï¼š</strong></p>
<p>æƒé‡çŸ©é˜µå’Œåç½®å‘é‡æ˜¯éšæœºçš„ã€‚</p>
<p>nn.ReLU</p>
<p>éçº¿æ€§æ¿€æ´»æ˜¯åœ¨æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºä¹‹é—´åˆ›å»ºå¤æ‚æ˜ å°„çš„åŸå› ã€‚å®ƒä»¬åœ¨çº¿æ€§å˜æ¢ååº”ç”¨ä»¥å¼•å…¥éçº¿æ€§ï¼Œå¸®åŠ©ç¥ç»ç½‘ç»œå­¦ä¹ å„ç§ç°è±¡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">output = nn.ReLU()(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/3.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>tipsï¼š</strong></p>
<ul>
<li>ReLUï¼ˆRectified Linear Unitï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œè¢«å¹¿æ³›åº”ç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œä¸­ã€‚ReLUå‡½æ•°å®šä¹‰ä¸ºï¼š<code>f(x)=max(0,x)</code>ï¼Œå³ï¼Œå½“è¾“å…¥ <em>x</em> å¤§äºç­‰äº0æ—¶ï¼ŒReLUå‡½æ•°è¿”å›è¾“å…¥ <em>x</em>ï¼›å½“è¾“å…¥ <em>x</em> å°äº0æ—¶ï¼ŒReLUå‡½æ•°è¿”å›0ã€‚å¦‚ä¸Šå›¾ç»“æœæ‰€ç¤ºã€‚</li>
<li>å¸¸è§çš„éçº¿æ€§æ¿€æ´»å‡½æ•°åŒ…æ‹¬ï¼š</li>
</ul>
<ol>
<li>Sigmoidå‡½æ•°ï¼šå°†è¾“å…¥æ˜ å°„åˆ°0åˆ°1ä¹‹é—´çš„è¿ç»­èŒƒå›´ï¼Œå¸¸ç”¨äºè¾“å‡ºå±‚çš„äºŒåˆ†ç±»é—®é¢˜ã€‚</li>
<li>Tanhå‡½æ•°ï¼šç±»ä¼¼äºSigmoidå‡½æ•°ï¼Œä½†å°†è¾“å…¥æ˜ å°„åˆ°-1åˆ°1ä¹‹é—´çš„è¿ç»­èŒƒå›´ï¼Œä¹Ÿå¸¸ç”¨äºéšè—å±‚ã€‚</li>
<li>ReLUï¼ˆRectified Linear Unitï¼‰å‡½æ•°ï¼šå¯¹äºæ­£æ•°è¾“å…¥ï¼Œè¾“å‡ºç­‰äºè¾“å…¥ï¼›å¯¹äºè´Ÿæ•°è¾“å…¥ï¼Œè¾“å‡ºä¸º0ã€‚ReLUå‡½æ•°åœ¨æ·±åº¦å­¦ä¹ ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå› ä¸ºå®ƒçš„è®¡ç®—ç®€å•ä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥åŠ é€Ÿæ”¶æ•›ã€‚</li>
<li>Leaky ReLUå‡½æ•°ï¼šä¸ReLUç±»ä¼¼ï¼Œä½†å¯¹è´Ÿæ•°è¾“å…¥æœ‰å°çš„çº¿æ€§æ–œç‡ï¼Œå¯ä»¥é¿å…ReLUä¸­çš„â€œæ­»äº¡ç¥ç»å…ƒâ€é—®é¢˜ã€‚</li>
<li>Softmaxå‡½æ•°ï¼šå¸¸ç”¨äºå¤šåˆ†ç±»é—®é¢˜çš„è¾“å‡ºå±‚ï¼Œå°†è¾“å…¥è½¬æ¢æˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä½¿å¾—è¾“å‡ºçš„æ‰€æœ‰å€¼éƒ½åœ¨0åˆ°1ä¹‹é—´ä¸”æ€»å’Œä¸º1ã€‚</li>
</ol>
<h4 id="nn-Sequential"><a href="#nn-Sequential" class="headerlink" title="nn.Sequential"></a>nn.Sequential</h4><p>nn.Sequential æ˜¯æ¨¡å—çš„æœ‰åºå®¹å™¨ã€‚æ•°æ®ä»¥ä¸å®šä¹‰çš„ç›¸åŒçš„é¡ºåºä¼ é€’åˆ°æ‰€æœ‰æ¨¡å—ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">linear_relu_stack = nn.Sequential(<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>),<br>            nn.ReLU(),<br>        )<br>output2 = linear_relu_stack(input_tensor)<br></code></pre></td></tr></table></figure>

<p>æ•ˆæœä¸ä¹‹å‰çš„å®šä¹‰ç›¸åŒã€‚</p>
<h4 id="nn-Softmax"><a href="#nn-Softmax" class="headerlink" title="nn.Softmax"></a>nn.Softmax</h4><p>Softmaxå‡½æ•°æ˜¯ä¸€ç§å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸ç”¨äºå¤šåˆ†ç±»é—®é¢˜çš„è¾“å‡ºå±‚ï¼Œå°†åŸå§‹çš„ç½‘ç»œè¾“å‡ºè½¬æ¢ä¸ºè¡¨ç¤ºæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚Softmaxå‡½æ•°å°†è¾“å…¥å‘é‡ <em>z</em> çš„æ¯ä¸ªå…ƒç´ è½¬æ¢ä¸ºä¸€ä¸ªä»‹äº0å’Œ1ä¹‹é—´çš„å®æ•°ï¼ŒåŒæ—¶ç¡®ä¿æ‰€æœ‰å…ƒç´ çš„æ€»å’Œä¸º1ï¼Œå› æ­¤å¯ä»¥çœ‹ä½œæ˜¯å¯¹è¾“å…¥å‘é‡çš„å½’ä¸€åŒ–ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">output = nn.Softmax(dim=<span class="hljs-number">1</span>)(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/4.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>tipsï¼š</strong></p>
<p>dimä¸º1è¡¨ç¤ºè¡Œçš„å’Œä¸º1ï¼Œdimä¸º0è¡¨ç¤ºåˆ—çš„å’Œä¸º 1ã€‚</p>
<h3 id="3-3-æ¨¡å‹å‚æ•°"><a href="#3-3-æ¨¡å‹å‚æ•°" class="headerlink" title="3.3 æ¨¡å‹å‚æ•°"></a>3.3 æ¨¡å‹å‚æ•°</h3><p>ç¥ç»ç½‘ç»œä¸­çš„è®¸å¤šå±‚éƒ½æ˜¯å‚æ•°åŒ–çš„ï¼Œå³å…·æœ‰ç›¸å…³çš„æƒé‡å’Œåå·®ï¼Œè¿™äº›æƒé‡å’Œåå·®åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾—åˆ°ä¼˜åŒ–ã€‚å­ç±» <code>nn.Module</code> ä¼šè‡ªåŠ¨è·Ÿè¸ªæ¨¡å‹å¯¹è±¡ä¸­å®šä¹‰çš„æ‰€æœ‰å­—æ®µï¼Œå¹¶ä½¿æ‰€æœ‰å‚æ•°éƒ½å¯ä»¥ä½¿ç”¨æ¨¡å‹ <code>parameters()</code> æˆ– <code>named_parameters()</code> æ–¹æ³•è®¿é—®ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>],<br>                      [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>]])  <span class="hljs-comment"># 2ä¸ªæ ·æœ¬ï¼Œ3ä¸ªç‰¹å¾</span><br><br><span class="hljs-comment"># å®šä¹‰æƒé‡çŸ©é˜µå’Œåç½®å‘é‡</span><br>weight = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>],   <span class="hljs-comment"># 2ä¸ªè¾“å‡ºç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾å¯¹åº”3ä¸ªè¾“å…¥ç‰¹å¾</span><br>                       [<span class="hljs-number">0.4</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.6</span>]])<br>bias = torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])  <span class="hljs-comment"># 2ä¸ªè¾“å‡ºç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾éƒ½æœ‰ä¸€ä¸ªåç½®</span><br><br><span class="hljs-comment"># æ‰§è¡Œçº¿æ€§å˜æ¢æ“ä½œ</span><br>output = F.linear(<span class="hljs-built_in">input</span>, weight, bias)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output after linear transformation:&quot;</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure>

<p>ç»“æœï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/5.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>tipsï¼š</strong></p>
<p>åå·®ä¼šåŠ åœ¨<strong>æ¯ä¸€è¡Œ</strong>ä¸Šã€‚</p>
<h2 id="4-torch-autogradè‡ªåŠ¨å¾®åˆ†"><a href="#4-torch-autogradè‡ªåŠ¨å¾®åˆ†" class="headerlink" title="4.torch.autogradè‡ªåŠ¨å¾®åˆ†"></a>4.torch.autogradè‡ªåŠ¨å¾®åˆ†</h2><p>åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæœ€å¸¸ç”¨çš„ç®—æ³•æ˜¯åå‘ä¼ æ’­ã€‚åœ¨è¯¥ç®—æ³•ä¸­ï¼Œå‚æ•°ï¼ˆæ¨¡å‹æƒé‡ï¼‰æ ¹æ®æŸå¤±å‡½æ•°ç›¸å¯¹äºç»™å®šå‚æ•°çš„æ¢¯åº¦è¿›è¡Œè°ƒæ•´ã€‚</p>
<p>ä¸ºäº†è®¡ç®—è¿™äº›æ¢¯åº¦ï¼ŒPyTorch æœ‰ä¸€ä¸ªå†…ç½®çš„å¾®åˆ†å¼•æ“ï¼Œç§°ä¸º <code>torch.autograd</code> ã€‚å®ƒæ”¯æŒè‡ªåŠ¨è®¡ç®—ä»»ä½•è®¡ç®—å›¾çš„æ¢¯åº¦ã€‚</p>
<p>è€ƒè™‘æœ€ç®€å•çš„å•å±‚ç¥ç»ç½‘ç»œï¼Œå…·æœ‰è¾“å…¥ <code>x</code> ã€å‚æ•° <code>w</code> ï¼Œ <code>b</code> å’Œä¸€äº›æŸå¤±å‡½æ•°ã€‚å¯ä»¥åœ¨ PyTorch ä¸­æŒ‰ä»¥ä¸‹æ–¹å¼å®šä¹‰å®ƒï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>y = torch.zeros(<span class="hljs-number">3</span>)  <span class="hljs-comment"># expected output</span><br>w = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.randn(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)<br>z = torch.matmul(x, w)+b<br>loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)<br></code></pre></td></tr></table></figure>

<p>PyTorchä¸­å®ç°è‡ªåŠ¨è®¡ç®—æ¢¯åº¦çš„æœºåˆ¶æ˜¯é€šè¿‡<strong>åŠ¨æ€è®¡ç®—å›¾</strong>å®ç°çš„ã€‚å½“ä½ åœ¨PyTorchä¸­å®šä¹‰å¼ é‡å¹¶è¿›è¡Œæ“ä½œæ—¶ï¼ŒPyTorchä¼šæ„å»ºä¸€ä¸ªè®¡ç®—å›¾ï¼Œè¯¥è®¡ç®—å›¾æè¿°äº†æ•°æ®æµç»è¿‡çš„æ“ä½œï¼Œå¹¶ä¸”çŸ¥é“æ¯ä¸ªæ“ä½œæ¶‰åŠçš„å¼ é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™ä¸ªè®¡ç®—å›¾æ˜¯åŠ¨æ€çš„ï¼Œå› ä¸ºå®ƒåœ¨æ¯æ¬¡æ‰§è¡Œæ—¶éƒ½ä¼šé‡æ–°æ„å»ºã€‚</p>
<p>æ­¤ä»£ç å®šä¹‰ä»¥ä¸‹è®¡ç®—å›¾ï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/6.png" srcset="/img/loading.gif" lazyload></p>
<p>ä¸ºäº†ä¼˜åŒ–ç¥ç»ç½‘ç»œä¸­å‚æ•°çš„æƒé‡ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºå‚æ•°çš„å¯¼æ•°ã€‚ä¸ºäº†è®¡ç®—è¿™äº›å¯¼æ•°ï¼Œæˆ‘ä»¬è°ƒç”¨ <code>loss.backward()</code> ï¼Œç„¶åä» <code>w.grad</code> å’Œ <code>b.grad</code> ä¸­æ£€ç´¢å€¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">loss.backward()<br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br></code></pre></td></tr></table></figure>

<p>ç®€è€Œè¨€ä¹‹ï¼ŒPyTorchå®ç°è‡ªåŠ¨è®¡ç®—æ¢¯åº¦çš„ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li>å®šä¹‰å¼ é‡ï¼Œå¹¶åœ¨éœ€è¦è®¡ç®—æ¢¯åº¦çš„å¼ é‡ä¸Šè®¾ç½®<code>requires_grad=True</code>ã€‚</li>
<li>æ‰§è¡Œè®¡ç®—æ“ä½œï¼ŒPyTorchä¼šè·Ÿè¸ªè¿™äº›æ“ä½œå¹¶æ„å»ºè®¡ç®—å›¾ã€‚</li>
<li>å½“éœ€è¦è®¡ç®—æ¢¯åº¦æ—¶ï¼Œè°ƒç”¨<code>.backward()</code>æ–¹æ³•ã€‚PyTorchä¼šæ ¹æ®è®¡ç®—å›¾è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼Œå¹¶å°†æ¢¯åº¦ç´¯ç§¯åˆ°ç›¸åº”çš„å¼ é‡çš„<code>.grad</code>å±æ€§ä¸­ã€‚</li>
</ol>
<p><strong>tipsï¼š</strong></p>
<p>æˆ‘ä»¬åªèƒ½è·å–è®¡ç®—å›¾çš„å¶èŠ‚ç‚¹çš„å±æ€§ï¼Œè¿™äº›èŠ‚ç‚¹çš„ <code>grad</code> <code>requires_grad</code> å±æ€§è®¾ç½®ä¸º <code>True</code> ã€‚å¯¹äºå›¾ä¸­çš„æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ï¼Œæ¢¯åº¦å°†ä¸å¯ç”¨ã€‚</p>
<h2 id="5-ä¼˜åŒ–æ¨¡å‹å‚æ•°"><a href="#5-ä¼˜åŒ–æ¨¡å‹å‚æ•°" class="headerlink" title="5.ä¼˜åŒ–æ¨¡å‹å‚æ•°"></a>5.ä¼˜åŒ–æ¨¡å‹å‚æ•°</h2><p>ç°åœ¨æˆ‘ä»¬æœ‰äº†æ¨¡å‹å’Œæ•°æ®ï¼Œæ˜¯æ—¶å€™é€šè¿‡ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°æ¥è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹äº†ã€‚è®­ç»ƒæ¨¡å‹æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹;åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæ¨¡å‹å¯¹è¾“å‡ºè¿›è¡ŒçŒœæµ‹ï¼Œè®¡ç®—å…¶çŒœæµ‹ä¸­çš„è¯¯å·®ï¼ˆæŸå¤±ï¼‰ï¼Œæ”¶é›†è¯¯å·®ç›¸å¯¹äºå…¶å‚æ•°çš„å¯¼æ•°ï¼ˆå¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­çœ‹åˆ°çš„ï¼‰ï¼Œ<strong>å¹¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–è¿™äº›å‚æ•°</strong>ã€‚</p>
<h3 id="5-1-è¶…å‚æ•°"><a href="#5-1-è¶…å‚æ•°" class="headerlink" title="5.1 è¶…å‚æ•°"></a>5.1 è¶…å‚æ•°</h3><p>è¶…å‚æ•°æ˜¯å¯è°ƒæ•´çš„å‚æ•°ï¼Œå¯ç”¨äºæ§åˆ¶æ¨¡å‹ä¼˜åŒ–è¿‡ç¨‹ã€‚ä¸åŒçš„è¶…å‚æ•°å€¼ä¼šå½±å“æ¨¡å‹è®­ç»ƒå’Œæ”¶æ•›ç‡</p>
<p>æˆ‘ä»¬å®šä¹‰ä»¥ä¸‹ç”¨äºè®­ç»ƒçš„è¶…å‚æ•°ï¼š</p>
<ul>
<li><strong>Number of Epochs</strong>  - <strong>éå†æ•°æ®é›†çš„æ¬¡æ•°</strong></li>
<li><strong>Batch Size</strong> æ‰¹é‡å¤§å° - åœ¨<strong>æ›´æ–°å‚æ•°ä¹‹å‰</strong>é€šè¿‡ç½‘ç»œä¼ æ’­çš„<strong>æ•°æ®æ ·æœ¬æ•°</strong></li>
<li><strong>Learning Rate</strong> å­¦ä¹ ç‡ - åœ¨æ¯ä¸ªæ‰¹æ¬¡&#x2F;å‘¨æœŸ<strong>æ›´æ–°æ¨¡å‹å‚æ•°çš„ç¨‹åº¦</strong>ã€‚è¾ƒå°çš„å€¼ä¼šå¯¼è‡´å­¦ä¹ é€Ÿåº¦è¾ƒæ…¢ï¼Œè€Œè¾ƒå¤§çš„å€¼å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒæœŸé—´å‡ºç°ä¸å¯é¢„æµ‹çš„è¡Œä¸ºã€‚</li>
</ul>
<h3 id="5-2-ä¼˜åŒ–å¾ªç¯"><a href="#5-2-ä¼˜åŒ–å¾ªç¯" class="headerlink" title="5.2 ä¼˜åŒ–å¾ªç¯"></a>5.2 ä¼˜åŒ–å¾ªç¯</h3><p>ä¸€æ—¦æˆ‘ä»¬è®¾ç½®äº†è¶…å‚æ•°ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ä¼˜åŒ–å¾ªç¯æ¥è®­ç»ƒå’Œä¼˜åŒ–æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¼˜åŒ–å¾ªç¯çš„æ¯æ¬¡è¿­ä»£ç§°ä¸ºä¸€ä¸ªçºªå…ƒã€‚</p>
<p>æ¯ä¸ªçºªå…ƒç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼š</p>
<ul>
<li><strong>The Train Loop</strong> è®­ç»ƒå¾ªç¯ - éå†è®­ç»ƒæ•°æ®é›†å¹¶å°è¯•æ”¶æ•›åˆ°æœ€ä½³å‚æ•°ã€‚</li>
<li>**The Validation&#x2F;Test Loop **éªŒè¯&#x2F;æµ‹è¯•å¾ªç¯ - éå†æµ‹è¯•æ•°æ®é›†ï¼Œä»¥æ£€æŸ¥æ¨¡å‹æ€§èƒ½æ˜¯å¦æ­£åœ¨æé«˜ã€‚</li>
</ul>
<h3 id="5-3-æŸå¤±å‡½æ•°"><a href="#5-3-æŸå¤±å‡½æ•°" class="headerlink" title="5.3 æŸå¤±å‡½æ•°"></a>5.3 æŸå¤±å‡½æ•°</h3><p>å½“å‘ˆç°ä¸€äº›è®­ç»ƒæ•°æ®æ—¶ï¼Œæˆ‘ä»¬æœªç»è®­ç»ƒçš„ç½‘ç»œå¯èƒ½ä¸ä¼šç»™å‡ºæ­£ç¡®çš„ç­”æ¡ˆã€‚æŸå¤±å‡½æ•°è¡¡é‡è·å¾—çš„ç»“æœä¸ç›®æ ‡å€¼çš„å·®å¼‚ç¨‹åº¦ï¼Œå®ƒæ˜¯æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æƒ³è¦æœ€å°åŒ–çš„æŸå¤±å‡½æ•°ã€‚ä¸ºäº†è®¡ç®—æŸå¤±ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»™å®šæ•°æ®æ ·æœ¬çš„è¾“å…¥è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å°†å…¶ä¸çœŸå®æ•°æ®æ ‡ç­¾å€¼è¿›è¡Œæ¯”è¾ƒã€‚</p>
<h3 id="5-4-ä¼˜åŒ–"><a href="#5-4-ä¼˜åŒ–" class="headerlink" title="5.4 ä¼˜åŒ–"></a>5.4 ä¼˜åŒ–</h3><p>ä¼˜åŒ–æ˜¯è°ƒæ•´æ¨¡å‹å‚æ•°ä»¥å‡å°‘æ¯ä¸ªè®­ç»ƒæ­¥éª¤ä¸­çš„æ¨¡å‹è¯¯å·®çš„è¿‡ç¨‹ã€‚ä¼˜åŒ–ç®—æ³•å®šä¹‰äº†æ­¤è¿‡ç¨‹çš„æ‰§è¡Œæ–¹å¼ã€‚æ‰€æœ‰ä¼˜åŒ–é€»è¾‘éƒ½å°è£…åœ¨å¯¹è±¡ä¸­ <code>optimizer</code> ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ SGD ä¼˜åŒ–å™¨;æ­¤å¤–ï¼ŒPyTorch ä¸­è¿˜æœ‰è®¸å¤šä¸åŒçš„ä¼˜åŒ–å™¨ï¼Œä¾‹å¦‚ ADAM å’Œ RMSPropï¼Œå®ƒä»¬æ›´é€‚åˆä¸åŒç±»å‹çš„æ¨¡å‹å’Œæ•°æ®ã€‚</p>
<p>æˆ‘ä»¬é€šè¿‡æ³¨å†Œéœ€è¦è®­ç»ƒçš„æ¨¡å‹å‚æ•°å¹¶ä¼ å…¥å­¦ä¹ ç‡è¶…å‚æ•°æ¥åˆå§‹åŒ–ä¼˜åŒ–å™¨ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)<br></code></pre></td></tr></table></figure>

<p>åœ¨è®­ç»ƒå¾ªç¯ä¸­ï¼Œä¼˜åŒ–åˆ†ä¸‰ä¸ªæ­¥éª¤è¿›è¡Œï¼š</p>
<ul>
<li>è°ƒç”¨ <code>optimizer.zero_grad()</code> ä»¥é‡ç½®æ¨¡å‹å‚æ•°çš„æ¢¯åº¦ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¸å˜ç›¸åŠ ;ä¸ºäº†é˜²æ­¢é‡å¤è®¡ç®—ï¼Œæˆ‘ä»¬åœ¨æ¯æ¬¡è¿­ä»£æ—¶éƒ½æ˜ç¡®åœ°å°†å®ƒä»¬å½’é›¶ã€‚</li>
<li>é€šè¿‡è°ƒç”¨  <code>loss.backward()</code> åå‘ä¼ æ’­é¢„æµ‹æŸå¤±ã€‚PyTorch å°†æŸå¤±çš„æ¢¯åº¦ä¸æ¯ä¸ªå‚æ•°äº¤æ±‡ã€‚</li>
<li>ä¸€æ—¦æˆ‘ä»¬æœ‰äº†æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±ä¼šè°ƒç”¨ <code>optimizer.step()</code> é€šè¿‡å‘åä¼ é€’ä¸­æ”¶é›†çš„æ¢¯åº¦æ¥è°ƒæ•´å‚æ•°ã€‚</li>
</ul>
<p>ä¸¾ä¾‹ï¼š</p>
<p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/7.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="5-5-å…¨é¢å®æ–½"><a href="#5-5-å…¨é¢å®æ–½" class="headerlink" title="5.5   å…¨é¢å®æ–½"></a>5.5   å…¨é¢å®æ–½</h3><p>æˆ‘ä»¬åœ¨ä¼˜åŒ–ä»£ç ä¸Šå®šä¹‰ <code>train_loop</code> å¾ªç¯ï¼Œå¹¶ <code>test_loop</code> æ ¹æ®æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_loop</span>(<span class="hljs-params">dataloader, model, loss_fn, optimizer</span>):<br>    size = <span class="hljs-built_in">len</span>(dataloader.dataset)<br>    <span class="hljs-comment"># Set the model to training mode - important for batch normalization and dropout layers</span><br>    <span class="hljs-comment"># Unnecessary in this situation but added for best practices</span><br>    model.train()<br>    <span class="hljs-keyword">for</span> batch, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        <span class="hljs-comment"># Compute prediction and loss</span><br>        pred = model(X)<br>        loss = loss_fn(pred, y)<br><br>        <span class="hljs-comment"># Backpropagation</span><br>        loss.backward()<br>        optimizer.step()<br>        optimizer.zero_grad()<br><br>        <span class="hljs-keyword">if</span> batch % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            loss, current = loss.item(), batch * batch_size + <span class="hljs-built_in">len</span>(X)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">&#123;loss:&gt;7f&#125;</span>  [<span class="hljs-subst">&#123;current:&gt;5d&#125;</span>/<span class="hljs-subst">&#123;size:&gt;5d&#125;</span>]&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_loop</span>(<span class="hljs-params">dataloader, model, loss_fn</span>):<br>    <span class="hljs-comment"># Set the model to evaluation mode - important for batch normalization and dropout layers</span><br>    <span class="hljs-comment"># Unnecessary in this situation but added for best practices</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    size = <span class="hljs-built_in">len</span>(dataloader.dataset)<br>    num_batches = <span class="hljs-built_in">len</span>(dataloader)<br>    test_loss, correct = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><br>    <span class="hljs-comment"># Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode</span><br>    <span class="hljs-comment"># also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> dataloader:<br>            pred = model(X)<br>            test_loss += loss_fn(pred, y).item()<br>            correct += (pred.argmax(<span class="hljs-number">1</span>) == y).<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">float</span>).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= num_batches<br>    correct /= size<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test Error: \n Accuracy: <span class="hljs-subst">&#123;(<span class="hljs-number">100</span>*correct):&gt;<span class="hljs-number">0.1</span>f&#125;</span>%, Avg loss: <span class="hljs-subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>æˆ‘ä»¬åˆå§‹åŒ–æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ <code>train_loop</code> å’Œ <code>test_loop</code> ã€‚éšæ„å¢åŠ  epoch çš„æ•°é‡ä»¥è·Ÿè¸ªæ¨¡å‹çš„æ”¹è¿›æ€§èƒ½ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_fn = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)<br><br>epochs = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;t+<span class="hljs-number">1</span>&#125;</span>\n-------------------------------&quot;</span>)<br>    train_loop(train_dataloader, model, loss_fn, optimizer)<br>    test_loop(test_dataloader, model, loss_fn)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Done!&quot;</span>)<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong></p>
<p><code>model.train()</code> å’Œ <code>model.eval()</code> æ˜¯ PyTorch ä¸­ç”¨äºæ§åˆ¶æ¨¡å‹æ¨¡å¼çš„ä¸¤ä¸ªæ–¹æ³•ï¼Œå®ƒä»¬çš„ä¸»è¦åŒºåˆ«åœ¨äºæ¨¡å‹å¤„äºä¸åŒçš„è¿è¡Œæ¨¡å¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š</p>
<ol>
<li><code>model.train()</code>: è°ƒç”¨ <code>model.train()</code> å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ã€‚åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ¨¡å‹ä¸­çš„ä¸€äº›ç‰¹å®šå±‚ï¼Œæ¯”å¦‚ dropout å’Œ batch normalizationï¼Œä¼šä»¥ä¸åŒçš„æ–¹å¼å¤„ç†è¾“å…¥æ•°æ®ã€‚ä¾‹å¦‚ï¼Œdropout åœ¨è®­ç»ƒæ—¶ä¼šéšæœºä¸¢å¼ƒéƒ¨åˆ†èŠ‚ç‚¹ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼›è€Œ batch normalization åœ¨è®­ç»ƒæ—¶ä¼šæ ¹æ®å½“å‰ mini-batch çš„ç»Ÿè®¡æ•°æ®æ¥æ ‡å‡†åŒ–è¾“å…¥æ•°æ®ã€‚å› æ­¤ï¼Œåœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œè¿™äº›å±‚ä¼šæ‰§è¡Œç›¸åº”çš„è®­ç»ƒæ“ä½œã€‚</li>
<li><code>model.eval()</code>: è°ƒç”¨ <code>model.eval()</code> å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚åœ¨è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹çš„è¡Œä¸ºä¼šå‘ç”Ÿå˜åŒ–ã€‚ä¾‹å¦‚ï¼Œdropout å±‚ä¸å†éšæœºä¸¢å¼ƒèŠ‚ç‚¹ï¼Œè€Œæ˜¯å°†æ‰€æœ‰èŠ‚ç‚¹ä¿ç•™ï¼Œä»¥ä¾¿è·å–æ›´åŠ ç¨³å®šçš„é¢„æµ‹ç»“æœï¼›batch normalization ä¹Ÿä¼šä½¿ç”¨å›ºå®šçš„ç»Ÿè®¡æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å½“å‰ mini-batch çš„ç»Ÿè®¡æ•°æ®ã€‚è¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹çš„è¡Œä¸ºæ›´æ¥è¿‘äºå®é™…ä½¿ç”¨åœºæ™¯ã€‚</li>
</ol>
<p>æ€»çš„æ¥è¯´ï¼Œ<code>model.train()</code> å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­ï¼›<code>model.eval()</code> å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç”¨äºæµ‹è¯•ã€éªŒè¯æˆ–æ¨æ–­è¿‡ç¨‹ä¸­ï¼Œä»¥è·å¾—æ›´ç¨³å®šå’Œå¯é çš„è¾“å‡ºç»“æœã€‚</p>
<h3 id="5-6-ä¿å­˜å¹¶åŠ è½½æ¨¡å‹"><a href="#5-6-ä¿å­˜å¹¶åŠ è½½æ¨¡å‹" class="headerlink" title="5.6  ä¿å­˜å¹¶åŠ è½½æ¨¡å‹"></a>5.6  ä¿å­˜å¹¶åŠ è½½æ¨¡å‹</h3><p>åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•é€šè¿‡ä¿å­˜ã€åŠ è½½å’Œè¿è¡Œæ¨¡å‹é¢„æµ‹æ¥æŒä¹…åŒ–æ¨¡å‹çŠ¶æ€ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br></code></pre></td></tr></table></figure>

<p><strong>ä¿å­˜å’ŒåŠ è½½æ¨¡å‹æƒé‡</strong></p>
<p>PyTorch æ¨¡å‹å°†å­¦ä¹ åˆ°çš„å‚æ•°å­˜å‚¨åœ¨åä¸º <code>state_dict</code> çš„å†…éƒ¨çŠ¶æ€å­—å…¸ä¸­ã€‚è¿™äº›å¯ä»¥é€šè¿‡ä»¥ä¸‹ <code>torch.save</code> æ–¹æ³•æŒä¹…åŒ–ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = models.vgg16(weights=<span class="hljs-string">&#x27;IMAGENET1K_V1&#x27;</span>)<br>torch.save(model.state_dict(), <span class="hljs-string">&#x27;model_weights.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>è¦åŠ è½½æ¨¡å‹æƒé‡ï¼Œæ‚¨éœ€è¦å…ˆåˆ›å»ºåŒä¸€æ¨¡å‹çš„å®ä¾‹ï¼Œç„¶åä½¿ç”¨ <code>load_state_dict()</code> method åŠ è½½å‚æ•°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model = models.vgg16() <span class="hljs-comment"># we do not specify ``weights``, i.e. create untrained model</span><br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;model_weights.pth&#x27;</span>))<br>model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>

<p><strong>tipsï¼š</strong></p>
<p>è¯·åŠ¡å¿…åœ¨æ¨ç†å‰è°ƒç”¨ <code>model.eval()</code> æ–¹æ³•ï¼Œå°† dropout å’Œ Batch å½’ä¸€åŒ–å±‚è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ã€‚å¦‚æœä¸è¿™æ ·åšï¼Œå°†äº§ç”Ÿä¸ä¸€è‡´çš„æ¨ç†ç»“æœã€‚</p>
<p><strong>Saving and Loading Models with Shapes</strong></p>
<p>åœ¨åŠ è½½æ¨¡å‹æƒé‡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®ä¾‹åŒ–æ¨¡å‹ç±»ï¼Œå› ä¸ºè¯¥ç±»å®šä¹‰äº†ç½‘ç»œçš„ç»“æ„ã€‚æˆ‘ä»¬å¯èƒ½å¸Œæœ›å°†æ­¤ç±»çš„ç»“æ„ä¸æ¨¡å‹ä¸€èµ·ä¿å­˜ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ é€’<code>model</code>ï¼ˆè€Œä¸æ˜¯ <code>model.state_dict()</code> ï¼‰åˆ°ä¿å­˜å‡½æ•°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model, <span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥åƒè¿™æ ·åŠ è½½æ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.load(<span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>


                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI-%CA%A2%E1%B5%95%E1%B4%97%E1%B5%95%CA%A1/" class="category-chain-item">AI Ê¢áµ•á´—áµ•Ê¡</a>
  
  
    <span>></span>
    
  <a href="/categories/AI-%CA%A2%E1%B5%95%E1%B4%97%E1%B5%95%CA%A1/Pytorch/" class="category-chain-item">Pytorch</a>
  
  
    <span>></span>
    
  <a href="/categories/AI-%CA%A2%E1%B5%95%E1%B4%97%E1%B5%95%CA%A1/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="category-chain-item">åŸºç¡€çŸ¥è¯†</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/Pytorch/" class="print-no-link">#Pytorch</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>pytorchåŸºç¡€!ğŸ§</div>
      <div>https://yangchuanzhi20.github.io/2024/01/24/äººå·¥æ™ºèƒ½/Pytorch/åŸºç¡€çŸ¥è¯†/pytorchåŸºç¡€/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>ç™½è‰²å¾ˆå“‡å¡</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2024å¹´1æœˆ24æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/" title="PyCharmä½¿ç”¨æŠ€å·§!ğŸ©">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">PyCharmä½¿ç”¨æŠ€å·§!ğŸ©</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/" title="ieir2024ç½‘ç«™æ­å»º!ğŸ§">
                        <span class="hidden-mobile">ieir2024ç½‘ç«™æ­å»º!ğŸ§</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"uchVjxnRW51J2Mm7CW00jbKk-MdYXbMMI","appKey":"salCKdKKc0oJUGN300BBLXeE","path":"window.location.pathname","placeholder":"Ê• áµ”á´¥áµ” Ê”","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"https://uchvjxnr.api.lncldglobal.com","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div style="font-size: 0.85rem"> <span id="timeDate">è½½å…¥å¤©æ•°...</span> <span id="times">è½½å…¥æ—¶åˆ†ç§’...</span> <script src="/vvd_js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="busuanzi_value_site_pv"></span>
         æ¬¡
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="busuanzi_value_site_uv"></span>
         äºº
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/js/gongde.js"></script>
<script src="/js/move.js"></script>
<script src="/live2d-widget/autoload.js"></script>
<script src="/js/duration.js"></script>



<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/js/backgroundize.js"></script><!-- hexo injector body_end end --></body>
</html>
