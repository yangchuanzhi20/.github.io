<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>latex使用!🦸🏻‍♂️</title>
    <link href="/2024/06/18/%E5%B7%A5%E5%85%B7/latex%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/06/18/%E5%B7%A5%E5%85%B7/latex%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="latex使用"><a href="#latex使用" class="headerlink" title="latex使用"></a>latex使用</h1><h2 id="1-Latex宏包"><a href="#1-Latex宏包" class="headerlink" title="1.Latex宏包"></a>1.Latex宏包</h2><h3 id="1-1-dutchcal"><a href="#1-1-dutchcal" class="headerlink" title="1.1 dutchcal"></a>1.1 dutchcal</h3><p>用于更改数学模式下的教科书字母（calligraphic letters）的外观。默认情况下，LaTeX 提供 <code>\mathcal</code> 命令用于生成教科书字母，但它的风格可能比较简单。<code>dutchcal</code> 包提供了一种替代的风格，通常更加复杂和具有装饰性。</p><p>使用：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\documentclass</span>&#123;article&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;dutchcal&#125;<br><br><span class="hljs-keyword">\begin</span>&#123;document&#125;<br><br>这是一些使用 `dutchcal` 风格的字母：<span class="hljs-built_in">$</span><span class="hljs-keyword">\mathcal</span>&#123;A&#125;<span class="hljs-built_in">$</span>, <span class="hljs-built_in">$</span><span class="hljs-keyword">\mathcal</span>&#123;B&#125;<span class="hljs-built_in">$</span>, <span class="hljs-built_in">$</span><span class="hljs-keyword">\mathcal</span>&#123;C&#125;<span class="hljs-built_in">$</span>。<br><br><span class="hljs-keyword">\end</span>&#123;document&#125;<br></code></pre></td></tr></table></figure><p>使用前：</p><p><img src="/2024/06/18/%E5%B7%A5%E5%85%B7/latex%E4%BD%BF%E7%94%A8/1.png"></p><p>使用后：</p><p><img src="/2024/06/18/%E5%B7%A5%E5%85%B7/latex%E4%BD%BF%E7%94%A8/2.png"></p><h2 id="2-特殊命令"><a href="#2-特殊命令" class="headerlink" title="2.特殊命令"></a>2.特殊命令</h2><h3 id="2-1-hyphenation"><a href="#2-1-hyphenation" class="headerlink" title="2.1 \hyphenation"></a>2.1 \hyphenation</h3><p>在 LaTeX 中，<code>\hyphenation</code> 命令用于指定单词的断字位置。当 LaTeX 需要在单词的某个位置断行时，如果默认的断字规则不符合要求，可以使用这个命令手动指定可断开的词缀。</p><p>例如：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\hyphenation</span>&#123;op-tical net-works semi-conduc-tor&#125;<br></code></pre></td></tr></table></figure><p>这个命令告诉 LaTeX 在排版 <code>optical</code>、<code>networks</code> 和 <code>semiconductor</code> 这些单词时，可以在指定的位置进行断字。这在长单词需要在行尾断开时特别有用，确保断字的地方符合读者的习惯并保持美观。</p><h2 id="3-特殊符号"><a href="#3-特殊符号" class="headerlink" title="3.特殊符号"></a>3.特殊符号</h2><h3 id="3-1-u"><a href="#3-1-u" class="headerlink" title="3.1 \u{  }"></a>3.1 \u{  }</h3><p>在 LaTeX 中，<code>\u&#123;&#125;</code> 命令用于生成具有上方小勾（也称为标记或音标）的字符。这种小勾通常用于标记重音或特定语音特征。在 <code>\u&#123;&#125;</code> 命令中，你可以指定要在其上方添加的字符，并使用其 Unicode 编码点来定义。</p><p>例如，<code>\u&#123;G&#125;</code> 可能用于生成带有 G 字符上方小勾的字符。这种符号在语言学和语音学上有特定的用途，用于指示音素或语音变体。</p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python爬虫！🦸🏻‍♂️</title>
    <link href="/2024/06/14/%E5%B7%A5%E5%85%B7/python%E7%88%AC%E8%99%AB/"/>
    <url>/2024/06/14/%E5%B7%A5%E5%85%B7/python%E7%88%AC%E8%99%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="python爬虫"><a href="#python爬虫" class="headerlink" title="python爬虫"></a>python爬虫</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-keyword">from</span> selenium.webdriver.chrome.options <span class="hljs-keyword">import</span> Options<br><span class="hljs-keyword">from</span> selenium.webdriver.common.by <span class="hljs-keyword">import</span> By<br><span class="hljs-keyword">from</span> selenium.webdriver.support.ui <span class="hljs-keyword">import</span> WebDriverWait<br><span class="hljs-keyword">from</span> selenium.webdriver.support <span class="hljs-keyword">import</span> expected_conditions <span class="hljs-keyword">as</span> EC<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br><span class="hljs-keyword">import</span> json<br><br>chrome_options = Options()<br><span class="hljs-comment"># chrome_options.add_argument(&quot;--headless&quot;)</span><br><br>driver = webdriver.Chrome(options=chrome_options)<br><br>url_conf_cat = <span class="hljs-string">&#x27;https://papers.cool&#x27;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;confs_data.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    datas = json.load(f)<br>    <span class="hljs-keyword">for</span> num, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(datas):<br>        href = data[<span class="hljs-string">&#x27;url&#x27;</span>]<br>        conf_name = data[<span class="hljs-string">&#x27;name&#x27;</span>]<br><br>        <span class="hljs-keyword">if</span> num &gt;= <span class="hljs-number">1</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;num:&#x27;</span>+<span class="hljs-built_in">str</span>(num))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;conf_name:&#x27;</span>+<span class="hljs-built_in">str</span>(conf_name))<br><br>            driver.get(href)<br>            <span class="hljs-comment"># print(href)</span><br><br>            scroll_pause_time = <span class="hljs-number">2</span>  <span class="hljs-comment"># 每次滚动后暂停的时间</span><br>            last_height = driver.execute_script(<span class="hljs-string">&quot;return document.body.scrollHeight&quot;</span>)  <span class="hljs-comment"># 获取当前页面的总高度</span><br><br>            <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>                <span class="hljs-comment"># 执行 JavaScript 将页面滚动到底部</span><br>                driver.execute_script(<span class="hljs-string">&quot;window.scrollTo(0, document.body.scrollHeight);&quot;</span>)<br>                <span class="hljs-comment"># 等待页面加载</span><br>                time.sleep(scroll_pause_time)<br>                <span class="hljs-comment"># 获取当前页面的总高度</span><br>                new_height = driver.execute_script(<span class="hljs-string">&quot;return document.body.scrollHeight&quot;</span>)<br>                <span class="hljs-comment"># 如果滚动条已经到达页面底部，则退出循环</span><br>                <span class="hljs-keyword">if</span> new_height == last_height:<br>                    <span class="hljs-keyword">break</span><br><br>                last_height = new_height<br>                <span class="hljs-comment"># print(new_height)</span><br><br>            page_source = driver.page_source<br>            soup = BeautifulSoup(page_source, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br>            conf_items = soup.find_all(<span class="hljs-string">&#x27;a&#x27;</span>, class_=<span class="hljs-string">&#x27;title-link&#x27;</span>)<br><br>            link_lists = []<br>            name_lists = []<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> conf_items:<br>                url_p_list = url_conf_cat + item.attrs[<span class="hljs-string">&#x27;href&#x27;</span>]<br>                name_lists.append(item.text)<br>                link_lists.append(url_p_list)<br>            <span class="hljs-comment"># print(len(link_lists))</span><br>            <span class="hljs-comment"># print(name_lists)</span><br>            time.sleep(<span class="hljs-number">4</span>)<br><br>            <span class="hljs-keyword">for</span> i, link <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(link_lists):<br>                name = name_lists[i]<br>                <span class="hljs-keyword">try</span>:<br>                    driver.get(link)<br><br>                    time.sleep(<span class="hljs-number">2</span>)<br><br>                    <span class="hljs-comment"># 查找下载按钮并点击</span><br>                    pdf_link = WebDriverWait(driver, <span class="hljs-number">10</span>).until(<br>                        EC.element_to_be_clickable((By.CLASS_NAME, <span class="hljs-string">&quot;title-pdf&quot;</span>))<br>                    )<br>                    pdf_link.click()<br><br>                    <span class="hljs-comment"># 等待页面加载完成</span><br>                    time.sleep(<span class="hljs-number">1</span>)<br><br>                    <span class="hljs-comment"># 获取页面源码</span><br>                    page_source = driver.page_source<br><br>                    <span class="hljs-comment"># 使用BeautifulSoup解析HTML内容</span><br>                    soup = BeautifulSoup(page_source, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><br>                    <span class="hljs-comment"># 查找iframe标签</span><br>                    iframe = soup.find(<span class="hljs-string">&#x27;iframe&#x27;</span>)<br><br>                    <span class="hljs-comment"># 提取iframe中的src链接</span><br>                    iframe_src = iframe[<span class="hljs-string">&#x27;src&#x27;</span>]<br>                    <span class="hljs-comment"># print(&quot;iframe中的src链接:&quot;, iframe_src)</span><br><br>                    pdf_url = <span class="hljs-string">&#x27;https://papers.cool&#x27;</span> + iframe_src<br><br>                    driver.get(pdf_url)<br><br>                    page_source1 = driver.page_source<br><br>                    <span class="hljs-comment"># 使用BeautifulSoup解析HTML内容</span><br>                    soup = BeautifulSoup(page_source, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br><br>                    <span class="hljs-comment"># print(soup.prettify())</span><br><br>                    time.sleep(<span class="hljs-number">2</span>)<br><br>                    save_button = WebDriverWait(driver, <span class="hljs-number">10</span>).until(<br>                        EC.element_to_be_clickable((By.ID, <span class="hljs-string">&quot;download&quot;</span>))<br>                    )<br>                    time.sleep(<span class="hljs-number">12</span>)<br>                    save_button.click()<br><br>                    time.sleep(<span class="hljs-number">3</span>)<br><br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;confs:&#x27;</span> + <span class="hljs-built_in">str</span>(conf_name) + <span class="hljs-string">&#x27;-paper:&#x27;</span> + <span class="hljs-built_in">str</span>(name))<br><br>                <span class="hljs-keyword">except</span>:<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;confs:&#x27;</span> + <span class="hljs-built_in">str</span>(conf_name) + <span class="hljs-string">&#x27;-paper:&#x27;</span> + <span class="hljs-built_in">str</span>(name) + <span class="hljs-string">&#x27;下载失败&#x27;</span>)<br><br>            <span class="hljs-comment"># 等待一段时间，确保页面加载完成</span><br>            time.sleep(<span class="hljs-number">4</span>)<br><br></code></pre></td></tr></table></figure><p>上述部分是爬取论文网站的代码。</p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实用网站大全！🦸🏻‍♂️</title>
    <link href="/2024/06/12/%E5%B7%A5%E5%85%B7/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99%E5%A4%A7%E5%85%A8/"/>
    <url>/2024/06/12/%E5%B7%A5%E5%85%B7/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99%E5%A4%A7%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="实用网站大全"><a href="#实用网站大全" class="headerlink" title="实用网站大全"></a>实用网站大全</h1><p>1.<a href="https://papers.cool/">https://papers.cool/</a> papers.cool 文章阅读网站</p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LSTM介绍！💐</title>
    <link href="/2024/06/05/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/LSTM/"/>
    <url>/2024/06/05/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/LSTM/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于loss和优化器的细节！👕</title>
    <link href="/2024/05/31/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E4%BD%BF%E7%94%A8%E7%BB%86%E8%8A%82/%E5%85%B3%E4%BA%8Eloss%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E7%BB%86%E8%8A%82/"/>
    <url>/2024/05/31/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E4%BD%BF%E7%94%A8%E7%BB%86%E8%8A%82/%E5%85%B3%E4%BA%8Eloss%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<h1 id="loss和优化器的细节"><a href="#loss和优化器的细节" class="headerlink" title="loss和优化器的细节"></a>loss和优化器的细节</h1><h2 id="1-梯度累计过程"><a href="#1-梯度累计过程" class="headerlink" title="1.梯度累计过程"></a>1.梯度累计过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 输入和期望输出</span><br>x = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>w0 = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]<br>y = torch.zeros(<span class="hljs-number">3</span>)  <span class="hljs-comment"># expected output</span><br><br><span class="hljs-comment"># 初始化参数</span><br>w = torch.tensor(w0, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br>b0 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>b = torch.tensor(b0, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 设置优化器和学习率</span><br>optimizer = torch.optim.SGD([w, b], lr=<span class="hljs-number">0.0009</span>)<br><br><span class="hljs-comment"># 训练循环</span><br>num_epochs = <span class="hljs-number">10000</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    optimizer.zero_grad()  <span class="hljs-comment"># 梯度清零</span><br>    z = torch.matmul(x, w) + b<br>    loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)<br>    loss.backward()  <span class="hljs-comment"># 反向传播计算梯度</span><br>    torch.nn.utils.clip_grad_norm_([w, b], max_norm=<span class="hljs-number">1.0</span>)<br>    optimizer.step()  <span class="hljs-comment"># 更新参数</span><br><br>    <span class="hljs-comment"># print(&#x27;internal w:&#x27;, w)</span><br>    <span class="hljs-comment"># print(&#x27;internal b:&#x27;, b)</span><br>    <span class="hljs-comment"># print(&#x27;internal z:&#x27;, z)</span><br>    <span class="hljs-comment"># print(&#x27;internal loss:&#x27;, loss)</span><br><br>    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">500</span> == <span class="hljs-number">0</span>:  <span class="hljs-comment"># 每100个epoch打印一次损失</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch&#125;</span>, Loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(z)<br><br><span class="hljs-comment"># 打印最终结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Final w:&#x27;</span>, w)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Final b:&#x27;</span>, b)<br><br><br><br></code></pre></td></tr></table></figure><ul><li>w，y在上述代码中为自定义张量，在模型中为某一层中随机初始化的张量</li><li>该代码验证了<strong>反向传播算法对参数的影响</strong></li><li>可以优化的参数为带有requires_grad&#x3D;True的变量，且<strong>变量类型为浮点型</strong></li><li>优化器的初始化要设置需要优化的参数，在这里是[w,b]，在实际模型训练过程中改为<strong>model.parameters</strong>()</li><li>学习率对实验结果影响较大，影响学习的速度，<strong>学习率越大，epoch可以越小</strong></li><li>在每一次循环之前要将梯度清零，否则每一次loss.backward都会让梯度累计，<strong>查看梯度使用w.grad</strong></li><li>使用 <code>torch.nn.utils.clip_grad_norm_</code> 对梯度进行裁剪，<strong>防止梯度爆炸</strong>。这里设置最大范数 <code>max_norm</code> 为 <code>1.0</code>，否则，当epoch过多时，z会越来越小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>w0 = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]<br>y = torch.zeros(<span class="hljs-number">3</span>)  <span class="hljs-comment"># expected output</span><br>w = torch.tensor(w0, dtype=torch.float32,requires_grad=<span class="hljs-literal">True</span>)<br>b0 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>b = torch.tensor(b0, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br>z = torch.matmul(x, w) + b<br>loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)<br><br>loss.backward()<br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br><br>x1 = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>z1 = torch.matmul(x1, w) + b<br>loss = torch.nn.functional.binary_cross_entropy_with_logits(z1, y)<br><br>loss.backward()<br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br><br><br><span class="hljs-comment"># 结果</span><br>tensor([[<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>],<br>        [<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>],<br>        [<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>],<br>        [<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>],<br>        [<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>]])<br>tensor([<span class="hljs-number">0.3325</span>, <span class="hljs-number">0.3333</span>, <span class="hljs-number">0.3333</span>])<br>tensor([[<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>],<br>        [<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>],<br>        [<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>],<br>        [<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>],<br>        [<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>]])<br>tensor([<span class="hljs-number">0.6650</span>, <span class="hljs-number">0.6667</span>, <span class="hljs-number">0.6667</span>])<br></code></pre></td></tr></table></figure><p>如上所示，每调用一次loss.backward()，梯度就会累计（直接相加）。</p><p>用随机数种子来保留每次随机初始化的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 设置随机数种子</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 输入和期望输出</span><br>x = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>y = torch.zeros(<span class="hljs-number">3</span>)  <span class="hljs-comment"># expected output</span><br><br><span class="hljs-comment"># 初始化参数 w 和 b 为随机值</span><br>w = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.randn(<span class="hljs-number">3</span>, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 设置优化器和学习率</span><br>optimizer = torch.optim.SGD([w, b], lr=<span class="hljs-number">0.01</span>)  <span class="hljs-comment"># 降低学习率</span><br><br><span class="hljs-comment"># 训练循环</span><br>num_epochs = <span class="hljs-number">1000</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    optimizer.zero_grad()  <span class="hljs-comment"># 梯度清零</span><br>    z = torch.matmul(x, w) + b<br>    loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)<br>    loss.backward()  <span class="hljs-comment"># 反向传播计算梯度</span><br><br>    <span class="hljs-comment"># 梯度裁剪，防止梯度爆炸</span><br>    torch.nn.utils.clip_grad_norm_([w, b], max_norm=<span class="hljs-number">1.0</span>)<br><br>    optimizer.step()  <span class="hljs-comment"># 更新参数</span><br><br>    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:  <span class="hljs-comment"># 每1000个epoch打印一次损失</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch&#125;</span>, Loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;z: <span class="hljs-subst">&#123;z.detach().numpy()&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 打印最终结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Final w:&#x27;</span>, w)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Final b:&#x27;</span>, b)<br></code></pre></td></tr></table></figure><h2 id="2-梯度下降原理"><a href="#2-梯度下降原理" class="headerlink" title="2.梯度下降原理"></a>2.梯度下降原理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">category_tensor, line_tensor</span>):<br>    hidden = rnn.initHidden()<br><br>    rnn.zero_grad()<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(line_tensor.size()[<span class="hljs-number">0</span>]):<br>        output, hidden = rnn(line_tensor[i], hidden)<br>        <span class="hljs-comment"># print(rnn.parameters())</span><br><br>    loss = criterion(output, category_tensor)<br>    loss.backward()<br></code></pre></td></tr></table></figure><p>在上述代码中，output经过多次的rnn，则其计算图为output &#x3D; <code>&#123;[（i1+h1)\*w+b+i2]\*w+b+i3&#125;\*w+b</code></p><p>w,b在计算图中出现多次，则在loss.backward中，根据下列原则</p><p><img src="/2024/05/31/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E4%BD%BF%E7%94%A8%E7%BB%86%E8%8A%82/%E5%85%B3%E4%BA%8Eloss%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E7%BB%86%E8%8A%82/1.png"></p><p>损失函数中包含了output的整个表达式，所以在计算梯度时会应用相应的求导方式。</p><p><strong>结论：</strong></p><p>调用一次RNN和多次调用RNN结果不同。</p><h2 id="3-loss累加反向传播"><a href="#3-loss累加反向传播" class="headerlink" title="3.loss累加反向传播"></a>3.loss累加反向传播</h2><p>在用rnn处理序列任务时，需要累加不同output的loss进行一次反向传播</p><p>单个时间步反向传播和最后一起反向传播的区别主要在于参数更新的时机和计算效率。</p><ol><li><strong>单个时间步反向传播</strong>：<ul><li>在每个时间步都进行反向传播，即每个时间步都计算损失并更新参数。</li><li>优点是可以更快地更新模型参数，因为每个时间步都有梯度信息来更新参数。</li><li>缺点是计算开销较大，因为需要在每个时间步都进行一次前向传播和一次反向传播。</li></ul></li><li><strong>最后一起反向传播</strong>：<ul><li>在整个序列处理完毕后，再进行一次反向传播。</li><li>优点是计算效率高，因为只需要进行一次前向传播和一次反向传播，节省了计算资源。</li><li>缺点是可能会出现梯度消失或爆炸的问题，因为在长序列中梯度信息可能会衰减或者放大。</li></ul></li></ol><p>通常情况下，如果序列长度不是特别长，可以考虑使用单个时间步反向传播；而如果序列长度较长，为了减少计算量，可以考虑最后一起反向传播。此外，还有一些方法，如使用门控循环单元（GRU）或长短期记忆网络（LSTM）等，可以在长序列中更好地处理梯度消失或爆炸的问题。</p><h2 id="4-with-torch-no-grad-的好处"><a href="#4-with-torch-no-grad-的好处" class="headerlink" title="4.with torch.no_grad()的好处"></a>4.with torch.no_grad()的好处</h2><p>在推理阶段，如果不使用 <code>torch.no_grad()</code>，虽然模型的参数不会自动改变，但会产生一些不必要的计算开销和潜在的风险。以下是详细说明：</p><h3 id="无需梯度计算的开销"><a href="#无需梯度计算的开销" class="headerlink" title="无需梯度计算的开销"></a>无需梯度计算的开销</h3><p>在前向传播过程中，PyTorch 会跟踪所有计算以便于后续的反向传播。这会<strong>消耗额外的内存来存储计算图</strong>。如果你在推理阶段不使用 <code>torch.no_grad()</code>，PyTorch 仍然会跟踪这些操作并构建计算图，导致内存使用的增加。</p><h3 id="意外的反向传播风险"><a href="#意外的反向传播风险" class="headerlink" title="意外的反向传播风险"></a>意外的反向传播风险</h3><p>尽管你在推理阶段不打算进行反向传播，但如果你不使用 <code>torch.no_grad()</code>，模型的参数和输入仍然会被记录到计算图中。如果在推理过程中你意外调用了 <code>loss.backward()</code>，这会导致梯度计算和潜在的参数更新（如果你之后调用 <code>optimizer.step()</code>）。</p><h2 id="5-不同优化器以及adam优化器"><a href="#5-不同优化器以及adam优化器" class="headerlink" title="5.不同优化器以及adam优化器"></a>5.不同优化器以及adam优化器</h2><p>不同优化器有不同的优化策略，主要是在更新模型参数时的方式上有所不同。以下是几种常见的优化器及其优化策略：</p><ol><li><strong>梯度下降法（Gradient Descent）</strong>：是最基本的优化算法之一。它根据损失函数对模型参数的梯度方向，以一定的步长更新参数，使损失函数逐渐减小。缺点是可能收敛速度慢，容易陷入局部最优解。</li><li><strong>随机梯度下降法（Stochastic Gradient Descent，SGD）</strong>：与梯度下降类似，但每次更新参数时只使用一个样本的梯度。因为每次只考虑一个样本，收敛速度较快，但可能导致参数更新的方差较大，甚至无法收敛到最优解。</li><li><strong>小批量随机梯度下降法（Mini-batch Stochastic Gradient Descent）</strong>：是SGD的一种改进版本，每次更新参数时使用一个小批量（mini-batch）的样本来计算梯度。它综合了梯度下降的稳定性和SGD的收敛速度。</li><li><strong>动量（Momentum）</strong>：在更新参数时引入了动量项，模拟物体在运动中的惯性，使得更新方向不仅取决于当前的梯度，还取决于历史梯度的加权平均。这样可以加速收敛并减少震荡。</li><li><strong>AdaGrad</strong>：自适应学习率算法，对每个参数应用不同的学习率，学习率随着参数的更新而逐渐减小。对于频繁出现的参数，学习率将减小得更快，对于不频繁出现的参数，学习率将减小得更慢。</li><li><strong>RMSProp</strong>（Root Mean Square Propagation）：与AdaGrad类似，但对学习率的累积进行了指数加权移动平均，以减少学习率的快速降低。</li><li><strong>Adam</strong>（Adaptive Moment Estimation）：结合了动量和自适应学习率的优点，同时使用了动量的指数衰减平均和梯度的指数衰减平方平均来更新参数。通常被认为是最有效的优化算法之一。</li></ol><p>每种优化器都有其适用的场景，通常需要根据具体问题和数据集的特点选择合适的优化器。</p><p><strong>Adam（Adaptive Moment Estimation）</strong>优化器是一种结合了动量（momentum）和自适应学习率（adaptive learning rate）的优化算法。它在更新参数时同时考虑了梯度的一阶矩估计（梯度的平均值）和二阶矩估计（梯度的平方的平均值），并通过偏置校正来纠正估计的偏差。</p><p>具体来说，Adam算法的更新规则如下：</p><ol><li><p>初始化参数 $θ$ 和一阶矩估计 $m$ 和二阶矩估计 $v$，通常初始化为0。</p></li><li><p>在每次迭代中，计算梯度 $g_t$。</p></li><li><p>更新一阶矩估计 $m_t$ 和二阶矩估计 $v_t$：</p><p>mt&#x3D;β1mt−1+(1−β1)gtm_t &#x3D; β_1m_{t-1} + (1-β_1)g_tmt&#x3D;β1mt−1+(1−β1)gt</p><p>vt&#x3D;β2vt−1+(1−β2)gt2v_t &#x3D; β_2v_{t-1} + (1-β_2)g_t^2vt&#x3D;β2vt−1+(1−β2)gt2</p><p>其中，$β_1$ 和 $β_2$ 是用于控制一阶矩估计和二阶矩估计的指数衰减率，通常设定为接近1的值，例如0.9 和 0.999。</p></li><li><p>根据一阶矩估计和二阶矩估计来更新参数：</p><p>θt+1&#x3D;θt−αvt+ϵ⋅mtθ_{t+1} &#x3D; θ_t - \frac{α}{\sqrt{v_t}+\epsilon} \cdot m_tθt+1&#x3D;θt−vt+ϵα⋅mt</p><p>其中，$α$ 是学习率，$\epsilon$ 是为了数值稳定性而添加的小常数，通常设为 $10^{-8}$。</p></li></ol><p>Adam优化器的优点在于能够在不同参数的梯度变化范围很大的情况下自适应地调整学习率，同时结合了动量的优点，能够在训练过程中保持稳定性并且有效地收敛到局部最优解。因此，Adam优化器在深度学习中被广泛使用，并且通常是默认的优化器之一。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch使用细节</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender火焰!🐅</title>
    <link href="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/"/>
    <url>/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="火焰"><a href="#火焰" class="headerlink" title="火焰"></a>火焰</h1><p>新建火焰的形状</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/1.png"></p><p>添加置换修改器，使用云絮类型</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/2.png"></p><p><strong>添加顶点组</strong>，选择顶点，选择物体属性，点击加号添加群组，点击指定，则点击选择的时候可以直接选择顶点组</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/3.png"></p><p><strong>修改权重</strong></p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/4.png"></p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/5.png"></p><p>修改置换修改器，选择顶点组为fire，同时坐标改成物体</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/6.png"></p><p>新建空物体，将置换修改器的物体参数设为空物体，则火焰会跟着空物体的移动而移动</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/7.png"></p><p>做木头，勾选自动光滑或自动平滑着色，alt+D复制关联材质</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/8.png"></p><p>摆出合适的造型（注意旋转的时候会沿着电脑屏幕的面旋转）</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/9.png"></p><p>添加材质（给小火苗添加材质可以在编辑模式下先选中一条边，然后点击<code>L</code>）</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/10.png"></p><p>添加木头材质，ctrl+L关联材质</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/11.png"></p><p>添加圆环，添加粒子系统，关掉重力</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/12.png"></p><p>改变粒子为物体，打开辉光</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/13.png"></p><p>修改渲染，增加布朗运动，缩放，随机性等等，最终效果如下：</p><p><img src="/2024/05/13/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%81%AB%E7%84%B0%E5%BB%BA%E6%A8%A1/14.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender粒子！🥕</title>
    <link href="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/"/>
    <url>/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/</url>
    
    <content type="html"><![CDATA[<h2 id="粒子"><a href="#粒子" class="headerlink" title="粒子"></a>粒子</h2><h2 id="1-发射体粒子"><a href="#1-发射体粒子" class="headerlink" title="1.发射体粒子"></a>1.发射体粒子</h2><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/1.png"></p><p>如上图所示新建，空格键播放</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/2.png"></p><p>将三个物体框选，<code>M</code>快捷键新建&#x2F;移动到集合</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/3.png"></p><p>改变渲染的方式为集合，则发射的例子为集合中的内容</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/4.png"></p><p>源是改变粒子发射的位置，可以从面或者点或者体积（物体内部）发出。</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/5.png"></p><p>速度法向确定距离，物体对齐是在不同方向进行粒子的发射。</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/6.png"></p><p>力场和物理改变粒子的物理属性，如改变重力。</p><h2 id="2-碰撞"><a href="#2-碰撞" class="headerlink" title="2.碰撞"></a>2.碰撞</h2><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/7.png"></p><p>新建物体，增加物理状态，新增碰撞，修改阻尼，即会产生碰撞效果。</p><h2 id="3-力场"><a href="#3-力场" class="headerlink" title="3.力场"></a>3.力场</h2><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/8.png"></p><p>shift+A新建力场—》常力，相当于给整个世界系统添加了力场，粒子会向左移动。</p><h2 id="4-毛发粒子"><a href="#4-毛发粒子" class="headerlink" title="4.毛发粒子"></a>4.毛发粒子</h2><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/9.png"></p><p>生成草的形状，颜色和材质纹理颜色对应</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/10.png"></p><p>勾选高级，旋转改变随机化阶段，可以随机旋转，显示数量改为1</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/11.png"></p><p>打开移动的箭头，毛发粒子的方向和原点的方向有关，在移动仅原点的模式下移动原点。（或者打开渲染—》物体—》物体旋转，直接改变物体的旋转方向来改变粒子的方向）</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/12.png"></p><p>改变毛发的生长方向是在全局&#x2F;局部&#x2F;方向</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/13.png"></p><p>可以使用物体信息+颜色渐变（常值）来控制毛发颜色的随机性。</p><p><img src="/2024/05/11/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%B2%92%E5%AD%90/14.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender简单的UV纹理绘制！🥕</title>
    <link href="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/"/>
    <url>/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="简单的UV纹理绘制"><a href="#简单的UV纹理绘制" class="headerlink" title="简单的UV纹理绘制"></a>简单的UV纹理绘制</h1><p><strong>1.生成材质</strong></p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/1.png"></p><p><strong>2.纹理绘制</strong></p><p>进入纹理绘制</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/2.png"></p><p>调出颜色选项，x切换颜色</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/3.png"></p><p>勾选对称符号可以对称画图，F缩放画笔大小</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/4.png"></p><p>3.展开uv</p><p>选中缝合边，快捷键<code>U</code>打开选项框，点击标记缝合边，再点击<code>U</code>展开</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/5.png"></p><p>点击下图按钮，可以移动uv图的位置</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/6.png"></p><p>调色板添加基础色</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/7.png"></p><p>油漆桶工具画梯度渐变，从上往下一拉</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/8.png"></p><p>按退格键色板的点会回到中间</p><p>选择耳蜗的面进入绘制模式，点击遮罩进行绘制</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/9.png"></p><p>尾巴渐变如上同理</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%AE%80%E5%8D%95%E7%9A%84UV%E7%BA%B9%E7%90%86%E7%BB%98%E5%88%B6/10.png"></p><p>身体由于不规则投射，需要智能展uv，在编辑模式下U–》智能投射后，再用油漆桶工具即可</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender混合材质节点！🥕</title>
    <link href="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%B7%B7%E5%90%88%E6%9D%90%E8%B4%A8%E8%8A%82%E7%82%B9/"/>
    <url>/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%B7%B7%E5%90%88%E6%9D%90%E8%B4%A8%E8%8A%82%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="混合材质节点"><a href="#混合材质节点" class="headerlink" title="混合材质节点"></a>混合材质节点</h1><p><code>ctrl+J</code>打组</p><p>着色器—》混合着色器</p><p>将两个不同效果的BSDF输出连接到混合着色器进行混合，系数可由黑白纹理图确定。</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%B7%B7%E5%90%88%E6%9D%90%E8%B4%A8%E8%8A%82%E7%82%B9/1.png"></p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%B7%B7%E5%90%88%E6%9D%90%E8%B4%A8%E8%8A%82%E7%82%B9/2.png"></p><p>快捷键：</p><p>1.<code>ctrl+shift</code>右键拖拉可以快速增加一个混合BSDF节点</p><p>2.<code>alt+S</code>可以快速交换混合节点的着色器位置</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender凹凸感和置换形变！🥕</title>
    <link href="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/"/>
    <url>/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/</url>
    
    <content type="html"><![CDATA[<h1 id="凹凸感和置换形变"><a href="#凹凸感和置换形变" class="headerlink" title="凹凸感和置换形变"></a>凹凸感和置换形变</h1><h2 id="1-凹凸节点"><a href="#1-凹凸节点" class="headerlink" title="1.凹凸节点"></a>1.凹凸节点</h2><p><strong>矢量—》凹凸</strong></p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/1.png"></p><p>高度：接受0-1的值</p><p>法向：连接BSDF的法向</p><p><strong>tips：</strong></p><p>凹凸感的模拟并不是改变物体本身的形状，即<strong>不发生形变</strong>，而是<strong>改变法线的方向</strong>进行模拟。</p><h2 id="2-置换形变"><a href="#2-置换形变" class="headerlink" title="2.置换形变"></a>2.置换形变</h2><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/2.png"></p><p>如图所示是一张法线贴图，为什么法线贴图是彩色？因为法线是有方向的量，所以计算机就用RGB的三个值代表三维空间的xyz的位置</p><p><strong>举例：</strong>图中的砖块法线大部分垂直于xy平面，所以法向的值为（0，0，1），对应RGB的值带入后就是纯蓝色。</p><p>在<strong>cycles渲染引擎</strong>下，将设置下的置换改成置换与凹凸</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/3.png"></p><p><strong>方法一：置换节点</strong></p><p><strong>矢量—》置换</strong></p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/4.png"></p><p>注意，要将平面进行细分。修改置换节点的缩放参数进行调整。</p><p>快捷键：</p><p>创建新材质，在BSDF下使用快捷键<code>ctrl+shift+T</code>选择四个纹理图，修改材质–》设置—》置换—》置换与凹凸即可。</p><p><strong>方法二：置换修改器+置换纹理</strong></p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/5.png"></p><p>两种方式对比，第二种要明显很多，但更耗资源</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%87%B9%E5%87%B8%E6%84%9F%E5%92%8C%E7%BD%AE%E6%8D%A2%E5%BD%A2%E5%8F%98/6.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender蒙版添加材质！🥕</title>
    <link href="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/"/>
    <url>/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="蒙版添加材质"><a href="#蒙版添加材质" class="headerlink" title="蒙版添加材质"></a>蒙版添加材质</h1><h2 id="1-node-wrangler插件"><a href="#1-node-wrangler插件" class="headerlink" title="1.node wrangler插件"></a>1.node wrangler插件</h2><p>智能加节点。</p><p>选举需要加的节点，按<code>ctrl+T</code>可以自动添加映射和纹理坐标</p><h2 id="2-混合节点"><a href="#2-混合节点" class="headerlink" title="2.混合节点"></a>2.混合节点</h2><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/1.png"></p><p>AB控制混合的颜色，系数控制程度，系数越接近0，颜色越接近A，系数越接近1，颜色越接近B</p><h2 id="3-蒙版"><a href="#3-蒙版" class="headerlink" title="3.蒙版"></a>3.蒙版</h2><p>黑色：0</p><p>白色：1</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/2.png"></p><p>如图所示，当该纹理连接混合的系数时，其中黑色部分的系数为0，即A的颜色，白色部分为1，即B的颜色</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/3.png"></p><p>上面结果的连接节点如下：</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/4.png"></p><p>同理可以将其连接到颜色渐变的系数</p><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/5.png"></p><h2 id="4-多纹理混合"><a href="#4-多纹理混合" class="headerlink" title="4.多纹理混合"></a>4.多纹理混合</h2><p><img src="/2024/05/10/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E8%92%99%E7%89%88%E6%B7%BB%E5%8A%A0%E6%9D%90%E8%B4%A8/6.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender纹理！🥕</title>
    <link href="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/"/>
    <url>/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="blender纹理"><a href="#blender纹理" class="headerlink" title="blender纹理"></a>blender纹理</h1><h2 id="1-基础节点"><a href="#1-基础节点" class="headerlink" title="1.基础节点"></a>1.基础节点</h2><p><img src="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/1.png"></p><p>1.纹理—》图像纹理</p><p>2.矢量—》映射</p><p>3.输入—》纹理坐标</p><h2 id="2-UV"><a href="#2-UV" class="headerlink" title="2.UV"></a>2.UV</h2><p>在编辑模式下打开uv编辑器</p><p><img src="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/2.png"></p><p>可以移动uv编辑器中展开的图形</p><h2 id="3-生成"><a href="#3-生成" class="headerlink" title="3.生成"></a>3.生成</h2><p>基于全局坐标系，由图像纹理节点控制，可改变生成方式。</p><h2 id="4-物体"><a href="#4-物体" class="headerlink" title="4.物体"></a>4.物体</h2><p>基于局部坐标系。移动原点改变映射方式。</p><p><img src="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/3.png"></p><p>可以以其他物体作为原点，使纹理跟随物体移动。</p><h2 id="5-映射"><a href="#5-映射" class="headerlink" title="5.映射"></a>5.映射</h2><p><img src="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/4.png"></p><p>映射类型中点和纹理的区别在于点模式移动的是坐标轴，纹理模式移动的是纹理。</p><h2 id="6-渐变"><a href="#6-渐变" class="headerlink" title="6.渐变"></a>6.渐变</h2><p><img src="/2024/05/09/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%BA%B9%E7%90%86/5.png"></p><p>1.转换器—》颜色渐变</p><p>2.转换器—》分离xyz</p><p>选择分离xyz中的x&#x2F;y&#x2F;z连接到颜色渐变的系数上，会从不同轴向进行渐变。</p><p>可以使用映射中的属性进行调整。</p><p>思路就是：纹理坐标确定将模型放在哪个坐标系中进行渲染，不同的坐标系下由映射控制xyz的轴，分离xyz表示只考虑一个轴向的内容。</p><h2 id="7-关联材质"><a href="#7-关联材质" class="headerlink" title="7.关联材质"></a>7.关联材质</h2><p>先选需要关联的物体 ，再选关联材质的物体，<code>ctrl+L</code>选择关联材质</p><h2 id="8-程序化纹理"><a href="#8-程序化纹理" class="headerlink" title="8.程序化纹理"></a>8.程序化纹理</h2><p>程序化纹理（Procedural Texture）是计算机图形学中一种生成纹理的方法，它不依赖于事先准备好的纹理图像，而是通过算法在运行时动态生成。程序化纹理通常由一些数学函数、随机数生成器和参数控制组成，可以生成各种复杂的纹理效果，如大理石、木材、云彩等。</p><p>程序化纹理的主要优点包括：</p><ol><li><strong>无限分辨率</strong>：程序化纹理可以根据需要生成任意分辨率的纹理，不受原始纹理图像的限制。</li><li><strong>无缝重复</strong>：由于纹理是根据算法生成的，因此可以轻松实现无缝重复，避免了纹理贴图在重复拼接处产生不连续的视觉效果。</li><li><strong>灵活性</strong>：通过调整参数或修改生成算法，可以轻松地获得不同风格、不同形状的纹理效果，具有较高的灵活性和可定制性。</li><li><strong>节省资源</strong>：与使用预先制作的纹理图像相比，程序化纹理不需要存储大量的纹理图像文件，因此可以节省存储空间。</li></ol><p>程序化纹理的应用非常广泛，特别是在计算机图形学、电影特效、游戏开发等领域。通过程序化纹理，可以实现更加逼真和多样化的视觉效果，提高图形图像的真实感和艺术表现力。</p><p>A</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pycharm中gitee的使用!🦸🏻‍♂️</title>
    <link href="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="pycharm中gitee的使用"><a href="#pycharm中gitee的使用" class="headerlink" title="pycharm中gitee的使用"></a>pycharm中gitee的使用</h1><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/1.png"></p><p>首先在文件—》设置—-》插件中安装gitee</p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/2.png"></p><p>然后在版本控制—》gitee下登录gitee账号进行关联</p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/3.png"></p><p>找到gitee仓库下的下载地址</p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/4.png"></p><p>在本地新建一个push文件夹，打开git bash，将下载地址的代码粘贴进去，<strong>粘贴快捷键：</strong><code>shift+ins</code></p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/5.png"></p><p>打开pycharm，该文件将自动进行版本控制并和远程仓库进行关联（右键项目，在git—》管理远程中管理远程仓库）</p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/6.png"></p><p>从pycharm版本控制栏—》远程下选择需要进行推送的分支进行签出</p><p><img src="/2024/05/09/%E5%B7%A5%E5%85%B7/pycharm%E4%B8%ADgitee%E7%9A%84%E4%BD%BF%E7%94%A8/7.png"></p><p>则修改文件后提交并推送就会在gitee对应的项目分支下进行更新</p><p><strong>所以可以在本地的MImicSolver项目中将代码调试完成后复制到push_mimic文件夹下的mimicsolver项目中进行提交并推送到远程的码云仓库。</strong></p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git使用！🦸🏻‍♂️</title>
    <link href="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="git使用"><a href="#git使用" class="headerlink" title="git使用"></a>git使用</h1><h2 id="1-git-gui的使用"><a href="#1-git-gui的使用" class="headerlink" title="1.git gui的使用"></a>1.git gui的使用</h2><p>新建文件夹，在该文件夹中新建test文件，右键选择git gui，第一次使用时会弹出如图所示的选项，选择创建新的库，选择目录为该文件夹<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/1.png"></p><p>创建完成后，在test文件中增加内容，git gui中会有对应的显示，如图所示<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/2.png"></p><p>rescan是重新扫描整个文件夹</p><p>stage changed是将文件的修改状态移到暂存区，准备提交到版本控制系统，当你需要将这些文件当前的状态保存下来时进行该操作</p><p>sign off是增加修改的对象</p><p>commit是将文件提交到本地的版本控制系统</p><p>push是提交到网络</p><p><img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/3.png"></p><p>添加commit message后点击commit即可。</p><p>再次修改test文件的内容，<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/4.png">点击rescan，git gui中会显示修改的前后对比，按照第一次提交的方式提交。</p><p>点击如图所示的选项，可看到提交的版本记录。<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/5.png">分支的命名是你的commit message<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/6.png"></p><p>若想要文件恢复到历史版本，点击如图所示选项<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/7.png">，<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/8.png">选择hard即可恢复</p><h2 id="2-推送方式"><a href="#2-推送方式" class="headerlink" title="2.推送方式"></a>2.推送方式</h2><p>ssh推送和https推送的区别：<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/9.png"></p><ol><li><strong>认证方式</strong>：<ul><li><strong>SSH推送</strong>：使用SSH公钥认证。在SSH推送中，你需要在本地计算机上生成SSH密钥对，并将公钥添加到你的代码托管服务（如GitHub、GitLab、Bitbucket等）的帐户设置中。推送时，你的私钥用于身份验证。</li><li><strong>HTTPS推送</strong>：使用用户名和密码或个人访问令牌（Personal Access Token）进行认证。在HTTPS推送中，你需要在每次推送时提供用户名和密码，或者使用个人访问令牌作为凭证。</li></ul></li><li><strong>安全性</strong>：<ul><li><strong>SSH推送</strong>：SSH推送相对于HTTPS推送来说更加安全，因为它使用了非对称加密技术，私钥储存在本地，不会在网络上传输，因此更难受到中间人攻击。</li><li><strong>HTTPS推送</strong>：HTTPS推送需要在每次推送时输入用户名和密码或个人访问令牌，这可能会增加泄露凭证的风险，尤其是如果在不安全的网络上操作时。</li></ul></li><li><strong>配置要求</strong>：<ul><li><strong>SSH推送</strong>：使用SSH推送需要在本地生成SSH密钥对，并将公钥添加到你的代码托管服务中，这需要一些额外的配置步骤。</li><li><strong>HTTPS推送</strong>：使用HTTPS推送不需要额外的配置，只需在每次推送时提供用户名和密码或个人访问令牌即可。</li></ul></li><li><strong>网络代理</strong>：<ul><li><strong>SSH推送</strong>：SSH通常不受网络代理的限制，因此在某些网络环境中可能更容易使用。</li><li><strong>HTTPS推送</strong>：在某些网络环境中，如企业网络，可能存在对HTTPS协议的限制或审查，这可能会影响到推送操作的顺利进行。</li></ul></li></ol><p><strong>ssh推送设置：</strong></p><p>在下图中的目录中查看是否有rsa文件<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/10.png"></p><p><strong>pub文件的为公钥可以随便给人，非pub的为私钥不能给别人</strong></p><p>如果没有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs git">ssh-keygen -t rsa -C &quot;你的邮箱地址&quot;<br></code></pre></td></tr></table></figure><p><img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/11.png">根据如图所示操作，将pub中的内容复制到公钥中即可。</p><h2 id="3-本地推送"><a href="#3-本地推送" class="headerlink" title="3.本地推送"></a>3.本地推送</h2><p><img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/12.png">如图所示添加远程仓库，<img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/13.png">填写项目名称和远程仓库的location，https和ssh都可以填写，填写完后选择push提交。</p><p><img src="/2024/04/30/%E5%B7%A5%E5%85%B7/git%E4%BD%BF%E7%94%A8/14.png">push的时候选择远程仓库的项目名称，<strong>gitee和github原理一致</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具</tag>
      
      <tag>教程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>transformers库的使用！🐈</title>
    <link href="/2024/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/transformers%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/transformers%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="transformers库的使用"><a href="#transformers库的使用" class="headerlink" title="transformers库的使用"></a>transformers库的使用</h1><h2 id="1、加载预训练模型"><a href="#1、加载预训练模型" class="headerlink" title="1、加载预训练模型"></a><strong>1、加载预训练模型</strong></h2><p>例如，加载一个预训练的BERT模型，并查看一些关键的参数信息，可以使用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel<br><br><span class="hljs-comment"># 加载预训练模型，会自动下载</span><br>model = BertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)<br><span class="hljs-built_in">print</span>(model.config)<br></code></pre></td></tr></table></figure><p>1.<code>from transformers import BertModel</code>：这一行从Transformers库中导入<code>BertModel</code>类。Transformers库是Hugging Face公司开发的一个用于处理自然语言处理（NLP）任务的库。<code>BertModel</code>类是用于表示BERT模型的基本架构的类。</p><p>2.<code>model = BertModel.from_pretrained(&quot;bert-base-uncased&quot;)</code>：这一行加载一个预训练的BERT模型。<code>from_pretrained()</code>方法是一个类方法，它根据给定的预训练模型名称（在这里是”bert-base-uncased”）自动下载并加载相应的模型权重。”bert-base-uncased”是BERT模型的一个变体，它使用小写字母进行训练，具有较小的模型大小和计算复杂度。加载完成后，<code>model</code>变量将包含一个可以用于各种NLP任务的预训练BERT模型。</p><p>3.<code>print(model.config)</code>：这一行打印模型的配置信息。<code>model.config</code>是一个包含模型配置（例如模型架构、隐藏层大小、注意力头数等）的对象。通过打印这些信息，你可以了解模型的详细配置。</p><h2 id="2-Tokenizer的使用"><a href="#2-Tokenizer的使用" class="headerlink" title="2.Tokenizer的使用"></a>2.<strong>Tokenizer的使用</strong></h2><p>在使用预训练模型处理文本之前，我们需要将文本转换为模型可以理解的格式。这就需要使用tokenizer对文本进行分词、编码等操作。transformers库为每种预训练模型提供了相应的tokenizer类，使用方法非常简单。</p><p>例如，使用BERT的tokenizer进行文本编码，可以使用以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)<br>text = <span class="hljs-string">&quot;here is some text to encode&quot;</span><br>encoded_input = tokenizer(text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)<br><span class="hljs-built_in">print</span>(encoded_input)<br></code></pre></td></tr></table></figure><p><code>tokenizer</code> 是用于将文本数据转换为模型可接受的输入格式的工具。在 Hugging Face Transformers 库中，<code>tokenizer</code> 的参数通常有很多，下面是一些常用的参数及其作用：</p><ol><li><strong>text</strong>：要编码的文本数据。</li><li><strong>return_tensors</strong>：指定返回的张量类型，通常为 <code>&#39;pt&#39;</code>（PyTorch）或 <code>&#39;tf&#39;</code>（TensorFlow）。如果不指定，默认返回 Python 列表格式。</li><li><strong>padding</strong>：指定是否对输入序列进行填充，通常为 <code>&#39;max_length&#39;</code>（填充到指定的最大长度）或 <code>&#39;longest&#39;</code>（填充到最长样本的长度）。如果不需要填充，可以设置为 <code>False</code>。</li><li><strong>truncation</strong>：指定是否对输入序列进行截断，通常为 <code>&#39;max_length&#39;</code>（截断到指定的最大长度）或 <code>&#39;only_first&#39;</code>（仅截断第一个序列）等。如果不需要截断，可以设置为 <code>False</code>。</li><li><strong>max_length</strong>：指定输入序列的最大长度，超出该长度的序列将被截断或填充。</li><li><strong>return_attention_mask</strong>：指定是否返回注意力掩码（attention mask），用于标记输入序列中的填充部分。如果为 <code>True</code>，则返回一个二进制张量，表示哪些位置是填充的，哪些是真实的输入。</li><li><strong>return_offsets_mapping</strong>：指定是否返回偏移映射（offsets mapping），用于将编码后的序列映射回原始文本中的字符位置。</li><li><strong>return_token_type_ids</strong>：指定是否返回令牌类型 ID，用于区分不同的句子。通常在处理句子对时使用，比如问答任务或文本对分类任务。</li><li><strong>add_special_tokens</strong>：指定是否添加特殊令牌（如 <code>[CLS]</code>、<code>[SEP]</code>）到输入序列中。</li></ol><p>tips：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenized_input = tokenizer.encode(sentence, add_special_tokens=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>tokenized_input1 = tokenizer(sentence, add_special_tokens=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br><span class="hljs-comment">#分别使用：</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    outputs = model(tokenized_input)<br>    outputs1 = model(**tokenized_input1)<br>   <br><span class="hljs-comment">#结果一致</span><br></code></pre></td></tr></table></figure><h2 id="3-文本分类任务示例"><a href="#3-文本分类任务示例" class="headerlink" title="3.文本分类任务示例"></a>3.<strong>文本分类任务示例</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertForSequenceClassification<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 准备输入文本和对应的标签</span><br>model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, num_labels=<span class="hljs-number">2</span>)<br>input_text = [<span class="hljs-string">&quot;I love this movie!&quot;</span>, <span class="hljs-string">&quot;This movie is terrible.&quot;</span>]<br>labels = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment"># 1表示正面情感，0表示负面情感</span><br><br><span class="hljs-comment"># 使用tokenizer对输入文本进行编码：将文本转换为模型可以理解的向量（input_ids和attention_mask）</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)<br>encoded_inputs = tokenizer(input_text, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br><span class="hljs-comment"># 将编码结果输入到模型中，得到分类结果：</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    outputs = model(**encoded_inputs)<br>    logits = outputs.logits<br>    <span class="hljs-comment"># 对logits进行argmax操作，得到预测的类别</span><br>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-built_in">print</span>(predictions)<br></code></pre></td></tr></table></figure><ol><li><p><code>with torch.no_grad():</code>：这是一个上下文管理器，它在其内部的代码块中禁用梯度计算。这在评估或推理阶段（而非训练阶段）使用模型时非常有用，因为它可以减少内存使用并提高计算速度。</p></li><li><p>对模型的原始输出更感兴趣，而不是将其转换为概率分布。在这种情况下，我们可以直接使用 logits。此外，如果我们只关注模型对每个类别的相对置信度，而不需要概率值，也可以直接使用 logits。（<strong>logits是值的大小，没有进行归一化的概率计算，softmax进行了归一化的概率计算</strong>）</p><p>因此，在使用模型输出时，要根据具体任务和需求来决定是否进行 softmax 处理。如果<strong>需要概率分布</strong>或进行后续的<strong>概率计算</strong>（如交叉熵损失计算），则需要对 logits 进行 softmax 处理；如果只需要模型的原始输出或对置信度进行比较，则可以直接使用 <strong>logits</strong>。</p></li><li><p><strong>outputs.logits &#x3D; outputs[0]</strong></p></li></ol><h2 id="4-对模型进行微调与保存"><a href="#4-对模型进行微调与保存" class="headerlink" title="4.对模型进行微调与保存"></a>4.对模型进行微调与保存</h2>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch模型的保存和加载！🍧</title>
    <link href="/2024/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/"/>
    <url>/2024/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<h1 id="pytorch模型的保存和加载"><a href="#pytorch模型的保存和加载" class="headerlink" title="pytorch模型的保存和加载"></a>pytorch模型的保存和加载</h1><p>torch提供了两种方式进行保存：</p><ol><li><strong>保存整个模型</strong>：保存整个模型的结构（代码）、参数。</li><li><strong>保存模型参数</strong>：仅保存模型的参数，而不保存模型的结构（代码）。</li></ol><p>先看一下第一种保存方式，保存整个模型的结构（代码）、参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存模型</span><br>torch.save(model, <span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>那如何使用呢？特别简单：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加载整个模型</span><br>loaded_model = torch.load(<span class="hljs-string">&#x27;model.pth&#x27;</span>)<br><span class="hljs-comment"># 直接进行推理</span><br>output = loaded_model(input_tensor)<br></code></pre></td></tr></table></figure><p>第二种方式是只保存了保存模型的参数，不保存模型的结构（代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存模型参数</span><br>torch.save(model.state_dict(), <span class="hljs-string">&#x27;model_params.pth&#x27;</span><br></code></pre></td></tr></table></figure><p>那使用呢？和第一种方式有很大的差别！<strong>要先实例化模型，也是说要有模型结构的代码，才能加载参数</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型结构</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleNN, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>)  <span class="hljs-comment"># 输入大小为10，输出大小为20</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)   <span class="hljs-comment"># 输入大小为20，输出大小为1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = torch.relu(self.fc1(x))  <span class="hljs-comment"># 使用ReLU作为激活函数</span><br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 加载模型参数</span><br>model = SimpleNN()  <span class="hljs-comment"># 创建模型实例</span><br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;model_params.pth&#x27;</span>))<br><span class="hljs-comment"># 直接进行推理</span><br>output = model(input_tensor)<br></code></pre></td></tr></table></figure><p>两种保存方式的差别，但是还是要<strong>注意</strong>：第一种方式其实是在保存模型的时候，<a href="https://www.zhihu.com/search?q=%E5%BA%8F%E5%88%97%E5%8C%96&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3230090109%7D">序列化</a>的数据被绑定到了特定的类（代码中的模型类）和确切的目录，本质上是不保存模型结构（代码）本身，而是<strong>保存这个模型结构（代码）的路径</strong>，并且在加载的时候会使用，因此当在其他项目里使用或者重构的时候，这种方式加载模型的时候会出错。所以<strong>一般建议使用第二种方式！</strong></p><p><strong>tips：</strong></p><p>huggingface保存的bin文件和pth文件有什么区别？</p><p>答案是<a href="https://www.zhihu.com/search?q=bin%E6%96%87%E4%BB%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3230090109%7D">bin文件</a>保存的是模型的参数，是上述的torch的第二种方式，想要完整加载模型是需要模型结构（代码）的。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender材质基础!🥕</title>
    <link href="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/"/>
    <url>/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="blender材质基础"><a href="#blender材质基础" class="headerlink" title="blender材质基础"></a>blender材质基础</h1><h2 id="1-添加材质"><a href="#1-添加材质" class="headerlink" title="1.添加材质"></a>1.添加材质</h2><p><img src="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/1.png"></p><p>在<strong>渲染视图</strong>模式下选择材质栏，<strong>添加&#x2F;选择&#x2F;删除</strong>材质（+&#x2F;-符号）</p><p><img src="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/2.png"></p><p>默认情况下未用的材质在关闭窗口后会自动删除，点击盾牌可以将材质赋予给伪用户进行保护。</p><h2 id="2-着色器编辑器"><a href="#2-着色器编辑器" class="headerlink" title="2.着色器编辑器"></a>2.着色器编辑器</h2><p><img src="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/3.png"></p><p>打开着色器编辑器可以发现每一个材质背后都有节点。（n隐藏&#x2F;显示工具栏）</p><p><img src="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/4.png"></p><p>着色器右上角的菜单和材质栏菜单一一对应。</p><p><img src="/2024/04/27/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9D%90%E8%B4%A8%E5%9F%BA%E7%A1%80/5.png"></p><p>将场景世界的勾选去掉可以让让预览更清晰（假光）。</p><h2 id="3-BSDF"><a href="#3-BSDF" class="headerlink" title="3.BSDF"></a>3.BSDF</h2><p>1.金属度：一般要么0，要么1，不会给中间值。</p><p>2.糙度：改变粗糙程度。</p><p>3.自发光：在渲染栏改渲染引擎为cycles效果明显</p><h2 id="4-多材质"><a href="#4-多材质" class="headerlink" title="4.多材质"></a>4.多材质</h2><p>点击加号添加材质，编辑模式下选择面，选择材质，点击指定即可。</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender小狐狸！🐅</title>
    <link href="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/"/>
    <url>/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/</url>
    
    <content type="html"><![CDATA[<h1 id="blender小狐狸"><a href="#blender小狐狸" class="headerlink" title="blender小狐狸"></a>blender小狐狸</h1><p>导入正侧视图，选择图片深度为前，降低不透明度,防止误选，禁用选中项</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/1.png"></p><p>添加表面细分后调整正侧视图的位置，正视图调整好后正面的z轴就不动了，可以调整后视图的z轴，缩放时一定要选择方向，不然容易出错</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/2.png"></p><p>删除左侧顶点，添加镜像修改器，勾选范围限制（clipping），则右边选中的点不会移动到左侧</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/3.png"></p><p>按<strong>两次G（沿存在的路径移动）</strong>移动部分顶点，挤出耳朵，再挤出耳蜗</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/4.png"></p><p>身子鼻子和上述情况类似</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/5.png"></p><p>做眼睛的时候保证原点在几何中心，同时选择镜像物体为狐狸的头</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/6.png"></p><p>生成路径曲线，几何中心倒角，alt+S缩放，产生一个狐狸尾巴</p><p><img src="/2024/04/26/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E5%B0%8F%E7%8B%90%E7%8B%B8/7.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender平面建模细节！🦫</title>
    <link href="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/"/>
    <url>/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<h1 id="blender平面建模细节"><a href="#blender平面建模细节" class="headerlink" title="blender平面建模细节"></a>blender平面建模细节</h1><p>新建一个平面，添加表面细分修改器，先包裹大部分的面积，剩下的用挤出去铺平</p><h2 id="1-对于凸曲线"><a href="#1-对于凸曲线" class="headerlink" title="1.对于凸曲线"></a>1.对于凸曲线</h2><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/1.png"></p><p>尽量使挤出的四边形的边和原图形的曲线相切，且相切超出来的部分不要太多</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/2.png"></p><p>飙分细分后的图形会在点与点之间丝滑的拟合</p><h2 id="2-对于凹凸连接处"><a href="#2-对于凹凸连接处" class="headerlink" title="2.对于凹凸连接处"></a>2.对于凹凸连接处</h2><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/3.png"></p><p>点的分布上也要有一个凹凸的分布过程</p><h2 id="3-对于凸凸连接处或凹凹连接处"><a href="#3-对于凸凸连接处或凹凹连接处" class="headerlink" title="3.对于凸凸连接处或凹凹连接处"></a>3.对于凸凸连接处或凹凹连接处</h2><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E5%B9%B3%E9%9D%A2%E5%BB%BA%E6%A8%A1%E7%BB%86%E8%8A%82/4.png"></p><p>让分布的点接近，但必须有点在这里</p><p><strong>重点是：三个点拟合曲线！！！</strong></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender建模心得</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender曲线填充！🦫</title>
    <link href="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/"/>
    <url>/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/</url>
    
    <content type="html"><![CDATA[<h1 id="blender曲线填充"><a href="#blender曲线填充" class="headerlink" title="blender曲线填充"></a>blender曲线填充</h1><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/1.png"></p><p>先用贝塞尔曲线的矢量模式（V）勾勒一个曲线</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/2.png"></p><p>然后在几何节点编辑器中新建几何节点</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/3.png"></p><p>在添加，曲线，操作中选择填充曲线</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/4.png"></p><p>将填充曲线的节点连接，得到填充后的曲线</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/5.png"></p><p>将填充后的物体右键转换到网格</p><p><img src="/2024/04/23/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%BB%BA%E6%A8%A1%E5%BF%83%E5%BE%97/blender%E6%9B%B2%E7%BA%BF%E5%A1%AB%E5%85%85/6.png"></p><p>实体化并应用布尔修改器，可以生成如上的图形</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender建模心得</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender藤曼！🐅</title>
    <link href="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/%E8%97%A4%E6%9B%BC/"/>
    <url>/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/%E8%97%A4%E6%9B%BC/</url>
    
    <content type="html"><![CDATA[<h1 id="blender藤曼"><a href="#blender藤曼" class="headerlink" title="blender藤曼"></a>blender藤曼</h1><p>alt+D复制多片叶子，再shift+D复制到另一侧并给杆增加细分</p><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/%E8%97%A4%E6%9B%BC/1.png"></p><p><strong>tips：</strong></p><p>alt+D的复制：改变原始物体的状态，后续复制物体的状态同时改变</p><p>创建一条NUBURS路径，改变位置，给杆增加曲线修改器</p><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/%E8%97%A4%E6%9B%BC/2.png"></p><p>创建叶子和杆的父级关系，选则顶点（基于三点）</p><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/%E8%97%A4%E6%9B%BC/3.png"></p><p><strong>tips:</strong></p><p>建立父级时：</p><p>单纯的<strong>顶点</strong>，叶子不会改变方向。</p><p>单纯的<strong>物体</strong>，叶子不会改变。</p><p><strong>alt+P清空父级</strong>。</p><p>移动杆的轴，叶子和杆会跟着曲线走。</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender曲线建模！🥕</title>
    <link href="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9B%B2%E7%BA%BF%E5%BB%BA%E6%A8%A1/"/>
    <url>/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9B%B2%E7%BA%BF%E5%BB%BA%E6%A8%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="blender曲线建模"><a href="#blender曲线建模" class="headerlink" title="blender曲线建模"></a>blender曲线建模</h1><h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1.基础知识"></a>1.基础知识</h2><h3 id="1-1-贝塞尔曲线"><a href="#1-1-贝塞尔曲线" class="headerlink" title="1.1 贝塞尔曲线"></a>1.1 贝塞尔曲线</h3><p>shift+A新建，tab进入编辑模式</p><p><strong>矢量控制：</strong></p><p>V选择矢量，可以控制控制柄的一半</p><p><strong>生成</strong>：</p><p>选择一个点，E挤出生成新的点</p><p><strong>合并：</strong></p><p>选择两端的点，F合并（或者选择曲线任何一点，alt+C闭合）</p><p><strong>删除：</strong></p><p>选择要删除的段的两个端点，X选择删除段数</p><h3 id="1-2-圆环"><a href="#1-2-圆环" class="headerlink" title="1.2 圆环"></a>1.2 圆环</h3><p>封闭的贝塞尔曲线</p><h3 id="1-3-路径曲线"><a href="#1-3-路径曲线" class="headerlink" title="1.3 路径曲线"></a>1.3 路径曲线</h3><p>根据控制点拟合曲线哎u你，可以控制点的权重。</p><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9B%B2%E7%BA%BF%E5%BB%BA%E6%A8%A1/3.png"></p><p>打开法线方向。</p><p><strong>tips：</strong></p><p>无法旋转时，修改变换轴心点为<strong>质心</strong></p><h3 id="1-4-NURBS曲线"><a href="#1-4-NURBS曲线" class="headerlink" title="1.4 NURBS曲线"></a>1.4 NURBS曲线</h3><p><strong>生成：</strong></p><p>E</p><p><strong>合并：</strong><br>两端+F或alt+C（同上 ）</p><h3 id="1-4-NURBS圆环"><a href="#1-4-NURBS圆环" class="headerlink" title="1.4 NURBS圆环"></a>1.4 NURBS圆环</h3><p>封闭的NURBS曲线</p><h2 id="2-使用"><a href="#2-使用" class="headerlink" title="2.使用"></a>2.使用</h2><h3 id="2-1-贝塞尔曲线"><a href="#2-1-贝塞尔曲线" class="headerlink" title="2.1 贝塞尔曲线"></a>2.1 贝塞尔曲线</h3><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9B%B2%E7%BA%BF%E5%BB%BA%E6%A8%A1/1.png"></p><p>在几何数据栏下的倒角中：</p><p><strong>圆：</strong></p><p>修改深度和分辨率形成管道，勾选封盖会闭合管道，只会是圆形</p><p><strong>物体：</strong></p><p>新建一个曲线，修改形状，吸管选中该形状，则生成的曲线保留该形状</p><p>alt+S缩放管道某一点的粗细</p><p><img src="/2024/04/20/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E6%9B%B2%E7%BA%BF%E5%BB%BA%E6%A8%A1/2.png"></p><h3 id="2-2-NURBS曲线"><a href="#2-2-NURBS曲线" class="headerlink" title="2.2 NURBS曲线"></a>2.2 NURBS曲线</h3><p>同上</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender棕榈树！🐅</title>
    <link href="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/"/>
    <url>/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/</url>
    
    <content type="html"><![CDATA[<h1 id="blender棕榈树"><a href="#blender棕榈树" class="headerlink" title="blender棕榈树"></a>blender棕榈树</h1><h2 id="1-第一种棕榈树"><a href="#1-第一种棕榈树" class="headerlink" title="1.第一种棕榈树"></a>1.第一种棕榈树</h2><p>先建一个叶子，用ctrl+R&#x2F;ctrl+B多切几刀，添加表面细分和实体化修改器</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/1.png"></p><p>添加阵列修改器，沿z轴使用</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/2.png"></p><p>添加镜像修改器，并增加树干</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/3.png"></p><p>使用晶格修改器改变树叶的形状，ctrl+J让叶子和树干结合成一个物体，添加简易型变修改器</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/4.png"></p><h2 id="2-第二种棕榈树"><a href="#2-第二种棕榈树" class="headerlink" title="2.第二种棕榈树"></a>2.第二种棕榈树</h2><p>用上述方式生成第二种叶子</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/5.png"></p><p>添加阵列修改器，选择物体偏移，创建空对象，物体偏移下的物体则选中该空对象，移动空对象并旋转角度获得树叶的形状</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/6.png"></p><p>打开衰减模式，选择叶子的尖端部分按住G调整衰减的范围，移动尖端使叶子呈现下垂的形状</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/7.png"></p><p>不断调整空物体的位置，旋转角度，缩放，产生一个合适的形状</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/8.png"></p><p>设置空立方体将物体包裹，先选择树（ctrl+点击选择进行多选），再shift选择空物体，ctrl+P设置父级</p><p><img src="/2024/04/19/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A3%95%E6%A6%88%E6%A0%91/9.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender龟背竹！🐅</title>
    <link href="/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/"/>
    <url>/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="blender龟背竹"><a href="#blender龟背竹" class="headerlink" title="blender龟背竹"></a>blender龟背竹</h1><p>shift+A载入参考图，在右边图像栏调整透明度</p><p><img src="/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/1.png"></p><p>不断地选择边挤出调整点，下面的豁口先用<code>K</code>切一刀然后空格退出，选择分离的点按<code>v</code>分离。选择两个点<code>M</code>合并。</p><p><img src="/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/2.png"></p><p>应用实体化修改器，选择末端的面挤出合并做杆</p><p><img src="/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/3.png"></p><p>ctrl+A应用全部变换（条目），添加简易形变修改器，可以添加三个不同的方向（注意顺序）</p><p><img src="/2024/04/17/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E9%BE%9F%E8%83%8C%E7%AB%B9/4.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender树干！🐅</title>
    <link href="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/"/>
    <url>/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/</url>
    
    <content type="html"><![CDATA[<h1 id="blender树干"><a href="#blender树干" class="headerlink" title="blender树干"></a>blender树干</h1><p><code>R+X+90</code>绕x轴旋转90度</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/1.png"></p><p><code>I+ctrl+E</code>桥接循环边</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/2.png"></p><p><code>ctrl+B</code>倒角（也可以<code>ctrl+R</code>环切）</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/3.png"></p><p>选择苔藓网格，shift+D+右键复制并撤销移动+实体化+网格细分修改器+缩裹修改器</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E5%B9%B2/4.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender实用操作！🥕</title>
    <link href="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="blender实用操作"><a href="#blender实用操作" class="headerlink" title="blender实用操作"></a>blender实用操作</h1><h2 id="1-吸附"><a href="#1-吸附" class="headerlink" title="1.吸附"></a>1.吸附</h2><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/1.png"></p><p>使用前一定要将每个物体的原点设置在几何中心。</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/2.png"></p><h2 id="2-衰减（O）"><a href="#2-衰减（O）" class="headerlink" title="2.衰减（O）"></a>2.衰减（O）</h2><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/3.png">使用时按住移动建后滑动滚轮缩放缩减范围。</p><h2 id="3-旋绕"><a href="#3-旋绕" class="headerlink" title="3.旋绕"></a>3.旋绕</h2><p>选择步数（生成的个数）+旋绕的轴+旋绕的中心点的位置</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/4.png"></p><p>直接点击加号会自动生成，勾选使用副本会保留原始的形状</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/5.png"></p><h2 id="4-晶格"><a href="#4-晶格" class="headerlink" title="4.晶格"></a>4.晶格</h2><p><code>shift+A</code>生成晶格，在五一模式下编辑晶格的范围。</p><p>选中使用晶格的物体，再选中晶格，按住<code>ctrl+P</code>选择晶格形变，或者在需要使用的晶格物体中添加晶格修改器，再选择晶格即可应用。</p><p>在编辑模式编辑晶格，即可操作物体。</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/6.png"></p><h2 id="5-空物体"><a href="#5-空物体" class="headerlink" title="5.空物体"></a>5.空物体</h2><p><code>shift+A</code>新建空物体</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C/7.png"></p><p>用来做阵列修改器的物体偏移模式下的物体。</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender花朵！🐅</title>
    <link href="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/"/>
    <url>/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="blender花朵"><a href="#blender花朵" class="headerlink" title="blender花朵"></a>blender花朵</h1><p>新建平面+表面细分+<code>ctrl+R</code>+缩放+环绕</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/1.png"></p><p><code>O+G</code>衰减缩放中心一圈点+实体化修改器</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/2.png"></p><p>在物体模式下选择花朵右键设置原点到几何中心+<code>alt+G</code>移动到世界中心</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/3.png"></p><p>新建一个花蕊，不断挤出缩放来做出圆滚滚的效果（不要先切很多刀再调，先调一个再挤出缩放来调）</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%8A%B1%E6%9C%B5/4.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender树桩!🐅</title>
    <link href="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/"/>
    <url>/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/</url>
    
    <content type="html"><![CDATA[<h1 id="blender树桩"><a href="#blender树桩" class="headerlink" title="blender树桩"></a>blender树桩</h1><p><code>ctrl+R</code>循环切割+<code>S+Z</code>拉长底座</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/1.png"></p><p><code>I</code>向内挤出+<code>G+Z</code>向下</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/2.png"></p><p>选择四个面+<code>I+Loop+E+S/R</code></p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/3.png"></p><p><code>E+O</code>（衰减,按<code>G</code>后可以滑动滚轮缩放缩减的范围)</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/4.png"></p><p>S+Z+0拉平树桩底部</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/5.png"></p><p>选择一部分树桩+<code>Shift+D+右键撤销移动+P</code>复制并分离选中项+实体化修改器</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/6.png"></p><p>选择随机改变物体的颜色让观察更仔细，点击苔藓的点G+Z下拉</p><p><img src="/2024/04/16/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E6%A0%91%E6%A1%A9/7.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender蘑菇！🐅</title>
    <link href="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/"/>
    <url>/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/</url>
    
    <content type="html"><![CDATA[<h1 id="blender蘑菇"><a href="#blender蘑菇" class="headerlink" title="blender蘑菇"></a>blender蘑菇</h1><h2 id="1-蘑菇头"><a href="#1-蘑菇头" class="headerlink" title="1.蘑菇头"></a>1.蘑菇头</h2><p>表面细分+<code>alt+Z</code>透视+正视图+<code>S</code>缩放+<code>ctrl+R</code>循环切割</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/1.png"></p><p><code>ctrl+I</code>向内挤出+<code>S</code>缩放+向内挤出（千万别按到<code>O</code>,<code>O</code>是衰减编辑，如果按到了再按一次<code>O</code>)</p><p>+<code>G+Z</code>拉到内部</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/2.png"></p><p>通过ctrl+R不断调整缩放+改名+平滑着色</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/3.png"></p><h2 id="2-蘑菇杆"><a href="#2-蘑菇杆" class="headerlink" title="2.蘑菇杆"></a>2.蘑菇杆</h2><p><code>ctrl+2</code>添加表面细分为2的修改器+<code>ctrl+R</code>循环切割+<code>S</code>调整</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/4.png"></p><p>选择底面+<code>ctrl+I</code>向内挤出+<code>S</code>缩放+<code>G+Z</code>向外拉出产生突起感+改名+<code>ctrl+S</code>保存（<strong>要习惯性保存</strong>）</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/5.png"></p><p>添加简易形变修改器+<strong>移动原点到蘑菇杆底部（选项—》仅影响原点）</strong>+调整修改器</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/6.png"></p><p>点击蘑菇头和蘑菇杆<strong>分别<code>ctrl+a</code>应用缩放</strong>（尽量在<strong>编辑模式下使用缩放！！！！！</strong>）应用后右上角缩放会设置默认大小，不应用则在导入其他设备时会导致缩放效果不一致。</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/7.png"></p><p>新建集合+导入蘑菇头蘑菇杆+<code>按住蘑菇杆+shift</code>移动到蘑菇头上<strong>创建父子集的关系</strong>（或者先点击蘑菇杆（子）然后按住<code>shift</code>点击蘑菇头（父），再<code>ctrl+P</code>设置父子集关系）</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/8.png"></p><h2 id="3-蘑菇点"><a href="#3-蘑菇点" class="headerlink" title="3.蘑菇点"></a>3.蘑菇点</h2><p>缩放+倒角</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/9.png"></p><p>吸附</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/10.png"></p><p>吸附之前一定要把所有的物体的原点设置到几何中心，才能有想要的吸附效果</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/11.png"></p><p>最终效果：</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E8%98%91%E8%8F%87/12.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blender修改器！🥕</title>
    <link href="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/"/>
    <url>/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="修改器"><a href="#修改器" class="headerlink" title="修改器"></a>修改器</h1><p>修改器的目的是使模型的改变可控。</p><p>修改器使用完成后需要在<strong>物体模式</strong>的<strong>修改器栏从上到下</strong>进行应用。</p><p>应用快捷键：</p><p><code>ctrl+A</code></p><h2 id="1-插件安装及使用"><a href="#1-插件安装及使用" class="headerlink" title="1.插件安装及使用"></a>1.插件安装及使用</h2><p>编辑—-》偏好设置—-》插件—–》勾选</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/1.png"></p><p>按住<code>n</code>键，弹出选择栏，选择编辑，调出插件</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/2.png"></p><p><strong>tips:</strong></p><p>在<strong>编辑模式</strong>的<strong>边面板</strong>进行细分，在<strong>物体模式</strong>下进行平滑着色。</p><h2 id="2-添加修改器"><a href="#2-添加修改器" class="headerlink" title="2.添加修改器"></a>2.添加修改器</h2><p>选择要添加修改器的物体，按如下图的操作进行修改器的添加</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/3.png"></p><h2 id="3-细分修改器"><a href="#3-细分修改器" class="headerlink" title="3.细分修改器"></a>3.细分修改器</h2><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/4.png"></p><p><strong>视图层级</strong>：编辑时的细分等级</p><p><strong>渲染层级</strong>：渲染时的细分等级</p><p><strong>tips：</strong></p><p>细分修改器和平滑着色的区别：</p><ol><li><strong>细分修改器</strong>：<ul><li>细分修改器会根据原始网格的拓扑结构，在渲染时<strong>自动增加细分</strong>。这种细分会使模型的表面看起来更加光滑，因为它会在原始几何体的基础上生成更多的几何细节。</li><li>使用细分修改器，你可以通过增加迭代次数来调整模型的光滑度。迭代次数越高，模型的细节越丰富，但也会<strong>增加计算量</strong>。</li></ul></li><li><strong>平滑着色</strong>：<ul><li>平滑着色是一种外观效果，它会使模型的表面在渲染时看起来更加光滑，而不会改变模型的几何结构。</li><li>平滑着色通过将相邻三角形或多边形的<strong>法线平均化</strong>来实现。这样会使相邻的面之间的过渡更加平滑，而不会有锐利的边缘或角。</li><li>平滑着色并<strong>不会增加几何细分</strong>，因此不会增加模型的顶点数量或者计算复杂度。</li></ul></li></ol><p><strong>一般先添加细分修改器，然后再平滑着色</strong>。</p><p>下列选项可以修改观察方式。</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/5.png"></p><h2 id="4-实体化修改器"><a href="#4-实体化修改器" class="headerlink" title="4.实体化修改器"></a>4.实体化修改器</h2><p>生成栏中找到。</p><p>偏移量是选择往什么地方增加厚度。如图所示</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/6.png"></p><h2 id="5-倒角修改器"><a href="#5-倒角修改器" class="headerlink" title="5.倒角修改器"></a>5.倒角修改器</h2><p>生成栏中找到。</p><p>由数量和段数控制。</p><h2 id="6-布尔修改器"><a href="#6-布尔修改器" class="headerlink" title="6.布尔修改器"></a>6.布尔修改器</h2><p>生成栏中找到。</p><p>选择运算方式，选择<strong>运算物体</strong>。</p><p>运算物体是用来进行运算的工具，运算完成后可以<strong>隐藏</strong>。</p><h2 id="7-简易形变修改器"><a href="#7-简易形变修改器" class="headerlink" title="7.简易形变修改器"></a>7.简易形变修改器</h2><p>形变栏中找到。</p><p>弯曲：</p><p>弯曲的点以原点为弯曲点进行弯曲，可以移动角度和轴进行调整。</p><p>锥化：</p><p>选择锥化的方向。</p><h2 id="8-缩裹修改器"><a href="#8-缩裹修改器" class="headerlink" title="8.缩裹修改器"></a>8.缩裹修改器</h2><p>形变栏中找到。</p><p>用吸棒选择需要吸附的对象。需要缩裹的对象一定要有<strong>足够多的细分</strong>才能达到更好的效果。</p><h2 id="9-阵列修改器"><a href="#9-阵列修改器" class="headerlink" title="9.阵列修改器"></a>9.阵列修改器</h2><p>生成栏中找到。</p><p>可以生成多种数量的模型并一起调整。</p><p>物体偏移模式下选择一个物体（可以是空物体），该物体相对于原物体的偏移方式即是接下来的物体相对于前一个物体的偏移方式。</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/7.png"></p><h2 id="10-镜像修改器"><a href="#10-镜像修改器" class="headerlink" title="10.镜像修改器"></a>10.镜像修改器</h2><p>生成栏中找到。</p><p>可以将选择的物体进行镜像。</p><h2 id="11-晶格修改器"><a href="#11-晶格修改器" class="headerlink" title="11.晶格修改器"></a>11.晶格修改器</h2><p>形变栏中找到。</p><p>使用晶格修改器之前一定要生成晶格。晶格选定框住的位置，在需要用晶格的模型上添加晶格修改器后在物体栏选定生成的晶格。编辑晶格可以操作物体。</p><h2 id="12-曲线修改器"><a href="#12-曲线修改器" class="headerlink" title="12.曲线修改器"></a>12.曲线修改器</h2><p>形变栏中找到。</p><p>先生成一个曲线，添加曲线修改器后选择曲线物体为曲线，修改形变轴。</p><p>需要与物体重合。</p><p>选择物体，选择曲线，ctrl+P绑定父级</p><h2 id="13-蒙皮修改器"><a href="#13-蒙皮修改器" class="headerlink" title="13.蒙皮修改器"></a>13.蒙皮修改器</h2><p>生成栏中找到。</p><p>新建平面，选择四个点+M合并到中心</p><p>E挤出一条线，添加蒙皮修改器</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/8.png"></p><p>选择<strong>任意一个点+E</strong>可以挤出分叉，<strong>ctrl+A</strong>修改半径，<strong>ctrl+R</strong>增加分段</p><p><img src="/2024/04/14/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E4%BF%AE%E6%94%B9%E5%99%A8/9.png"></p><p>在蒙皮修改器中选择平滑着色进行平滑。</p><h2 id="14-置换修改器"><a href="#14-置换修改器" class="headerlink" title="14.置换修改器"></a>14.置换修改器</h2><p>形变栏中找到。</p><p>新建平面，细分或添加细分修改器，再添加置换修改器，选择纹理（黑白）</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blender十大建模操作！🥕</title>
    <link href="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="建模操作"><a href="#建模操作" class="headerlink" title="建模操作"></a>建模操作</h1><h2 id="1-挤出（E）"><a href="#1-挤出（E）" class="headerlink" title="1.挤出（E）"></a>1.挤出（E）</h2><p><code>E</code>挤出是挤出+移动操作</p><p>按XYZ可以切换挤出方向。</p><p><strong>tips:</strong></p><p>挤出流形：无重复边。</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/1.png"></p><p>沿法线方向挤出：挤出方向为法线。</p><p>挤出各个面：</p><p>如果不使用，各个面是连在一起的，如图所示</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/2.png"></p><p>使用后各个面是分开的。</p><p>挤出至光标（<code>ctrl+右键</code>)：</p><p>先选择一个面，然后光标点击哪则挤到哪。</p><h2 id="2-内插（I）"><a href="#2-内插（I）" class="headerlink" title="2.内插（I）"></a>2.内插（I）</h2><p>用<code>s</code>调整大小。</p><h2 id="3-倒角（ctrl-B）"><a href="#3-倒角（ctrl-B）" class="headerlink" title="3.倒角（ctrl+B）"></a>3.倒角（ctrl+B）</h2><p>滑动鼠标中键增加细分面。</p><h2 id="4-循环切割（ctrl-R）"><a href="#4-循环切割（ctrl-R）" class="headerlink" title="4.循环切割（ctrl+R）"></a>4.循环切割（ctrl+R）</h2><p>滑动鼠标中键增加条数，点击后移动确定位置。</p><h2 id="5-合并（M）"><a href="#5-合并（M）" class="headerlink" title="5.合并（M）"></a>5.合并（M）</h2><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/3.png"></p><h2 id="6-断开（V）"><a href="#6-断开（V）" class="headerlink" title="6.断开（V）"></a>6.断开（V）</h2><p>前提是一个点有三条边。</p><h2 id="7-填充（F）"><a href="#7-填充（F）" class="headerlink" title="7.填充（F）"></a>7.填充（F）</h2><p>先选择填充的边，再填充。</p><p>或者使用栅格填充，会增加四边形。（<strong>边必须为偶数</strong>）</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E6%93%8D%E4%BD%9C/4.png"></p><h2 id="8-切刀（K）"><a href="#8-切刀（K）" class="headerlink" title="8.切刀（K）"></a>8.切刀（K）</h2><p>右键退出编辑，空格退出模式。</p><h2 id="9-桥接"><a href="#9-桥接" class="headerlink" title="9.桥接"></a>9.桥接</h2><p><code>ctr+E</code>调出边面板，选择桥接循环边。<strong>（<code>alt</code>选择循环边，再<code>shift+alt</code>选择另一条循环边）</strong></p><p><strong>tips：</strong></p><p>桥接的前提是桥接对象为同一物体。</p><p><code>ctrl+J</code>将两个物体合并为同一个物体。</p><h2 id="10-分离（P）"><a href="#10-分离（P）" class="headerlink" title="10.分离（P）"></a>10.分离（P）</h2><p>分离后要按<code>tab</code>退出编辑模式。</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blender点线面的选择与控制！🥕</title>
    <link href="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/"/>
    <url>/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="点线面的选择与控制"><a href="#点线面的选择与控制" class="headerlink" title="点线面的选择与控制"></a>点线面的选择与控制</h1><h2 id="1-模式切换"><a href="#1-模式切换" class="headerlink" title="1.模式切换"></a>1.模式切换</h2><p><code>tab键</code>切换物体模式和编辑模式，物体模式是对整个物体进行操作，编辑模式是对点线面进行操作。</p><h2 id="2-点线面切换"><a href="#2-点线面切换" class="headerlink" title="2.点线面切换"></a>2.点线面切换</h2><p><strong>快捷键：</strong></p><p><code>1</code>：点，<code>2</code>：线，<code>3</code>面</p><p><strong>界面点击：</strong></p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/1.png"></p><p><strong>同时选：</strong></p><p><code>shift+1/2/3</code>可以一起选择</p><h2 id="3-点线面选择"><a href="#3-点线面选择" class="headerlink" title="3.点线面选择"></a>3.点线面选择</h2><p><code>w</code>键切换选择方式，或者长按下图的选择键进行选择。</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/2.png"></p><p><strong>快捷键：</strong></p><p>框选：<code>B</code>   刷选：<code>C</code></p><p><strong>tips：</strong></p><p>快捷键进入选择状态，会无法按其他键。鼠标中键可以进行擦除，按<code>esc</code>或者鼠标右键在空白处点击退出。</p><p><strong>反选</strong>：<code>ctrl+i</code></p><p><strong>多选</strong>：<code>shift</code>+选择点</p><p>最短路径选择：</p><p>先选择一个点&#x2F;线&#x2F;面，然后按住<code>ctrl</code>选择另一个点&#x2F;线&#x2F;面，则可以选择最短路径。</p><p>选择相连：</p><p><code>L</code>(鼠标需要在物体上，以四边形为基础)</p><p><strong>循环选择</strong>：</p><p>先选择一个点，再按住<code>alt</code>键双击循环方向的位置进行循环选择。鼠标偏向纵向则会选择纵向循环，鼠标偏向横向则会选择横向循环。</p><p>tips：</p><p><code>ctrl+alt</code>双击会沿垂直方向循环。</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/3.png"></p><p><strong>透视选择</strong>：</p><p><code>alt+Z</code>切换透视模式，选择的时候可以选择背面。</p><p><strong>扩大&#x2F;缩小选区</strong>：</p><p><code>ctrl+（小键盘）+/-</code>进行扩大&#x2F;缩小的选择。</p><h2 id="4-点线面控制"><a href="#4-点线面控制" class="headerlink" title="4.点线面控制"></a>4.点线面控制</h2><p>选择完后按照<code>G/R/S</code>进行控制。</p><p>删除：</p><p><code>X</code>(弹出选择框)</p><p>tips：</p><p><strong>融并：</strong></p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/4.png">将选择的内容删除后，会用面进行缝合。</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/5.png"></p><h2 id="6-法线"><a href="#6-法线" class="headerlink" title="6.法线"></a>6.法线</h2><p>打开面朝向</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/6.png"></p><p><strong>蓝色</strong>为正面，<strong>红色</strong>为反面。</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/7.png"></p><p>选择法向可以看到法线</p><p><img src="/2024/04/13/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E7%82%B9%E7%BA%BF%E9%9D%A2%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E6%8E%A7%E5%88%B6/8.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>matplotlib库的使用!☃️</title>
    <link href="/2024/04/11/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADmatplotlib%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/04/11/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADmatplotlib%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="matplotlib库的使用"><a href="#matplotlib库的使用" class="headerlink" title="matplotlib库的使用"></a>matplotlib库的使用</h1><h2 id="1-导入"><a href="#1-导入" class="headerlink" title="1.导入"></a>1.导入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br></code></pre></td></tr></table></figure><h2 id="2-启用"><a href="#2-启用" class="headerlink" title="2.启用"></a>2.启用</h2><p>在matplotlib中，<code>plt.ion()</code>是一个函数调用，用于启用交互式模式（interactive mode）。交互式模式允许在图形窗口打开时动态更新和修改图形，而不需要重新绘制整个图形。这对于实时数据可视化和动画非常有用。</p><p>在调用<code>plt.ion()</code>之后，使用<code>plt.plot()</code>或其他绘图函数创建的图形将在窗口中立即显示，而不需要等到整个图形创建完成。此外，可以通过修改已创建的图形对象的属性或添加新的绘图元素来动态更新图形，而不必重新绘制整个图形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 启用交互式模式</span><br>plt.ion()<br><br><span class="hljs-comment"># 创建一个空图形窗口</span><br>plt.figure()<br><br><span class="hljs-comment"># 添加一些数据点并实时更新</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    plt.plot([i], [i], <span class="hljs-string">&#x27;ro&#x27;</span>)  <span class="hljs-comment"># 添加一个红色的点</span><br>    plt.pause(<span class="hljs-number">0.5</span>)  <span class="hljs-comment"># 暂停0.5秒，允许图形更新</span><br></code></pre></td></tr></table></figure><p>在这个例子中，<code>plt.ion()</code>使得每次调用<code>plt.plot()</code>都会立即更新图形窗口，而不必等到所有点都添加完成。</p><h2 id="3-窗口"><a href="#3-窗口" class="headerlink" title="3.窗口"></a>3.窗口</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">fig = plt.figure(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>这行代码创建了一个新的图形窗口，并将其存储在变量 <code>fig</code> 中。在这个例子中，数字参数 <code>1</code> 是一个可选的参数，表示创建的图形的标识符或编号。如果没有提供这个参数，matplotlib会自动为图形分配一个编号。</p><p>这行代码的效果类似于在交互式模式下调用 <code>plt.figure()</code> 函数来创建一个新的图形窗口，但是它将返回的图形对象存储在变量 <code>fig</code> 中，以便之后可以方便地引用和操作它。</p><p>在创建图形之后，你可以使用 <code>fig</code> 对象进行各种操作，例如添加子图、设置图形属性、保存图形等。示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>fig = plt.figure(<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 添加一个子图</span><br>ax = fig.add_subplot(<span class="hljs-number">111</span>)<br>ax.plot([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 设置图形标题</span><br>fig.suptitle(<span class="hljs-string">&#x27;My First Figure&#x27;</span>)<br><br><span class="hljs-comment"># 显示图形</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>在这个示例中，<code>fig</code> 对象用于添加子图、设置标题，并最后显示图形。</p><h2 id="4-窗口方法"><a href="#4-窗口方法" class="headerlink" title="4.窗口方法"></a>4.窗口方法</h2><h3 id="1-add-subplot"><a href="#1-add-subplot" class="headerlink" title="1.add_subplot()"></a>1.add_subplot()</h3><p>具体来说，<code>add_subplot()</code> 方法接受三个参数：行数、列数和子图编号。</p><p>例如:参数<code>(223)</code>表示图形窗口将被分割成一个 2x2 的网格，并且当前子图是这个网格中的第三个子图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">mport matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>fig = plt.figure()<br><br><span class="hljs-comment"># 添加两个 3D 投影的子图</span><br>ax = fig.add_subplot(<span class="hljs-number">223</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax1 = fig.add_subplot(<span class="hljs-number">222</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br></code></pre></td></tr></table></figure><p>效果:</p><p><img src="/2024/04/11/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADmatplotlib%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/1.png"></p><h3 id="2-scatter"><a href="#2-scatter" class="headerlink" title="2.scatter()"></a>2.scatter()</h3><p>窗口使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>plt.figure()<br><br><span class="hljs-comment"># 创建一些数据</span><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>y = [<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># 绘制二维散点图</span><br>plt.scatter(x, y)<br></code></pre></td></tr></table></figure><p>子图使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>fig = plt.figure()<br><br><span class="hljs-comment"># 添加一个 3D 投影的子图</span><br>ax = fig.add_subplot(<span class="hljs-number">223</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br>ax1 = fig.add_subplot(<span class="hljs-number">222</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br><br><span class="hljs-comment"># 绘制三维散点图</span><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>y = [<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]<br>z = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>ax.scatter(x, y, z)<br></code></pre></td></tr></table></figure><p>效果:</p><p><img src="/2024/04/11/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADmatplotlib%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/2.png"></p><h3 id="3-plot"><a href="#3-plot" class="headerlink" title="3.plot()"></a>3.plot()</h3><p><code>plot</code> 函数用于绘制线图，它可以在二维或三维空间中显示数据点之间的连接关系。线图通常用于显示数据随某个变量（通常是 x 轴变量）的变化情况，例如时间序列数据或者变量之间的函数关系。</p><p>窗口使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>plt.figure()<br><br><span class="hljs-comment"># 创建一些数据</span><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>y = [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>]<br><br><span class="hljs-comment"># 绘制二维线图</span><br>plt.plot(x, y)<br><br><span class="hljs-comment"># 设置图形标题和坐标轴标签</span><br>plt.title(<span class="hljs-string">&#x27;2D Line Plot&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;X&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Y&#x27;</span>)<br><br><span class="hljs-comment"># 显示图形</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>子图使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>fig = plt.figure()<br><br><span class="hljs-comment"># 添加一个 3D 投影的子图</span><br>ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br><br><span class="hljs-comment"># 绘制三维散点图</span><br>x = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>y = [<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]<br>z = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>ax.plot(x, y, z)<br><br><span class="hljs-comment"># 设置图形标题和坐标轴标签</span><br>ax.set_title(<span class="hljs-string">&#x27;3D Scatter Plot&#x27;</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;X&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Y&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;Z&#x27;</span>)<br><br><span class="hljs-comment"># 显示图形</span><br>plt.show()<br></code></pre></td></tr></table></figure><p>效果:</p><p><img src="/2024/04/11/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADmatplotlib%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/3.png"></p><h2 id="5-清除"><a href="#5-清除" class="headerlink" title="5.清除"></a>5.清除</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.clf()<br></code></pre></td></tr></table></figure><p><code>plt.clf()</code> 是 matplotlib 中的一个函数，用于清除当前图形窗口中的所有绘图元素，使得窗口变为空白。其作用类似于清除画布上的所有内容，相当于 “clear figure”。</p><p>具体而言，<code>plt.clf()</code> 会清除当前活动的图形（active figure），这是通过最近创建或获取的图形来识别的。调用 <code>plt.clf()</code> 后，图形窗口仍然保持打开状态，但其中的内容被清除。</p><p>这在需要更新图形内容或者需要重新绘制时非常有用，而不必关闭窗口并再次创建新的图形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>plt.figure()<br><br><span class="hljs-comment"># 绘制一些数据</span><br>plt.plot([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 显示图形</span><br>plt.show()<br><br><span class="hljs-comment"># 等待用户交互后清除图形内容</span><br>plt.pause(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 等待3秒钟</span><br>plt.clf()  <span class="hljs-comment"># 清除图形内容</span><br><br><span class="hljs-comment"># 绘制新的数据</span><br>plt.plot([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>])<br><br><span class="hljs-comment"># 显示更新后的图形</span><br>plt.show()<br></code></pre></td></tr></table></figure><h2 id="6-暂停"><a href="#6-暂停" class="headerlink" title="6.暂停"></a>6.暂停</h2><p><code>plt.pause(1)</code> 是一个 matplotlib 函数调用，用于暂停程序执行指定的时间（以秒为单位）。在这段时间内，程序会暂停执行，并且图形窗口将保持显示状态，以便用户有足够的时间观察图形。</p><p>通常，<code>plt.pause()</code> 函数用于交互式图形显示中，特别是在需要动态更新图形或在图形窗口中显示一段时间后等待用户交互时。在这段暂停期间，用户可以浏览图形，然后程序会在指定的时间后继续执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一个新的图形窗口</span><br>plt.figure()<br><br><span class="hljs-comment"># 绘制一些数据</span><br>plt.plot([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 显示图形</span><br>plt.show()<br><br><span class="hljs-comment"># 等待1秒钟</span><br>plt.pause(<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 继续执行后续代码</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Continuing execution...&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="7-设置"><a href="#7-设置" class="headerlink" title="7.设置"></a>7.设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置图形标题和坐标轴标签</span><br>plt.title(<span class="hljs-string">&#x27;Simple Plot&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;X&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Y&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="8-显示"><a href="#8-显示" class="headerlink" title="8.显示"></a>8.显示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 显示图形</span><br>plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hanlp库的使用！🐈</title>
    <link href="/2024/04/09/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/hanlp%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/04/09/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/hanlp%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="hanlp库的使用"><a href="#hanlp库的使用" class="headerlink" title="hanlp库的使用"></a>hanlp库的使用</h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install hanlp<br></code></pre></td></tr></table></figure><h3 id="1-1-多任务模型"><a href="#1-1-多任务模型" class="headerlink" title="1.1 多任务模型"></a>1.1 多任务模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>HanLP = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH) <span class="hljs-comment"># 世界最大中文语料库</span><br></code></pre></td></tr></table></figure><p>通过代码将模型下载到本地</p><p><img src="/2024/04/09/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/hanlp%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/1.png"></p><p>将模型移动到本地调用的位置</p><p><img src="/2024/04/09/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/hanlp%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/2.png"></p><p>模型库：<a href="https://hanlp.hankcs.com/docs/api/hanlp/pretrained/mtl.html">https://hanlp.hankcs.com/docs/api/hanlp/pretrained/mtl.html</a></p><h3 id="1-2-单任务模型"><a href="#1-2-单任务模型" class="headerlink" title="1.2 单任务模型"></a>1.2 单任务模型</h3><p>多任务学习的优势在于速度和显存，然而精度往往不如单任务模型。所以，HanLP预训练了许多单任务模型并设计了优雅的<a href="https://hanlp.hankcs.com/docs/api/hanlp/components/pipeline.html#hanlp.components.pipeline.Pipeline">流水线模式</a>将其组装起来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>HanLP = hanlp.pipeline() \<br>    .append(hanlp.utils.rules.split_sentence, output_key=<span class="hljs-string">&#x27;sentences&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;FINE_ELECTRA_SMALL_ZH&#x27;</span>), output_key=<span class="hljs-string">&#x27;tok&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_POS_ELECTRA_SMALL&#x27;</span>), output_key=<span class="hljs-string">&#x27;pos&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;MSRA_NER_ELECTRA_SMALL_ZH&#x27;</span>), output_key=<span class="hljs-string">&#x27;ner&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_DEP_ELECTRA_SMALL&#x27;</span>, conll=<span class="hljs-number">0</span>), output_key=<span class="hljs-string">&#x27;dep&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>)\<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_CON_ELECTRA_SMALL&#x27;</span>), output_key=<span class="hljs-string">&#x27;con&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>)<br>HanLP(<span class="hljs-string">&#x27;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>)<br></code></pre></td></tr></table></figure><p>同多任务模型，将单任务模型保存到本地。</p><p><img src="/2024/04/09/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/hanlp%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/3.png"></p><h2 id="2-调用"><a href="#2-调用" class="headerlink" title="2.调用"></a>2.调用</h2><h3 id="2-1-多任务"><a href="#2-1-多任务" class="headerlink" title="2.1 多任务"></a>2.1 多任务</h3><h4 id="2-1-1-批量分析"><a href="#2-1-1-批量分析" class="headerlink" title="2.1.1 批量分析"></a>2.1.1 批量分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">doc = HanLP([<span class="hljs-string">&#x27;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。&#x27;</span>, <span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>])<br><span class="hljs-built_in">print</span>(doc)<br></code></pre></td></tr></table></figure><h4 id="2-1-2-可视化"><a href="#2-1-2-可视化" class="headerlink" title="2.1.2 可视化"></a>2.1.2 可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">doc.pretty_print()<br></code></pre></td></tr></table></figure><h4 id="2-1-3-指定任务"><a href="#2-1-3-指定任务" class="headerlink" title="2.1.3 指定任务"></a>2.1.3 指定任务</h4><p><strong>分词：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;tok&#x27;</span>).pretty_print()<br></code></pre></td></tr></table></figure><p><strong>粗颗粒度分词：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;tok/coarse&#x27;</span>).pretty_print()<br></code></pre></td></tr></table></figure><p><strong>分词和PKU词性标注：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;pos/pku&#x27;</span>).pretty_print()<br></code></pre></td></tr></table></figure><p><strong>粗颗粒度分词和PKU词性标注：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=[<span class="hljs-string">&#x27;tok/coarse&#x27;</span>, <span class="hljs-string">&#x27;pos/pku&#x27;</span>], skip_tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>).pretty_print()<br></code></pre></td></tr></table></figure><p><strong>分词和MSRA标准NER：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;ner/msra&#x27;</span>).pretty_print()<br></code></pre></td></tr></table></figure><p><strong>分词、词性标注和依存句法分析：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">doc = HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=[<span class="hljs-string">&#x27;pos&#x27;</span>, <span class="hljs-string">&#x27;dep&#x27;</span>])<br>doc.pretty_print()<br><br>转换为CoNLL格式：<br><span class="hljs-built_in">print</span>(doc.to_conll())<br></code></pre></td></tr></table></figure><p><strong>分词、词性标注和短语成分分析：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">doc = HanLP(<span class="hljs-string">&#x27;阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=[<span class="hljs-string">&#x27;pos&#x27;</span>, <span class="hljs-string">&#x27;con&#x27;</span>])<br>doc.pretty_print()<br><br>将短语结构树以bracketed形式打印<br><span class="hljs-built_in">print</span>(doc[<span class="hljs-string">&#x27;con&#x27;</span>])<br></code></pre></td></tr></table></figure><p><strong>语义依存分析：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">sdp = hanlp.load(<span class="hljs-string">&#x27;SEMEVAL16_ALL_ELECTRA_SMALL_ZH&#x27;</span>)<br>graph = sdp([<span class="hljs-string">&quot;2021年&quot;</span>, <span class="hljs-string">&quot;HanLPv2.1&quot;</span>, <span class="hljs-string">&quot;为&quot;</span>, <span class="hljs-string">&quot;生产&quot;</span>, <span class="hljs-string">&quot;环境&quot;</span>, <span class="hljs-string">&quot;带来&quot;</span>, <span class="hljs-string">&quot;次&quot;</span>, <span class="hljs-string">&quot;世代&quot;</span>, <span class="hljs-string">&quot;最&quot;</span>, <span class="hljs-string">&quot;先进&quot;</span>, <span class="hljs-string">&quot;的&quot;</span>, <span class="hljs-string">&quot;多&quot;</span>, <span class="hljs-string">&quot;语种&quot;</span>, <span class="hljs-string">&quot;NLP&quot;</span>, <span class="hljs-string">&quot;技术&quot;</span>, <span class="hljs-string">&quot;。&quot;</span>])<br><span class="hljs-built_in">print</span>(graph)<br><br>或者：<br><span class="hljs-keyword">import</span> hanlp<br>HanLP = hanlp.pipeline() \<br>    .append(hanlp.utils.rules.split_sentence, output_key=<span class="hljs-string">&#x27;sentences&#x27;</span>).append(hanlp.load(<span class="hljs-string">&#x27;D:/Python/new_pytorch/HanLP/single_task/tok/fine_electra_small&#x27;</span>), output_key=<span class="hljs-string">&#x27;tok&#x27;</span>)<br>tok = HanLP(<span class="hljs-string">&#x27;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>)<br><span class="hljs-built_in">print</span>(tok[<span class="hljs-string">&quot;tok&quot;</span>][<span class="hljs-number">0</span>])<br>sdp = hanlp.load(<span class="hljs-string">&#x27;D:/Python/new_pytorch/HanLP/single_task/sdp/semeval16_sdp_electra_small&#x27;</span>)<br>graph = sdp(tok[<span class="hljs-string">&quot;tok&quot;</span>][<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(graph)<br></code></pre></td></tr></table></figure><h4 id="2-1-4-删除冗余任务"><a href="#2-1-4-删除冗余任务" class="headerlink" title="2.1.4 删除冗余任务"></a>2.1.4 删除冗余任务</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br><span class="hljs-keyword">from</span> hanlp.components.mtl.multi_task_learning <span class="hljs-keyword">import</span> MultiTaskLearning<br><span class="hljs-keyword">from</span> hanlp_common.document <span class="hljs-keyword">import</span> Document<br><br>HanLP: MultiTaskLearning = hanlp.load(hanlp.pretrained.mtl.OPEN_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH)<br>tasks = <span class="hljs-built_in">list</span>(HanLP.tasks.keys())<br><span class="hljs-built_in">print</span>(tasks)  <span class="hljs-comment"># Pick what you need from what we have</span><br><span class="hljs-keyword">for</span> task <span class="hljs-keyword">in</span> tasks:<br>    <span class="hljs-keyword">if</span> task <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;tok&#x27;</span>, <span class="hljs-string">&#x27;pos&#x27;</span>):<br>        <span class="hljs-keyword">del</span> HanLP[task]<br><span class="hljs-comment"># You can save it as a new component</span><br><span class="hljs-comment"># HanLP.save(&#x27;path/to/new/component&#x27;)</span><br><span class="hljs-comment"># HanLP.load(&#x27;path/to/new/component&#x27;)</span><br><span class="hljs-built_in">print</span>(HanLP.tasks.keys())<br>doc: Document = HanLP([<span class="hljs-string">&#x27;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。&#x27;</span>, <span class="hljs-string">&#x27;up主来到北京立方庭参观自然语义科技公司。&#x27;</span>])<br><span class="hljs-built_in">print</span>(doc)<br>doc.pretty_print()<br></code></pre></td></tr></table></figure><h4 id="2-1-5-自定义词典"><a href="#2-1-5-自定义词典" class="headerlink" title="2.1.5 自定义词典"></a>2.1.5 自定义词典</h4><p>先获取分词任务：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tok = HanLP[<span class="hljs-string">&#x27;tok/fine&#x27;</span>]<br></code></pre></td></tr></table></figure><p>以“商品和服务项目”为例，不做任何修改的情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 【python">tok.dict_force = tok.dict_combine = None<br>HanLP(&quot;商品和服务项目&quot;, tasks=&#x27;tok/fine&#x27;).pretty_print()<br><br>输出：<br>商品 和 服务 项目<br></code></pre></td></tr></table></figure><p><strong>强制模式</strong>（强制模式优先输出正向最长匹配到的自定义词条）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tok.dict_force = &#123;<span class="hljs-string">&#x27;和服&#x27;</span>, <span class="hljs-string">&#x27;服务项目&#x27;</span>&#125;<br>HanLP(<span class="hljs-string">&quot;商品和服务项目&quot;</span>, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>).pretty_print()<br><br>输出：<br>商品 和服 务 项目<br></code></pre></td></tr></table></figure><p><strong>强制校正模式</strong>（匹配到的自定义词条替换为相应的分词结果）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tok.dict_force = &#123;<span class="hljs-string">&#x27;和服务&#x27;</span>: [<span class="hljs-string">&#x27;和&#x27;</span>, <span class="hljs-string">&#x27;服务&#x27;</span>]&#125;<br>HanLP(<span class="hljs-string">&quot;商品和服务项目&quot;</span>, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>).pretty_print()<br><br>输出：<br>商品 和 服务 项目<br></code></pre></td></tr></table></figure><p><strong>合并模式</strong>（合并模式的优先级低于统计模型，即<code>dict_combine</code>会在统计模型的分词结果上执行最长匹配并合并匹配到的词条）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tok.dict_force = <span class="hljs-literal">None</span><br>tok.dict_combine = &#123;<span class="hljs-string">&#x27;和服&#x27;</span>, <span class="hljs-string">&#x27;服务项目&#x27;</span>&#125;<br>HanLP(<span class="hljs-string">&quot;商品和服务项目&quot;</span>, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>).pretty_print()<br><br>输出：<br>商品 和 服务项目<br></code></pre></td></tr></table></figure><h4 id="2-1-6-单词位置"><a href="#2-1-6-单词位置" class="headerlink" title="2.1.6 单词位置"></a>2.1.6 单词位置</h4><p>HanLP支持输出每个单词在文本中的原始位置，以便用于搜索引擎等场景。在词法分析中，非语素字符（空格、换行、制表符等）会被剔除，此时需要额外的位置信息才能定位每个单词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">tok.config.output_spans = <span class="hljs-literal">True</span><br>sent = <span class="hljs-string">&#x27;2021 年\nHanLPv2.1 为生产环境带来次世代最先进的多语种NLP技术。&#x27;</span><br>word_offsets = HanLP(sent, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>)[<span class="hljs-string">&#x27;tok/fine&#x27;</span>]<br><span class="hljs-built_in">print</span>(word_offsets)<br><br>输出：<br>[[<span class="hljs-string">&#x27;2021 年&#x27;</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>], [<span class="hljs-string">&#x27;HanLPv2.1&#x27;</span>, <span class="hljs-number">7</span>, <span class="hljs-number">16</span>], [<span class="hljs-string">&#x27;为&#x27;</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>], [<span class="hljs-string">&#x27;生产&#x27;</span>, <span class="hljs-number">18</span>, <span class="hljs-number">20</span>], [<span class="hljs-string">&#x27;环境&#x27;</span>, <span class="hljs-number">20</span>, <span class="hljs-number">22</span>], [<span class="hljs-string">&#x27;带来&#x27;</span>, <span class="hljs-number">22</span>, <span class="hljs-number">24</span>], [<span class="hljs-string">&#x27;次&#x27;</span>, <span class="hljs-number">24</span>, <span class="hljs-number">25</span>], [<span class="hljs-string">&#x27;世代&#x27;</span>, <span class="hljs-number">25</span>, <span class="hljs-number">27</span>], [<span class="hljs-string">&#x27;最&#x27;</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>], [<span class="hljs-string">&#x27;先进&#x27;</span>, <span class="hljs-number">28</span>, <span class="hljs-number">30</span>], [<span class="hljs-string">&#x27;的&#x27;</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>], [<span class="hljs-string">&#x27;多&#x27;</span>, <span class="hljs-number">31</span>, <span class="hljs-number">32</span>], [<span class="hljs-string">&#x27;语种&#x27;</span>, <span class="hljs-number">32</span>, <span class="hljs-number">34</span>], [<span class="hljs-string">&#x27;NLP&#x27;</span>, <span class="hljs-number">34</span>, <span class="hljs-number">37</span>], [<span class="hljs-string">&#x27;技术&#x27;</span>, <span class="hljs-number">37</span>, <span class="hljs-number">39</span>], [<span class="hljs-string">&#x27;。&#x27;</span>, <span class="hljs-number">39</span>, <span class="hljs-number">40</span>]]<br></code></pre></td></tr></table></figure><h3 id="2-2-单任务"><a href="#2-2-单任务" class="headerlink" title="2.2 单任务"></a>2.2 单任务</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>HanLP = hanlp.pipeline() \<br>    .append(hanlp.utils.rules.split_sentence, output_key=<span class="hljs-string">&#x27;sentences&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;FINE_ELECTRA_SMALL_ZH&#x27;</span>), output_key=<span class="hljs-string">&#x27;tok&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_POS_ELECTRA_SMALL&#x27;</span>), output_key=<span class="hljs-string">&#x27;pos&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;MSRA_NER_ELECTRA_SMALL_ZH&#x27;</span>), output_key=<span class="hljs-string">&#x27;ner&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>) \<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_DEP_ELECTRA_SMALL&#x27;</span>, conll=<span class="hljs-number">0</span>), output_key=<span class="hljs-string">&#x27;dep&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>)\<br>    .append(hanlp.load(<span class="hljs-string">&#x27;CTB9_CON_ELECTRA_SMALL&#x27;</span>), output_key=<span class="hljs-string">&#x27;con&#x27;</span>, input_key=<span class="hljs-string">&#x27;tok&#x27;</span>)<br>    <br>HanLP(<span class="hljs-string">&#x27;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。阿婆主来到北京立方庭参观自然语义科技公司。&#x27;</span>, tasks=<span class="hljs-string">&#x27;tok/fine&#x27;</span>).pretty_print()<br><br>输出：<br><span class="hljs-number">2021</span>年 HanLPv2<span class="hljs-number">.1</span> 为 生产 环境 带来 次 世代 最 先进 的 多 语种 NLP 技术 。<br>阿婆主 来到 北京 立方庭 参观 自然 语义 科技 公司 。<br></code></pre></td></tr></table></figure><h3 id="2-3-word2vec"><a href="#2-3-word2vec" class="headerlink" title="2.3 word2vec"></a>2.3 word2vec</h3><h4 id="2-3-1-加载模型"><a href="#2-3-1-加载模型" class="headerlink" title="2.3.1 加载模型"></a>2.3.1 加载模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>word2vec = hanlp.load(<span class="hljs-string">&quot;/HanLP/word2vec/MERGE_SGNS_BIGRAM_CHAR_300_ZH&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="2-3-2-输出向量"><a href="#2-3-2-输出向量" class="headerlink" title="2.3.2 输出向量"></a>2.3.2 输出向量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(word2vec(<span class="hljs-string">&#x27;先进&#x27;</span>))<br></code></pre></td></tr></table></figure><h4 id="2-3-3-计算相似度"><a href="#2-3-3-计算相似度" class="headerlink" title="2.3.3 计算相似度"></a>2.3.3 计算相似度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-built_in">print</span>(torch.nn.functional.cosine_similarity(word2vec(<span class="hljs-string">&#x27;先进&#x27;</span>), word2vec(<span class="hljs-string">&#x27;优秀&#x27;</span>), dim=<span class="hljs-number">0</span>))<br><span class="hljs-built_in">print</span>(torch.nn.functional.cosine_similarity(word2vec(<span class="hljs-string">&#x27;先进&#x27;</span>), word2vec(<span class="hljs-string">&#x27;水果&#x27;</span>), dim=<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><h4 id="2-3-4-最相似单词"><a href="#2-3-4-最相似单词" class="headerlink" title="2.3.4 最相似单词"></a>2.3.4 最相似单词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">word2vec.most_similar(<span class="hljs-string">&#x27;上海&#x27;</span>)<br><br>输出：<br>&#123;<span class="hljs-string">&#x27;广州&#x27;</span>: <span class="hljs-number">0.8630875945091248</span>,<br> <span class="hljs-string">&#x27;北京&#x27;</span>: <span class="hljs-number">0.8542779088020325</span>,<br> <span class="hljs-string">&#x27;天津&#x27;</span>: <span class="hljs-number">0.8537402153015137</span>,<br> <span class="hljs-string">&#x27;深圳&#x27;</span>: <span class="hljs-number">0.8526542782783508</span>,<br> <span class="hljs-string">&#x27;成都&#x27;</span>: <span class="hljs-number">0.8255313634872437</span>,<br> <span class="hljs-string">&#x27;西安&#x27;</span>: <span class="hljs-number">0.8215534687042236</span>,<br> <span class="hljs-string">&#x27;杭州&#x27;</span>: <span class="hljs-number">0.8207105398178101</span>,<br> <span class="hljs-string">&#x27;厦门&#x27;</span>: <span class="hljs-number">0.8186136484146118</span>,<br> <span class="hljs-string">&#x27;昆明&#x27;</span>: <span class="hljs-number">0.8184518814086914</span>,<br> <span class="hljs-string">&#x27;武汉&#x27;</span>: <span class="hljs-number">0.8055384755134583</span>&#125;<br></code></pre></td></tr></table></figure><p><code>Word2Vec 通常无法处理 OOV 或短语</code></p><p>Doc2Vec 与 Word2Vec 模型相反，可以通过平均一组单词来创建矢量化表示。要为 OOV 和短语启用 Doc2Vec，请传递 <code>doc2vec=True</code> ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">word2vec.most_similar(<span class="hljs-string">&#x27;非常寒冷&#x27;</span>, doc2vec=<span class="hljs-literal">True</span>)<br><br>输出：<br>&#123;<span class="hljs-string">&#x27;寒冷&#x27;</span>: <span class="hljs-number">0.7510591745376587</span>,<br> <span class="hljs-string">&#x27;非常&#x27;</span>: <span class="hljs-number">0.7510591745376587</span>,<br> <span class="hljs-string">&#x27;很&#x27;</span>: <span class="hljs-number">0.7312490344047546</span>,<br> <span class="hljs-string">&#x27;比较&#x27;</span>: <span class="hljs-number">0.6991080045700073</span>,<br> <span class="hljs-string">&#x27;无比&#x27;</span>: <span class="hljs-number">0.685967743396759</span>,<br> <span class="hljs-string">&#x27;极其&#x27;</span>: <span class="hljs-number">0.6834490895271301</span>,<br> <span class="hljs-string">&#x27;十分&#x27;</span>: <span class="hljs-number">0.6786675453186035</span>,<br> <span class="hljs-string">&#x27;潮湿&#x27;</span>: <span class="hljs-number">0.67008376121521</span>,<br> <span class="hljs-string">&#x27;焦躁不安&#x27;</span>: <span class="hljs-number">0.6699174642562866</span>,<br> <span class="hljs-string">&#x27;阴冷&#x27;</span>: <span class="hljs-number">0.6695235967636108</span>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-4-mlm"><a href="#2-4-mlm" class="headerlink" title="2.4 mlm"></a>2.4 mlm</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> hanlp.components.lm.mlm <span class="hljs-keyword">import</span> MaskedLanguageModel<br>mlm = MaskedLanguageModel()<br>mlm.load(<span class="hljs-string">&#x27;bert-base-chinese&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">mlm(<span class="hljs-string">&#x27;生活的真谛是[MASK]。&#x27;</span>)<br><br>输出：<br>[&#123;<span class="hljs-string">&#x27;美&#x27;</span>: <span class="hljs-number">0.3407564163208008</span>,<br>  <span class="hljs-string">&#x27;爱&#x27;</span>: <span class="hljs-number">0.2292439043521881</span>,<br>  <span class="hljs-string">&#x27;乐&#x27;</span>: <span class="hljs-number">0.032554809004068375</span>,<br>  <span class="hljs-string">&#x27;人&#x27;</span>: <span class="hljs-number">0.022961532697081566</span>,<br>  <span class="hljs-string">&#x27;：&#x27;</span>: <span class="hljs-number">0.01942446455359459</span>,<br>  <span class="hljs-string">&#x27;笑&#x27;</span>: <span class="hljs-number">0.017893701791763306</span>,<br>  <span class="hljs-string">&#x27;-&#x27;</span>: <span class="hljs-number">0.016441352665424347</span>,<br>  <span class="hljs-string">&#x27;玩&#x27;</span>: <span class="hljs-number">0.016314353793859482</span>,<br>  <span class="hljs-string">&#x27;活&#x27;</span>: <span class="hljs-number">0.014588544145226479</span>,<br>  <span class="hljs-string">&#x27;好&#x27;</span>: <span class="hljs-number">0.013642454519867897</span>&#125;]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">mlm([<span class="hljs-string">&#x27;生活的真谛是[MASK]。&#x27;</span>, <span class="hljs-string">&#x27;巴黎是[MASK][MASK]的首都。&#x27;</span>])<br><br>输出：<br>[[&#123;<span class="hljs-string">&#x27;美&#x27;</span>: <span class="hljs-number">0.3407564163208008</span>,<br>   <span class="hljs-string">&#x27;爱&#x27;</span>: <span class="hljs-number">0.2292439043521881</span>,<br>   <span class="hljs-string">&#x27;乐&#x27;</span>: <span class="hljs-number">0.032554809004068375</span>,<br>   <span class="hljs-string">&#x27;人&#x27;</span>: <span class="hljs-number">0.022961532697081566</span>,<br>   <span class="hljs-string">&#x27;：&#x27;</span>: <span class="hljs-number">0.01942446455359459</span>,<br>   <span class="hljs-string">&#x27;笑&#x27;</span>: <span class="hljs-number">0.017893701791763306</span>,<br>   <span class="hljs-string">&#x27;-&#x27;</span>: <span class="hljs-number">0.016441352665424347</span>,<br>   <span class="hljs-string">&#x27;玩&#x27;</span>: <span class="hljs-number">0.016314353793859482</span>,<br>   <span class="hljs-string">&#x27;活&#x27;</span>: <span class="hljs-number">0.014588544145226479</span>,<br>   <span class="hljs-string">&#x27;好&#x27;</span>: <span class="hljs-number">0.013642454519867897</span>&#125;],<br> [&#123;<span class="hljs-string">&#x27;法&#x27;</span>: <span class="hljs-number">0.5057310461997986</span>,<br>   <span class="hljs-string">&#x27;德&#x27;</span>: <span class="hljs-number">0.08851869404315948</span>,<br>   <span class="hljs-string">&#x27;歐&#x27;</span>: <span class="hljs-number">0.06904969364404678</span>,<br>   <span class="hljs-string">&#x27;巴&#x27;</span>: <span class="hljs-number">0.04269423708319664</span>,<br>   <span class="hljs-string">&#x27;瑞&#x27;</span>: <span class="hljs-number">0.039870887994766235</span>,<br>   <span class="hljs-string">&#x27;英&#x27;</span>: <span class="hljs-number">0.03201477229595184</span>,<br>   <span class="hljs-string">&#x27;美&#x27;</span>: <span class="hljs-number">0.02721557952463627</span>,<br>   <span class="hljs-string">&#x27;荷&#x27;</span>: <span class="hljs-number">0.02194151096045971</span>,<br>   <span class="hljs-string">&#x27;中&#x27;</span>: <span class="hljs-number">0.018307117745280266</span>,<br>   <span class="hljs-string">&#x27;欧&#x27;</span>: <span class="hljs-number">0.011474725790321827</span>&#125;,<br>  &#123;<span class="hljs-string">&#x27;國&#x27;</span>: <span class="hljs-number">0.6981891989707947</span>,<br>   <span class="hljs-string">&#x27;国&#x27;</span>: <span class="hljs-number">0.10869748890399933</span>,<br>   <span class="hljs-string">&#x27;洲&#x27;</span>: <span class="hljs-number">0.03609883040189743</span>,<br>   <span class="hljs-string">&#x27;蘭&#x27;</span>: <span class="hljs-number">0.013893415220081806</span>,<br>   <span class="hljs-string">&#x27;臘&#x27;</span>: <span class="hljs-number">0.010245074518024921</span>,<br>   <span class="hljs-string">&#x27;士&#x27;</span>: <span class="hljs-number">0.009544524364173412</span>,<br>   <span class="hljs-string">&#x27;盟&#x27;</span>: <span class="hljs-number">0.00916974525898695</span>,<br>   <span class="hljs-string">&#x27;西&#x27;</span>: <span class="hljs-number">0.005254795774817467</span>,<br>   <span class="hljs-string">&#x27;典&#x27;</span>: <span class="hljs-number">0.004525361582636833</span>,<br>   <span class="hljs-string">&#x27;邦&#x27;</span>: <span class="hljs-number">0.0044594407081604</span>&#125;]]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三维网格细分算法！🐶</title>
    <link href="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/"/>
    <url>/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="三维网格细分算法"><a href="#三维网格细分算法" class="headerlink" title="三维网格细分算法"></a>三维网格细分算法</h1><p>在建模的过程中往往需要用到平滑网格的操作，而在目前的大多数建模软件中，最常用到的平滑操作即是Catmull-Clark细分曲面方法。Catmull-Clark主要是针对四边形网格细分的算法，具体的过程如下。</p><h2 id="1-新增点"><a href="#1-新增点" class="headerlink" title="1.新增点"></a>1.新增点</h2><p>新增点包括<strong>面点</strong>和<strong>边点</strong>。</p><h3 id="1-计算面点（face-points"><a href="#1-计算面点（face-points" class="headerlink" title="1.计算面点（face_points)"></a>1.计算面点（face_points)</h3><p>在后面计算边点（edge_points）时需要用到这一步的结果。</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/1.png"></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/2.png"></p><h3 id="2-计算边点（edge-points）"><a href="#2-计算边点（edge-points）" class="headerlink" title="2.计算边点（edge_points）"></a>2.计算边点（edge_points）</h3><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/3.png"></p><p>计算边点（edge_point）需要三个步骤，如上图所示</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/4.png"></p><h2 id="2-原始点"><a href="#2-原始点" class="headerlink" title="2.原始点"></a>2.原始点</h2><h3 id="1-计算平均面点（avg-face-points）"><a href="#1-计算平均面点（avg-face-points）" class="headerlink" title="1. 计算平均面点（avg_face_points）"></a>1. 计算平均面点（avg_face_points）</h3><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/5.png"></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/6.png"></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/7.png"></p><h3 id="2-计算平均边中点（avg-mid-edges）"><a href="#2-计算平均边中点（avg-mid-edges）" class="headerlink" title="2.计算平均边中点（avg_mid_edges）"></a>2.计算平均边中点（avg_mid_edges）</h3><p><strong>注意，这里计算的是平均边中点，而不是平均边点！</strong></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/8.png"></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/9.png"></p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/10.png"></p><h2 id="3-更新原始点"><a href="#3-更新原始点" class="headerlink" title="3.更新原始点"></a>3.更新原始点</h2><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/11.png"></p><h2 id="4-插入新增点"><a href="#4-插入新增点" class="headerlink" title="4.插入新增点"></a>4.插入新增点</h2><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/12.png"></p><h2 id="5-源码"><a href="#5-源码" class="headerlink" title="5.源码"></a>5.源码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> axes3d<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> time<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">center_point</span>(<span class="hljs-params">p1, p2</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    returns a point in the center of the</span><br><span class="hljs-string">    segment ended by points p1 and p2</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    cp = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        cp.append((p1[i] + p2[i]) / <span class="hljs-number">2</span>)<br><br>    <span class="hljs-keyword">return</span> cp<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sum_point</span>(<span class="hljs-params">p1, p2</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    adds points p1 and p2</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sp = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        sp.append(p1[i] + p2[i])<br><br>    <span class="hljs-keyword">return</span> sp<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">div_point</span>(<span class="hljs-params">p, d</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    divide point p by d</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sp = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        sp.append(p[i] / d)<br><br>    <span class="hljs-keyword">return</span> sp<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mul_point</span>(<span class="hljs-params">p, m</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    multiply point p by m</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sp = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>        sp.append(p[i] * m)<br><br>    <span class="hljs-keyword">return</span> sp<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_face_points</span>(<span class="hljs-params">input_points, input_faces</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    From http://rosettacode.org/wiki/Catmull%E2%80%93Clark_subdivision_surface</span><br><span class="hljs-string"></span><br><span class="hljs-string">    1. for each face, a face point is created which is the average of all the points of the face.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 3 dimensional space</span><br><br>    NUM_DIMENSIONS = <span class="hljs-number">3</span><br><br>    <span class="hljs-comment"># face_points will have one point for each face</span><br><br>    face_points = []<br><br>    <span class="hljs-keyword">for</span> curr_face <span class="hljs-keyword">in</span> input_faces:<br>        face_point = [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>]<br>        <span class="hljs-keyword">for</span> curr_point_index <span class="hljs-keyword">in</span> curr_face:<br>            curr_point = input_points[curr_point_index]<br>            <span class="hljs-comment"># add curr_point to face_point</span><br>            <span class="hljs-comment"># will divide later</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_DIMENSIONS):<br>                face_point[i] += curr_point[i]<br>        <span class="hljs-comment"># divide by number of points for average</span><br>        num_points = <span class="hljs-built_in">len</span>(curr_face)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_DIMENSIONS):<br>            face_point[i] /= num_points<br>        face_points.append(face_point)<br><br>    <span class="hljs-keyword">return</span> face_points<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_edges_faces</span>(<span class="hljs-params">input_points, input_faces</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Get list of edges and the one or two adjacent faces in a list.</span><br><span class="hljs-string">    also get center point of edge</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Each edge would be [pointnum_1, pointnum_2, facenum_1, facenum_2, center]</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># will have [pointnum_1, pointnum_2, facenum]</span><br><br>    edges = []<br><br>    <span class="hljs-comment"># get edges from each face</span><br><br>    <span class="hljs-keyword">for</span> facenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(input_faces)):<br>        face = input_faces[facenum]<br>        num_points = <span class="hljs-built_in">len</span>(face)<br>        <span class="hljs-comment"># loop over index into face</span><br>        <span class="hljs-keyword">for</span> pointindex <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>            <span class="hljs-comment"># if not last point then edge is curr point and next point</span><br>            <span class="hljs-keyword">if</span> pointindex &lt; num_points - <span class="hljs-number">1</span>:<br>                pointnum_1 = face[pointindex]<br>                pointnum_2 = face[pointindex + <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># for last point edge is curr point and first point</span><br>                pointnum_1 = face[pointindex]<br>                pointnum_2 = face[<span class="hljs-number">0</span>]<br>            <span class="hljs-comment"># order points in edge by lowest point number</span><br>            <span class="hljs-keyword">if</span> pointnum_1 &gt; pointnum_2:<br>                temp = pointnum_1<br>                pointnum_1 = pointnum_2<br>                pointnum_2 = temp<br>            edges.append([pointnum_1, pointnum_2, facenum])<br><br>    <span class="hljs-comment"># sort edges by pointnum_1, pointnum_2, facenum</span><br><br>    edges = <span class="hljs-built_in">sorted</span>(edges)<br><br>    <span class="hljs-comment"># merge edges with 2 adjacent faces</span><br>    <span class="hljs-comment"># [pointnum_1, pointnum_2, facenum_1, facenum_2] or</span><br>    <span class="hljs-comment"># [pointnum_1, pointnum_2, facenum_1, None]</span><br><br>    num_edges = <span class="hljs-built_in">len</span>(edges)<br>    eindex = <span class="hljs-number">0</span><br>    merged_edges = []<br><br>    <span class="hljs-keyword">while</span> eindex &lt; num_edges:<br>        e1 = edges[eindex]<br>        <span class="hljs-comment"># check if not last edge</span><br>        <span class="hljs-keyword">if</span> eindex &lt; num_edges - <span class="hljs-number">1</span>:<br>            e2 = edges[eindex + <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> e1[<span class="hljs-number">0</span>] == e2[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> e1[<span class="hljs-number">1</span>] == e2[<span class="hljs-number">1</span>]:<br>                merged_edges.append([e1[<span class="hljs-number">0</span>], e1[<span class="hljs-number">1</span>], e1[<span class="hljs-number">2</span>], e2[<span class="hljs-number">2</span>]])<br>                eindex += <span class="hljs-number">2</span><br>            <span class="hljs-keyword">else</span>:<br>                merged_edges.append([e1[<span class="hljs-number">0</span>], e1[<span class="hljs-number">1</span>], e1[<span class="hljs-number">2</span>], <span class="hljs-literal">None</span>])<br>                eindex += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            merged_edges.append([e1[<span class="hljs-number">0</span>], e1[<span class="hljs-number">1</span>], e1[<span class="hljs-number">2</span>], <span class="hljs-literal">None</span>])<br>            eindex += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># add edge centers</span><br><br>    edges_centers = []<br><br>    <span class="hljs-keyword">for</span> me <span class="hljs-keyword">in</span> merged_edges:<br>        p1 = input_points[me[<span class="hljs-number">0</span>]]<br>        p2 = input_points[me[<span class="hljs-number">1</span>]]<br>        cp = center_point(p1, p2)<br>        edges_centers.append(me + [cp])<br><br>    <span class="hljs-keyword">return</span> edges_centers<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_edge_points</span>(<span class="hljs-params">input_points, edges_faces, face_points</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    for each edge, an edge point is created which is the average</span><br><span class="hljs-string">    between the center of the edge and the center of the segment made</span><br><span class="hljs-string">    with the face points of the two adjacent faces.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    edge_points = []<br><br>    <span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> edges_faces:<br>        <span class="hljs-comment"># get center of edge</span><br>        cp = edge[<span class="hljs-number">4</span>]<br>        <span class="hljs-comment"># get center of two facepoints</span><br>        fp1 = face_points[edge[<span class="hljs-number">2</span>]]<br>        <span class="hljs-comment"># if not two faces just use one facepoint</span><br>        <span class="hljs-comment"># should not happen for solid like a cube</span><br>        <span class="hljs-keyword">if</span> edge[<span class="hljs-number">3</span>] == <span class="hljs-literal">None</span>:<br>            fp2 = fp1<br>        <span class="hljs-keyword">else</span>:<br>            fp2 = face_points[edge[<span class="hljs-number">3</span>]]<br>        cfp = center_point(fp1, fp2)<br>        <span class="hljs-comment"># get average between center of edge and</span><br>        <span class="hljs-comment"># center of facepoints</span><br>        edge_point = center_point(cp, cfp)<br>        edge_points.append(edge_point)<br><br>    <span class="hljs-keyword">return</span> edge_points<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_avg_face_points</span>(<span class="hljs-params">input_points, input_faces, face_points</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    for each point calculate</span><br><span class="hljs-string"></span><br><span class="hljs-string">    the average of the face points of the faces the point belongs to (avg_face_points)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    create a list of lists of two numbers [facepoint_sum, num_points] by going through the</span><br><span class="hljs-string">    points in all the faces.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    then create the avg_face_points list of point by dividing point_sum (x, y, z) by num_points</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># initialize list with [[0.0, 0.0, 0.0], 0]</span><br><br>    num_points = <span class="hljs-built_in">len</span>(input_points)<br><br>    temp_points = []<br><br>    <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>        temp_points.append([[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>], <span class="hljs-number">0</span>])<br><br>    <span class="hljs-comment"># loop through faces updating temp_points</span><br><br>    <span class="hljs-keyword">for</span> facenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(input_faces)):<br>        fp = face_points[facenum]<br>        <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> input_faces[facenum]:<br>            tp = temp_points[pointnum][<span class="hljs-number">0</span>]<br>            temp_points[pointnum][<span class="hljs-number">0</span>] = sum_point(tp, fp)<br>            temp_points[pointnum][<span class="hljs-number">1</span>] += <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 以上统计每个点属于多少个面，并将每个面点求和，在接下来求平均</span><br>    <span class="hljs-comment"># divide to create avg_face_points</span><br><br>    avg_face_points = []<br><br>    <span class="hljs-keyword">for</span> tp <span class="hljs-keyword">in</span> temp_points:<br>        afp = div_point(tp[<span class="hljs-number">0</span>], tp[<span class="hljs-number">1</span>])<br>        avg_face_points.append(afp)<br><br>    <span class="hljs-keyword">return</span> avg_face_points<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_avg_mid_edges</span>(<span class="hljs-params">input_points, edges_faces</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    the average of the centers of edges the point belongs to (avg_mid_edges)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    create list with entry for each point</span><br><span class="hljs-string">    each entry has two elements. one is a point that is the sum of the centers of the edges</span><br><span class="hljs-string">    and the other is the number of edges. after going through all edges divide by</span><br><span class="hljs-string">    number of edges.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># initialize list with [[0.0, 0.0, 0.0], 0]</span><br><br>    num_points = <span class="hljs-built_in">len</span>(input_points)<br><br>    temp_points = []<br><br>    <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>        temp_points.append([[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>], <span class="hljs-number">0</span>])<br><br>    <span class="hljs-comment"># go through edges_faces using center updating each point</span><br><br>    <span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> edges_faces:<br>        cp = edge[<span class="hljs-number">4</span>]<br>        <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> [edge[<span class="hljs-number">0</span>], edge[<span class="hljs-number">1</span>]]:<br>            tp = temp_points[pointnum][<span class="hljs-number">0</span>]<br>            temp_points[pointnum][<span class="hljs-number">0</span>] = sum_point(tp, cp)<br>            temp_points[pointnum][<span class="hljs-number">1</span>] += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># divide out number of points to get average</span><br><br>    avg_mid_edges = []<br><br>    <span class="hljs-keyword">for</span> tp <span class="hljs-keyword">in</span> temp_points:<br>        ame = div_point(tp[<span class="hljs-number">0</span>], tp[<span class="hljs-number">1</span>])<br>        avg_mid_edges.append(ame)<br><br>    <span class="hljs-keyword">return</span> avg_mid_edges<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_points_faces</span>(<span class="hljs-params">input_points, input_faces</span>):<br>    <span class="hljs-comment"># initialize list with 0</span><br><br>    num_points = <span class="hljs-built_in">len</span>(input_points)<br><br>    points_faces = []<br><br>    <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_points):<br>        points_faces.append(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># loop through faces updating points_faces</span><br><br>    <span class="hljs-keyword">for</span> facenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(input_faces)):<br>        <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> input_faces[facenum]:<br>            points_faces[pointnum] += <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> points_faces<br><br><br><span class="hljs-comment"># 统计每个点属于多少个面</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_new_points</span>(<span class="hljs-params">input_points, points_faces, avg_face_points, avg_mid_edges</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    m1 = (n - 3.0) / n</span><br><span class="hljs-string">    m2 = 1.0 / n</span><br><span class="hljs-string">    m3 = 2.0 / n</span><br><span class="hljs-string">    new_coords = (m1 * old_coords)</span><br><span class="hljs-string">               + (m2 * avg_face_points)</span><br><span class="hljs-string">               + (m3 * avg_mid_edges)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    new_points = []<br><br>    <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(input_points)):<br>        n = points_faces[pointnum]<br>        m1 = (n - <span class="hljs-number">3.0</span>) / n<br>        m2 = <span class="hljs-number">1.0</span> / n<br>        m3 = <span class="hljs-number">2.0</span> / n<br>        old_coords = input_points[pointnum]<br>        p1 = mul_point(old_coords, m1)<br>        afp = avg_face_points[pointnum]<br>        p2 = mul_point(afp, m2)<br>        ame = avg_mid_edges[pointnum]<br>        p3 = mul_point(ame, m3)<br>        p4 = sum_point(p1, p2)<br>        new_coords = sum_point(p4, p3)<br><br>        new_points.append(new_coords)<br><br>    <span class="hljs-keyword">return</span> new_points<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">switch_nums</span>(<span class="hljs-params">point_nums</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Returns tuple of point numbers</span><br><span class="hljs-string">    sorted least to most</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> point_nums[<span class="hljs-number">0</span>] &lt; point_nums[<span class="hljs-number">1</span>]:<br>        <span class="hljs-keyword">return</span> point_nums<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> (point_nums[<span class="hljs-number">1</span>], point_nums[<span class="hljs-number">0</span>])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cmc_subdiv</span>(<span class="hljs-params">input_points, input_faces</span>):<br>    <span class="hljs-comment"># 1. for each face, a face point is created which is the average of all the points of the face.</span><br>    <span class="hljs-comment"># each entry in the returned list is a point (x, y, z).</span><br><br>    face_points = get_face_points(input_points, input_faces)<br><br>    <span class="hljs-comment"># get list of edges with 1 or 2 adjacent faces</span><br>    <span class="hljs-comment"># [pointnum_1, pointnum_2, facenum_1, facenum_2, center] or</span><br>    <span class="hljs-comment"># [pointnum_1, pointnum_2, facenum_1, None, center]</span><br><br>    edges_faces = get_edges_faces(input_points, input_faces)<br><br>    <span class="hljs-comment"># get edge points, a list of points</span><br><br>    edge_points = get_edge_points(input_points, edges_faces, face_points)<br><br>    <span class="hljs-comment"># the average of the face points of the faces the point belongs to (avg_face_points)</span><br><br>    avg_face_points = get_avg_face_points(input_points, input_faces, face_points)<br><br>    <span class="hljs-comment"># the average of the centers of edges the point belongs to (avg_mid_edges)</span><br><br>    avg_mid_edges = get_avg_mid_edges(input_points, edges_faces)<br><br>    <span class="hljs-comment"># how many faces a point belongs to</span><br><br>    points_faces = get_points_faces(input_points, input_faces)<br><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    m1 = (n - 3) / n</span><br><span class="hljs-string">    m2 = 1 / n</span><br><span class="hljs-string">    m3 = 2 / n</span><br><span class="hljs-string">    new_coords = (m1 * old_coords)</span><br><span class="hljs-string">               + (m2 * avg_face_points)</span><br><span class="hljs-string">               + (m3 * avg_mid_edges)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    new_points = get_new_points(input_points, points_faces, avg_face_points, avg_mid_edges)<br><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Then each face is replaced by new faces made with the new points,</span><br><span class="hljs-string"></span><br><span class="hljs-string">    for a triangle face (a,b,c):</span><br><span class="hljs-string">       (a, edge_point ab, face_point abc, edge_point ca)</span><br><span class="hljs-string">       (b, edge_point bc, face_point abc, edge_point ab)</span><br><span class="hljs-string">       (c, edge_point ca, face_point abc, edge_point bc)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    for a quad face (a,b,c,d):</span><br><span class="hljs-string">       (a, edge_point ab, face_point abcd, edge_point da)</span><br><span class="hljs-string">       (b, edge_point bc, face_point abcd, edge_point ab)</span><br><span class="hljs-string">       (c, edge_point cd, face_point abcd, edge_point bc)</span><br><span class="hljs-string">       (d, edge_point da, face_point abcd, edge_point cd)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    face_points is a list indexed by face number so that is</span><br><span class="hljs-string">    easy to get.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    edge_points is a list indexed by the edge number</span><br><span class="hljs-string">    which is an index into edges_faces.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    need to add face_points and edge points to </span><br><span class="hljs-string">    new_points and get index into each.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    then create two new structures</span><br><span class="hljs-string"></span><br><span class="hljs-string">    face_point_nums - list indexes by facenum</span><br><span class="hljs-string">    whose value is the index into new_points</span><br><span class="hljs-string"></span><br><span class="hljs-string">    edge_point num - dictionary with key (pointnum_1, pointnum_2)</span><br><span class="hljs-string">    and value is index into new_points</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># add face points to new_points</span><br><br>    face_point_nums = []<br><br>    <span class="hljs-comment"># point num after next append to new_points</span><br>    next_pointnum = <span class="hljs-built_in">len</span>(new_points)<br><br>    <span class="hljs-keyword">for</span> face_point <span class="hljs-keyword">in</span> face_points:<br>        new_points.append(face_point)<br>        face_point_nums.append(next_pointnum)<br>        next_pointnum += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># add edge points to new_points</span><br><br>    edge_point_nums = <span class="hljs-built_in">dict</span>()<br><br>    <span class="hljs-keyword">for</span> edgenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(edges_faces)):<br>        pointnum_1 = edges_faces[edgenum][<span class="hljs-number">0</span>]<br>        pointnum_2 = edges_faces[edgenum][<span class="hljs-number">1</span>]<br>        edge_point = edge_points[edgenum]<br>        new_points.append(edge_point)<br>        edge_point_nums[(pointnum_1, pointnum_2)] = next_pointnum<br>        next_pointnum += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># new_points now has the points to output. Need new</span><br>    <span class="hljs-comment"># faces</span><br><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    just doing this case for now:</span><br><span class="hljs-string"></span><br><span class="hljs-string">    for a quad face (a,b,c,d):</span><br><span class="hljs-string">       (a, edge_point ab, face_point abcd, edge_point da)</span><br><span class="hljs-string">       (b, edge_point bc, face_point abcd, edge_point ab)</span><br><span class="hljs-string">       (c, edge_point cd, face_point abcd, edge_point bc)</span><br><span class="hljs-string">       (d, edge_point da, face_point abcd, edge_point cd)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    new_faces will be a list of lists where the elements are like this:</span><br><span class="hljs-string"></span><br><span class="hljs-string">    [pointnum_1, pointnum_2, pointnum_3, pointnum_4]</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    new_faces = []<br><br>    <span class="hljs-keyword">for</span> oldfacenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(input_faces)):<br>        oldface = input_faces[oldfacenum]<br>        <span class="hljs-comment"># 4 point face</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(oldface) == <span class="hljs-number">4</span>:<br>            a = oldface[<span class="hljs-number">0</span>]<br>            b = oldface[<span class="hljs-number">1</span>]<br>            c = oldface[<span class="hljs-number">2</span>]<br>            d = oldface[<span class="hljs-number">3</span>]<br>            face_point_abcd = face_point_nums[oldfacenum]<br>            edge_point_ab = edge_point_nums[switch_nums((a, b))]<br>            edge_point_da = edge_point_nums[switch_nums((d, a))]<br>            edge_point_bc = edge_point_nums[switch_nums((b, c))]<br>            edge_point_cd = edge_point_nums[switch_nums((c, d))]<br>            new_faces.append((a, edge_point_ab, face_point_abcd, edge_point_da))<br>            new_faces.append((b, edge_point_bc, face_point_abcd, edge_point_ab))<br>            new_faces.append((c, edge_point_cd, face_point_abcd, edge_point_bc))<br>            new_faces.append((d, edge_point_da, face_point_abcd, edge_point_cd))<br><br>    <span class="hljs-keyword">return</span> new_points, new_faces<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">graph_output</span>(<span class="hljs-params">output_points, output_faces, fig</span>):<br>    ax = fig.add_subplot(<span class="hljs-number">111</span>, projection=<span class="hljs-string">&#x27;3d&#x27;</span>)<br><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Plot each face</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">for</span> facenum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(output_faces)):<br>        curr_face = output_faces[facenum]<br>        xcurr = []<br>        ycurr = []<br>        zcurr = []<br>        <span class="hljs-keyword">for</span> pointnum <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(curr_face)):<br>            xcurr.append(output_points[curr_face[pointnum]][<span class="hljs-number">0</span>])<br>            ycurr.append(output_points[curr_face[pointnum]][<span class="hljs-number">1</span>])<br>            zcurr.append(output_points[curr_face[pointnum]][<span class="hljs-number">2</span>])<br>        xcurr.append(output_points[curr_face[<span class="hljs-number">0</span>]][<span class="hljs-number">0</span>])<br>        ycurr.append(output_points[curr_face[<span class="hljs-number">0</span>]][<span class="hljs-number">1</span>])<br>        zcurr.append(output_points[curr_face[<span class="hljs-number">0</span>]][<span class="hljs-number">2</span>])<br><br>        ax.plot(xcurr, ycurr, zcurr, color=<span class="hljs-string">&#x27;b&#x27;</span>)<br><br><br><span class="hljs-comment"># cube</span><br><br>input_points = [<br>    [-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],<br>    [-<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],<br>    [<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],<br>    [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],<br>    [<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>],<br>    [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>],<br>    [-<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>],<br>    [-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, -<span class="hljs-number">1.0</span>]<br>]<br><br>input_faces = [<br>    [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>    [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>    [<span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>],<br>    [<span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>],<br>    [<span class="hljs-number">7</span>, <span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>    [<span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>],<br>]<br><br>iterations = <span class="hljs-number">7</span><br><br>plt.ion()<br>output_points, output_faces = input_points, input_faces<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iterations):<br>    fig = plt.figure(<span class="hljs-number">1</span>)<br>    plt.clf()<br>    graph_output(output_points, output_faces, fig)<br>    output_points, output_faces = cmc_subdiv(output_points, output_faces)<br><br>    plt.pause(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><h2 id="6-效果"><a href="#6-效果" class="headerlink" title="6.效果"></a>6.效果</h2><p>输入数据为一个立方体，包含八个顶点坐标，对其进行细分。<br>输入数据：</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/13.png"></p><p>细分1次的结果：</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/14.png"></p><p>细分2次的结果：</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/15.png"></p><p>细分4次的结果：</p><p><img src="/2024/04/09/%E5%BB%BA%E6%A8%A1/%E5%BB%BA%E6%A8%A1%E7%AE%97%E6%B3%95/%E4%B8%89%E7%BB%B4%E7%BD%91%E6%A0%BC%E7%BB%86%E5%88%86%E7%AE%97%E6%B3%95/16.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>建模算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>建模</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>语义依存分析任务！🐯</title>
    <link href="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E4%BB%BB%E5%8A%A1/"/>
    <url>/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="语义依存分析任务"><a href="#语义依存分析任务" class="headerlink" title="语义依存分析任务"></a>语义依存分析任务</h1><p>让机器能够理解自然语言，需要对原始文本自底向上进行分词、词性标注、命名实体识别和句法分析，若想要机器更智能，像人一样理解和运用语言，还需要对句子进行更深一层的分析，即句子级语义分析。</p><p>语义依存分析将会是通往语义深层理解的一条蹊径。语义依存分析是指在句子结构中分析实词和实词之间的语义关系，这种关系是一种事实上或逻辑上的关系，且只有当词语进入到句子时才会存在。语义依存分析的目的即回答句子的”Who did what to whom when and where”的问题。例如句子“张三昨天告诉李四一个秘密”，语义依存分析可以回答四个问题，即谁告诉了李四一个秘密，张三告诉谁一个秘密，张三什么时候告诉李四一个秘密，张三告诉李四什么。</p><p>举例：</p><p><strong>奥巴马昨晚在白宫发表了演说。</strong></p><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[&#123;<span class="hljs-string">&#x27;head&#x27;</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>], <span class="hljs-string">&#x27;label&#x27;</span>: [<span class="hljs-string">&#x27;AGT&#x27;</span>, <span class="hljs-string">&#x27;TIME&#x27;</span>, <span class="hljs-string">&#x27;mRELA&#x27;</span>, <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;Root&#x27;</span>, <span class="hljs-string">&#x27;mDEPD&#x27;</span>, <span class="hljs-string">&#x27;CONT&#x27;</span>, <span class="hljs-string">&#x27;mPUNC&#x27;</span>]&#125;]<br></code></pre></td></tr></table></figure><p>图示：</p><p><img src="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E4%BB%BB%E5%8A%A1/1.png"></p><p>具体标注：</p><p><img src="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E4%BB%BB%E5%8A%A1/2.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP任务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LTP库的使用！🐈</title>
    <link href="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/LTP%E5%BA%93/"/>
    <url>/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/LTP%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="LTP库的使用"><a href="#LTP库的使用" class="headerlink" title="LTP库的使用"></a>LTP库的使用</h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install -U ltp ltp-core ltp-extension -i https://pypi.org/simple<br></code></pre></td></tr></table></figure><h2 id="2-本地模型调用"><a href="#2-本地模型调用" class="headerlink" title="2.本地模型调用"></a>2.本地模型调用</h2><p>从huggingface下载模型后保存在本地。用下述代码进行本地调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ltp = LTP(<span class="hljs-string">&quot;D:/Python/MimicSolver/conf/model/LTP_Base1&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="3-应用举例"><a href="#3-应用举例" class="headerlink" title="3.应用举例"></a>3.应用举例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> ltp <span class="hljs-keyword">import</span> LTP<br><br>ltp = LTP(<span class="hljs-string">&quot;LTP/small&quot;</span>)  <span class="hljs-comment"># 默认加载 Small 模型</span><br><br><span class="hljs-comment"># 将模型移动到 GPU 上</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    <span class="hljs-comment"># ltp.cuda()</span><br>    ltp.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br>output = ltp.pipeline([<span class="hljs-string">&quot;他叫汤姆去拿外衣。&quot;</span>], tasks=[<span class="hljs-string">&quot;cws&quot;</span>, <span class="hljs-string">&quot;pos&quot;</span>, <span class="hljs-string">&quot;ner&quot;</span>, <span class="hljs-string">&quot;srl&quot;</span>, <span class="hljs-string">&quot;dep&quot;</span>, <span class="hljs-string">&quot;sdp&quot;</span>])<br><span class="hljs-comment"># 使用字典格式作为返回结果</span><br><span class="hljs-built_in">print</span>(output.cws) <span class="hljs-comment"># print(output[0]) / print(output[&#x27;cws&#x27;]) # 也可以使用下标访问</span><br><span class="hljs-built_in">print</span>(output.pos)<br><span class="hljs-built_in">print</span>(output.sdp)<br><span class="hljs-built_in">print</span>(output.ner)<br><br><span class="hljs-comment"># 使用感知机算法实现的分词、词性和命名实体识别，速度比较快，但是精度略低</span><br>ltp = LTP(<span class="hljs-string">&quot;LTP/legacy&quot;</span>)<br><span class="hljs-comment"># cws, pos, ner = ltp.pipeline([&quot;他叫汤姆去拿外衣。&quot;], tasks=[&quot;cws&quot;, &quot;ner&quot;]).to_tuple() # error: NER 需要 词性标注任务的结果</span><br>cws, pos, ner = ltp.pipeline([<span class="hljs-string">&quot;他叫汤姆去拿外衣。&quot;</span>], tasks=[<span class="hljs-string">&quot;cws&quot;</span>, <span class="hljs-string">&quot;pos&quot;</span>, <span class="hljs-string">&quot;ner&quot;</span>]).to_tuple() <span class="hljs-comment"># to tuple 可以自动转换为元组格式</span><br><span class="hljs-comment"># 使用元组格式作为返回结果</span><br><span class="hljs-built_in">print</span>(cws, pos, ner)<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p>分词 <code>cws</code>、词性 <code>pos</code>、命名实体标注 <code>ner</code>、语义角色标注 <code>srl</code>、依存句法分析 <code>dep</code>、语义依存分析树 <code>sdp</code>、语义依存分析图 <code>sdpg</code>。</p><p>输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">[[<span class="hljs-string">&#x27;他&#x27;</span>, <span class="hljs-string">&#x27;叫&#x27;</span>, <span class="hljs-string">&#x27;汤姆&#x27;</span>, <span class="hljs-string">&#x27;去&#x27;</span>, <span class="hljs-string">&#x27;拿&#x27;</span>, <span class="hljs-string">&#x27;外衣&#x27;</span>, <span class="hljs-string">&#x27;。&#x27;</span>]]<br>[[<span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>, <span class="hljs-string">&#x27;nh&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>, <span class="hljs-string">&#x27;n&#x27;</span>, <span class="hljs-string">&#x27;wp&#x27;</span>]]<br>[&#123;<span class="hljs-string">&#x27;head&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>], <span class="hljs-string">&#x27;label&#x27;</span>: [<span class="hljs-string">&#x27;AGT&#x27;</span>, <span class="hljs-string">&#x27;Root&#x27;</span>, <span class="hljs-string">&#x27;DATV&#x27;</span>, <span class="hljs-string">&#x27;eSUCC&#x27;</span>, <span class="hljs-string">&#x27;eSUCC&#x27;</span>, <span class="hljs-string">&#x27;PAT&#x27;</span>, <span class="hljs-string">&#x27;mPUNC&#x27;</span>]&#125;]<br>[[(<span class="hljs-string">&#x27;Nh&#x27;</span>, <span class="hljs-string">&#x27;汤姆&#x27;</span>)]]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>语义角色标注任务！🐯</title>
    <link href="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/"/>
    <url>/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="语义角色标注任务"><a href="#语义角色标注任务" class="headerlink" title="语义角色标注任务"></a>语义角色标注任务</h1><p>语义角色标注是一种浅层语义分析技术，以句子为单位，分析句子的<strong>谓词-论元</strong>结构，其理论基础来源于Fillmore(1968)年提出的格语法，不对句子所包含的语义信息进行深入分析。具体来说，语义角色标注的任务就是以句子的谓词为中心，研究句子中各成分与谓词之间的关系，并且用语义角色来描述他们之间的关系。例如如下所示</p><p><img src="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/1.png"></p><p>这个句子中包括：</p><ol><li>谓词 “发表”</li><li>施事 “奥巴马”</li><li>受事 “演说”</li><li>时间 “昨晚”</li><li>地点 “在白宫”</li></ol><p>语义角色标注就是要针对句子中的（核心）谓词来确定其他论元以及其他论元的角色。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># LTP输出结果</span><br>[[&#123;<span class="hljs-string">&#x27;predicate&#x27;</span>: <span class="hljs-string">&#x27;发表&#x27;</span>, <span class="hljs-string">&#x27;arguments&#x27;</span>: [(<span class="hljs-string">&#x27;A0&#x27;</span>, <span class="hljs-string">&#x27;奥巴马&#x27;</span>), (<span class="hljs-string">&#x27;ARGM-TMP&#x27;</span>, <span class="hljs-string">&#x27;昨晚&#x27;</span>), (<span class="hljs-string">&#x27;ARGM-LOC&#x27;</span>, <span class="hljs-string">&#x27;在白宫&#x27;</span>), (<span class="hljs-string">&#x27;A1&#x27;</span>, <span class="hljs-string">&#x27;演说&#x27;</span>)]&#125;]]<br></code></pre></td></tr></table></figure><p>标签：</p><p>A0：施事</p><p>A1：受事</p><p>ARGM-TMP：时间</p><p>ARGM-LOC：地点</p><p>更具体的标签：</p><p><img src="/2024/04/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E4%BB%BB%E5%8A%A1/%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/2.png"></p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP任务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MimicSolver更新过程!🐡</title>
    <link href="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/"/>
    <url>/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="MimicSolver更新过程"><a href="#MimicSolver更新过程" class="headerlink" title="MimicSolver更新过程"></a>MimicSolver更新过程</h1><h2 id="1-修改json文件"><a href="#1-修改json文件" class="headerlink" title="1.修改json文件"></a>1.修改json文件</h2><p>以SceneCombination为例，分别修改：</p><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/1.png"></p><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/2.png"></p><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/3.png"></p><p>该例为新增路径：APText—-SceneCombination—-OutputSolution</p><h2 id="2-修改主函数"><a href="#2-修改主函数" class="headerlink" title="2.修改主函数"></a>2.修改主函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> mimic <span class="hljs-keyword">import</span> UserConfig, SolvingEngine, MimicConfig<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br><br>    start_path = <span class="hljs-string">&quot;D:/Python/MimicSolver/tests/usage/start.yaml&quot;</span><br>    user_cfg = UserConfig(start_path)<br><br>    mimicConfig = MimicConfig()  <br><br>    solving_engine = SolvingEngine(mimicConfig)<br><br>    feed_input_ap = &#123;<br>        <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;有一堆黄沙，先运走18吨，剩下的用7辆车运完，每车运6吨，这堆黄沙共有多少吨？&quot;</span>,<br>        <span class="hljs-string">&quot;expression&quot;</span>: <span class="hljs-string">&quot;x=18+6*7&quot;</span><br>    &#125;<br><br>    solving_engine.run(feed_input_ap)<br><br>    <span class="hljs-comment"># 深拷贝来解决获取对象参数改变，列表内容同时改变的情况</span><br>    result = solving_engine.get_solving_result()<br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> result.items():<br>        <span class="hljs-keyword">if</span> value != [] <span class="hljs-keyword">and</span> value != <span class="hljs-string">&quot;&quot;</span> <span class="hljs-keyword">and</span> value != &#123;&#125;:<br>            <span class="hljs-built_in">print</span>(key, value)<br><br></code></pre></td></tr></table></figure><p>1.重点修改<code>feed_input_ap</code>。且<strong>字典的key值应在SharedStateData的属性中</strong>。</p><h2 id="3-修改MimicConfig"><a href="#3-修改MimicConfig" class="headerlink" title="3.修改MimicConfig"></a>3.修改MimicConfig</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/4.png"></p><h2 id="4-新增state"><a href="#4-新增state" class="headerlink" title="4.新增state"></a>4.新增state</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/5.png"></p><h2 id="5-修改其他state的decide"><a href="#5-修改其他state的decide" class="headerlink" title="5.修改其他state的decide"></a>5.修改其他state的decide</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/6.png"></p><h2 id="6-修改state-init-py"><a href="#6-修改state-init-py" class="headerlink" title="6.修改state&#x2F;init.py"></a>6.修改state&#x2F;init.py</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/7.png"></p><h2 id="7-新增transit"><a href="#7-新增transit" class="headerlink" title="7.新增transit"></a>7.新增transit</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">APTextToSceneCombination</span>(<span class="hljs-title class_ inherited__">Transit</span>):<br>    transit_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;APTextToSceneCombination&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_check</span>(<span class="hljs-params">self, transitors: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Executes the transit check, checking whether all transitors have been defined.</span><br><span class="hljs-string">        :param transitors:</span><br><span class="hljs-string">        :raises AssertionError: If operation has no predecessors.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        functions = [<br>            fn_name<br>            <span class="hljs-keyword">for</span> fn_name, _ <span class="hljs-keyword">in</span> inspect.getmembers(<br>                APTextToSceneCombination, predicate=inspect.isfunction<br>            )<br>        ]<br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> transitors:<br>            <span class="hljs-keyword">if</span> t <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> functions:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;transitors %s has not defined&quot;</span>.<span class="hljs-built_in">format</span>(t))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">scene_reasoning</span>(<span class="hljs-params">self, shared_state_data: SharedStateData</span>):<br>        sentence= shared_state_data.text<br>        model_path1 = <span class="hljs-string">&#x27;D:/Python/MimicSolver/dl_model/trained_model/scene_trm/best_model1.pth&#x27;</span><br>        model_path2 = <span class="hljs-string">&#x27;D:/Python/MimicSolver/dl_model/trained_model/scene_trm/best_model2.pth&#x27;</span><br><br>        result1 = predict_scene_trm1(sentence, model_path1)<br>        result2 = predict_scene_trm2(sentence, model_path2)<br><br>        <span class="hljs-built_in">print</span>(result1,result2)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SceneCombinationToOutputSolution</span>(<span class="hljs-title class_ inherited__">Transit</span>):<br>    transit_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;SceneCombinationToOutputSolution&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_check</span>(<span class="hljs-params">self, transitors: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Executes the transit check, checking whether all transitors have been defined.</span><br><span class="hljs-string">        :param transitors:</span><br><span class="hljs-string">        :raises AssertionError: If operation has no predecessors.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        functions = [<br>            fn_name<br>            <span class="hljs-keyword">for</span> fn_name, _ <span class="hljs-keyword">in</span> inspect.getmembers(<br>                SceneCombinationToOutputSolution, predicate=inspect.isfunction<br>            )<br>        ]<br>        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> transitors:<br>            <span class="hljs-keyword">if</span> t <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> functions:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;transitors %s has not defined&quot;</span>.<span class="hljs-built_in">format</span>(t))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">scene_compute</span>(<span class="hljs-params">self, shared_state_data: SharedStateData</span>):<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;scene_compute&quot;</span>)<br></code></pre></td></tr></table></figure><p>1.修改check</p><p>2.修改transit类中的具体执行函数，改成对应的的transit名字</p><h2 id="8-修改transit-init-py"><a href="#8-修改transit-init-py" class="headerlink" title="8.修改transit&#x2F;init.py"></a>8.修改transit&#x2F;init.py</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/8.png"></p><h2 id="9-修改core-init-py"><a href="#9-修改core-init-py" class="headerlink" title="9.修改core&#x2F;init.py"></a>9.修改core&#x2F;init.py</h2><p><img src="/2024/03/30/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MimicSolver/MimicSolver%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B/9.png"></p><h2 id="10-修改ShareStateData"><a href="#10-修改ShareStateData" class="headerlink" title="10.修改ShareStateData"></a>10.修改ShareStateData</h2><p>如需新增状态，则修改</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP项目实战</category>
      
      <category>MWP</category>
      
      <category>MimicSolver</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bert预训练!🌞</title>
    <link href="/2024/03/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Bert%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    <url>/2024/03/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Bert%E9%A2%84%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bert介绍！💐</title>
    <link href="/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/"/>
    <url>/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/</url>
    
    <content type="html"><![CDATA[<h1 id="Bert介绍"><a href="#Bert介绍" class="headerlink" title="Bert介绍"></a>Bert介绍</h1><h2 id="1-模型结构"><a href="#1-模型结构" class="headerlink" title="1.模型结构"></a>1.模型结构</h2><p><img src="/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/1.png"></p><p>模型可以简单的归纳为三个部分，分别是输入层，中间层，以及输出层。这些都和transformer的encoder一致，除了输入层有略微变化。</p><h3 id="1-1-输入层"><a href="#1-1-输入层" class="headerlink" title="1.1 输入层"></a>1.1 输入层</h3><p><img src="/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/2.png"></p><p>为了使得BERT模型适应下游的任务（比如说分类任务，以及句子关系QA的任务），输入将被改造成[CLS]+句子A（+[SEP]+句子B+[SEP]） 其中</p><ul><li>[CLS]: 代表的是分类任务的特殊token，它的输出就是模型的pooler output</li><li>[SEP]：分隔符</li><li>句子A以及句子B是模型的输入文本，其中句子B可以为空，则输入变为[CLS]+句子A</li></ul><p>因为trasnformer无法获得字的位置信息，BERT和transformer一样也加入了 绝对位置 position encoding，但是和transformer不同的是，BERT使用的是不是transformer对应的函数型(functional)的encoding方式，而是直接采用类似word embedding的方式（Parametric），直接获得position embedding。</p><p>因为我们对输入进行了改造，使得模型可能有多个句子Segment的输入，所以我们也需要加入segment的embedding，例如<code>[CLS], A_1, A_2, A_3,[SEP], B_1, B_2, B_3, [SEP]</code> 对应的segment的输入是<code>[0,0,0,0,0,1,1,1,1]</code>, 然后在根据segment id进行embedding_lookup得到segment embedding。 code snippet如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">tokens.append(<span class="hljs-string">&quot;[CLS]&quot;</span>)<br>segment_ids.append(<span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens_a:<br>  tokens.append(token)<br>  segment_ids.append(<span class="hljs-number">0</span>)<br><br>tokens.append(<span class="hljs-string">&quot;[SEP]&quot;</span>)<br>segment_ids.append(<span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens_b:<br>  tokens.append(token)<br>  segment_ids.append(<span class="hljs-number">1</span>)<br>tokens.append(<span class="hljs-string">&quot;[SEP]&quot;</span>)<br>segment_ids.append(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="1-2-中间层"><a href="#1-2-中间层" class="headerlink" title="1.2 中间层"></a>1.2 中间层</h3><p><img src="/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/3.png"></p><p>模型的中间层和transformer的encoder一样，都是由self-attention layer + ADD&amp;BatchNorm layer + FFN 层组成的。</p><h3 id="1-3-输出层"><a href="#1-3-输出层" class="headerlink" title="1.3 输出层"></a>1.3 输出层</h3><p><img src="/2024/03/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Bert/4.png"></p><p>模型的每一个输入都对应这一个输出，根据不同的任务我们可以选择不同的输出，主要有两类输出</p><ul><li>pooler output：对应的是[CLS]的输出。</li><li>sequence output：对应的是所有其他的输入字的最后输出。</li></ul><h2 id="2-模型框架"><a href="#2-模型框架" class="headerlink" title="2.模型框架"></a>2.模型框架</h2><p>BERT提出的是一个框架，主要由两个阶段组成。分别是Pre-training以及Fine-Tuning。</p><h3 id="2-1-预训练"><a href="#2-1-预训练" class="headerlink" title="2.1 预训练"></a>2.1 预训练</h3><h4 id="2-1-1-MLM"><a href="#2-1-1-MLM" class="headerlink" title="2.1.1 MLM"></a>2.1.1 MLM</h4><p>BERT第一次采用了mask language model（MLM）任务，这就类似于完形填空(Cloze task)。</p><p>具体的做法： 我们会随机mask输入的几个词，然后预测这个词。但是这样子做的坏处是因为fine-tuning阶段中并没有[MASK] token，所以导致了pre-training 和 ﬁne-tuning的不匹配的情况。所以为了减轻这个问题，文章中采用的做法是：对于要MASK 15%的tokens，</p><ul><li>(1) 80%的情况是替换成[MASK]</li><li>(2) 10%的情况是替换为随机的token</li><li>(3) 10%的情况是保持不变 具体的code snippet如下。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> cand_indexes:<br>  <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(masked_lms) &gt;= num_to_predict: <span class="hljs-comment"># 15% of total tokens</span><br>    <span class="hljs-keyword">break</span><br>  ...<br>  masked_token = <span class="hljs-literal">None</span><br>  <span class="hljs-comment"># 80% of the time, replace with [MASK]</span><br>  <span class="hljs-keyword">if</span> rng.random() &lt; <span class="hljs-number">0.8</span>:<br>    masked_token = <span class="hljs-string">&quot;[MASK]&quot;</span><br>  <span class="hljs-keyword">else</span>:<br>    <span class="hljs-comment"># 10% of the time, keep original</span><br>    <span class="hljs-keyword">if</span> rng.random() &lt; <span class="hljs-number">0.5</span>:<br>      masked_token = tokens[index]<br>    <span class="hljs-comment"># 10% of the time, replace with random word</span><br>    <span class="hljs-keyword">else</span>:<br>      masked_token = vocab_words[rng.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(vocab_words) - <span class="hljs-number">1</span>)]<br><br>  output_tokens[index] = masked_token<br></code></pre></td></tr></table></figure><h4 id="2-1-2-NSP"><a href="#2-1-2-NSP" class="headerlink" title="2.1.2 NSP"></a>2.1.2 NSP</h4><p>为了适配下游任务，使得模型懂得句子之间的关系，BERT加了一个新的训练任务，预测两个句子是不是下一句的关系。</p><p>具体来说：50%的概率，句子A和句子B是来自同一个文档的上下句，标记为<code>is_random_next=False</code>, 50%的概率，句子A和句子B不是同一个文档的上下句，具体的做法就是，采用从其他的文档(document)中，加入新的连续句子(segments)作为句子B。具体参考<code>create_instances_from_document</code>函数。</p><p>首先我们会有一个all_documents存储所有的documents，每个documents是由句子segemnts组成的，每个segment是由单个token组成的。我们首先初始化一个chunk数组，每次都往chunk中添加同一个document中的一个句子，当chunk的长度大于target的长度（此处target的长度一般是<code>max_seq_length</code>，但是为了匹配下游任务，target的长度可以设置一定比例<code>short_seq_prob</code>的长度少于<code>max_seq_length</code>）的时候，随机选择一个某个句子作为分割点，前面的作为句子A，后面的作为句子B。 chunk &#x3D; [Sentence1, Sentence2,…, SentenceN], 我们随机选择选择一个句子作为句子A的结尾，例如2作为句子结尾，则句子A为&#x3D;[Sentence1, Sentence2]。我们有50%的几率选择剩下的句子[Sentence3,…SentenceN]作为句子B，或者50%的几率时的句子B是从其他文档中的另外多个句子。</p><p>这时候可能会导致我们的训练样本的总长度<code>len(input_ids)</code>大于或者小于我们的需要的训练样本长度<code>max_seq_length</code>。</p><ul><li>如果<code>len(input_ids) &gt; max_seq_length</code>, 具体的做法是分别删除比较长的一个句子中的头(50%)或尾(50%)的token</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">truncate_seq_pair</span>(<span class="hljs-params">tokens_a, tokens_b, max_num_tokens, rng</span>):<br><span class="hljs-string">&quot;&quot;&quot;Truncates a pair of sequences to a maximum sequence length.&quot;&quot;&quot;</span><br>  <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    total_length = <span class="hljs-built_in">len</span>(tokens_a) + <span class="hljs-built_in">len</span>(tokens_b)<br>    <span class="hljs-keyword">if</span> total_length &lt;= max_num_tokens:<br>      <span class="hljs-keyword">break</span><br><br>    trunc_tokens = tokens_a <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(tokens_a) &gt; <span class="hljs-built_in">len</span>(tokens_b) <span class="hljs-keyword">else</span> tokens_b<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(trunc_tokens) &gt;= <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># We want to sometimes truncate from the front and sometimes from the</span><br>    <span class="hljs-comment"># back to add more randomness and avoid biases.</span><br>    <span class="hljs-keyword">if</span> rng.random() &lt; <span class="hljs-number">0.5</span>:<br>      <span class="hljs-keyword">del</span> trunc_tokens[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">else</span>:<br>      trunc_tokens.pop()<br></code></pre></td></tr></table></figure><ul><li>如果<code>len(input_ids) &lt; max_seq_length</code>, 采用的做法是补0。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(input_ids) &lt; max_seq_length:<br>   input_ids.append(<span class="hljs-number">0</span>)<br>   input_mask.append(<span class="hljs-number">0</span>)<br>   segment_ids.append(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>根据我们的两个任务，我们预训练模型的输入主要由以下7个特征组成。</p><ul><li><code>input_ids</code>: 输入的token对应的id</li><li><code>input_mask</code>: 输入的mask，1代表是正常输入，0代表的是padding的输入</li><li><code>segment_ids</code>: 输入的0：代表句子A或者padding句子，1代表句子B</li><li><code>masked_lm_positions</code>：我们mask的token的位置</li><li><code>masked_lm_ids</code>：我们mask的token的对应id</li><li><code>masked_lm_weights</code>：我们mask的token的权重，1代表是真实mask的，0代表的是padding的mask</li><li><code>next_sentence_labels</code>：句子A和B是否是上下句</li></ul><h3 id="2-2-微调"><a href="#2-2-微调" class="headerlink" title="2.2 微调"></a>2.2 微调</h3><p>在Fine-Tuning阶段的时候，我们可以简单的plugin任务特定的输入和输出，作为训练。 例如：</p><ul><li>2句子 pairs： 相似度任务,</li><li>假设-前提 pairs： 推理任务,</li><li>问题-文章 pairs ： QA任务</li><li>text−∅ pair： 文本分类 or 序列标注.</li></ul><p>[CLS] representation 被喂到 最后一层作为classiﬁcation的结果例如 推理任务或者 情感分析任务。</p><p>在这个任务中，就不需要MLM任务以及NSP任务所需要的输入了，所以就只有固定输入features(<code>input_ids</code>, <code>input_mask</code>, <code>segment_ids</code>)以及任务特定features</p><p>例如分类任务的输入特征：</p><ul><li><code>input_ids</code>: 输入的token对应的id</li><li><code>input_mask</code>: 输入的mask，1代表是正常输入，0代表的是padding的输入</li><li><code>segment_ids</code>: 输入的0：代表句子A或者padding句子，1代表句子B</li><li><code>label_ids</code>：输入的样本的label</li></ul>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>transformer语言翻译!🌞</title>
    <link href="/2024/03/19/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/transformer%E8%AF%AD%E8%A8%80%E7%BF%BB%E8%AF%91/"/>
    <url>/2024/03/19/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/transformer%E8%AF%AD%E8%A8%80%E7%BF%BB%E8%AF%91/</url>
    
    <content type="html"><![CDATA[<h1 id="transformer语言翻译"><a href="#transformer语言翻译" class="headerlink" title="transformer语言翻译"></a>transformer语言翻译</h1><h2 id="1-数据来源和处理"><a href="#1-数据来源和处理" class="headerlink" title="1.数据来源和处理"></a>1.数据来源和处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python">SRC_LANGUAGE = <span class="hljs-string">&#x27;de&#x27;</span><br>TGT_LANGUAGE = <span class="hljs-string">&#x27;en&#x27;</span><br><br>token_transform = &#123;&#125;<br>vocab_transform = &#123;&#125;<br><br>token_transform[SRC_LANGUAGE] = get_tokenizer(<span class="hljs-string">&#x27;spacy&#x27;</span>, language=<span class="hljs-string">&#x27;de_core_news_md-3.7.0&#x27;</span>)<br>token_transform[TGT_LANGUAGE] = get_tokenizer(<span class="hljs-string">&#x27;spacy&#x27;</span>, language=<span class="hljs-string">&#x27;en_core_web_md-3.7.1&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">yield_tokens</span>(<span class="hljs-params">data_iter: Iterable, language: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>    language_index = &#123;SRC_LANGUAGE: <span class="hljs-number">0</span>, TGT_LANGUAGE: <span class="hljs-number">1</span>&#125;<br><br>    <span class="hljs-keyword">for</span> data_sample <span class="hljs-keyword">in</span> data_iter:<br>        tokenized_text = token_transform[language](data_sample[language_index[language]])<br>        <span class="hljs-comment"># print(tokenized_text)</span><br>        <span class="hljs-keyword">yield</span> tokenized_text<br><br><br>UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span><br><br>special_symbols = [<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>]<br><br>train_path_en = <span class="hljs-string">&#x27;train.en&#x27;</span><br>train_path_de = <span class="hljs-string">&#x27;train.de&#x27;</span><br>data_pipe_train_en = dp.<span class="hljs-built_in">iter</span>.IterableWrapper([train_path_en])<br>data_pipe_train_de = dp.<span class="hljs-built_in">iter</span>.IterableWrapper([train_path_de])<br><br>train_src_data_dp = dp.<span class="hljs-built_in">iter</span>.FileOpener(data_pipe_train_de, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>).readlines(<br>    return_path=<span class="hljs-literal">False</span>, strip_newline=<span class="hljs-literal">True</span><br>)<br><br>train_tgt_data_dp = dp.<span class="hljs-built_in">iter</span>.FileOpener(data_pipe_train_en, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>).readlines(<br>    return_path=<span class="hljs-literal">False</span>, strip_newline=<span class="hljs-literal">True</span><br>)<br><br>train_iter = train_src_data_dp.<span class="hljs-built_in">zip</span>(train_tgt_data_dp).shuffle().set_shuffle(<span class="hljs-literal">False</span>).sharding_filter()<br><br><span class="hljs-comment"># for sample in train_iter:</span><br><span class="hljs-comment">#     print(sample)</span><br><br><span class="hljs-keyword">for</span> ln <span class="hljs-keyword">in</span> [SRC_LANGUAGE, TGT_LANGUAGE]:<br>    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),<br>                                                    min_freq=<span class="hljs-number">1</span>,<br>                                                    specials=special_symbols,<br>                                                    special_first=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">for</span> ln <span class="hljs-keyword">in</span> [SRC_LANGUAGE, TGT_LANGUAGE]:<br>    vocab_transform[ln].set_default_index(UNK_IDX)<br><br><span class="hljs-comment"># print(vocab_transform[TGT_LANGUAGE].get_stoi())</span><br></code></pre></td></tr></table></figure><h2 id="2-使用-Transformer-的-Seq2Seq-网络"><a href="#2-使用-Transformer-的-Seq2Seq-网络" class="headerlink" title="2.使用 Transformer 的 Seq2Seq 网络"></a>2.使用 Transformer 的 Seq2Seq 网络</h2><h3 id="2-1-位置编码"><a href="#2-1-位置编码" class="headerlink" title="2.1 位置编码"></a>2.1 位置编码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">DEVICE = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><br><span class="hljs-comment"># print(DEVICE.type)</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 emb_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 dropout: <span class="hljs-built_in">float</span>,</span><br><span class="hljs-params">                 maxlen: <span class="hljs-built_in">int</span> = <span class="hljs-number">5000</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># (emb_size/2)的一维张量</span><br>        den = torch.exp(- torch.arange(<span class="hljs-number">0</span>, emb_size, <span class="hljs-number">2</span>) * math.log(<span class="hljs-number">10000</span>) / emb_size)<br>        <span class="hljs-comment"># (5000, 1)的二维张量</span><br>        pos = torch.arange(<span class="hljs-number">0</span>, maxlen).reshape(maxlen, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># (5000, emb_size)的二维全0张量</span><br>        pos_embedding = torch.zeros((maxlen, emb_size))<br>        pos_embedding[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(pos * den)<br>        pos_embedding[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(pos * den)<br>        pos_embedding = pos_embedding.unsqueeze(-<span class="hljs-number">2</span>)<br><br>        self.dropout = nn.Dropout(dropout)<br>        self.register_buffer(<span class="hljs-string">&#x27;pos_embedding&#x27;</span>, pos_embedding)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, token_embedding: Tensor</span>):<br>        <span class="hljs-comment"># pos_embedding[:token_embedding.size(0), :]，其中token_embedding.size(0)是获取输入字符串的长度，所以在初始pos_embedding时会用maxlen的大小</span><br>        <span class="hljs-keyword">return</span> self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(<span class="hljs-number">0</span>), :])<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>1.一旦使用 <code>self.register_buffer(&#39;pos_embedding&#39;, pos_embedding)</code> 将 <code>pos_embedding</code> 注册为模型的缓冲区，就可以使用 <code>self.pos_embedding</code> 来调用它。</p><p>2.<strong>为什么要注册到缓冲区？</strong>在 PyTorch 中，模型的参数通常是通过 <code>nn.Parameter</code> 对象进行管理的，这些参数会随着模型的训练而更新。然而，并非所有的模型参数都需要在训练过程中被更新。有些参数是在模型的初始化阶段就固定下来的，比如在 Transformer 模型中的位置编码。</p><p>对于这种不需要更新的固定参数，将它们注册为模型的缓冲区是一个比较好的做法，这样做有几个好处：</p><ol><li><strong>状态保存和加载</strong>：注册为缓冲区的参数会被包含在模型的状态字典（state_dict）中，因此在保存模型时，这些参数会自动保存。在加载模型时，这些参数也会被自动加载，而不需要额外的处理。</li><li><strong>GPU&#x2F;CPU 转移</strong>：当模型移动到 GPU 或者 CPU 上时，注册为缓冲区的参数也会自动跟着移动，而不需要额外的处理。这样可以使得代码更具有通用性，不需要针对不同设备编写不同的逻辑。</li><li><strong>代码可读性和可维护性</strong>：通过将不需要更新的参数注册为缓冲区，可以更加清晰地表达模型结构。这样可以使得代码更易于理解和维护。</li></ol><p>综上所述，将不需要更新的固定参数注册为模型的缓冲区是一种良好的实践，能够提高代码的可读性、可维护性，并且能够自动处理状态保存、加载和设备转移等问题。</p><h3 id="2-2-字符编码"><a href="#2-2-字符编码" class="headerlink" title="2.2 字符编码"></a>2.2 字符编码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenEmbedding</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size: <span class="hljs-built_in">int</span>, emb_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.embedding = nn.Embedding(vocab_size, emb_size)<br>        self.emb_size = emb_size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, tokens: Tensor</span>):<br>        <span class="hljs-comment"># embedding的输入是一个张量</span><br>        <span class="hljs-keyword">return</span> self.embedding(tokens.long()) * math.sqrt(self.emb_size)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>1.<strong>为什么要用tokens.long()？</strong>在PyTorch中，<code>nn.Embedding</code>层的输入需要是长整型（<code>LongTensor</code>）类型的数据。<code>tokens.long()</code> 的作用就是将输入的 <code>tokens</code> 张量中的数据类型转换为长整型。这是因为在实际应用中，tokens 往往是表示词汇表中某个词的索引，索引一般是整数类型，因此需要将其转换为长整型，以便与 <code>nn.Embedding</code> 层兼容。</p><p>2.<strong>为什么要乘math.sqrt(self.emb_size)？</strong><code>math.sqrt(self.emb_size)</code> 被用来对嵌入向量进行缩放操作，可能是为了控制嵌入向量的数值范围或方差。</p><h3 id="2-3-Transformer"><a href="#2-3-Transformer" class="headerlink" title="2.3 Transformer"></a>2.3 Transformer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2SeqTransformer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 num_encoder_layers: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 num_decoder_layers: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 emb_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 nhead: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 src_vocab_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 tgt_vocab_size: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">                 dim_feedforward: <span class="hljs-built_in">int</span> = <span class="hljs-number">512</span>,</span><br><span class="hljs-params">                 dropout: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.transformer = Transformer(d_model=emb_size,<br>                                       nhead=nhead,<br>                                       num_encoder_layers=num_encoder_layers,<br>                                       num_decoder_layers=num_decoder_layers,<br>                                       dim_feedforward=dim_feedforward,<br>                                       dropout=dropout)<br>        <span class="hljs-comment"># 初始化一个线性层作为生成器，用于将 Transformer 输出转换为目标语言词汇表的大小。</span><br>        self.generator = nn.Linear(emb_size, tgt_vocab_size)<br>        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)<br>        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)<br>        self.positional_encoding = PositionalEncoding(<br>            emb_size, dropout=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                src: Tensor,</span><br><span class="hljs-params">                trg: Tensor,</span><br><span class="hljs-params">                src_mask: Tensor,</span><br><span class="hljs-params">                tgt_mask: Tensor,</span><br><span class="hljs-params">                src_padding_mask: Tensor,</span><br><span class="hljs-params">                tgt_padding_mask: Tensor,</span><br><span class="hljs-params">                memory_key_padding_mask: Tensor</span>):<br>        src_emb = self.positional_encoding(self.src_tok_emb(src))<br>        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))<br>        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, <span class="hljs-literal">None</span>,<br>                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)<br>        <span class="hljs-keyword">return</span> self.generator(outs)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, src: Tensor, src_mask: Tensor</span>):<br>        <span class="hljs-keyword">return</span> self.transformer.encoder(self.positional_encoding(<br>            self.src_tok_emb(src)), src_mask)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor</span>):<br>        <span class="hljs-keyword">return</span> self.transformer.decoder(self.positional_encoding(<br>            self.tgt_tok_emb(tgt)), memory,<br>            tgt_mask)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>在 Seq2Seq 模型中，通常分为编码器 (Encoder) 和解码器 (Decoder) 两个部分。编码器负责将输入序列编码为一个语义空间中的表示，而解码器则根据这个表示生成输出序列。</p><p>虽然在 <code>forward</code> 方法中已经调用了 Transformer 模型进行编码器-解码器的处理，但是在某些情况下，我们可能需要分别对编码器和解码器进行操作，这就是为什么额外定义了 <code>encode</code> 和 <code>decode</code> 方法的原因。</p><ol><li><strong>编码器操作</strong>：<code>encode</code> 方法允许我们单独对输入序列进行编码，而不需要进行解码器的操作。这在某些情况下是有用的，比如对于一些无需生成输出的任务，只需要输入序列的表示即可。</li><li><strong>解码器操作</strong>：<code>decode</code> 方法允许我们在给定编码后的记忆的情况下，单独对目标序列进行解码。这在一些场景下也是有用的，比如基于已有的语义表示生成一些补充信息，或者在解码器训练中进行推理。</li></ol><p>通过将编码器和解码器的操作分别定义成方法，可以使模型更加灵活，可以根据需求进行更细粒度的操作。</p><h3 id="2-4-单词掩码"><a href="#2-4-单词掩码" class="headerlink" title="2.4 单词掩码"></a>2.4 单词掩码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_square_subsequent_mask</span>(<span class="hljs-params">sz</span>):<br>    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == <span class="hljs-number">1</span>).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    mask = mask.<span class="hljs-built_in">float</span>().masked_fill(mask == <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>)).masked_fill(mask == <span class="hljs-number">1</span>, <span class="hljs-built_in">float</span>(<span class="hljs-number">0.0</span>))<br>    <span class="hljs-keyword">return</span> mask<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_mask</span>(<span class="hljs-params">src, tgt</span>):<br>    src_seq_len = src.shape[<span class="hljs-number">0</span>]<br>    tgt_seq_len = tgt.shape[<span class="hljs-number">0</span>]<br><br>    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)<br>    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">bool</span>)<br><br>    src_padding_mask = (src == PAD_IDX).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    tgt_padding_mask = (tgt == PAD_IDX).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> src_mask, tgt_mask, src_padding_mask, tgt_padding_mask<br></code></pre></td></tr></table></figure><p>假如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">src = torch.tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>]])<br>tgt = torch.tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure><p>则输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">0.</span>, -inf, -inf, -inf],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, -inf, -inf],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, -inf],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br>src_mask:<br> tensor([[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br><br>tgt_mask:<br> tensor([[<span class="hljs-number">0.</span>, -inf],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br><br>src_padding_mask:<br> tensor([[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>,  <span class="hljs-literal">True</span>],<br>        [ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]])<br><br>tgt_padding_mask:<br> tensor([[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>        [ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>],<br>        [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]])<br></code></pre></td></tr></table></figure><h3 id="2-5-实例化"><a href="#2-5-实例化" class="headerlink" title="2.5 实例化"></a>2.5 实例化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.manual_seed(<span class="hljs-number">0</span>)<br><br>SRC_VOCAB_SIZE = <span class="hljs-built_in">len</span>(vocab_transform[SRC_LANGUAGE])<br>TGT_VOCAB_SIZE = <span class="hljs-built_in">len</span>(vocab_transform[TGT_LANGUAGE])<br>EMB_SIZE = <span class="hljs-number">512</span><br>NHEAD = <span class="hljs-number">8</span><br>FFN_HID_DIM = <span class="hljs-number">512</span><br>BATCH_SIZE = <span class="hljs-number">128</span><br>NUM_ENCODER_LAYERS = <span class="hljs-number">3</span><br>NUM_DECODER_LAYERS = <span class="hljs-number">3</span><br><br>transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,<br>                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)<br><br><span class="hljs-comment"># 权重初始化</span><br><span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> transformer.parameters():<br>    <span class="hljs-keyword">if</span> p.dim() &gt; <span class="hljs-number">1</span>:<br>        nn.init.xavier_uniform_(p)<br><br>transformer = transformer.to(DEVICE)<br><br>loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)<br><br>optimizer = torch.optim.Adam(transformer.parameters(), lr=<span class="hljs-number">0.0001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.98</span>), eps=<span class="hljs-number">1e-9</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>权重初始化时，这段代码遍历了 Transformer 模型中的所有参数，如果参数的维度大于 1（即不是偏置项），则使用 Xavier 均匀分布进行初始化。Xavier 初始化旨在使得每一层的输出方差保持相等，从而避免梯度消失或爆炸问题，有助于加速模型的收敛。</p><h2 id="3-整理"><a href="#3-整理" class="headerlink" title="3.整理"></a>3.整理</h2><h3 id="3-1-数据转换"><a href="#3-1-数据转换" class="headerlink" title="3.1 数据转换"></a>3.1 数据转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">from</span> torch.nn.utils.rnn <span class="hljs-keyword">import</span> pad_sequence<br><br><span class="hljs-comment"># 对输入的字符串进行转化，*transforms分别表示进行分词，数字化并且添加开始符和结束符</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sequential_transforms</span>(<span class="hljs-params">*transforms</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>(<span class="hljs-params">txt_input</span>):<br>        <span class="hljs-keyword">for</span> transform <span class="hljs-keyword">in</span> transforms:<br>            txt_input = transform(txt_input)<br>        <span class="hljs-keyword">return</span> txt_input<br>    <span class="hljs-keyword">return</span> func<br><br><span class="hljs-comment"># 添加开始符和结束符</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_transform</span>(<span class="hljs-params">token_ids: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>):<br>    <span class="hljs-keyword">return</span> torch.cat((torch.tensor([BOS_IDX]),<br>                      torch.tensor(token_ids),<br>                      torch.tensor([EOS_IDX])))<br><br><span class="hljs-comment"># 对源字符串和目标字符串进行转换</span><br>text_transform = &#123;&#125;<br><span class="hljs-keyword">for</span> ln <span class="hljs-keyword">in</span> [SRC_LANGUAGE, TGT_LANGUAGE]:<br>    text_transform[ln] = sequential_transforms(token_transform[ln], <span class="hljs-comment"># 分词</span><br>                                               vocab_transform[ln], <span class="hljs-comment"># 数字化</span><br>                                               tensor_transform) <span class="hljs-comment"># 添加开始和终止符</span><br><br><br><span class="hljs-comment"># 对批量的数据进行填充，填充的长度按批次中最大长度进行处理</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):<br>    src_batch, tgt_batch = [], []<br>    <span class="hljs-keyword">for</span> src_sample, tgt_sample <span class="hljs-keyword">in</span> batch:<br>        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(<span class="hljs-string">&quot;\n&quot;</span>)))<br>        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(<span class="hljs-string">&quot;\n&quot;</span>)))<br><br>    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)<br>    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)<br>    <span class="hljs-keyword">return</span> src_batch, tgt_batch<br><br><span class="hljs-comment"># 将数据集用数据加载器包裹</span><br>train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)<br><br><span class="hljs-comment"># 输出第一个批次的结果</span><br><span class="hljs-keyword">for</span> src, tgt <span class="hljs-keyword">in</span> train_dataloader:<br>    <span class="hljs-built_in">print</span>(src)<br>    <span class="hljs-built_in">print</span>(tgt)<br>    <span class="hljs-built_in">print</span>(src.shape, tgt.shape)<br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[ <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>,  ...,  <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>],<br>        [<span class="hljs-number">21</span>, <span class="hljs-number">84</span>,  <span class="hljs-number">5</span>,  ..., <span class="hljs-number">21</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">85</span>, <span class="hljs-number">31</span>, <span class="hljs-number">69</span>,  ..., <span class="hljs-number">46</span>, <span class="hljs-number">38</span>, <span class="hljs-number">17</span>],<br>        ...,<br>        [ <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  ...,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  ...,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  ...,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">1</span>]])<br>tensor([[  <span class="hljs-number">2</span>,   <span class="hljs-number">2</span>,   <span class="hljs-number">2</span>,  ...,   <span class="hljs-number">2</span>,   <span class="hljs-number">2</span>,   <span class="hljs-number">2</span>],<br>        [ <span class="hljs-number">19</span>, <span class="hljs-number">165</span>,   <span class="hljs-number">6</span>,  ...,  <span class="hljs-number">19</span>,   <span class="hljs-number">6</span>,   <span class="hljs-number">6</span>],<br>        [ <span class="hljs-number">25</span>,  <span class="hljs-number">36</span>,  <span class="hljs-number">61</span>,  ...,  <span class="hljs-number">52</span>,  <span class="hljs-number">39</span>,  <span class="hljs-number">16</span>],<br>        ...,<br>        [  <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,  ...,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>],<br>        [  <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,  ...,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>],<br>        [  <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,  ...,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>]])<br>torch.Size([<span class="hljs-number">27</span>, <span class="hljs-number">128</span>]) torch.Size([<span class="hljs-number">24</span>, <span class="hljs-number">128</span>])<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p>如果<code>padded_sequences</code>中没加 <code>batch_first=True</code>，则填充过程中张量会发生转置。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn.utils.rnn <span class="hljs-keyword">import</span> pad_sequence<br><br><span class="hljs-comment"># 假设我们有一组序列张量</span><br>sequences = [torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]),<br>             torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>]),<br>             torch.tensor([<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>])]<br><br><span class="hljs-comment"># 使用pad_sequence进行填充</span><br>padded_sequences = pad_sequence(sequences, padding_value=<span class="hljs-number">0</span>)<br><br><span class="hljs-built_in">print</span>(padded_sequences)<br><br><span class="hljs-comment"># 没有 batch_first=True 的输出</span><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>],<br>        [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>],<br>        [<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">8</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">9</span>]])<br><br><span class="hljs-comment"># 有 batch_first=True 的输出</span><br>padded_sequences = pad_sequence(sequences, batch_first=<span class="hljs-literal">True</span>, padding_value=<span class="hljs-number">0</span>)<br><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure><h3 id="3-2-训练"><a href="#3-2-训练" class="headerlink" title="3.2 训练"></a>3.2 训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch</span>(<span class="hljs-params">model, optimizer</span>):<br>    model.train()<br>    losses = <span class="hljs-number">0</span><br>    train_iter = Multi30k(split=<span class="hljs-string">&#x27;train&#x27;</span>, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))<br>    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)<br><br>    <span class="hljs-keyword">for</span> src, tgt <span class="hljs-keyword">in</span> train_dataloader:<br>        src = src.to(DEVICE)<br>        tgt = tgt.to(DEVICE)<br>        <br>        <span class="hljs-comment"># 解码器的输入，输入序列是包括开始符但不包括结束符</span><br>        tgt_input = tgt[:-<span class="hljs-number">1</span>, :]<br><br>        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)<br><br>        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)<br><br>        optimizer.zero_grad()<br><br>        <span class="hljs-comment"># 解码器的输出，输出包括终止符但不包括开始符</span><br>        tgt_out = tgt[<span class="hljs-number">1</span>:, :]<br>        <br>        <span class="hljs-comment"># 将模型的输出和应该有的输出进行损失的计算</span><br>        loss = loss_fn(logits.reshape(-<span class="hljs-number">1</span>, logits.shape[-<span class="hljs-number">1</span>]), tgt_out.reshape(-<span class="hljs-number">1</span>))<br>        loss.backward()<br><br>        optimizer.step()<br>        losses += loss.item()<br><br>    <span class="hljs-keyword">return</span> losses / <span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(train_dataloader))<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>1.<code>logits</code>的shape为torch.Size([23, 128, 10837])，也就是经过一个线性层之后，会输出10837的维度，也就是输出词表的长度。</p><p>2.<strong>为什么最后一层不用softmax？</strong>通常，在使用交叉熵损失函数时，softmax 操作会被包含在损失函数中。因此，在训练过程中，我们通常不需要显式地在模型中加入 softmax 操作。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 假设模型输出的 logits 是一个包含三个类别的向量</span><br>logits = torch.tensor([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.1</span>], [<span class="hljs-number">0.9</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>]])<br><br><span class="hljs-comment"># 假设目标标签是 [0, 2]</span><br>targets = torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>])<br><br><span class="hljs-comment"># 创建交叉熵损失函数</span><br>loss_function = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># 计算损失</span><br>loss = loss_function(logits, targets)<br><br><span class="hljs-built_in">print</span>(loss)<br></code></pre></td></tr></table></figure><p>在上述示例中，<code>logits</code> 是模型的输出，<code>targets</code> 是目标标签。在计算损失时，我们只需要将 logits 和 targets 传递给交叉熵损失函数 <code>nn.CrossEntropyLoss()</code>，而不需要显式地在模型中使用 softmax 激活函数。交叉熵损失函数内部将 logits 应用 softmax 操作，并计算损失。</p><h3 id="3-3-评估"><a href="#3-3-评估" class="headerlink" title="3.3 评估"></a>3.3 评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    losses = <span class="hljs-number">0</span><br><br>    val_iter = Multi30k(split=<span class="hljs-string">&#x27;valid&#x27;</span>, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))<br>    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)<br><br>    <span class="hljs-keyword">for</span> src, tgt <span class="hljs-keyword">in</span> val_dataloader:<br>        src = src.to(DEVICE)<br>        tgt = tgt.to(DEVICE)<br><br>        tgt_input = tgt[:-<span class="hljs-number">1</span>, :]<br><br>        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)<br><br>        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)<br><br>        tgt_out = tgt[<span class="hljs-number">1</span>:, :]<br>        loss = loss_fn(logits.reshape(-<span class="hljs-number">1</span>, logits.shape[-<span class="hljs-number">1</span>]), tgt_out.reshape(-<span class="hljs-number">1</span>))<br>        losses += loss.item()<br><br>    <span class="hljs-keyword">return</span> losses / <span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(val_dataloader))<br></code></pre></td></tr></table></figure><h2 id="4-开始"><a href="#4-开始" class="headerlink" title="4.开始"></a>4.开始</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> timeit <span class="hljs-keyword">import</span> default_timer <span class="hljs-keyword">as</span> timer<br>NUM_EPOCHS = <span class="hljs-number">18</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, NUM_EPOCHS+<span class="hljs-number">1</span>):<br>    start_time = timer()<br>    train_loss = train_epoch(transformer, optimizer)<br>    end_time = timer()<br>    val_loss = evaluate(transformer)<br>    <span class="hljs-built_in">print</span>((<span class="hljs-string">f&quot;Epoch: <span class="hljs-subst">&#123;epoch&#125;</span>, Train loss: <span class="hljs-subst">&#123;train_loss:<span class="hljs-number">.3</span>f&#125;</span>, Val loss: <span class="hljs-subst">&#123;val_loss:<span class="hljs-number">.3</span>f&#125;</span>, &quot;</span><span class="hljs-string">f&quot;Epoch time = <span class="hljs-subst">&#123;(end_time - start_time):<span class="hljs-number">.3</span>f&#125;</span>s&quot;</span>))<br><br><br><span class="hljs-comment"># function to generate output sequence using greedy algorithm</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greedy_decode</span>(<span class="hljs-params">model, src, src_mask, max_len, start_symbol</span>):<br>    src = src.to(DEVICE)<br>    src_mask = src_mask.to(DEVICE)<br><br>    memory = model.encode(src, src_mask)<br>    ys = torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).fill_(start_symbol).<span class="hljs-built_in">type</span>(torch.long).to(DEVICE)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_len-<span class="hljs-number">1</span>):<br>        memory = memory.to(DEVICE)<br>        tgt_mask = (generate_square_subsequent_mask(ys.size(<span class="hljs-number">0</span>))<br>                    .<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">bool</span>)).to(DEVICE)<br>        out = model.decode(ys, memory, tgt_mask)<br>        out = out.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>        prob = model.generator(out[:, -<span class="hljs-number">1</span>])<br>        _, next_word = torch.<span class="hljs-built_in">max</span>(prob, dim=<span class="hljs-number">1</span>)<br>        next_word = next_word.item()<br><br>        ys = torch.cat([ys,<br>                        torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> next_word == EOS_IDX:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">return</span> ys<br><br><br><span class="hljs-comment"># actual function to translate input sentence into target language</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">translate</span>(<span class="hljs-params">model: torch.nn.Module, src_sentence: <span class="hljs-built_in">str</span></span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    src = text_transform[SRC_LANGUAGE](src_sentence).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    num_tokens = src.shape[<span class="hljs-number">0</span>]<br>    src_mask = (torch.zeros(num_tokens, num_tokens)).<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">bool</span>)<br>    tgt_tokens = greedy_decode(<br>        model,  src, src_mask, max_len=num_tokens + <span class="hljs-number">5</span>, start_symbol=BOS_IDX).flatten()<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot; &quot;</span>.join(vocab_transform[TGT_LANGUAGE].lookup_tokens(<span class="hljs-built_in">list</span>(tgt_tokens.cpu().numpy()))).replace(<span class="hljs-string">&quot;&lt;bos&gt;&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).replace(<span class="hljs-string">&quot;&lt;eos&gt;&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gensim库的使用！🐈</title>
    <link href="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/gensim%E5%BA%93/"/>
    <url>/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/gensim%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="gensim库的使用"><a href="#gensim库的使用" class="headerlink" title="gensim库的使用"></a>gensim库的使用</h1><h2 id="1-文本相似度"><a href="#1-文本相似度" class="headerlink" title="1.文本相似度"></a>1.文本相似度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> KeyedVectors<br><span class="hljs-keyword">import</span> jieba<br><br><span class="hljs-comment"># 加载预训练的 Word2Vec 模型</span><br>word2vec_model_path = <span class="hljs-string">&#x27;path_to_pretrained_word2vec_model.bin&#x27;</span>  <span class="hljs-comment"># 替换为你的预训练模型路径</span><br>word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 分词函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-keyword">return</span> [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> jieba.cut(text)]<br><br><span class="hljs-comment"># 计算两个句子的相似度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_similarity</span>(<span class="hljs-params">sentence1, sentence2</span>):<br>    <span class="hljs-comment"># 分词</span><br>    tokens1 = tokenize(sentence1)<br>    tokens2 = tokenize(sentence2)<br><br>    <span class="hljs-comment"># 移除停用词</span><br>    tokens1 = [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens1 <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> word2vec_model.vocab]<br>    tokens2 = [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens2 <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> word2vec_model.vocab]<br><br>    <span class="hljs-comment"># 计算句子的向量表示</span><br>    vector1 = word2vec_model[tokens1].mean(axis=<span class="hljs-number">0</span>)<br>    vector2 = word2vec_model[tokens2].mean(axis=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 计算余弦相似度</span><br>    similarity = word2vec_model.similarity(<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br><br>    <span class="hljs-keyword">return</span> similarity<br><br><span class="hljs-comment"># 测试句子相似度</span><br>sentence1 = <span class="hljs-string">&#x27;我喜欢吃水果&#x27;</span><br>sentence2 = <span class="hljs-string">&#x27;水果是我喜欢吃的&#x27;</span><br>similarity_score = sentence_similarity(sentence1, sentence2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;两个句子的相似度：&quot;</span>, similarity_score)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer介绍！💐</title>
    <link href="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/"/>
    <url>/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/</url>
    
    <content type="html"><![CDATA[<h1 id="Transformer介绍"><a href="#Transformer介绍" class="headerlink" title="Transformer介绍"></a>Transformer介绍</h1><h2 id="1-整体结构"><a href="#1-整体结构" class="headerlink" title="1.整体结构"></a>1.整体结构</h2><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/1.png"></p><h2 id="2-输入"><a href="#2-输入" class="headerlink" title="2.输入"></a>2.输入</h2><p>Transformer 中单词的输入表示 <strong>x</strong>由<strong>单词 Embedding</strong> 和<strong>位置 Embedding</strong> （Positional Encoding）相加得到。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/2.png"></p><h3 id="2-1-单词-Embedding"><a href="#2-1-单词-Embedding" class="headerlink" title="2.1 单词 Embedding"></a>2.1 单词 Embedding</h3><p>单词的 Embedding 有很多种方式可以获取，例如可以采用 Word2Vec、Glove 等算法预训练得到，也可以在 Transformer 中训练得到。</p><h3 id="2-2-位置-Embedding"><a href="#2-2-位置-Embedding" class="headerlink" title="2.2 位置 Embedding"></a>2.2 位置 Embedding</h3><p>Transformer 中除了单词的 Embedding，还需要使用位置 Embedding 表示单词出现在句子中的位置。<strong>因为 Transformer 不采用 RNN 的结构，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要。</strong>所以 Transformer 中使用位置 Embedding 保存单词在序列中的相对或绝对位置。</p><p>位置 Embedding 用 <strong>PE</strong>表示，<strong>PE</strong> 的维度与单词 Embedding 是一样的。PE 可以通过训练得到，也可以使用某种公式计算得到。在 Transformer 中采用了后者，计算公式如下：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/3.png"></p><p>其中，pos 表示单词在句子中的位置，d 表示 PE的维度 (与词 Embedding 一样)，2i 表示偶数的维度，2i+1 表示奇数维度 (即 2i≤d, 2i+1≤d)。使用这种公式计算 PE 有以下的好处：</p><ul><li>使 PE 能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20 个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第 21 位的 Embedding。</li><li>可以让模型容易地计算出相对位置，对于固定长度的间距 k，<strong>PE(pos+k)</strong> 可以用 <strong>PE(pos)</strong> 计算得到。因为 Sin(A+B) &#x3D; Sin(A)Cos(B) + Cos(A)Sin(B), Cos(A+B) &#x3D; Cos(A)Cos(B) - Sin(A)Sin(B)。</li></ul><p>将单词的词 Embedding 和位置 Embedding 相加，就可以得到单词的表示向量 <strong>x</strong>，<strong>x</strong> 就是 Transformer 的输入。</p><h2 id="3-Encoder"><a href="#3-Encoder" class="headerlink" title="3.Encoder"></a>3.Encoder</h2><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/4.png"></p><h3 id="3-1-Add-Norm"><a href="#3-1-Add-Norm" class="headerlink" title="3.1 Add &amp; Norm"></a>3.1 Add &amp; Norm</h3><p>Add &amp; Norm 层由 Add 和 Norm 两部分组成，其计算公式如下：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/5.png"></p><p>其中 <strong>X</strong>表示 Multi-Head Attention 或者 Feed Forward 的输入，MultiHeadAttention(<strong>X</strong>) 和 FeedForward(<strong>X</strong>) 表示输出 (输出与输入 <strong>X</strong> 维度是一样的，所以可以相加)。</p><p><strong>Add</strong>指 <strong>X</strong>+MultiHeadAttention(<strong>X</strong>)，是一种残差连接，通常用于解决多层网络训练的问题，可以让网络只关注当前差异的部分，在 ResNet 中经常用到：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/6.png"></p><p><strong>Norm</strong>指 Layer Normalization，通常用于 RNN 结构，Layer Normalization 会将每一层神经元的输入都转成均值方差都一样的，这样可以加快收敛。</p><h3 id="3-2-Feed-Forward"><a href="#3-2-Feed-Forward" class="headerlink" title="3.2 Feed Forward"></a>3.2 Feed Forward</h3><p>Feed Forward 层比较简单，是一个两层的全连接层，第一层的激活函数为 Relu，第二层不使用激活函数，对应的公式如下。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/7.png"></p><p><strong>X</strong>是输入，Feed Forward 最终得到的输出矩阵的维度与<strong>X</strong>一致。</p><h3 id="3-3-组成-Encoder"><a href="#3-3-组成-Encoder" class="headerlink" title="3.3 组成 Encoder"></a>3.3 组成 Encoder</h3><p>通过上面描述的 Multi-Head Attention, Feed Forward, Add &amp; Norm 就可以构造出一个 Encoder block，Encoder block 接收输入矩阵 X(n×d) ，并输出一个矩阵 O(n×d) 。通过多个 Encoder block 叠加就可以组成 Encoder。</p><p>第一个 Encoder block 的输入为句子单词的表示向量矩阵，后续 Encoder block 的输入是前一个 Encoder block 的输出，最后一个 Encoder block 输出的矩阵就是<strong>编码信息矩阵 C</strong>，这一矩阵后续会用到 Decoder 中。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/8.png"></p><h2 id="4-Decoder"><a href="#4-Decoder" class="headerlink" title="4.Decoder"></a>4.Decoder</h2><p>与 Encoder block 相似，但是存在一些区别：</p><ul><li>包含两个 Multi-Head Attention 层。</li><li>第一个 Multi-Head Attention 层采用了 Masked 操作。</li><li>第二个 Multi-Head Attention 层的<strong>K, V</strong>矩阵使用 Encoder 的<strong>编码信息矩阵C</strong>进行计算，而<strong>Q</strong>使用上一个 Decoder block 的输出计算。</li><li>最后有一个 Softmax 层计算下一个翻译单词的概率。</li></ul><h3 id="4-1-First-Multi-Head-Attention"><a href="#4-1-First-Multi-Head-Attention" class="headerlink" title="4.1 First Multi-Head Attention"></a>4.1 First Multi-Head Attention</h3><p>Decoder block 的第一个 Multi-Head Attention 采用了 Masked 操作，因为在翻译的过程中是顺序翻译的，即翻译完第 i 个单词，才可以翻译第 i+1 个单词。通过 Masked 操作可以防止第 i 个单词知道 i+1 个单词之后的信息。</p><p>Decoder 可以在训练的过程中使用 Teacher Forcing 并且并行化训练，即将正确的单词序列 (<Begin> I have a cat) 和对应输出 (I have a cat <end>) 传递到 Decoder。那么在预测第 i 个输出时，就要将第 i+1 之后的单词掩盖住，<strong>注意 Mask 操作是在 Self-Attention 的 Softmax 之前使用的，下面用 0 1 2 3 4 5 分别表示 “<Begin> I have a cat <end>“。</strong></p><p><strong>第一步：</strong>是 Decoder 的输入矩阵和 <strong>Mask</strong> 矩阵，输入矩阵包含 “&lt;Begin&gt; I have a cat” (0, 1, 2, 3, 4) 五个单词的表示向量，<strong>Mask</strong> 是一个 5×5 的矩阵。在 <strong>Mask</strong> 可以发现单词 0 只能使用单词 0 的信息，而单词 1 可以使用单词 0, 1 的信息，即只能使用之前的信息。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/9.png"></p><p><strong>第二步：</strong>接下来的操作和之前的 Self-Attention 一样，通过输入矩阵<strong>X</strong>计算得到<strong>Q,K,V</strong>矩阵。然后计算<strong>Q</strong>和 KT 的乘积 QKT 。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/10.png"></p><p><strong>第三步：</strong>在得到 QKT 之后需要进行 Softmax，计算 attention score，我们在 Softmax 之前需要使用<strong>Mask</strong>矩阵遮挡住每一个单词之后的信息，遮挡操作如下：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/11.png"></p><p>得到 <strong>Mask</strong> QKT 之后在 <strong>Mask</strong> QKT上进行 Softmax，每一行的和都为 1。但是单词 0 在单词 1, 2, 3, 4 上的 attention score 都为 0。</p><p><strong>第四步：</strong>使用 <strong>Mask</strong> QKT与矩阵 <strong>V</strong>相乘，得到输出 <strong>Z</strong>，则单词 1 的输出向量 Z1 是只包含单词 1 信息的。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/12.png"></p><p><strong>第五步：</strong>通过上述步骤就可以得到一个 Mask Self-Attention 的输出矩阵 Zi ，然后和 Encoder 类似，通过 Multi-Head Attention 拼接多个输出Zi 然后计算得到第一个 Multi-Head Attention 的输出<strong>Z</strong>，<strong>Z</strong>与输入<strong>X</strong>维度一样。</p><h3 id="4-2-Second-Multi-Head-Attention"><a href="#4-2-Second-Multi-Head-Attention" class="headerlink" title="4.2 Second Multi-Head Attention"></a>4.2 Second Multi-Head Attention</h3><p>Decoder block 第二个 Multi-Head Attention 变化不大， 主要的区别在于其中 Self-Attention 的 <strong>K, V</strong>矩阵不是使用 上一个 Decoder block 的输出计算的，而是使用 <strong>Encoder 的编码信息矩阵 C</strong> 计算的。</p><p>根据 Encoder 的输出 <strong>C</strong>计算得到 <strong>K, V</strong>，根据上一个 Decoder block 的输出 <strong>Z</strong> 计算 <strong>Q</strong> (如果是第一个 Decoder block 则使用输入矩阵 <strong>X</strong> 进行计算)，后续的计算方法与之前描述的一致。</p><p>这样做的好处是在 Decoder 的时候，每一位单词都可以利用到 Encoder 所有单词的信息 (这些信息无需 <strong>Mask</strong>)。</p><h3 id="4-3-Softmax-预测输出单词"><a href="#4-3-Softmax-预测输出单词" class="headerlink" title="4.3 Softmax 预测输出单词"></a>4.3 Softmax 预测输出单词</h3><p>Decoder block 最后的部分是利用 Softmax 预测下一个单词，在之前的网络层我们可以得到一个最终的输出 Z，因为 Mask 的存在，使得单词 0 的输出 Z0 只包含单词 0 的信息，如下：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/13.png"></p><p>Softmax 根据输出矩阵的每一行预测下一个单词：</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/Transformer/14.png"></p><p>这就是 Decoder block 的定义，与 Encoder 一样，Decoder 是由多个 Decoder block 组合而成。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>word2vec介绍！💐</title>
    <link href="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/"/>
    <url>/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/</url>
    
    <content type="html"><![CDATA[<h1 id="word2vec介绍"><a href="#word2vec介绍" class="headerlink" title="word2vec介绍"></a>word2vec介绍</h1><h2 id="1-词向量"><a href="#1-词向量" class="headerlink" title="1.词向量"></a>1.词向量</h2><p>词向量就是用来将语言中的词进行数学化的一种方式，顾名思义，词向量就是把一个词表示成一个向量。 我们都知道词在送到神经网络训练之前需要将其编码成数值变量，常见的编码方式有两种：One-Hot Representation 和 Distributed Representation。</p><h3 id="1-1-One-Hot编码"><a href="#1-1-One-Hot编码" class="headerlink" title="1.1 One-Hot编码"></a>1.1 One-Hot编码</h3><p>One-Hot编码 ，就是用一个很长的向量来表示一个词，向量的长度为词典的大小，向量中只有一个 1 ， 其他全为 0 ，1 的位置对应该词在词典中的位置。</p><p>举个例子：I like writing code，那么转换成独热编码就是:</p><p>**I **1 0 0 0 <strong>like</strong> 0 1 0 0 <strong>writing</strong> 0 0 1 0 <strong>code</strong> 0 0 0 1</p><p>缺点：</p><p>1.容易受维数灾难的困扰，尤其是将其用于 Deep Learning的一些算法时</p><p>2.词汇鸿沟，不能很好地刻画词与词之间的相似性</p><p>3.强稀疏性</p><h3 id="1-2-Distributed编码"><a href="#1-2-Distributed编码" class="headerlink" title="1.2 Distributed编码"></a>1.2 <strong>Distributed</strong>编码</h3><p>其基本想法是：通过训练将某种语言中的每一个词 映射成一个固定长度的短向量（当然这里的“短”是相对于One-Hot Representation的“长”而言的），所有这些向量构成一个词向量空间，而每一个向量则可视为 该空间中的一个点，在这个空间上引入“距离”，就可以根据词之间的距离来判断它们之间的语法、语义上的相似性了。</p><h2 id="2-Word2Vec的网络结构"><a href="#2-Word2Vec的网络结构" class="headerlink" title="2.Word2Vec的网络结构"></a>2.<strong>Word2Vec的网络结构</strong></h2><p>Word2Vec是轻量级的神经网络，其模型仅仅包括输入层、隐藏层和输出层，模型框架根据输入输出的不同，主要包括CBOW和Skip-gram模型。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/1.png"></p><h3 id="2-1-CBOW"><a href="#2-1-CBOW" class="headerlink" title="2.1 CBOW"></a>2.1 <strong>CBOW</strong></h3><h4 id="2-1-1-Simple-CBOW-Model"><a href="#2-1-1-Simple-CBOW-Model" class="headerlink" title="2.1.1 Simple CBOW Model"></a>2.1.1 <strong>Simple CBOW Model</strong></h4><p>为了更好的了解模型深处的原理，我们先从Simple CBOW model（仅输入一个词，输出一个词）框架说起。</p><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/2.png"></p><p>如上图所示：</p><ul><li>input layer输入的X是单词的one-hot representation（考虑一个词表V，里面的每一个词 x 都有一个编号i∈{1,…,|V|}，那么词 x 的one-hot表示就是一个维度为|V|的向量，其中第i个元素值非零，其余元素全为0，例如： x2&#x3D;[0,1,0,…,0]T ）；</li><li>输入层到隐藏层之间有一个权重矩阵W，隐藏层得到的值是由输入X乘上权重矩阵得到的（细心的人会发现，0-1向量乘上一个矩阵，就相当于选择了权重矩阵的某一行，如图：输入的向量X是[0，0，1，0，0，0]，W的转置乘上X就相当于从矩阵中选择第3行[2,1,3]作为隐藏层的值）;</li><li>隐藏层到输出层也有一个权重矩阵W’，因此，输出层向量y的每一个值，其实就是隐藏层的向量点乘权重向量W’的每一列，比如输出层的第一个数7，就是向量[2,1,3]和列向量[1，2，1]点乘之后的结果；</li><li>最终的输出需要经过softmax函数，将输出向量中的每一个元素归一化到0-1之间的概率，概率最大的，就是预测的词。</li></ul><h4 id="2-1-2-CBOW-Multi-Word-Context-Model"><a href="#2-1-2-CBOW-Multi-Word-Context-Model" class="headerlink" title="2.1.2 CBOW Multi-Word Context Model"></a>2.1.2 <strong>CBOW Multi-Word Context Model</strong></h4><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/3.png"></p><p>了解了Simple CBOW model之后，扩展到CBOW就很容易了，只是把单个输入换成多个输入罢了（划红线部分）。</p><p><strong>h是求平均值后的结果。</strong></p><h3 id="2-2-Skip-gram"><a href="#2-2-Skip-gram" class="headerlink" title="2.2 Skip-gram"></a>2.2 <strong>Skip-gram</strong></h3><p><img src="/2024/03/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/word2vec/4.png"></p><p>如上图所示，Skip-gram model是通过输入一个词去预测多个词的概率。输入层到隐藏层的原理和simple CBOW一样，不同的是隐藏层到输出层，损失函数变成了C个词损失函数的总和，权重矩阵W’还是共享的。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torchtext预处理自定义文本数据集！🌞</title>
    <link href="/2024/03/12/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/torchtext%E9%A2%84%E5%A4%84%E7%90%86%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2024/03/12/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/torchtext%E9%A2%84%E5%A4%84%E7%90%86%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1 id="torchtext预处理自定义文本数据集"><a href="#torchtext预处理自定义文本数据集" class="headerlink" title="torchtext预处理自定义文本数据集"></a>torchtext预处理自定义文本数据集</h1><h2 id="1-设置"><a href="#1-设置" class="headerlink" title="1.设置"></a>1.设置</h2><p>导入必要的包：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchdata.datapipes <span class="hljs-keyword">as</span> dp<br><span class="hljs-keyword">import</span> torchtext.transforms <span class="hljs-keyword">as</span> T<br><span class="hljs-keyword">import</span> spacy<br><span class="hljs-keyword">from</span> torchtext.vocab <span class="hljs-keyword">import</span> build_vocab_from_iterator<br></code></pre></td></tr></table></figure><p>下载分词的模型：</p><p><img src="/2024/03/12/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/torchtext%E9%A2%84%E5%A4%84%E7%90%86%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%9B%86/1.png"></p><p>加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">eng = spacy.load(<span class="hljs-string">&quot;en_core_web_md-3.7.1&quot;</span>)  <span class="hljs-comment"># Load the English model to tokenize English text</span><br>zh = spacy.load(<span class="hljs-string">&quot;zh_core_web_md-3.7.0&quot;</span>)<br></code></pre></td></tr></table></figure><p>加载数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">FILE_PATH = <span class="hljs-string">&#x27;cmn.txt&#x27;</span><br>data_pipe = dp.<span class="hljs-built_in">iter</span>.IterableWrapper([FILE_PATH])<br>data_pipe = dp.<span class="hljs-built_in">iter</span>.FileOpener(data_pipe, mode=<span class="hljs-string">&#x27;rb&#x27;</span>)<br>data_pipe = data_pipe.parse_csv(skip_lines=<span class="hljs-number">0</span>, delimiter=<span class="hljs-string">&#x27;\t&#x27;</span>, as_tuple=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><ol><li>在第 2 行，我们正在创建文件名的可迭代对象</li><li>在第 3 行，我们将可迭代对象传递给 FileOpener，然后 FileOpener 以读取模式打开文件</li><li>在第 4 行，我们调用一个函数来解析文件，该函数再次返回一个元组的可迭代对象，表示制表符分隔文件的每一行</li></ol><p><strong>DataPipes 可以被认为是一个数据集对象，我们可以在它上面执行各种操作。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">removeAttribution</span>(<span class="hljs-params">row</span>):<br>    <span class="hljs-keyword">return</span> row[:<span class="hljs-number">2</span>]<br><br><br>data_pipe = data_pipe.<span class="hljs-built_in">map</span>(removeAttribution)<br></code></pre></td></tr></table></figure><p><strong>map 函数可用于对data_pipe的每个元素应用一些函数。</strong></p><p>分词：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">engTokenize</span>(<span class="hljs-params">text</span>):<br>    engTokenList = [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> eng.tokenizer(text)]<br>    <span class="hljs-keyword">return</span> engTokenList<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">zhTokenize</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-keyword">return</span> [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> zh.tokenizer(text)]<br></code></pre></td></tr></table></figure><h2 id="2-建立词汇表"><a href="#2-建立词汇表" class="headerlink" title="2.建立词汇表"></a>2.建立词汇表</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">getTokens</span>(<span class="hljs-params">data_iter, place</span>):<br>    <span class="hljs-keyword">for</span> english, chinese <span class="hljs-keyword">in</span> data_iter:<br>        <span class="hljs-keyword">if</span> place == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">yield</span> engTokenize(english)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">yield</span> zhTokenize(chinese)<br><br><br><br>source_vocab = build_vocab_from_iterator(<br>    getTokens(data_pipe, <span class="hljs-number">0</span>),<br>    min_freq=<span class="hljs-number">2</span>,<br>    specials=[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;sos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>],<br>    special_first=<span class="hljs-literal">True</span><br>)<br>source_vocab.set_default_index(source_vocab[<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>])<br><br>target_vocab = build_vocab_from_iterator(<br>    getTokens(data_pipe, <span class="hljs-number">1</span>),<br>    min_freq=<span class="hljs-number">2</span>,<br>    specials=[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;sos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>],<br>    special_first=<span class="hljs-literal">True</span><br>)<br>target_vocab.set_default_index(target_vocab[<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>])<br><br><span class="hljs-built_in">print</span>(source_vocab.get_itos()[:<span class="hljs-number">9</span>])<br></code></pre></td></tr></table></figure><p><strong>source_vocab.get_itos（） 返回一个列表，其中包含基于词汇的索引中的标记。</strong></p><h2 id="3-使用词汇对句子进行数字化"><a href="#3-使用词汇对句子进行数字化" class="headerlink" title="3.使用词汇对句子进行数字化"></a>3.使用词汇对句子进行数字化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">getTransform</span>(<span class="hljs-params">vocab</span>):<br>    text_tranform = T.Sequential(<br>        T.VocabTransform(vocab=vocab),<br>        T.AddToken(<span class="hljs-number">1</span>, begin=<span class="hljs-literal">True</span>),<br>        T.AddToken(<span class="hljs-number">2</span>, begin=<span class="hljs-literal">False</span>)<br>    )<br>    <span class="hljs-keyword">return</span> text_tranform<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">applyTransform</span>(<span class="hljs-params">sequence_pair</span>):<br>    <span class="hljs-keyword">return</span> (<br>        getTransform(source_vocab)(engTokenize(sequence_pair[<span class="hljs-number">0</span>])),<br>        getTransform(target_vocab)(zhTokenize(sequence_pair[<span class="hljs-number">1</span>]))<br>    )<br><br><br>data_pipe = data_pipe.<span class="hljs-built_in">map</span>(applyTransform)<br></code></pre></td></tr></table></figure><h2 id="4-制作批次"><a href="#4-制作批次" class="headerlink" title="4.制作批次"></a>4.制作批次</h2><p>通常，我们分批训练模型。在处理序列到序列模型时，建议保持批次中序列的长度相似。为此，我们将使用 data_pipe 的 bucketbatch 函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sortBucket</span>(<span class="hljs-params">bucket</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sorted</span>(bucket, key=<span class="hljs-keyword">lambda</span> x: (<span class="hljs-built_in">len</span>(x[<span class="hljs-number">0</span>]), <span class="hljs-built_in">len</span>(x[<span class="hljs-number">1</span>])))<br><br><br>data_pipe = data_pipe.bucketbatch(<br>    batch_size=<span class="hljs-number">4</span>, batch_num=<span class="hljs-number">5</span>, bucket_num=<span class="hljs-number">1</span>,<br>    use_in_batch_shuffle=<span class="hljs-literal">False</span>, sort_key=sortBucket<br>)<br></code></pre></td></tr></table></figure><p>data_pipe中的一批是 <code>[（X_1，y_1）、（X_2，y_2）、（X_3，y_3）、（X_4，y_4）]</code></p><p>因此，我们现在将它们转换为以下形式：<code>（（X_1，X_2，X_3，X_4）， （y_1，y_2，y_3，y_4））</code>。为此，我们将编写一个小函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">separateSourceTarget</span>(<span class="hljs-params">sequence_pairs</span>):<br>    sources, targets = <span class="hljs-built_in">zip</span>(*sequence_pairs)<br>    <span class="hljs-keyword">return</span> sources, targets<br><br><br>data_pipe = data_pipe.<span class="hljs-built_in">map</span>(separateSourceTarget)<br></code></pre></td></tr></table></figure><h2 id="5-填充"><a href="#5-填充" class="headerlink" title="5.填充"></a>5.填充</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">applyPadding</span>(<span class="hljs-params">pair_of_sequences</span>):<br>    <span class="hljs-keyword">return</span> (T.ToTensor(<span class="hljs-number">0</span>)(<span class="hljs-built_in">list</span>(pair_of_sequences[<span class="hljs-number">0</span>])), T.ToTensor(<span class="hljs-number">0</span>)(<span class="hljs-built_in">list</span>(pair_of_sequences[<span class="hljs-number">1</span>])))<br><br><br>data_pipe = data_pipe.<span class="hljs-built_in">map</span>(applyPadding)<br><br>source_index_to_string = source_vocab.get_itos()<br>target_index_to_string = target_vocab.get_itos()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">showSomeTransformedSentences</span>(<span class="hljs-params">data_pipe</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Function to show how the sentences look like after applying all transforms.</span><br><span class="hljs-string">    Here we try to print actual words instead of corresponding index</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> sources, targets <span class="hljs-keyword">in</span> data_pipe:<br>        <span class="hljs-keyword">if</span> sources[<span class="hljs-number">0</span>][-<span class="hljs-number">1</span>] != <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">continue</span>  <span class="hljs-comment"># Just to visualize padding of shorter sentences</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>            source = <span class="hljs-string">&quot;&quot;</span><br>            <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> sources[i]:<br>                source += <span class="hljs-string">&quot; &quot;</span> + source_index_to_string[token]<br>            target = <span class="hljs-string">&quot;&quot;</span><br>            <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> targets[i]:<br>                target += <span class="hljs-string">&quot; &quot;</span> + target_index_to_string[token]<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Source: <span class="hljs-subst">&#123;source&#125;</span>&quot;</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Traget: <span class="hljs-subst">&#123;target&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">break</span><br><br><br>showSomeTransformedSentences(data_pipe)<br></code></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">Source:  &lt;sos&gt; &lt;unk&gt; ! &lt;eos&gt; &lt;pad&gt;<br>Traget:  &lt;sos&gt; 完美 ！ &lt;eos&gt;<br>Source:  &lt;sos&gt; Hold on . &lt;eos&gt;<br>Traget:  &lt;sos&gt; 坚持 。 &lt;eos&gt;<br>Source:  &lt;sos&gt; See you . &lt;eos&gt;<br>Traget:  &lt;sos&gt; 再见 ！ &lt;eos&gt;<br>Source:  &lt;sos&gt; Shut up ! &lt;eos&gt;<br>Traget:  &lt;sos&gt; &lt;unk&gt; ！ &lt;eos&gt;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>collections库的使用！☃️</title>
    <link href="/2024/03/12/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADcollections%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/03/12/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADcollections%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="collections库的使用"><a href="#collections库的使用" class="headerlink" title="collections库的使用"></a>collections库的使用</h1><p>在Python中，<code>collections</code> 模块提供了许多有用的数据结构，用于扩展内置的容器类型（如列表、元组、字典等），以满足各种编程需求。这些数据结构在处理特定任务时比内置类型更高效，并且提供了额外的功能。</p><p>以下是 <code>collections</code> 模块中一些常用的数据结构：</p><h2 id="1-Counter"><a href="#1-Counter" class="headerlink" title="1.Counter"></a>1.Counter</h2><p>用于计数可哈希对象，是字典的子类。提供了快速计数和集合操作的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><br><span class="hljs-comment"># 创建Counter对象</span><br>c = Counter([<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>])<br><span class="hljs-built_in">print</span>(c)  <span class="hljs-comment"># 输出: Counter(&#123;&#x27;a&#x27;: 3, &#x27;b&#x27;: 2, &#x27;c&#x27;: 1&#125;)</span><br><br><span class="hljs-comment"># 访问元素的计数</span><br><span class="hljs-built_in">print</span>(c[<span class="hljs-string">&#x27;a&#x27;</span>])  <span class="hljs-comment"># 输出: 3</span><br><br><span class="hljs-comment"># 元素计数的集合操作</span><br>d = Counter([<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;d&#x27;</span>])<br><span class="hljs-built_in">print</span>(c + d)  <span class="hljs-comment"># 输出: Counter(&#123;&#x27;a&#x27;: 4, &#x27;b&#x27;: 3, &#x27;c&#x27;: 1, &#x27;d&#x27;: 1&#125;)</span><br></code></pre></td></tr></table></figure><h3 id="1-1-Counter-update"><a href="#1-1-Counter-update" class="headerlink" title="1.1 Counter.update"></a>1.1 Counter.update</h3><p> <code>update()</code> 方法用于将另一个可迭代对象中的元素计数添加到当前 <code>Counter</code> 中。如果没有指定可迭代对象，则不会进行任何操作。这个方法可以用于更新计数器的内容，例如合并两个计数器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><br><span class="hljs-comment"># 创建两个Counter对象</span><br>c1 = Counter(&#123;<span class="hljs-string">&#x27;a&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;b&#x27;</span>: <span class="hljs-number">2</span>&#125;)<br>c2 = Counter(&#123;<span class="hljs-string">&#x27;a&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;b&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;c&#x27;</span>: <span class="hljs-number">2</span>&#125;)<br><br><span class="hljs-comment"># 使用update方法合并两个Counter对象</span><br>c1.update(c2)<br><br><span class="hljs-built_in">print</span>(c1)<br><span class="hljs-comment"># 输出: Counter(&#123;&#x27;a&#x27;: 4, &#x27;b&#x27;: 6, &#x27;c&#x27;: 2&#125;)</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>logging库的使用！☃️</title>
    <link href="/2024/02/27/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADlogging%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/27/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADlogging%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="logging库的使用"><a href="#logging库的使用" class="headerlink" title="logging库的使用"></a>logging库的使用</h1><h2 id="1-Formatter"><a href="#1-Formatter" class="headerlink" title="1.Formatter"></a>1.Formatter</h2><p>在Python中，<code>logging.Formatter</code>是用于配置日志消息的格式的类。它允许你指定日志消息的输出格式。<code>logging.Formatter</code>类有两个主要参数：</p><ol><li><code>fmt</code>：这是一个字符串，用于指定日志消息的输出格式。可以使用格式化代码来包含日志记录中的各种信息，例如时间戳、日志级别、消息内容等。</li><li><code>datefmt</code>：这是一个可选参数，用于指定时间戳的格式。如果日志消息中包含日期和时间信息，可以使用这个参数来指定输出的时间戳格式。</li></ol><p>例如，使用<code>logging.Formatter</code>类设置日志消息的格式的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-comment"># 创建一个Formatter对象</span><br>formatter = logging.Formatter(fmt=<span class="hljs-string">&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;</span>, datefmt=<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br><br><span class="hljs-comment"># 创建一个StreamHandler，并设置其Formatter</span><br>stream_handler = logging.StreamHandler()<br>stream_handler.setFormatter(formatter)<br><br><span class="hljs-comment"># 创建一个Logger对象</span><br>logger = logging.getLogger(<span class="hljs-string">&#x27;example&#x27;</span>)<br>logger.setLevel(logging.DEBUG)<br><br><span class="hljs-comment"># 将StreamHandler添加到Logger中</span><br>logger.addHandler(stream_handler)<br><br><span class="hljs-comment"># 输出日志消息</span><br>logger.debug(<span class="hljs-string">&#x27;This is a debug message.&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;This is an info message.&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;This is a warning message.&#x27;</span>)<br>logger.error(<span class="hljs-string">&#x27;This is an error message.&#x27;</span>)<br>logger.critical(<span class="hljs-string">&#x27;This is a critical message.&#x27;</span>)<br></code></pre></td></tr></table></figure><p>在这个示例中，<code>fmt</code>参数指定了日志消息的输出格式，其中包含了时间戳、日志级别和消息内容；<code>datefmt</code>参数指定了时间戳的格式为年-月-日 时:分:秒。</p><p>tips：</p><p>1.日志消息的输出格式：</p><ul><li><code>%(asctime)-15s</code>: 这个部分表示日志记录的时间，格式为日志消息被创建的时间，通过 <code>asctime</code> 属性提供。<code>-15s</code> 指定了一个最小宽度为 15 个字符的字段，并且左对齐填充空白。这意味着无论实际时间字符串的长度是多少，都会被填充到 15 个字符的宽度，并向左对齐。</li><li><code>%(levelname)s</code>: 这个部分表示日志级别，即日志消息的重要性等级，例如 DEBUG、INFO、WARNING、ERROR 或 CRITICAL。</li><li><code>%(message)s</code>: 这个部分表示实际的日志消息内容，即要记录的信息文本。</li></ul><p>2.时间戳的格式：</p><ul><li><code>%a</code>: 星期的缩写，例如 “Mon”, “Tue” 等。</li><li><code>%d</code>: 日期，即月中的第几天（1-31）。</li><li><code>%b</code>: 月份的缩写，例如 “Jan”, “Feb” 等。</li><li><code>%Y</code>: 四位数的年份（例如：1998, 2004, 2022）。</li><li><code>%H</code>: 小时（24小时制，00-23）。</li><li><code>%M</code>: 分钟（00-59）。</li><li><code>%S</code>: 秒（00-59）。</li></ul><h2 id="2-Level"><a href="#2-Level" class="headerlink" title="2.Level"></a>2.Level</h2><h3 id="2-1-日志级别"><a href="#2-1-日志级别" class="headerlink" title="2.1 日志级别"></a>2.1 日志级别</h3><p>在 Python 的 logging 模块中，定义了以下几个日志级别（按照严重程度递增的顺序）：</p><ol><li><strong>DEBUG</strong>: 最详细的日志级别，用于提供关于程序运行状态的详细信息，通常用于调试目的。</li><li><strong>INFO</strong>: 提供程序运行状态的一般信息，表明程序正在正常工作。</li><li><strong>WARNING</strong>: 表示可能出现问题的情况，但不会影响程序的正常运行。</li><li><strong>ERROR</strong>: 表示已经发生了错误，但是不会导致程序停止运行。</li><li><strong>CRITICAL</strong>: 表示严重的错误，可能导致程序无法继续运行。</li></ol><p>这些日志级别在 logging 模块中通过对应的方法来记录日志消息，分别是 <code>debug()</code>, <code>info()</code>, <code>warning()</code>, <code>error()</code>, 和 <code>critical()</code> 方法。当设置日志记录器的级别时，高于或等于该级别的日志消息将被记录，低于该级别的日志消息将被忽略。</p><h3 id="2-2-setLevel"><a href="#2-2-setLevel" class="headerlink" title="2.2 setLevel"></a>2.2 setLevel</h3><p><code>setLevel</code> 是 Python logging 模块中用于设置日志记录器的日志级别的方法。通过这个方法，可以控制日志记录器记录日志消息的最低级别。</p><p>例如，如果你设置了一个日志记录器 <code>logger</code>，你可以通过以下方式设置其记录的最低级别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-comment"># 创建一个日志记录器</span><br>logger = logging.getLogger(<span class="hljs-string">&#x27;example_logger&#x27;</span>)<br><br><span class="hljs-comment"># 设置日志记录器的级别为DEBUG</span><br>logger.setLevel(logging.DEBUG)<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>setLevel(logging.DEBUG)</code> 将会使得日志记录器 <code>logger</code> 记录所有级别的日志消息，包括 DEBUG、INFO、WARNING、ERROR 和 CRITICAL。如果你希望日志记录器只记录警告级别及以上的日志消息，可以将级别设置为 <code>logging.WARNING</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">logger.setLevel(logging.WARNING)<br></code></pre></td></tr></table></figure><p>这样，DEBUG 和 INFO 级别的日志消息就不会被记录了。<code>setLevel</code> 方法设置的级别会应用到该日志记录器以及其所有子记录器上，除非子记录器单独设置了不同的级别。</p><h2 id="3-Handler"><a href="#3-Handler" class="headerlink" title="3.Handler"></a>3.Handler</h2><h3 id="3-1-FileHandler"><a href="#3-1-FileHandler" class="headerlink" title="3.1 FileHandler"></a>3.1 FileHandler</h3><p><code>logging.FileHandler</code> 是 Python logging 模块中用于将日志消息记录到文件的处理器（handler）。它允许你指定一个文件名，将日志消息写入到该文件中。</p><p>以下是一个简单的示例，演示如何使用 <code>FileHandler</code> 将日志消息记录到文件中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-comment"># 创建一个日志记录器</span><br>logger = logging.getLogger(<span class="hljs-string">&#x27;example_logger&#x27;</span>)<br>logger.setLevel(logging.DEBUG)<br><br><span class="hljs-comment"># 创建一个文件处理器，将日志消息记录到文件中</span><br>file_handler = logging.FileHandler(<span class="hljs-string">&#x27;example.log&#x27;</span>)<br><br><span class="hljs-comment"># 设置文件处理器的日志级别为DEBUG</span><br>file_handler.setLevel(logging.DEBUG)<br><br><span class="hljs-comment"># 创建一个格式化器</span><br>formatter = logging.Formatter(<span class="hljs-string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)<br><br><span class="hljs-comment"># 将格式化器应用到文件处理器上</span><br>file_handler.setFormatter(formatter)<br><br><span class="hljs-comment"># 将文件处理器添加到日志记录器中</span><br>logger.addHandler(file_handler)<br><br><span class="hljs-comment"># 记录一些日志消息</span><br>logger.debug(<span class="hljs-string">&#x27;This is a debug message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;This is an info message&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;This is a warning message&#x27;</span>)<br>logger.error(<span class="hljs-string">&#x27;This is an error message&#x27;</span>)<br>logger.critical(<span class="hljs-string">&#x27;This is a critical message&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="3-2-StreamHandler"><a href="#3-2-StreamHandler" class="headerlink" title="3.2 StreamHandler"></a>3.2 StreamHandler</h3><p><code>logging.StreamHandler</code> 是 Python logging 模块中用于将日志消息输出到流（例如标准输出流）的处理器（handler）。它允许你指定一个流对象，将日志消息写入到该流中，通常用于将日志消息输出到控制台或者其他标准输出设备上。</p><p>以下是一个简单的示例，演示如何使用 <code>StreamHandler</code> 将日志消息输出到控制台：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-comment"># 创建一个日志记录器</span><br>logger = logging.getLogger(<span class="hljs-string">&#x27;example_logger&#x27;</span>)<br>logger.setLevel(logging.DEBUG)<br><br><span class="hljs-comment"># 创建一个流处理器，将日志消息输出到控制台</span><br>stream_handler = logging.StreamHandler()<br><br><span class="hljs-comment"># 设置流处理器的日志级别为DEBUG</span><br>stream_handler.setLevel(logging.DEBUG)<br><br><span class="hljs-comment"># 创建一个格式化器</span><br>formatter = logging.Formatter(<span class="hljs-string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)<br><br><span class="hljs-comment"># 将格式化器应用到流处理器上</span><br>stream_handler.setFormatter(formatter)<br><br><span class="hljs-comment"># 将流处理器添加到日志记录器中</span><br>logger.addHandler(stream_handler)<br><br><span class="hljs-comment"># 记录一些日志消息</span><br>logger.debug(<span class="hljs-string">&#x27;This is a debug message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;This is an info message&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;This is a warning message&#x27;</span>)<br>logger.error(<span class="hljs-string">&#x27;This is an error message&#x27;</span>)<br>logger.critical(<span class="hljs-string">&#x27;This is a critical message&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="4-basicConfig"><a href="#4-basicConfig" class="headerlink" title="4.basicConfig"></a>4.basicConfig</h2><p><code>logging.basicConfig()</code> 是 Python logging 模块中用于简化配置日志系统的方法。它允许你通过一次调用来设置日志系统的一些基本配置，包括日志级别、输出格式、输出目标等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">logging.basicConfig(<br>        level=level,<br>        handlers=[fh, sh]<br>    )<br></code></pre></td></tr></table></figure><h2 id="5-初始化"><a href="#5-初始化" class="headerlink" title="5.初始化"></a>5.初始化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">logger = logging.getLogger()<br>logger.info(<span class="hljs-string">&#x27;具体内容&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python特殊变量！🍩</title>
    <link href="/2024/02/27/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E7%89%B9%E6%AE%8A%E5%8F%98%E9%87%8F/"/>
    <url>/2024/02/27/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E7%89%B9%E6%AE%8A%E5%8F%98%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="python特殊变量"><a href="#python特殊变量" class="headerlink" title="python特殊变量"></a>python特殊变量</h1><h2 id="1-file"><a href="#1-file" class="headerlink" title="1.__file__"></a>1.__file__</h2><p>在Python中，<code>__file__</code> 是一个内置的变量，它包含着当前正在执行的 Python 脚本的文件路径。当你在一个 Python 脚本中访问 <code>__file__</code> 变量时，它将返回包含该脚本的文件路径的字符串。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mwptoolkit全局概览！🍺</title>
    <link href="/2024/02/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MWP_toolkit/mwptoolkit/"/>
    <url>/2024/02/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MWP/MWP_toolkit/mwptoolkit/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP项目实战</category>
      
      <category>MWP</category>
      
      <category>MWPToolkit</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torchtext库的使用！🦔</title>
    <link href="/2024/02/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADtorchtext%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADtorchtext%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="torchtext库的使用"><a href="#torchtext库的使用" class="headerlink" title="torchtext库的使用"></a>torchtext库的使用</h1><h2 id="1-vocab"><a href="#1-vocab" class="headerlink" title="1.vocab"></a>1.vocab</h2><h3 id="1-1-build-vocab-from-iterator"><a href="#1-1-build-vocab-from-iterator" class="headerlink" title="1.1 build_vocab_from_iterator"></a>1.1 build_vocab_from_iterator</h3><p><code>build_vocab_from_iterator</code>是TorchText库中用于构建词汇表（vocabulary）的方法之一。它允许你从一个迭代器中构建词汇表，而不是从一个已有的数据集中。</p><p>下面是使用<code>build_vocab_from_iterator</code>方法的一个简单示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchtext.vocab <span class="hljs-keyword">import</span> Vocab<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><br><span class="hljs-comment"># 假设你有一个文本数据的迭代器，每个元素是一个句子或文本段落</span><br><span class="hljs-comment"># 这里我们简单地用一个列表模拟了一个文本迭代器</span><br>text_iterator = [<br>    [<span class="hljs-string">&quot;I&quot;</span>, <span class="hljs-string">&quot;love&quot;</span>, <span class="hljs-string">&quot;natural&quot;</span>, <span class="hljs-string">&quot;language&quot;</span>, <span class="hljs-string">&quot;processing&quot;</span>],<br>    [<span class="hljs-string">&quot;TorchText&quot;</span>, <span class="hljs-string">&quot;is&quot;</span>, <span class="hljs-string">&quot;great&quot;</span>, <span class="hljs-string">&quot;for&quot;</span>, <span class="hljs-string">&quot;NLP&quot;</span>, <span class="hljs-string">&quot;tasks&quot;</span>],<br>    [<span class="hljs-string">&quot;I&quot;</span>, <span class="hljs-string">&quot;want&quot;</span>, <span class="hljs-string">&quot;to&quot;</span>, <span class="hljs-string">&quot;learn&quot;</span>, <span class="hljs-string">&quot;more&quot;</span>, <span class="hljs-string">&quot;about&quot;</span>, <span class="hljs-string">&quot;TorchText&quot;</span>]<br>]<br><br><span class="hljs-comment"># 首先，我们使用Counter来计算词频</span><br>counter = Counter()<br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> text_iterator:<br>    counter.update(text)<br><br><span class="hljs-comment"># 然后，我们可以使用build_vocab_from_iterator来构建词汇表</span><br>vocab = Vocab(counter, specials=[<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;sos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>])<br><br><span class="hljs-comment"># 查看词汇表中的前几个词</span><br><span class="hljs-built_in">print</span>(vocab.itos[:<span class="hljs-number">10</span>])<br><br><span class="hljs-comment"># 查看词汇表的大小</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(vocab))<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p><code>build_vocab_from_iterator</code>方法的具体参数含义如下：</p><ul><li><strong>iterator</strong>：一个迭代器，它产生文本数据的序列，每个序列可以是一个句子或文本段落。</li><li><strong>min_freq</strong>：一个整数，表示词汇表中词的最小出现频率。低于这个频率的词将被视为未知词（<unk>）。</li><li><strong>cut_under</strong>：一个布尔值，表示是否在构建词汇表之前将低于<code>min_freq</code>的词剪掉。如果为<code>True</code>，则会剪掉低频词；如果为<code>False</code>，则不会剪掉。</li><li><strong>specials</strong>：一个包含特殊标记的列表，如<code>&lt;unk&gt;</code>（未知词）、<code>&lt;pad&gt;</code>（填充）、<code>&lt;bos&gt;</code>（开始标记）、<code>&lt;eos&gt;</code>（结束标记）。这些特殊标记将始终包含在词汇表中。</li><li><strong>special_first</strong>：一个布尔值，表示是否将特殊标记放在词汇表的开头。如果为<code>True</code>，则特殊标记会放在词汇表的最前面；如果为<code>False</code>，则会按照词频的顺序放置。</li><li><strong>min_size</strong>：一个整数，表示词汇表的最小大小。如果指定了这个参数，并且词汇表的大小小于<code>min_size</code>，则会用未知词填充词汇表，直到词汇表的大小达到<code>min_size</code>。这意味着<pad>将获得索引 1、 <sos> 索引 2、 <eos> 索引 3，并将<unk>在词汇表中获得索引 0。</li></ul><h3 id="1-2-set-default-index"><a href="#1-2-set-default-index" class="headerlink" title="1.2 set_default_index"></a>1.2 set_default_index</h3><p><code>set_default_index</code>是<code>torchtext.vocab.Vocab</code>类中的一个方法。它用于设置默认的未知词索引。</p><p>在使用TorchText构建词汇表时，如果给定的词汇表中包含未知词（即在文本数据中出现但未在词汇表中找到的词），默认情况下，这些未知词的索引会被设置为0。但是，你可以使用<code>set_default_index</code>方法来改变这个默认索引。这在某些情况下可能很有用，特别是当你希望将未知词的索引设置为词汇表中的一个特殊标记的索引时。</p><p>以下是<code>set_default_index</code>方法的使用示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchtext.vocab <span class="hljs-keyword">import</span> Vocab<br><br><span class="hljs-comment"># 假设你已经有一个词汇表 vocab，并且已经构建好了</span><br>vocab = Vocab(counter)<br><br><span class="hljs-comment"># 设置默认的未知词索引为特殊标记 &#x27;&lt;unk&gt;&#x27; 的索引</span><br>vocab.set_default_index(vocab[<span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>])<br></code></pre></td></tr></table></figure><p>在这个示例中，我们首先创建了一个词汇表对象<code>vocab</code>，然后使用<code>set_default_index</code>方法将默认的未知词索引设置为词汇表中特殊标记<code>&#39;&lt;unk&gt;&#39;</code>的索引。这样，当词汇表中遇到未知词时，其索引将被设置为<code>&#39;&lt;unk&gt;&#39;</code>的索引。</p><h3 id="1-3-get-itos"><a href="#1-3-get-itos" class="headerlink" title="1.3 get_itos"></a>1.3 get_itos</h3><p>source_vocab.get_itos（） 返回一个列表，其中包含基于词汇的索引中的标记。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(source_vocab.get_itos()[:<span class="hljs-number">9</span>])<br></code></pre></td></tr></table></figure><p>返回：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;sos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;Tom&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>]<br></code></pre></td></tr></table></figure><p>在构建词汇表时，首先会对训练数据进行分析，统计每个单词在数据集中出现的次数，然后按照单词出现的频率进行排序，出现频率较高的单词将排在词汇表中的靠前位置。</p><h3 id="1-4-get-stoi"><a href="#1-4-get-stoi" class="headerlink" title="1.4 get_stoi"></a>1.4 get_stoi</h3><p><code>source_vocab.get_stoi()</code> 是一个方法调用，用于获取源语言词汇表（source vocabulary）中词语到索引的映射。在机器翻译任务中，通常会构建源语言和目标语言的词汇表，以便将单词转换为对应的索引，便于在模型中进行处理。</p><p>这个方法返回一个字典，其中键是词语（或者说是单词），值是该词语在词汇表中对应的索引号。例如，如果源语言词汇表中包含单词 “hello”，并且它在词汇表中的索引号为 5，那么调用 <code>source_vocab.get_stoi()</code> 方法后会得到一个字典，其中包含键值对 <code>&#123;&#39;hello&#39;: 5&#125;</code>。</p><p>这个方法的调用是用于在源语言词汇表中查询单词对应的索引号，以便在训练或推断时将单词转换为索引号进行处理。</p><h2 id="2-transforms"><a href="#2-transforms" class="headerlink" title="2.transforms"></a>2.transforms</h2><p><code>torchtext.transforms</code>模块提供了一系列用于数据转换和处理的类和函数，它们可用于预处理文本数据或应用特定的转换。这些转换包括文本标记化、转换为小写、去除特定字符、截断或填充文本序列等。</p><h3 id="2-1-AddToken"><a href="#2-1-AddToken" class="headerlink" title="2.1 AddToken"></a>2.1 AddToken</h3><p>具体用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchtext.transforms <span class="hljs-keyword">as</span> T<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">getTransform</span>(<span class="hljs-params">vocab</span>):<br>    text_tranform = T.Sequential(<br>        T.VocabTransform(vocab=vocab),<br>        T.AddToken(<span class="hljs-number">1</span>, begin=<span class="hljs-literal">True</span>),<br>        T.AddToken(<span class="hljs-number">2</span>, begin=<span class="hljs-literal">False</span>)<br>    )<br>    <span class="hljs-keyword">return</span> text_tranform<br><br>transformed_sentence = getTransform(source_vocab)(engTokenize(some_sentence))<br></code></pre></td></tr></table></figure><p>返回：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-number">1</span>, <span class="hljs-number">90</span>, <span class="hljs-number">1089</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><p>这段代码定义了一个名为 <code>getTransform</code> 的函数，该函数接受一个词汇表 <code>vocab</code> 作为参数，并返回一个由三个转换组成的序列。下面是对每个转换的解释：</p><ol><li><code>T.VocabTransform(vocab=vocab)</code>：此转换将文本数据映射到词汇表中的索引。<code>vocab</code>参数是一个词汇表对象，它将用于将文本转换为索引序列。</li><li><code>T.AddToken(1, begin=True)</code>：此转换将在每个样本的开头添加一个特殊的标记。<code>1</code> 是要添加的标记的索引，<code>begin=True</code> 表示这个标记应该添加在序列的开头。</li><li><code>T.AddToken(2, begin=False)</code>：类似地，此转换将在每个样本的末尾添加一个特殊的标记。<code>2</code> 是要添加的标记的索引，<code>begin=False</code> 表示这个标记应该添加在序列的末尾。</li></ol><h3 id="2-2-ToTensor"><a href="#2-2-ToTensor" class="headerlink" title="2.2 ToTensor"></a>2.2 ToTensor</h3><p><code>T.ToTensor(0)</code> 是一个 TorchText 中的转换操作，它不仅将序列转换为张量形式，还会应用填充操作。在这里，<code>0</code> 被传递给构造函数，用于指定词汇表中 <code>&lt;pad&gt;</code> 标记的索引位置。</p><p>具体用法：</p><p><code>T.ToTensor(1)</code>和<code>T.ToTensor(0)</code>区别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">applyPadding</span>(<span class="hljs-params">pair_of_sequences</span>):<br>    <span class="hljs-keyword">return</span> (T.ToTensor(<span class="hljs-number">1</span>)(<span class="hljs-built_in">list</span>(pair_of_sequences[<span class="hljs-number">0</span>])), T.ToTensor(<span class="hljs-number">0</span>)(<span class="hljs-built_in">list</span>(pair_of_sequences[<span class="hljs-number">1</span>])))<br><br>data_pipe = data_pipe.<span class="hljs-built_in">map</span>(applyPadding)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(data_pipe)[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">(tensor([[   <span class="hljs-number">1</span>,    <span class="hljs-number">3</span>,  <span class="hljs-number">126</span>,    <span class="hljs-number">2</span>,    <span class="hljs-number">1</span> <span class="hljs-comment">#这里是1],</span><br><br>如果是T.ToTensor(<span class="hljs-number">0</span>)<br>tensor([[   <span class="hljs-number">1</span>, <span class="hljs-number">4020</span>,    <span class="hljs-number">4</span>,    <span class="hljs-number">2</span>,    <span class="hljs-number">0</span> <span class="hljs-comment">#这里会用0来填充]</span><br></code></pre></td></tr></table></figure><h2 id="3-data"><a href="#3-data" class="headerlink" title="3.data"></a>3.data</h2><h3 id="3-1-utils"><a href="#3-1-utils" class="headerlink" title="3.1 utils"></a>3.1 utils</h3><h4 id="3-1-1-get-tokenizer"><a href="#3-1-1-get-tokenizer" class="headerlink" title="3.1.1 get_tokenizer"></a>3.1.1 get_tokenizer</h4><p><code>get_tokenizer</code> 函数是 TorchText 库中的一个函数，用于将文本数据进行分词，通常用于自然语言处理任务。然而，需要注意的是 TorchText 是一个与 PyTorch 结合使用的库，主要用于处理自然语言处理任务。</p><p>在 TorchText 中，以下是一些常用的分词器模型：</p><ol><li><code>&#39;basic_english&#39;</code>：基本英文分词器，适用于英文文本数据的简单分词。</li><li><code>&#39;spacy&#39;</code>：SpaCy 分词器，通过 SpaCy 库提供的分词功能进行分词。需要安装 SpaCy 库以及相应的语言模型。</li><li><code>&#39;moses&#39;</code>：Moses 分词器，使用 Moses 工具包提供的分词功能进行分词。</li><li><code>&#39;bert-base-uncased&#39;</code>：BERT 分词器，使用 BERT 模型进行分词。需要安装 Transformers 库。</li></ol>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torchdata库的使用！🦔</title>
    <link href="/2024/02/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADtorchdata%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADtorchdata%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="torchdata库的使用"><a href="#torchdata库的使用" class="headerlink" title="torchdata库的使用"></a>torchdata库的使用</h1><h2 id="1-datapipes"><a href="#1-datapipes" class="headerlink" title="1.datapipes"></a>1.datapipes</h2><h3 id="1-1-iter"><a href="#1-1-iter" class="headerlink" title="1.1 iter"></a>1.1 iter</h3><h4 id="1-1-1-IterableWrapper"><a href="#1-1-1-IterableWrapper" class="headerlink" title="1.1.1 IterableWrapper"></a>1.1.1 IterableWrapper</h4><p>在 TorchData 中，<code>torchdata.datapipes.iter.IterableWrapper</code> 是一个用于封装迭代器的类。它允许你将普通的 Python 迭代器包装成一个 TorchData 可用的数据管道（DataPipe），以便进行更加灵活的数据处理和转换。</p><p><code>IterableWrapper</code> 方法的主要作用是将 Python 中的迭代器包装为 TorchData 中的数据管道，使其可以在 TorchData 的数据处理流程中被使用。这个方法接受一个迭代器作为参数，并返回一个实现了 TorchData 数据管道接口的对象，使得你可以在 TorchData 的管道中应用各种数据转换和操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">FILE_PATH = <span class="hljs-string">&#x27;cmn.txt&#x27;</span><br>data_pipe = dp.<span class="hljs-built_in">iter</span>.IterableWrapper([FILE_PATH])<br></code></pre></td></tr></table></figure><p>总的来说，<code>IterableWrapper</code> 方法为 TorchData 提供了一种便捷的方式来将普通的 Python 迭代器转换为可以在 TorchData 数据处理流程中使用的数据管道。</p><h4 id="1-1-2-FileOpener"><a href="#1-1-2-FileOpener" class="headerlink" title="1.1.2 FileOpener"></a>1.1.2 FileOpener</h4><p>在 TorchData 中，<code>torchdata.datapipes.iter.FileOpener</code> 是用于打开文件并生成可迭代对象的类。它可以将文件操作转换为 TorchData 中的数据管道，使得可以轻松地在数据处理流程中使用文件数据。</p><p><code>FileOpener</code> 主要用于处理文件数据，例如读取文本文件、图像文件等等。它接受文件路径作为参数，并返回一个实现了 TorchData 数据管道接口的对象，使得可以在 TorchData 的管道中对文件数据进行各种操作和转换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data_pipe = dp.<span class="hljs-built_in">iter</span>.FileOpener(data_pipe, mode=<span class="hljs-string">&#x27;rb&#x27;</span>)<br></code></pre></td></tr></table></figure><h4 id="1-1-3-CSVParser"><a href="#1-1-3-CSVParser" class="headerlink" title="1.1.3 CSVParser"></a>1.1.3 CSVParser</h4><p>接受由文件名和 CSV 数据流组成的 DataPipe，一次读取并返回 CSV 文件中的内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchdata.datapipes.<span class="hljs-built_in">iter</span> <span class="hljs-keyword">import</span> IterableWrapper, FileOpener<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_name</span>(<span class="hljs-params">path_and_stream</span>):<br>    <span class="hljs-keyword">return</span> os.path.basename(path_and_stream[<span class="hljs-number">0</span>]), path_and_stream[<span class="hljs-number">1</span>]<br>datapipe1 = IterableWrapper([<span class="hljs-string">&quot;1.csv&quot;</span>, <span class="hljs-string">&quot;empty.csv&quot;</span>, <span class="hljs-string">&quot;empty2.csv&quot;</span>])<br>datapipe2 = FileOpener(datapipe1, mode=<span class="hljs-string">&quot;b&quot;</span>)<br>datapipe3 = datapipe2.<span class="hljs-built_in">map</span>(get_name)<br>csv_parser_dp = datapipe3.parse_csv()<br><span class="hljs-built_in">list</span>(csv_parser_dp)<br><br><span class="hljs-comment"># 输出</span><br>[[<span class="hljs-string">&#x27;key&#x27;</span>, <span class="hljs-string">&#x27;item&#x27;</span>], [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;1&#x27;</span>], [<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>], []]<br></code></pre></td></tr></table></figure><h3 id="1-2-map"><a href="#1-2-map" class="headerlink" title="1.2 map"></a>1.2 map</h3><h4 id="1-2-1-MapDataPipe"><a href="#1-2-1-MapDataPipe" class="headerlink" title="1.2.1 MapDataPipe"></a>1.2.1 MapDataPipe</h4><p>Map 样式的 DataPipe 是实现 <code>__getitem__()</code> and <code>__len__()</code> 协议的 DataPipe，它表示从（可能是非整型）索引&#x2F;键到数据样本的映射。这与 PyTorch 核心库中的 <code>Dataset</code> 类似。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># xdoctest: +SKIP</span><br><span class="hljs-keyword">from</span> torchdata.datapipes.<span class="hljs-built_in">map</span> <span class="hljs-keyword">import</span> SequenceWrapper, Mapper<br>dp = SequenceWrapper(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br>map_dp_1 = dp.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x + <span class="hljs-number">1</span>)  <span class="hljs-comment"># Using functional form (recommended)</span><br><span class="hljs-built_in">list</span>(map_dp_1)<br><br><span class="hljs-comment"># 输出</span><br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]<br>map_dp_2 = Mapper(dp, <span class="hljs-keyword">lambda</span> x: x + <span class="hljs-number">1</span>)  <span class="hljs-comment"># Using class constructor</span><br><span class="hljs-built_in">list</span>(map_dp_2)<br><br><span class="hljs-comment"># 输出</span><br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]<br>batch_dp = map_dp_1.batch(batch_size=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">list</span>(batch_dp)<br><br><span class="hljs-comment"># 输出</span><br>[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>], [<span class="hljs-number">9</span>, <span class="hljs-number">10</span>]]<br></code></pre></td></tr></table></figure><h3 id="1-3-bucketbatch"><a href="#1-3-bucketbatch" class="headerlink" title="1.3 bucketbatch"></a>1.3 bucketbatch</h3><p><code>bucketbatch</code> 是 TorchText 中用于将数据集分组成桶（buckets）并生成批次数据的函数。这个函数通常在数据处理和准备阶段使用，特别是在序列到序列（sequence-to-sequence）模型中。</p><p><code>bucketbatch</code> 的作用是将具有相似长度的样本分组到同一个桶中，并且可以选择是否对这些桶进行随机化。随后，对每个桶中的样本进行排序，以便能够产生长度相似的序列，并且可以有效地利用填充（padding）以提高批次处理效率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data_pipe = data_pipe.bucketbatch(<br>    batch_size = <span class="hljs-number">4</span>, batch_num=<span class="hljs-number">5</span>,  bucket_num=<span class="hljs-number">1</span>,<br>    use_in_batch_shuffle=<span class="hljs-literal">False</span>, sort_key=sortBucket<br>)<br></code></pre></td></tr></table></figure><ul><li>我们保持批量大小 &#x3D; 4。</li><li>batch_num 是要保留在存储桶中的批次数</li><li>bucket_num 是池中用于洗牌的存储桶数</li><li>sort_key指定获取存储桶并对其进行排序的函数</li></ul>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spacy库的使用！🐈</title>
    <link href="/2024/02/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADspacy%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pytorch%E4%B8%ADspacy%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="spacy库的使用"><a href="#spacy库的使用" class="headerlink" title="spacy库的使用"></a>spacy库的使用</h1><h2 id="1-下载模型"><a href="#1-下载模型" class="headerlink" title="1.下载模型"></a>1.下载模型</h2><p>下载对应的github地址为<a href="https://blog.51cto.com/transfer?https://github.com/explosion/spacy-models/tags">https://blog.51cto.com/transfer?https://github.com/explosion/spacy-models/tags</a></p><h2 id="2-加载模型"><a href="#2-加载模型" class="headerlink" title="2.加载模型"></a>2.加载模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">eng = spacy.load(<span class="hljs-string">&quot;en_core_web_md-3.7.1&quot;</span>)  <span class="hljs-comment"># Load the English model to tokenize English text</span><br>zh = spacy.load(<span class="hljs-string">&quot;zh_core_web_md-3.7.0&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="3-使用模型"><a href="#3-使用模型" class="headerlink" title="3.使用模型"></a>3.使用模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">engTokenize</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Tokenize an English text and return a list of tokens</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    engTokenList = [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> eng.tokenizer(text)]<br>    <span class="hljs-keyword">return</span> engTokenList<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">zhTokenize</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Tokenize a German text and return a list of tokens</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> zh.tokenizer(text)]<br><br><br><span class="hljs-built_in">print</span>(engTokenize(<span class="hljs-string">&quot;Have a good day!!!&quot;</span>))<br><span class="hljs-built_in">print</span>(zhTokenize(<span class="hljs-string">&quot;我今天过的很开心，谭国军去哪玩 !!!&quot;</span>))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP库的使用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>numpy库的使用！☃️</title>
    <link href="/2024/02/21/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADnumpy%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/21/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADnumpy%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="numpy库的使用"><a href="#numpy库的使用" class="headerlink" title="numpy库的使用"></a>numpy库的使用</h1><p>获取指定的行列规则:</p><p>1.逗号隔开维度。</p><p>2.分号选择某一维度中的范围，<strong>不可省略分号</strong>，只能省略范围值。</p><p>3.省略号等于多个分号，<strong>一个索引中只能出现一个省略号</strong>。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>arr = np.random.rand(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(arr)<br><br><span class="hljs-comment"># 获取所有第一个维度、第二个维度中的前两个元素，以及第三个维度中的所有元素</span><br>result = arr[..., :<span class="hljs-number">2</span>,:]<br><br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 (2, 3, 2, 5)，其中是省略号代表前两个维度，第三个维度省略起始值0，最后一个维度省略起始值和终止值。</span><br></code></pre></td></tr></table></figure><h2 id="1-np-zeros"><a href="#1-np-zeros" class="headerlink" title="1.np.zeros"></a>1.np.zeros</h2><p><code>np.zeros()</code> 是 NumPy 中的一个函数，用于创建一个由零组成的数组。其语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">numpy.zeros(shape, dtype=<span class="hljs-built_in">float</span>, order=<span class="hljs-string">&#x27;C&#x27;</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>shape</code>：生成数组的形状，可以是一个整数或者一个元组。</li><li><code>dtype</code>（可选）：生成数组的数据类型，默认为 <code>float</code>。</li><li><code>order</code>（可选）：数组的存储顺序，可以是 <code>&#39;C&#39;</code>（C 风格，按行存储）或者 <code>&#39;F&#39;</code>（Fortran 风格，按列存储），默认为 <code>&#39;C&#39;</code>。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 创建一个形状为 (3, 3) 的零数组</span><br>arr = np.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><span class="hljs-built_in">print</span>(arr)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 创建一个形状为 (3, 3) 的零数组</span><br>arr = np.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><span class="hljs-built_in">print</span>(arr)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch中数据的加载!🍧</title>
    <link href="/2024/02/21/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E4%B8%AD%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD/"/>
    <url>/2024/02/21/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E4%B8%AD%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<h1 id="pytorch中数据的加载"><a href="#pytorch中数据的加载" class="headerlink" title="pytorch中数据的加载"></a>pytorch中数据的加载</h1><h2 id="1-TensorDataset"><a href="#1-TensorDataset" class="headerlink" title="1.TensorDataset"></a>1.TensorDataset</h2><p><code>TensorDataset</code>是PyTorch中的一个类，用于创建一个张量数据集，它可以将多个张量打包成一个数据集。通常情况下，这个数据集会用于数据加载器（<code>DataLoader</code>）中，以便于对张量数据进行批处理、随机采样等操作。</p><p><code>TensorDataset</code>的常见用法是将特征张量和标签张量打包在一起，然后将它们传递给<code>DataLoader</code>，以便于对数据进行迭代访问。在每次迭代中，<code>DataLoader</code>会返回一个批量的特征张量和对应的标签张量。</p><p>下面是一个示例代码，演示了如何使用<code>TensorDataset</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset, DataLoader<br><br><span class="hljs-comment"># 假设有特征张量 features 和标签张量 labels</span><br>features = torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">5</span>)  <span class="hljs-comment"># 100个样本，每个样本包含5个特征</span><br>labels = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">100</span>,))  <span class="hljs-comment"># 100个样本的二元标签</span><br><br><span class="hljs-comment"># 创建一个TensorDataset对象，将特征张量和标签张量打包在一起</span><br>dataset = TensorDataset(features, labels)<br><br><span class="hljs-comment"># 创建一个DataLoader，用于对数据进行批处理和随机采样</span><br>batch_size = <span class="hljs-number">32</span><br>data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 遍历数据加载器，对数据进行迭代访问</span><br><span class="hljs-keyword">for</span> batch_features, batch_labels <span class="hljs-keyword">in</span> data_loader:<br>    <span class="hljs-comment"># 这里可以对每个批量的特征和标签进行处理</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Batch Features:&quot;</span>, batch_features.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Batch Labels:&quot;</span>, batch_labels.shape)<br></code></pre></td></tr></table></figure><p>在这个示例中，<code>TensorDataset</code>被用来将特征张量和标签张量打包在一起，然后通过<code>DataLoader</code>对数据进行批处理和随机采样。<code>DataLoader</code>每次返回一个由特征和标签组成的批量。</p><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">Batch Features: torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">5</span>])<br>Batch Labels: torch.Size([<span class="hljs-number">32</span>])<br>Batch Features: torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">5</span>])<br>Batch Labels: torch.Size([<span class="hljs-number">32</span>])<br>Batch Features: torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">5</span>])<br>Batch Labels: torch.Size([<span class="hljs-number">32</span>])<br>Batch Features: torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br>Batch Labels: torch.Size([<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure><h2 id="2-RandomSampler"><a href="#2-RandomSampler" class="headerlink" title="2.RandomSampler"></a>2.RandomSampler</h2><p>RandomSampler是PyTorch中的一个采样器（Sampler），用于在数据集中进行随机采样。在PyTorch中，它通常与DataLoader一起使用，用于生成mini-batches，以便进行训练或评估。</p><p>RandomSampler的工作原理如下：</p><ol><li>初始化时，RandomSampler接收一个数据集（如PyTorch的Dataset对象）作为参数，并确定要采样的数据集大小（即数据集的长度）。</li><li>在每个epoch开始时，RandomSampler会随机打乱数据集的索引。</li><li>在训练或评估过程中，当DataLoader从数据集中获取mini-batch时，它会使用RandomSampler生成的随机索引来选择数据样本。这样可以确保每个epoch中的mini-batches都是随机的，从而增加模型的泛化能力和训练的多样性。</li></ol><p>总之，RandomSampler通过在每个epoch开始时重新打乱数据集索引，以确保每个mini-batch的样本是随机选择的，从而帮助模型更好地学习数据的分布特征。</p><p>具体用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">train_data = TensorDataset(torch.LongTensor(input_ids).to(device),<br>                               torch.LongTensor(target_ids).to(device))<br><br>    train_sampler = RandomSampler(train_data)<br>    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)<br>    <span class="hljs-keyword">return</span> input_lang, output_lang, train_dataloader<br></code></pre></td></tr></table></figure><h2 id="3-DataLoader"><a href="#3-DataLoader" class="headerlink" title="3.DataLoader"></a>3.DataLoader</h2><p>在 PyTorch 中，DataLoader 是一个用于加载数据的实用工具，通常用于训练神经网络模型时。它可以自动批处理、并行加载数据以及数据打乱，提高了数据加载的效率。下面是一个简单的示例，演示如何使用 DataLoader：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, Dataset<br><br><span class="hljs-comment"># 假设你有一个自定义的数据集类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data</span>):<br>        self.data = data<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">return</span> self.data[index]<br><br><span class="hljs-comment"># 创建一个示例数据集</span><br>data = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)]<br><br><span class="hljs-comment"># 创建数据集实例</span><br>dataset = CustomDataset(data)<br><br><span class="hljs-comment"># 定义 DataLoader 参数</span><br>batch_size = <span class="hljs-number">10</span><br>shuffle = <span class="hljs-literal">True</span><br><br><span class="hljs-comment"># 创建 DataLoader 实例</span><br>dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)<br><br><span class="hljs-comment"># 遍历 DataLoader 获取数据批次</span><br><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> dataloader:<br>    <span class="hljs-built_in">print</span>(batch)<br></code></pre></td></tr></table></figure><p>在这个示例中：</p><ul><li>首先定义了一个 <code>CustomDataset</code> 类，该类继承自 <code>torch.utils.data.Dataset</code>，并实现了 <code>__len__</code> 和 <code>__getitem__</code> 方法，其中 <code>__len__</code> 返回数据集的大小，<code>__getitem__</code> 根据给定索引返回对应的数据样本。</li><li>创建了一个示例数据集 <code>data</code>，并使用 <code>CustomDataset</code> 类创建了一个数据集实例 <code>dataset</code>。</li><li>定义了 <code>DataLoader</code> 的参数，包括 <code>batch_size</code>（批量大小）和 <code>shuffle</code>（是否在每个 epoch 中打乱数据）。</li><li>使用 <code>DataLoader</code> 类创建了一个数据加载器实例 <code>dataloader</code>。</li><li>最后，通过遍历 <code>dataloader</code>，可以逐批获取数据。</li></ul><p><strong>tips：</strong></p><p>在 PyTorch 中，<code>sampler</code> 和 <code>shuffle</code> 是 DataLoader 的两个重要参数，它们在控制数据加载时起着不同的作用。</p><ol><li><strong>shuffle</strong>：<ul><li><code>shuffle</code> 参数是一个布尔值，用于指定是否在每个 epoch 中对数据进行随机打乱。</li><li>当 <code>shuffle=True</code> 时，数据会在每个 epoch 开始时被随机打乱，这有助于模型更好地学习数据的分布，防止模型对数据的顺序产生依赖。</li><li>如果 <code>shuffle=False</code>，则数据不会被打乱，按照原始顺序被加载。</li></ul></li><li><strong>sampler</strong>：<ul><li><code>sampler</code> 参数用于指定数据采样器对象，允许用户自定义数据的采样方式。</li><li>默认情况下，当没有指定 <code>sampler</code> 参数时，DataLoader 会使用 <code>SequentialSampler</code>，它按顺序返回数据样本的索引。</li><li>另一方面，如果你想要自定义采样逻辑，比如实现自己的采样器对象或者使用带权重的采样方式，你可以通过指定 <code>sampler</code> 参数来实现这一目的。</li></ul></li></ol><p>在实践中，通常情况下会将 <code>shuffle=True</code> 以打乱数据顺序，从而增加模型的泛化能力，特别是在训练深度学习模型时。而 <code>sampler</code> 参数则允许更进一步的自定义数据加载方式，比如处理不均衡的数据集或者实现特殊的采样逻辑。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用torch方法！🍧</title>
    <link href="/2024/02/21/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B8%B8%E7%94%A8torch%E6%96%B9%E6%B3%95/"/>
    <url>/2024/02/21/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B8%B8%E7%94%A8torch%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="常用torch方法"><a href="#常用torch方法" class="headerlink" title="常用torch方法"></a>常用torch方法</h1><h2 id="1-cat"><a href="#1-cat" class="headerlink" title="1.cat"></a>1.cat</h2><p><code>torch.cat</code> 是 PyTorch 中的一个函数，用于沿指定的维度拼接（连接）多个张量。</p><p>具体而言，<code>Tensor.cat</code> 函数将多个张量沿着指定的维度连接在一起，形成一个新的张量。连接的维度称为“拼接维度”。函数的签名通常如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">output_tensor = torch.cat(tensors, dim=<span class="hljs-number">0</span>, out=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>tensors</code> 是一个张量列表，包含了要连接的张量。</li><li><code>dim</code> 是一个整数，表示沿着哪个维度进行连接。默认为 0。</li><li><code>out</code> 是一个可选的输出张量。</li></ul><p>以下是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建两个示例张量</span><br>tensor1 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>tensor2 = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br><span class="hljs-comment"># 在第0维度上拼接这两个张量</span><br>concatenated_tensor = torch.cat((tensor1, tensor2), dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(concatenated_tensor)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br>        [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],<br>        [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br></code></pre></td></tr></table></figure><p>在这个示例中，我们沿着第0维度拼接了两个二维张量，因此第一个张量的两行与第二个张量的两行按顺序连接在一起，形成了一个新的张量。</p><h2 id="2-empty"><a href="#2-empty" class="headerlink" title="2.empty"></a>2.empty</h2><p><code>torch.empty()</code> 是一个用于创建一个未初始化的张量的函数，其具体的签名如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.empty(*size, *, out=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>, layout=torch.strided, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>这个函数创建一个指定大小的张量，但是不会对张量进行初始化，即张量的元素值是未定义的，取决于内存的状态。</p><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个形状为 2x3 的未初始化的张量</span><br>empty_tensor = torch.empty(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Empty Tensor:&quot;</span>)<br><span class="hljs-built_in">print</span>(empty_tensor)<br><br><span class="hljs-comment"># 指定数据类型为 float32</span><br>empty_float_tensor = torch.empty(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, dtype=torch.float32)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nEmpty Float32 Tensor:&quot;</span>)<br><span class="hljs-built_in">print</span>(empty_float_tensor)<br></code></pre></td></tr></table></figure><h2 id="3-tanh"><a href="#3-tanh" class="headerlink" title="3.tanh"></a>3.tanh</h2><p><code>torch.tanh()</code> 是 PyTorch 中的一个函数，用于计算张量中每个元素的双曲正切值。双曲正切函数是一种常见的非线性激活函数，通常用于神经网络中。</p><p>该函数的输出范围是 <code>(−1,1)</code>，当输入接近正无穷时，输出接近于 1，当输入接近负无穷时，输出接近于 -1，当输入为 0 时，输出为 0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个张量</span><br>tensor = torch.tensor([-<span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>])<br><br><span class="hljs-comment"># 计算张量中每个元素的双曲正切值</span><br>result = torch.tanh(tensor)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Original Tensor:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nTanh Result:&quot;</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">Original Tensor:<br>tensor([-<span class="hljs-number">1.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>])<br><br>Tanh Result:<br>tensor([-<span class="hljs-number">0.7616</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.7616</span>])<br></code></pre></td></tr></table></figure><h2 id="4-bmm"><a href="#4-bmm" class="headerlink" title="4.bmm"></a>4.bmm</h2><p><code>torch.bmm</code> 是 PyTorch 中用于批量矩阵乘法（Batch Matrix Multiplication）的函数。假设你有两个张量 <code>A</code> 和 <code>B</code>，它们的形状分别为 <code>(batch_size, n, m)</code> 和 <code>(batch_size, m, p)</code>。<code>torch.bmm</code> 将执行批量的矩阵乘法，即对于每个批次中的矩阵对，计算矩阵乘积。</p><p>输出的结果将是一个形状为 <code>(batch_size, n, p)</code> 的张量，其中每个批次的乘积将会被计算。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 假设 A 和 B 是具体的张量，需要确保它们的形状匹配</span><br><span class="hljs-comment"># 例如，A的最后一个维度（m）应该与B的倒数第二个维度（m）相同</span><br>A = torch.tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                   [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]],<br><br>                  [[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>],<br>                   [<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>]]])<br><br>B = torch.tensor([[[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                   [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>],<br>                   [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],<br><br>                  [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br>                   [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>                   [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]]])<br><br><span class="hljs-comment"># 计算矩阵乘积</span><br>C = torch.bmm(A, B)<br><br><span class="hljs-built_in">print</span>(C)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">28</span>,  <span class="hljs-number">34</span>],<br>         [ <span class="hljs-number">64</span>,  <span class="hljs-number">79</span>]],<br><br>        [[ <span class="hljs-number">76</span>, <span class="hljs-number">100</span>],<br>         [<span class="hljs-number">103</span>, <span class="hljs-number">136</span>]]])<br></code></pre></td></tr></table></figure><p>即让每个批次的张量相乘。</p><h2 id="5-randn"><a href="#5-randn" class="headerlink" title="5.randn"></a>5.randn</h2><p><code>torch.randn()</code> 是 PyTorch 中的一个函数，用于生成具有标准正态分布（均值为0，标准差为1）的随机张量。其语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.randn(*size, dtype=<span class="hljs-literal">None</span>, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>*size</code>：生成张量的形状，可以是一个整数或者元组。</li><li><code>dtype</code>（可选）：生成张量的数据类型，默认为 <code>torch.float32</code>。</li><li><code>device</code>（可选）：生成张量所在的设备，默认为 <code>None</code>，表示使用当前的默认设备。</li><li><code>requires_grad</code>（可选）：指定是否需要计算梯度，默认为 <code>False</code>。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 生成一个形状为 (3, 3) 的随机张量，满足标准正态分布</span><br>x = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(x)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[-<span class="hljs-number">0.6848</span>, -<span class="hljs-number">0.3440</span>,  <span class="hljs-number">1.1301</span>],<br>        [-<span class="hljs-number">0.1869</span>,  <span class="hljs-number">1.0607</span>, -<span class="hljs-number">1.0181</span>],<br>        [ <span class="hljs-number">0.5477</span>, -<span class="hljs-number">0.1585</span>, -<span class="hljs-number">0.3474</span>]])<br></code></pre></td></tr></table></figure><h2 id="6-randint"><a href="#6-randint" class="headerlink" title="6.randint"></a>6.randint</h2><p><code>torch.randint()</code> 是 PyTorch 中的一个函数，用于生成具有离散均匀分布的随机整数张量。其语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.randint(low, high, size, dtype=<span class="hljs-literal">None</span>, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>low</code>：生成随机整数的下界（闭区间）。</li><li><code>high</code>：生成随机整数的上界（开区间）。</li><li><code>size</code>：生成张量的形状，可以是一个整数或者元组。</li><li><code>dtype</code>（可选）：生成张量的数据类型，默认为 <code>torch.int64</code>。</li><li><code>device</code>（可选）：生成张量所在的设备，默认为 <code>None</code>，表示使用当前的默认设备。</li><li><code>requires_grad</code>（可选）：指定是否需要计算梯度，默认为 <code>False</code>。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 生成一个形状为 (3, 3) 的随机整数张量，范围在 [0, 10) 内</span><br>x = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><span class="hljs-built_in">print</span>(x)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">9</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>],<br>        [<span class="hljs-number">8</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>]])<br></code></pre></td></tr></table></figure><h2 id="7-manual-seed"><a href="#7-manual-seed" class="headerlink" title="7.manual_seed"></a>7.manual_seed</h2><p><code>torch.manual_seed(seed)</code> 是 PyTorch 中的一个函数，用于设置随机数种子。随机数种子对于深度学习任务中的随机性操作是非常重要的，比如权重初始化、数据扰动等。</p><p>通过调用 <code>torch.manual_seed(seed)</code> 函数，可以在每次运行代码时生成相同的随机数序列，这样可以确保实验的可复现性。<code>seed</code> 参数是一个整数，它是随机数生成器的种子值。</p><p>示例用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 设置随机数种子为固定值 42</span><br>torch.manual_seed(<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 下面的操作将使用相同的随机数种子生成随机数</span><br>a = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>b = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-built_in">print</span>(a)<br><span class="hljs-built_in">print</span>(b)<br></code></pre></td></tr></table></figure><p>在此示例中，通过设置随机数种子为 42，每次运行代码时，生成的随机数将是相同的。这有助于实验结果的可重现性。</p><h2 id="8-exp"><a href="#8-exp" class="headerlink" title="8.exp"></a>8.exp</h2><p><code>torch.exp</code> 是 PyTorch 中的一个函数，用于计算输入张量的指数函数。该函数的输入可以是一个张量或者一个数值。对于张量输入，<code>torch.exp</code> 会对张量中的每个元素进行指数运算，即将每个元素取自然指数。对于数值输入，函数返回输入的指数值。</p><p>以下是 <code>torch.exp</code> 的基本使用方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 对数值进行指数运算</span><br>x = <span class="hljs-number">2.0</span><br>exp_x = torch.exp(x)<br><span class="hljs-built_in">print</span>(exp_x)  <span class="hljs-comment"># 输出: tensor(7.3891)</span><br><br><span class="hljs-comment"># 对张量进行指数运算</span><br>tensor_x = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>])<br>exp_tensor_x = torch.exp(tensor_x)<br><span class="hljs-built_in">print</span>(exp_tensor_x)  <span class="hljs-comment"># 输出: tensor([ 2.7183,  7.3891, 20.0855])</span><br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p>当 x 为任意实数时，exp(<em>x</em>) 的值等于 e 的 x 次方。</p><h2 id="9-arrange"><a href="#9-arrange" class="headerlink" title="9.arrange"></a>9.arrange</h2><p><code>torch.arange</code> 是 PyTorch 中的一个函数，用于创建一个包含等间隔值的一维张量。它的语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.arange(start=<span class="hljs-number">0</span>, end, step=<span class="hljs-number">1</span>, dtype=<span class="hljs-literal">None</span>, layout=torch.strided, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p><code>torch.arange</code> 是 PyTorch 中的一个函数，用于创建一个包含等间隔值的一维张量。它的语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pythonCopy code<br>torch.arange(start=<span class="hljs-number">0</span>, end, step=<span class="hljs-number">1</span>, dtype=<span class="hljs-literal">None</span>, layout=torch.strided, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>参数说明：</p><ul><li><code>start</code>：起始值（默认为 0）。</li><li><code>end</code>：终止值（不包含在结果中）。</li><li><code>step</code>：步长（默认为 1）。</li><li><code>dtype</code>：结果张量的数据类型（默认为 None，即根据上下文推断）。</li><li><code>layout</code>：结果张量的布局（默认为 torch.strided）。</li><li><code>device</code>：结果张量所在的设备（默认为 None，即使用当前设备）。</li><li><code>requires_grad</code>：结果张量是否需要梯度（默认为 False）。</li></ul><p><code>torch.arange</code> 返回一个从 <code>start</code> 到 <code>end</code>（不包含 <code>end</code>）的一维张量，步长为 <code>step</code>。下面是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个从 0 到 9（不包含 10）的一维张量</span><br>tensor = torch.arange(<span class="hljs-number">10</span>)<br><span class="hljs-built_in">print</span>(tensor)  <span class="hljs-comment"># 输出: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span><br><br><span class="hljs-comment"># 创建一个从 5 到 15（不包含 15）的一维张量，步长为 2</span><br>tensor = torch.arange(<span class="hljs-number">5</span>, <span class="hljs-number">15</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(tensor)  <span class="hljs-comment"># 输出: tensor([ 5,  7,  9, 11, 13])</span><br></code></pre></td></tr></table></figure><h2 id="10-triu"><a href="#10-triu" class="headerlink" title="10.triu"></a>10.triu</h2><p><code>torch.triu</code> 是 PyTorch 中的一个函数，用于生成一个张量，该张量包含给定输入张量的上三角部分（包括对角线）。在数学上，上三角矩阵是一个所有位于主对角线及其以上的元素都不为零的矩阵。</p><p>以下是 <code>torch.triu</code> 的中文解释：</p><ul><li>函数名：<code>torch.triu</code></li><li>功能：返回输入张量的上三角部分。</li><li>参数：<ul><li><code>input</code>：（张量）要处理的输入张量。</li><li><code>diagonal</code>：（整数，可选）对角线的偏移量。默认值为0，表示主对角线；正值表示上面的对角线，负值表示下面的对角线。</li></ul></li><li>返回值：一个张量，包含输入张量的上三角部分。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                  [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>],<br>                  [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]])<br><br>result = torch.triu(x)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>],<br>        [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>attention介绍！💐</title>
    <link href="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/"/>
    <url>/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/</url>
    
    <content type="html"><![CDATA[<h1 id="attention介绍"><a href="#attention介绍" class="headerlink" title="attention介绍"></a>attention介绍</h1><p>如果仅在编码器和解码器之间传递上下文向量，则该单个向量承担对整个句子进行编码的负担。注意力允许解码器网络“聚焦”在编码器输出的不同部分，用于解码器自身输出的每一步。</p><h2 id="1-soft-attention"><a href="#1-soft-attention" class="headerlink" title="1.soft attention"></a>1.soft attention</h2><p>**query:**解码器中对下一个预测目标作为输入的hidden值。</p><p>**key:**编码器的输出值。</p><p>具体为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BahdanauAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size</span>):<br>        <span class="hljs-built_in">super</span>(BahdanauAttention, self).__init__()<br>        self.Wa = nn.Linear(hidden_size, hidden_size)<br>        self.Ua = nn.Linear(hidden_size, hidden_size)<br>        self.Va = nn.Linear(hidden_size, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, keys</span>):<br>        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))<br>        scores = scores.squeeze(<span class="hljs-number">2</span>).unsqueeze(<span class="hljs-number">1</span>)<br><br>        weights = F.softmax(scores, dim=-<span class="hljs-number">1</span>)<br>        context = torch.bmm(weights, keys)<br><br>        <span class="hljs-keyword">return</span> context, weights<br></code></pre></td></tr></table></figure><p>注意力机制是将注意力上下文与decoder的输入值进行结合，加上前一个解码目标输出的隐藏值作为新的解码目标的输入。在解码器中具体应用在：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden, encoder_outputs</span>):<br>        embedded =  self.dropout(self.embedding(<span class="hljs-built_in">input</span>))<br><br>        query = hidden.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        context, attn_weights = self.attention(query, encoder_outputs)<br>        input_gru = torch.cat((embedded, context), dim=<span class="hljs-number">2</span>)<br><br>        output, hidden = self.gru(input_gru, hidden)<br>        output = self.out(output)<br><br>        <span class="hljs-keyword">return</span> output, hidden, attn_weights<br></code></pre></td></tr></table></figure><p>因为是求一个解码目标的注意力上下文，所以该上下文一定是和前一个解码目标相关且有一个独立的权重来和编码内容进行加权。</p><p>因此注意力网络需要将query和key作为输入，产生权重值之后进行梯度优化。</p><p>Wa，Ua，Va的初始值也是随机的，在训练过程中不断进行梯度优化，得到合适的权重值。</p><p><strong>tips：</strong></p><p>为什么需要单独对query和key都进行注意力空间的映射？如果不映射的话，那么从key*Va这一部分的值就是固定的，无法获取好的特征。</p><h2 id="2-self-attention"><a href="#2-self-attention" class="headerlink" title="2.self attention"></a>2.self attention</h2><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/1.png"></p><p>如图所示，每一个输入值都会映射到三个空间Q,K,V</p><p><strong>Q的作用：</strong>和soft attention中的query一样，用作指定解码目标的参数，在自注意力机制中，因为每一个解码目标的特异性参数是自己本身，所以需要一个Q的映射。</p><p><strong>K的作用：</strong>和soft attention中的key一样，用来获取每一个词对自身的影响。</p><p><strong>V的作用：</strong>和soft attention中求加权值时和权重相乘的值一样，只不过在soft attention中值是原来的encoder_output，而在自注意力机制中中需要多映射到一个值空间中去。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/2.png"></p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/3.png"></p><p>具体流程:</p><h3 id="2-1-Q-K-V-的计算"><a href="#2-1-Q-K-V-的计算" class="headerlink" title="2.1 Q, K, V 的计算"></a>2.1 Q, K, V 的计算</h3><p>Self-Attention 的输入用矩阵X进行表示，则可以使用线性变阵矩阵<strong>WQ,WK,WV</strong>计算得到<strong>Q,K,V</strong>。计算如下图所示，<strong>注意 X, Q, K, V 的每一行都表示一个单词。</strong></p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/4.png"></p><h3 id="2-2-Self-Attention-的输出"><a href="#2-2-Self-Attention-的输出" class="headerlink" title="2.2 Self-Attention 的输出"></a>2.2 Self-Attention 的输出</h3><p>得到矩阵 Q, K, V之后就可以计算出 Self-Attention 的输出了，计算的公式如下：</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/5.png"></p><p>公式中计算矩阵<strong>Q</strong>和<strong>K</strong>每一行向量的内积，为了防止内积过大，因此除以 dk 的平方根。<strong>Q</strong>乘以<strong>K</strong>的转置后，得到的矩阵行列数都为 n，n 为句子单词数，这个矩阵可以表示单词之间的 attention 强度。下图为<strong>Q</strong>乘以KT ，1234 表示的是句子中的单词。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/6.png"></p><p>得到QKT 之后，使用 Softmax 计算每一个单词对于其他单词的 attention 系数，公式中的 Softmax 是对矩阵的每一行进行 Softmax，即每一行的和都变为 1.</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/7.png"></p><p>得到 Softmax 矩阵之后可以和<strong>V</strong>相乘，得到最终的输出<strong>Z</strong>。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/8.png"></p><p>上图中 Softmax 矩阵的第 1 行表示单词 1 与其他所有单词的 attention 系数，最终单词 1 的输出 �1 等于所有单词 i 的值 �� 根据 attention 系数的比例加在一起得到，如下图所示：</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/9.png"></p><h2 id="3-Multi-Head-Attention"><a href="#3-Multi-Head-Attention" class="headerlink" title="3.Multi-Head Attention"></a>3.Multi-Head Attention</h2><p>在上一步，我们已经知道怎么通过 Self-Attention 计算得到输出矩阵 Z，而 Multi-Head Attention 是由多个 Self-Attention 组合形成的，下图是论文中 Multi-Head Attention 的结构图。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/10.png"></p><p>从上图可以看到 Multi-Head Attention 包含多个 Self-Attention 层，首先将输入<strong>X</strong>分别传递到 h 个不同的 Self-Attention 中，计算得到 h 个输出矩阵<strong>Z</strong>。下图是 h&#x3D;8 时候的情况，此时会得到 8 个输出矩阵<strong>Z</strong>。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/11.png"></p><p>得到 8 个输出矩阵 Z1 到 Z8 之后，Multi-Head Attention 将它们拼接在一起 <strong>(Concat)<strong>，然后传入一个</strong>Linear</strong>层，得到 Multi-Head Attention 最终的输出<strong>Z</strong>。</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/attention/12.png"></p><p>可以看到 Multi-Head Attention 输出的矩阵<strong>Z</strong>与其输入的矩阵<strong>X</strong>的维度是一样的。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>seq2seq介绍！💐</title>
    <link href="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/seq2seq/"/>
    <url>/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/seq2seq/</url>
    
    <content type="html"><![CDATA[<h1 id="seq2seq介绍"><a href="#seq2seq介绍" class="headerlink" title="seq2seq介绍"></a>seq2seq介绍</h1><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/seq2seq/1.png"></p><p>如上图所示，左边的解码器将单个的单词作为输入，每一个单词都有一个输出和隐藏值，基本原理同RNN，而最后一个隐藏值作为上下文向量输入到解码器，作为解码器第一个值的隐藏值，解码器的第一个输入值是<SOS>,输出的内容作为新的输入不断递归。</p><h2 id="1-编码器"><a href="#1-编码器" class="headerlink" title="1.编码器"></a>1.编码器</h2><p>图示：</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/seq2seq/2.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, dropout_p=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>(EncoderRNN, self).__init__()<br>        self.hidden_size = hidden_size<br><br>        self.embedding = nn.Embedding(input_size, hidden_size)<br>        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br>        self.dropout = nn.Dropout(dropout_p)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        embedded = self.dropout(self.embedding(<span class="hljs-built_in">input</span>))<br>        output, hidden = self.gru(embedded)<br>        <span class="hljs-keyword">return</span> output, hidden<br></code></pre></td></tr></table></figure><h2 id="2-解码器"><a href="#2-解码器" class="headerlink" title="2.解码器"></a>2.解码器</h2><p>图示：</p><p><img src="/2024/02/20/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/seq2seq/3.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(DecoderRNN, self).__init__()<br>        self.embedding = nn.Embedding(output_size, hidden_size)<br>        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br>        self.out = nn.Linear(hidden_size, output_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_outputs, encoder_hidden, target_tensor=<span class="hljs-literal">None</span></span>):<br>        batch_size = encoder_outputs.size(<span class="hljs-number">0</span>)<br>        decoder_input = torch.empty(batch_size, <span class="hljs-number">1</span>, dtype=torch.long, device=device).fill_(SOS_token)<br>        decoder_hidden = encoder_hidden<br>        decoder_outputs = []<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(MAX_LENGTH):<br>            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)<br>            decoder_outputs.append(decoder_output)<br><br>            <span class="hljs-keyword">if</span> target_tensor <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-comment"># Teacher forcing: Feed the target as the next input</span><br>                decoder_input = target_tensor[:, i].unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># Teacher forcing</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># Without teacher forcing: use its own predictions as the next input</span><br>                _, topi = decoder_output.topk(<span class="hljs-number">1</span>)<br>                decoder_input = topi.squeeze(-<span class="hljs-number">1</span>).detach()  <span class="hljs-comment"># detach from history as input</span><br><br>        decoder_outputs = torch.cat(decoder_outputs, dim=<span class="hljs-number">1</span>)<br>        decoder_outputs = F.log_softmax(decoder_outputs, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> decoder_outputs, decoder_hidden, <span class="hljs-literal">None</span> <span class="hljs-comment"># We return `None` for consistency in the training loop</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden</span>):<br>        output = self.embedding(<span class="hljs-built_in">input</span>)<br>        output = F.relu(output)<br>        output, hidden = self.gru(output, hidden)<br>        output = self.out(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>time库的使用！☃️</title>
    <link href="/2024/02/16/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADtime%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2024/02/16/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADtime%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="time库的使用"><a href="#time库的使用" class="headerlink" title="time库的使用"></a>time库的使用</h1><h2 id="1-具体使用方法"><a href="#1-具体使用方法" class="headerlink" title="1.具体使用方法"></a>1.具体使用方法</h2><p>在Python中，<code>time</code>库是用于处理时间的标准库之一。它提供了许多函数来获取当前时间、格式化时间、等待一段时间等功能。下面是一些<code>time</code>库中常用的函数和示例用法：</p><h3 id="1-1-time"><a href="#1-1-time" class="headerlink" title="1.1 time()"></a>1.1 <code>time()</code></h3><p>函数的结果是当前时间的时间戳</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br>current_time = time.time()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;当前时间戳:&quot;</span>, current_time)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">当前时间戳: <span class="hljs-number">1645049140.4448426</span><br></code></pre></td></tr></table></figure><h3 id="1-2-ctime"><a href="#1-2-ctime" class="headerlink" title="1.2 ctime()"></a>1.2 <code>ctime()</code></h3><p>函数将时间戳转换为可读的时间字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br>current_time = time.time()<br>readable_time = time.ctime(current_time)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;当前时间:&quot;</span>, readable_time)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pyhon">当前时间: Tue Feb 16 13:39:00 2024<br></code></pre></td></tr></table></figure><h3 id="1-3-sleep"><a href="#1-3-sleep" class="headerlink" title="1.3 sleep()"></a>1.3 <code>sleep()</code></h3><p>函数让程序休眠指定的时间</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始休眠...&quot;</span>)<br>time.sleep(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 休眠3秒</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;休眠结束。&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="1-4-strftime"><a href="#1-4-strftime" class="headerlink" title="1.4 strftime()"></a>1.4 <code>strftime()</code></h3><p>函数格式化时间字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br>current_time = time.localtime()<br>formatted_time = time.strftime(<span class="hljs-string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, current_time)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;格式化后的时间:&quot;</span>, formatted_time)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">格式化后的时间: <span class="hljs-number">2024</span>-02-<span class="hljs-number">16</span> <span class="hljs-number">13</span>:<span class="hljs-number">39</span>:<span class="hljs-number">00</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>seq2seq和注意力机制的翻译！🌞</title>
    <link href="/2024/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/seq2seq%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%BF%BB%E8%AF%91/"/>
    <url>/2024/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/seq2seq%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%BF%BB%E8%AF%91/</url>
    
    <content type="html"><![CDATA[<h1 id="seq2seq和注意力机制的翻译"><a href="#seq2seq和注意力机制的翻译" class="headerlink" title="seq2seq和注意力机制的翻译"></a>seq2seq和注意力机制的翻译</h1><h2 id="1-加载数据文件"><a href="#1-加载数据文件" class="headerlink" title="1.加载数据文件"></a>1.加载数据文件</h2><p>与字符级 RNN 教程中使用的字符编码类似，我们将语言中的每个单词表示为一个热向量，或除单个 0 之外的巨大向量（在单词的索引处）。与一种语言中可能存在的数十个字符相比，单词要多得多，因此编码向量要大得多。但是，我们将进行一些作弊，并将数据修剪为每种语言仅使用几千个单词。</p><p>我们需要每个单词的唯一索引，以便稍后用作网络的输入和目标。为了跟踪所有这些，我们将使用一个名为的 <code>Lang</code> 帮助程序类，该类具有单词→索引 （ <code>word2index</code> ） 和索引 → 单词 （ <code>index2word</code> ） 字典，以及每个单词 <code>word2count</code> 的计数，稍后将用于替换生僻词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">SOS_token = <span class="hljs-number">0</span><br>EOS_token = <span class="hljs-number">1</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Lang</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name</span>):<br>        self.name = name<br>        self.word2index = &#123;&#125;<br>        self.word2count = &#123;&#125;<br>        self.index2word = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;SOS&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;EOS&quot;</span>&#125;<br>        self.n_words = <span class="hljs-number">2</span>  <span class="hljs-comment"># Count SOS and EOS</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addSentence</span>(<span class="hljs-params">self, sentence</span>):<br>        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence.split(<span class="hljs-string">&#x27; &#x27;</span>):<br>            self.addWord(word)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addWord</span>(<span class="hljs-params">self, word</span>):<br>        <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.word2index:<br>            self.word2index[word] = self.n_words<br>            self.word2count[word] = <span class="hljs-number">1</span><br>            self.index2word[self.n_words] = word<br>            self.n_words += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            self.word2count[word] += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>这些文件都是Unicode格式，为了简化起见，我们将Unicode字符转换为ASCII，使所有内容都小写，并修剪大多数标点符号。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Turn a Unicode string to plain ASCII, thanks to</span><br><span class="hljs-comment"># https://stackoverflow.com/a/518232/2809427</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">unicodeToAscii</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(<br>        c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> unicodedata.normalize(<span class="hljs-string">&#x27;NFD&#x27;</span>, s)<br>        <span class="hljs-keyword">if</span> unicodedata.category(c) != <span class="hljs-string">&#x27;Mn&#x27;</span><br>    )<br><br><span class="hljs-comment"># Lowercase, trim, and remove non-letter characters</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalizeString</span>(<span class="hljs-params">s</span>):<br>    s = unicodeToAscii(s.lower().strip())<br>    s = re.sub(<span class="hljs-string">r&quot;([.!?])&quot;</span>, <span class="hljs-string">r&quot; \1&quot;</span>, s)<br>    s = re.sub(<span class="hljs-string">r&quot;[^a-zA-Z!?]+&quot;</span>, <span class="hljs-string">r&quot; &quot;</span>, s)<br>    <span class="hljs-keyword">return</span> s.strip()<br></code></pre></td></tr></table></figure><p>要读取数据文件，我们将文件拆分为行，然后将行拆分为成对。这些文件都是英语→其他语言，所以如果我们想从其他语言翻译→英语，我添加了 <code>reverse</code> 标志来反转对。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">readLangs</span>(<span class="hljs-params">lang1, lang2, reverse=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Reading lines...&quot;</span>)<br><br>    <span class="hljs-comment"># Read the file and split into lines</span><br>    lines = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/%s-%s.txt&#x27;</span> % (lang1, lang2), encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).\<br>        read().strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br><br>    <span class="hljs-comment"># Split every line into pairs and normalize</span><br>    pairs = [[normalizeString(s) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> l.split(<span class="hljs-string">&#x27;\t&#x27;</span>)] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lines]<br><br>    <span class="hljs-comment"># Reverse pairs, make Lang instances</span><br>    <span class="hljs-keyword">if</span> reverse:<br>        pairs = [<span class="hljs-built_in">list</span>(<span class="hljs-built_in">reversed</span>(p)) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pairs]<br>        input_lang = Lang(lang2)<br>        output_lang = Lang(lang1)<br>    <span class="hljs-keyword">else</span>:<br>        input_lang = Lang(lang1)<br>        output_lang = Lang(lang2)<br><br>    <span class="hljs-keyword">return</span> input_lang, output_lang, pairs<br></code></pre></td></tr></table></figure><p>由于有很多例句，并且我们想快速训练一些东西，因此我们将数据集修剪为仅相对简短和简单的句子。这里的最大长度是 10 个单词（包括结束标点符号），我们正在过滤到翻译为“我是”或“他是”等形式的句子（考虑到前面替换的撇号）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">MAX_LENGTH = <span class="hljs-number">10</span><br><br>eng_prefixes = (<br>    <span class="hljs-string">&quot;i am &quot;</span>, <span class="hljs-string">&quot;i m &quot;</span>,<br>    <span class="hljs-string">&quot;he is&quot;</span>, <span class="hljs-string">&quot;he s &quot;</span>,<br>    <span class="hljs-string">&quot;she is&quot;</span>, <span class="hljs-string">&quot;she s &quot;</span>,<br>    <span class="hljs-string">&quot;you are&quot;</span>, <span class="hljs-string">&quot;you re &quot;</span>,<br>    <span class="hljs-string">&quot;we are&quot;</span>, <span class="hljs-string">&quot;we re &quot;</span>,<br>    <span class="hljs-string">&quot;they are&quot;</span>, <span class="hljs-string">&quot;they re &quot;</span><br>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filterPair</span>(<span class="hljs-params">p</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(p[<span class="hljs-number">0</span>].split(<span class="hljs-string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="hljs-keyword">and</span> \<br>        <span class="hljs-built_in">len</span>(p[<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="hljs-keyword">and</span> \<br>        p[<span class="hljs-number">1</span>].startswith(eng_prefixes)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filterPairs</span>(<span class="hljs-params">pairs</span>):<br>    <span class="hljs-keyword">return</span> [pair <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> pairs <span class="hljs-keyword">if</span> filterPair(pair)]<br></code></pre></td></tr></table></figure><p>准备数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepareData</span>(<span class="hljs-params">lang1, lang2, reverse=<span class="hljs-literal">False</span></span>):<br>    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Read %s sentence pairs&quot;</span> % <span class="hljs-built_in">len</span>(pairs))<br>    pairs = filterPairs(pairs)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Trimmed to %s sentence pairs&quot;</span> % <span class="hljs-built_in">len</span>(pairs))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Counting words...&quot;</span>)<br>    <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> pairs:<br>        input_lang.addSentence(pair[<span class="hljs-number">0</span>])<br>        output_lang.addSentence(pair[<span class="hljs-number">1</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Counted words:&quot;</span>)<br>    <span class="hljs-built_in">print</span>(input_lang.name, input_lang.n_words)<br>    <span class="hljs-built_in">print</span>(output_lang.name, output_lang.n_words)<br>    <span class="hljs-keyword">return</span> input_lang, output_lang, pairs<br><br>input_lang, output_lang, pairs = prepareData(<span class="hljs-string">&#x27;eng&#x27;</span>, <span class="hljs-string">&#x27;fra&#x27;</span>, <span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(random.choice(pairs))<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">Reading lines...<br>Read <span class="hljs-number">135842</span> sentence pairs<br>Trimmed to <span class="hljs-number">11445</span> sentence pairs<br>Counting words...<br>Counted words:<br>fra <span class="hljs-number">4601</span><br>eng <span class="hljs-number">2991</span><br>[<span class="hljs-string">&#x27;tu preches une convaincue&#x27;</span>, <span class="hljs-string">&#x27;you re preaching to the choir&#x27;</span>]<br></code></pre></td></tr></table></figure><h2 id="2-Seq2Seq模型"><a href="#2-Seq2Seq模型" class="headerlink" title="2.Seq2Seq模型"></a>2.Seq2Seq模型</h2><h3 id="2-1-编码器"><a href="#2-1-编码器" class="headerlink" title="2.1 编码器"></a>2.1 编码器</h3><p>seq2seq 网络的编码器是一个 RNN，它为输入句子中的每个单词输出一些值。对于每个输入字，编码器输出一个向量和一个隐藏状态，并将隐藏状态用于下一个输入字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, dropout_p=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>(EncoderRNN, self).__init__()<br>        self.hidden_size = hidden_size<br><br>        self.embedding = nn.Embedding(input_size, hidden_size)<br>        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br>        self.dropout = nn.Dropout(dropout_p)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        embedded = self.dropout(self.embedding(<span class="hljs-built_in">input</span>))<br>        output, hidden = self.gru(embedded)<br>        <span class="hljs-keyword">return</span> output, hidden<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p><code>nn.Embedding</code>中第一个参数代表词表的个数范围，比如有1000个中文词语，那么第一个参数就为1000，接下来的input中就不能有超过1000的值，因为input代表的是词表的索引列表，列表的长度是需要嵌入的词语个数。第二个参数是每一个词映射后的维度。例如<code>embedding = nn.Embedding(8, 10)</code></p><ul><li>如果input为<code>torch.LongTensor([1, 2, 3])</code>，输出size是<code>torch.Size([3, 10])</code></li><li>如果input为<code>torch.LongTensor([[1, 2, 3], [4, 5, 6]])</code>，输出size是<code>torch.Size([2, 3, 10])</code></li></ul><h3 id="2-2-解码器"><a href="#2-2-解码器" class="headerlink" title="2.2 解码器"></a>2.2 解码器</h3><h4 id="2-2-1-简单解码器"><a href="#2-2-1-简单解码器" class="headerlink" title="2.2.1 简单解码器"></a>2.2.1 简单解码器</h4><p>在最简单的 seq2seq 解码器中，我们只使用编码器的最后一个输出。最后一个输出有时称为上下文向量，因为它对整个序列中的上下文进行编码。此上下文向量用作解码器的初始隐藏状态。</p><p>在解码的每一步中，解码器都会被赋予输入令牌和隐藏状态。初始输入标记是字符串 <code>&lt;SOS&gt;</code> 开头标记，第一个隐藏状态是上下文向量（编码器的最后一个隐藏状态）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(DecoderRNN, self).__init__()<br>        self.embedding = nn.Embedding(output_size, hidden_size)<br>        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br>        self.out = nn.Linear(hidden_size, output_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_outputs, encoder_hidden, target_tensor=<span class="hljs-literal">None</span></span>):<br>        batch_size = encoder_outputs.size(<span class="hljs-number">0</span>)<br>        decoder_input = torch.empty(batch_size, <span class="hljs-number">1</span>, dtype=torch.long, device=device).fill_(SOS_token)<br>        decoder_hidden = encoder_hidden<br>        decoder_outputs = []<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(MAX_LENGTH):<br>            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)<br>            decoder_outputs.append(decoder_output)<br><br>            <span class="hljs-keyword">if</span> target_tensor <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-comment"># Teacher forcing: Feed the target as the next input</span><br>                decoder_input = target_tensor[:, i].unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># Teacher forcing</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># Without teacher forcing: use its own predictions as the next input</span><br>                _, topi = decoder_output.topk(<span class="hljs-number">1</span>)<br>                decoder_input = topi.squeeze(-<span class="hljs-number">1</span>).detach()  <span class="hljs-comment"># detach from history as input</span><br><br>        decoder_outputs = torch.cat(decoder_outputs, dim=<span class="hljs-number">1</span>)<br>        decoder_outputs = F.log_softmax(decoder_outputs, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> decoder_outputs, decoder_hidden, <span class="hljs-literal">None</span> <span class="hljs-comment"># We return `None` for consistency in the training loop</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden</span>):<br>        output = self.embedding(<span class="hljs-built_in">input</span>)<br>        output = F.relu(output)<br>        output, hidden = self.gru(output, hidden)<br>        output = self.out(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p>假设batch_size为3，<code>decoder_input = torch.empty(3, 1, dtype=torch.long).fill_(0)</code>的输出结果是<code>tensor([[0]，[0], [0]])</code>,<code>decoder_input = target_tensor[:, 0].unsqueeze(1)</code>的目的是为了保证size一致。</p><p>测试代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">target_tensor = torch.LongTensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                               [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>],<br>                               [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]])<br>decoder_input = target_tensor[:, <span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(decoder_input)<br><br>decoder_input = torch.empty(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, dtype=torch.long).fill_(<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(decoder_input)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1</span>],<br>        [<span class="hljs-number">4</span>],<br>        [<span class="hljs-number">7</span>]])<br>tensor([[<span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>],<br>        [<span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure><h4 id="2-2-2-注意力解码器"><a href="#2-2-2-注意力解码器" class="headerlink" title="2.2.2 注意力解码器"></a>2.2.2 注意力解码器</h4><p>如果仅在编码器和解码器之间传递上下文向量，则该单个向量承担对整个句子进行编码的负担。</p><p>注意力允许解码器网络“聚焦”在编码器输出的不同部分，用于解码器自身输出的每一步。首先，我们计算一组注意力权重。这些将乘以编码器输出向量以创建加权组合。结果（在代码中调用 <code>attn_applied</code> ）应包含有关输入序列的特定部分的信息，从而帮助解码器选择正确的输出字。</p><p>注意力权重的计算是用另一个前馈层 <code>attn</code> 完成的，使用解码器的输入和隐藏状态作为输入。由于训练数据中有各种大小的句子，因此要实际创建和训练此层，我们必须选择它可以应用的最大句子长度（编码器输出的输入长度）。最大长度的句子将使用所有注意力权重，而较短的句子将仅使用前几个。</p><p>Bahdanau 注意力，也称为加法注意力，是序列到序列模型中常用的注意力机制，尤其是在神经机器翻译任务中。Bahdanau等人在他们的论文中介绍了它，题为“通过共同学习对齐和翻译进行神经机器翻译”。这种注意力机制采用学习对齐模型来计算编码器和解码器隐藏状态之间的注意力分数。它利用前馈神经网络来计算对齐分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BahdanauAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size</span>):<br>        <span class="hljs-built_in">super</span>(BahdanauAttention, self).__init__()<br>        self.Wa = nn.Linear(hidden_size, hidden_size)<br>        self.Ua = nn.Linear(hidden_size, hidden_size)<br>        self.Va = nn.Linear(hidden_size, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, keys</span>):<br>        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))<br>        scores = scores.squeeze(<span class="hljs-number">2</span>).unsqueeze(<span class="hljs-number">1</span>)<br><br>        weights = F.softmax(scores, dim=-<span class="hljs-number">1</span>)<br>        context = torch.bmm(weights, keys)<br><br>        <span class="hljs-keyword">return</span> context, weights<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AttnDecoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size, output_size, dropout_p=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-built_in">super</span>(AttnDecoderRNN, self).__init__()<br>        self.embedding = nn.Embedding(output_size, hidden_size)<br>        self.attention = BahdanauAttention(hidden_size)<br>        self.gru = nn.GRU(<span class="hljs-number">2</span> * hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br>        self.out = nn.Linear(hidden_size, output_size)<br>        self.dropout = nn.Dropout(dropout_p)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_outputs, encoder_hidden, target_tensor=<span class="hljs-literal">None</span></span>):<br>        batch_size = encoder_outputs.size(<span class="hljs-number">0</span>)<br>        decoder_input = torch.empty(batch_size, <span class="hljs-number">1</span>, dtype=torch.long, device=device).fill_(SOS_token)<br>        decoder_hidden = encoder_hidden<br>        decoder_outputs = []<br>        attentions = []<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(MAX_LENGTH):<br>            decoder_output, decoder_hidden, attn_weights = self.forward_step(<br>                decoder_input, decoder_hidden, encoder_outputs<br>            )<br>            decoder_outputs.append(decoder_output)<br>            attentions.append(attn_weights)<br><br>            <span class="hljs-keyword">if</span> target_tensor <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-comment"># Teacher forcing: Feed the target as the next input</span><br>                decoder_input = target_tensor[:, i].unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># Teacher forcing</span><br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># Without teacher forcing: use its own predictions as the next input</span><br>                _, topi = decoder_output.topk(<span class="hljs-number">1</span>)<br>                decoder_input = topi.squeeze(-<span class="hljs-number">1</span>).detach()  <span class="hljs-comment"># detach from history as input</span><br><br>        decoder_outputs = torch.cat(decoder_outputs, dim=<span class="hljs-number">1</span>)<br>        decoder_outputs = F.log_softmax(decoder_outputs, dim=-<span class="hljs-number">1</span>)<br>        attentions = torch.cat(attentions, dim=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">return</span> decoder_outputs, decoder_hidden, attentions<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_step</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden, encoder_outputs</span>):<br>        embedded =  self.dropout(self.embedding(<span class="hljs-built_in">input</span>))<br><br>        query = hidden.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>        context, attn_weights = self.attention(query, encoder_outputs)<br>        input_gru = torch.cat((embedded, context), dim=<span class="hljs-number">2</span>)<br><br>        output, hidden = self.gru(input_gru, hidden)<br>        output = self.out(output)<br><br>        <span class="hljs-keyword">return</span> output, hidden, attn_weights<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><ul><li><strong>为什么要使用attention</strong>：在解码的过程中每个被解码的目标所需要的上下文信息是不一样的，对原文中每个词的需求程度不一样，因此需要一个加权的权重来进行注意力的分配。</li><li><strong>为什么不直接将encoder_output加一个线性变换进行梯度优化</strong>：这样整个模型只有一个优化向量，无法满足针对不同的解码目标进行不同的注意力分配，因此需要根据decoder_hidden和encoder_outputs进行共同的梯度优化。</li><li><strong>为什么不直接将query和key相加进行变换再梯度优化</strong>：通过将查询向量和键向量分别通过线性变换映射到一个共享的注意力空间，可以<strong>增加模型的表达能力</strong>，使其能够更好地捕捉到它们之间的相关性，且<strong>学习到的注意力权重更具灵活性</strong>。</li><li><strong>为什么注意力分数不能直接作为上下文向量</strong>：因为注意力分数通常是一个标量值，它仅仅反映了查询向量与单个键向量之间的相似性，而无法反映与其他键向量的关系。因此，使用注意力分数作为上下文向量可能会丢失其他键向量的信息，导致模型无法充分利用所有键向量的信息。</li></ul><h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3.训练"></a>3.训练</h2><h3 id="3-1-准备训练数据"><a href="#3-1-准备训练数据" class="headerlink" title="3.1 准备训练数据"></a>3.1 准备训练数据</h3><p>为了训练，对于每一对，我们需要一个输入张量（输入句子中<strong>单词的索引</strong>）和目标张量（目标句子中<strong>单词的索引</strong>）。在创建这些向量时，我们将EOS令牌附加到两个序列中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">indexesFromSentence</span>(<span class="hljs-params">lang, sentence</span>):<br>    <span class="hljs-keyword">return</span> [lang.word2index[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence.split(<span class="hljs-string">&#x27; &#x27;</span>)]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensorFromSentence</span>(<span class="hljs-params">lang, sentence</span>):<br>    indexes = indexesFromSentence(lang, sentence)<br>    indexes.append(EOS_token)<br>    <span class="hljs-keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensorsFromPair</span>(<span class="hljs-params">pair</span>):<br>    input_tensor = tensorFromSentence(input_lang, pair[<span class="hljs-number">0</span>])<br>    target_tensor = tensorFromSentence(output_lang, pair[<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> (input_tensor, target_tensor)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader</span>(<span class="hljs-params">batch_size</span>):<br>    input_lang, output_lang, pairs = prepareData(<span class="hljs-string">&#x27;eng&#x27;</span>, <span class="hljs-string">&#x27;fra&#x27;</span>, <span class="hljs-literal">True</span>)<br><br>    n = <span class="hljs-built_in">len</span>(pairs)<br>    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)<br>    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)<br><br>    <span class="hljs-keyword">for</span> idx, (inp, tgt) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pairs):<br>        inp_ids = indexesFromSentence(input_lang, inp)<br>        tgt_ids = indexesFromSentence(output_lang, tgt)<br>        inp_ids.append(EOS_token)<br>        tgt_ids.append(EOS_token)<br>        input_ids[idx, :<span class="hljs-built_in">len</span>(inp_ids)] = inp_ids<br>        target_ids[idx, :<span class="hljs-built_in">len</span>(tgt_ids)] = tgt_ids<br><br>    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),<br>                               torch.LongTensor(target_ids).to(device))<br><br>    train_sampler = RandomSampler(train_data)<br>    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)<br>    <span class="hljs-keyword">return</span> input_lang, output_lang, train_dataloader<br></code></pre></td></tr></table></figure><p>上例中获取到的索引值先是用np包裹成一个<code>n*MAX_LENGTH</code>的二维矩阵，然后转换成张量，并生成TensorDataset实例，最后用DataLoader加载。</p><h3 id="3-2-训练模型"><a href="#3-2-训练模型" class="headerlink" title="3.2 训练模型"></a>3.2 训练模型</h3><p>为了训练，我们通过编码器运行输入句子，并跟踪每个输出和最新的隐藏状态。然后，为解码器提供 <code>&lt;SOS&gt;</code> 令牌作为其第一个输入，并将编码器的最后一个隐藏状态作为其第一个隐藏状态。</p><p><code>“Teacher forcing”</code>是使用真实目标输出作为每个下一个输入的概念，而不是使用解码器的猜测作为下一个输入。使用<code>Teacher forcing</code>会使其收敛得更快，但当训练好的网络被利用时，它可能会<strong>表现出不稳定</strong>。</p><p>于 PyTorch 的 autograd 为我们提供了自由，我们可以通过简单的 if 语句随机选择是否使用<code>Teacher forcing</code>。打开 <code>teacher_forcing_ratio</code> 以使用更多。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch</span>(<span class="hljs-params">dataloader, encoder, decoder, encoder_optimizer,</span><br><span class="hljs-params">          decoder_optimizer, criterion</span>):<br><br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>        input_tensor, target_tensor = data<br><br>        encoder_optimizer.zero_grad()<br>        decoder_optimizer.zero_grad()<br><br>        encoder_outputs, encoder_hidden = encoder(input_tensor)<br>        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)<br><br>        loss = criterion(<br>            decoder_outputs.view(-<span class="hljs-number">1</span>, decoder_outputs.size(-<span class="hljs-number">1</span>)),<br>            target_tensor.view(-<span class="hljs-number">1</span>)<br>        )<br>        loss.backward()<br><br>        encoder_optimizer.step()<br>        decoder_optimizer.step()<br><br>        total_loss += loss.item()<br><br>    <span class="hljs-keyword">return</span> total_loss / <span class="hljs-built_in">len</span>(dataloader)<br></code></pre></td></tr></table></figure><p>整个训练过程如下所示：</p><ul><li>启动计时器</li><li>初始化优化器和条件</li><li>创建一组训练对</li><li>启动用于绘图的空损失数组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">train_dataloader, encoder, decoder, n_epochs, learning_rate=<span class="hljs-number">0.001</span>,</span><br><span class="hljs-params">               print_every=<span class="hljs-number">100</span>, plot_every=<span class="hljs-number">100</span></span>):<br>    start = time.time()<br>    plot_losses = []<br>    print_loss_total = <span class="hljs-number">0</span>  <span class="hljs-comment"># Reset every print_every</span><br>    plot_loss_total = <span class="hljs-number">0</span>  <span class="hljs-comment"># Reset every plot_every</span><br><br>    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)<br>    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)<br>    criterion = nn.NLLLoss()<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_epochs + <span class="hljs-number">1</span>):<br>        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)<br>        print_loss_total += loss<br>        plot_loss_total += loss<br><br>        <span class="hljs-keyword">if</span> epoch % print_every == <span class="hljs-number">0</span>:<br>            print_loss_avg = print_loss_total / print_every<br>            print_loss_total = <span class="hljs-number">0</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s (%d %d%%) %.4f&#x27;</span> % (timeSince(start, epoch / n_epochs),<br>                                        epoch, epoch / n_epochs * <span class="hljs-number">100</span>, print_loss_avg))<br><br>        <span class="hljs-keyword">if</span> epoch % plot_every == <span class="hljs-number">0</span>:<br>            plot_loss_avg = plot_loss_total / plot_every<br>            plot_losses.append(plot_loss_avg)<br>            plot_loss_total = <span class="hljs-number">0</span><br><br>    showPlot(plot_losses)<br></code></pre></td></tr></table></figure><h2 id="4-评估"><a href="#4-评估" class="headerlink" title="4.评估"></a>4.评估</h2><p>评估与训练基本相同，但没有目标，因此我们只是将解码器的预测反馈给每个步骤。每当它预测一个单词时，我们都会将其添加到输出字符串中，如果它预测了EOS，我们就停在那里。我们还存储解码器的注意力输出，以便以后显示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">encoder, decoder, sentence, input_lang, output_lang</span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        input_tensor = tensorFromSentence(input_lang, sentence)<br><br>        encoder_outputs, encoder_hidden = encoder(input_tensor)<br>        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)<br><br>        _, topi = decoder_outputs.topk(<span class="hljs-number">1</span>)<br>        decoded_ids = topi.squeeze()<br><br>        decoded_words = []<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> decoded_ids:<br>            <span class="hljs-keyword">if</span> idx.item() == EOS_token:<br>                decoded_words.append(<span class="hljs-string">&#x27;&lt;EOS&gt;&#x27;</span>)<br>                <span class="hljs-keyword">break</span><br>            decoded_words.append(output_lang.index2word[idx.item()])<br>    <span class="hljs-keyword">return</span> decoded_words, decoder_attn<br></code></pre></td></tr></table></figure><p>我们可以评估训练集中的随机句子，并打印出输入、目标和输出，以做出一些主观的质量判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluateRandomly</span>(<span class="hljs-params">encoder, decoder, n=<span class="hljs-number">10</span></span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        pair = random.choice(pairs)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&gt;&#x27;</span>, pair[<span class="hljs-number">0</span>])<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;=&#x27;</span>, pair[<span class="hljs-number">1</span>])<br>        output_words, _ = evaluate(encoder, decoder, pair[<span class="hljs-number">0</span>], input_lang, output_lang)<br>        output_sentence = <span class="hljs-string">&#x27; &#x27;</span>.join(output_words)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&lt;&#x27;</span>, output_sentence)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="5-最终训练"><a href="#5-最终训练" class="headerlink" title="5.最终训练"></a>5.最终训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">hidden_size = <span class="hljs-number">128</span><br>batch_size = <span class="hljs-number">32</span><br><br>input_lang, output_lang, train_dataloader = get_dataloader(batch_size)<br><br>encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)<br>decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)<br><br>train(train_dataloader, encoder, decoder, <span class="hljs-number">80</span>, print_every=<span class="hljs-number">5</span>, plot_every=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>字符级RNN生成名称！🌞</title>
    <link href="/2024/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/%E5%AD%97%E7%AC%A6%E7%BA%A7RNN%E7%94%9F%E6%88%90%E5%90%8D%E7%A7%B0/"/>
    <url>/2024/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/%E5%AD%97%E7%AC%A6%E7%BA%A7RNN%E7%94%9F%E6%88%90%E5%90%8D%E7%A7%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="字符级RNN生成名称"><a href="#字符级RNN生成名称" class="headerlink" title="字符级RNN生成名称"></a>字符级RNN生成名称</h1><h2 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1.准备数据"></a>1.准备数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> <span class="hljs-built_in">open</span><br><span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">import</span> string<br><br>all_letters = string.ascii_letters + <span class="hljs-string">&quot; .,;&#x27;-&quot;</span><br>n_letters = <span class="hljs-built_in">len</span>(all_letters) + <span class="hljs-number">1</span> <span class="hljs-comment"># Plus EOS marker</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">findFiles</span>(<span class="hljs-params">path</span>): <span class="hljs-keyword">return</span> glob.glob(path)<br><br><span class="hljs-comment"># Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">unicodeToAscii</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(<br>        c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> unicodedata.normalize(<span class="hljs-string">&#x27;NFD&#x27;</span>, s)<br>        <span class="hljs-keyword">if</span> unicodedata.category(c) != <span class="hljs-string">&#x27;Mn&#x27;</span><br>        <span class="hljs-keyword">and</span> c <span class="hljs-keyword">in</span> all_letters<br>    )<br><br><span class="hljs-comment"># Read a file and split into lines</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">readLines</span>(<span class="hljs-params">filename</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> some_file:<br>        <span class="hljs-keyword">return</span> [unicodeToAscii(line.strip()) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> some_file]<br><br><span class="hljs-comment"># Build the category_lines dictionary, a list of lines per category</span><br>category_lines = &#123;&#125;<br>all_categories = []<br><span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> findFiles(<span class="hljs-string">&#x27;data/names/*.txt&#x27;</span>):<br>    category = os.path.splitext(os.path.basename(filename))[<span class="hljs-number">0</span>]<br>    all_categories.append(category)<br>    lines = readLines(filename)<br>    category_lines[category] = lines<br><br>n_categories = <span class="hljs-built_in">len</span>(all_categories)<br><br><span class="hljs-keyword">if</span> n_categories == <span class="hljs-number">0</span>:<br>    <span class="hljs-keyword">raise</span> RuntimeError(<span class="hljs-string">&#x27;Data not found. Make sure that you downloaded data &#x27;</span><br>        <span class="hljs-string">&#x27;from https://download.pytorch.org/tutorial/data.zip and extract it to &#x27;</span><br>        <span class="hljs-string">&#x27;the current directory.&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;# categories:&#x27;</span>, n_categories, all_categories)<br><span class="hljs-built_in">print</span>(unicodeToAscii(<span class="hljs-string">&quot;O&#x27;Néàl&quot;</span>))<br></code></pre></td></tr></table></figure><h2 id="2-创建网络"><a href="#2-创建网络" class="headerlink" title="2.创建网络"></a>2.创建网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(RNN, self).__init__()<br>        self.hidden_size = hidden_size<br><br>        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)<br>        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)<br>        self.o2o = nn.Linear(hidden_size + output_size, output_size)<br>        self.dropout = nn.Dropout(<span class="hljs-number">0.1</span>)<br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, category, <span class="hljs-built_in">input</span>, hidden</span>):<br>        input_combined = torch.cat((category, <span class="hljs-built_in">input</span>, hidden), <span class="hljs-number">1</span>)<br>        hidden = self.i2h(input_combined)<br>        output = self.i2o(input_combined)<br>        output_combined = torch.cat((hidden, output), <span class="hljs-number">1</span>)<br>        output = self.o2o(output_combined)<br>        output = self.dropout(output)<br>        output = self.softmax(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initHidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, self.hidden_size)<br></code></pre></td></tr></table></figure><p><strong>tIps：</strong></p><p>该网络与之前的实战网络有一定区别。</p><h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3.训练"></a>3.训练</h2><p>首先，帮助函数获取随机对（类别，行）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># Random item from a list</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randomChoice</span>(<span class="hljs-params">l</span>):<br>    <span class="hljs-keyword">return</span> l[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(l) - <span class="hljs-number">1</span>)]<br><br><span class="hljs-comment"># Get a random category and random line from that category</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randomTrainingPair</span>():<br>    category = randomChoice(all_categories)<br>    line = randomChoice(category_lines[category])<br>    <span class="hljs-keyword">return</span> category, line<br></code></pre></td></tr></table></figure><p>对于每个时间步（即，对于训练词中的每个字母），网络的输入将是<code>(category, current letter, hidden state)</code>,输出将是<code>(next letter, next hidden state)</code> 。</p><p><img src="/2024/02/16/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/%E5%AD%97%E7%AC%A6%E7%BA%A7RNN%E7%94%9F%E6%88%90%E5%90%8D%E7%A7%B0/1.png"></p><p>类别张量是大小 <code>&lt;1 x n_categories&gt;</code> 为 的单热张量。在训练时，我们会在每个时间步将其馈送到网络 - 这是一种设计选择，它可以作为初始隐藏状态或其他策略的一部分包含在内。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># One-hot vector for category</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">categoryTensor</span>(<span class="hljs-params">category</span>):<br>    li = all_categories.index(category)<br>    tensor = torch.zeros(<span class="hljs-number">1</span>, n_categories)<br>    tensor[<span class="hljs-number">0</span>][li] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br><br><span class="hljs-comment"># One-hot matrix of first to last letters (not including EOS) for input</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">inputTensor</span>(<span class="hljs-params">line</span>):<br>    tensor = torch.zeros(<span class="hljs-built_in">len</span>(line), <span class="hljs-number">1</span>, n_letters)<br>    <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(line)):<br>        letter = line[li]<br>        tensor[li][<span class="hljs-number">0</span>][all_letters.find(letter)] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br><br><span class="hljs-comment"># ``LongTensor`` of second letter to end (EOS) for target</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">targetTensor</span>(<span class="hljs-params">line</span>):<br>    letter_indexes = [all_letters.find(line[li]) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(line))]<br>    letter_indexes.append(n_letters - <span class="hljs-number">1</span>) <span class="hljs-comment"># EOS</span><br>    <span class="hljs-keyword">return</span> torch.LongTensor(letter_indexes)<br></code></pre></td></tr></table></figure><p>为了方便起见，在训练过程中，我们将创建一个 <code>randomTrainingExample</code> 函数来获取随机（类别、行）对并将它们转换为所需的（类别、输入、目标）张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Make category, input, and target tensors from a random category, line pair</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randomTrainingExample</span>():<br>    category, line = randomTrainingPair()<br>    category_tensor = categoryTensor(category)<br>    input_line_tensor = inputTensor(line)<br>    target_line_tensor = targetTensor(line)<br>    <span class="hljs-keyword">return</span> category_tensor, input_line_tensor, target_line_tensor<br></code></pre></td></tr></table></figure><h2 id="4-训练网络"><a href="#4-训练网络" class="headerlink" title="4.训练网络"></a>4.训练网络</h2><p>与仅使用最后一个输出的分类相反，我们在每一步都进行预测，因此我们正在计算每一步的损失。</p><p><strong>autograd 的魔力允许您简单地将每一步的这些损失相加，并在最后向后调用。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.NLLLoss()<br><br>learning_rate = <span class="hljs-number">0.0005</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">category_tensor, input_line_tensor, target_line_tensor</span>):<br>    target_line_tensor.unsqueeze_(-<span class="hljs-number">1</span>)<br>    hidden = rnn.initHidden()<br><br>    rnn.zero_grad()<br><br>    loss = torch.Tensor([<span class="hljs-number">0</span>]) <span class="hljs-comment"># you can also just simply use ``loss = 0``</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(input_line_tensor.size(<span class="hljs-number">0</span>)):<br>        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)<br>        l = criterion(output, target_line_tensor[i])<br>        loss += l<br><br>    loss.backward()<br><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> rnn.parameters():<br>        p.data.add_(p.grad.data, alpha=-learning_rate)<br><br>    <span class="hljs-keyword">return</span> output, loss.item() / input_line_tensor.size(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p>在PyTorch中，要实现将多个损失函数相加然后一起向后传播，你可以简单地将这些损失函数的结果相加，然后调用<code>backward()</code>函数来进行反向传播。下面是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># 假设有两个损失函数</span><br>criterion1 = nn.CrossEntropyLoss()<br>criterion2 = nn.MSELoss()<br><br><span class="hljs-comment"># 模拟输入数据和目标数据</span><br>inputs = torch.randn(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)  <span class="hljs-comment"># 示例输入数据，假设有10个样本，每个样本有5个特征</span><br>targets1 = torch.empty(<span class="hljs-number">10</span>, dtype=torch.long).random_(<span class="hljs-number">5</span>)  <span class="hljs-comment"># 示例目标数据1</span><br>targets2 = torch.randn(<span class="hljs-number">10</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 示例目标数据2</span><br><br><span class="hljs-comment"># 假设有一个模型</span><br>model = nn.Linear(<span class="hljs-number">5</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># 示例模型，输入维度为5，输出维度为2</span><br><br><span class="hljs-comment"># 假设有一个优化器</span><br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>)<br><br><span class="hljs-comment"># 前向传播</span><br>outputs = model(inputs)<br><br><span class="hljs-comment"># 计算损失</span><br>loss1 = criterion1(outputs, targets1)<br>loss2 = criterion2(outputs, targets2)<br><br><span class="hljs-comment"># 将损失相加</span><br>total_loss = loss1 + loss2<br><br><span class="hljs-comment"># 反向传播</span><br>optimizer.zero_grad()<br>total_loss.backward()<br><br><span class="hljs-comment"># 更新参数</span><br>optimizer.step()<br></code></pre></td></tr></table></figure><p>在这种情况下，将两个损失函数相加然后一起进行反向传播和分别计算每个损失函数然后分开进行反向传播是不完全一样的。</p><ol><li><strong>将两个损失函数相加然后一起进行反向传播</strong>：这种方法会将两个损失函数的梯度相加，然后一次性更新模型参数。这意味着模型的参数在一次优化步骤中同时考虑了两个损失函数的信息。</li><li><strong>分别计算每个损失函数然后分开进行反向传播</strong>：这种方法会分别计算每个损失函数的梯度，并分别调用<code>backward()</code>函数进行反向传播，然后根据每个损失函数的梯度更新模型参数。这意味着模型的参数在每个优化步骤中分别考虑每个损失函数的信息。</li></ol><p>通常情况下，这两种方法可能会得到不同的结果，尤其是在存在参数共享或者不同损失函数的梯度具有不同的量级时。在某些情况下，将两个损失函数相加然后一起进行反向传播可能会更加稳定和有效。但在其他情况下，分别计算每个损失函数然后分开进行反向传播可能更合适。要选择合适的方法，需要根据具体情况进行实验和评估。</p><h2 id="5-开始训练"><a href="#5-开始训练" class="headerlink" title="5.开始训练"></a>5.开始训练</h2><p>训练像往常一样 - 调用训练多次并等待几分钟，打印每个 <code>print_every</code> 示例的当前时间和损失，并存储每个 <code>plot_every</code> 示例的平均损失 <code>all_losses</code> 以备后用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> math<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">timeSince</span>(<span class="hljs-params">since</span>):<br>    now = time.time()<br>    s = now - since<br>    m = math.floor(s / <span class="hljs-number">60</span>)<br>    s -= m * <span class="hljs-number">60</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;%dm %ds&#x27;</span> % (m, s)<br>    <br>rnn = RNN(n_letters, <span class="hljs-number">128</span>, n_letters)<br><br>n_iters = <span class="hljs-number">100000</span><br>print_every = <span class="hljs-number">5000</span><br>plot_every = <span class="hljs-number">500</span><br>all_losses = []<br>total_loss = <span class="hljs-number">0</span> <span class="hljs-comment"># Reset every ``plot_every`` ``iters``</span><br><br>start = time.time()<br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_iters + <span class="hljs-number">1</span>):<br>    output, loss = train(*randomTrainingExample())<br>    total_loss += loss<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % print_every == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s (%d %d%%) %.4f&#x27;</span> % (timeSince(start), <span class="hljs-built_in">iter</span>, <span class="hljs-built_in">iter</span> / n_iters * <span class="hljs-number">100</span>, loss))<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % plot_every == <span class="hljs-number">0</span>:<br>        all_losses.append(total_loss / plot_every)<br>        total_loss = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><h2 id="6-对网络进行采样"><a href="#6-对网络进行采样" class="headerlink" title="6.对网络进行采样"></a>6.对网络进行采样</h2><p>为了取样，我们给网络一个字母，并询问下一个字母是什么，将其作为下一个字母输入，然后重复直到EOS令牌。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python">max_length = <span class="hljs-number">20</span><br><br><span class="hljs-comment"># Sample from a category and starting letter</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sample</span>(<span class="hljs-params">category, start_letter=<span class="hljs-string">&#x27;A&#x27;</span></span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># no need to track history in sampling</span><br>        category_tensor = categoryTensor(category)<br>        <span class="hljs-built_in">input</span> = inputTensor(start_letter)<br>        hidden = rnn.initHidden()<br><br>        output_name = start_letter<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_length):<br>            output, hidden = rnn(category_tensor, <span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>], hidden)<br>            topv, topi = output.topk(<span class="hljs-number">1</span>)<br>            topi = topi[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br>            <span class="hljs-keyword">if</span> topi == n_letters - <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">else</span>:<br>                letter = all_letters[topi]<br>                output_name += letter<br>            <span class="hljs-built_in">input</span> = inputTensor(letter)<br><br>        <span class="hljs-keyword">return</span> output_name<br><br><span class="hljs-comment"># Get multiple samples from one category and multiple starting letters</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">samples</span>(<span class="hljs-params">category, start_letters=<span class="hljs-string">&#x27;ABC&#x27;</span></span>):<br>    <span class="hljs-keyword">for</span> start_letter <span class="hljs-keyword">in</span> start_letters:<br>        <span class="hljs-built_in">print</span>(sample(category, start_letter))<br><br>samples(<span class="hljs-string">&#x27;Russian&#x27;</span>, <span class="hljs-string">&#x27;RUS&#x27;</span>)<br><br>samples(<span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;GER&#x27;</span>)<br><br>samples(<span class="hljs-string">&#x27;Spanish&#x27;</span>, <span class="hljs-string">&#x27;SPA&#x27;</span>)<br><br>samples(<span class="hljs-string">&#x27;Chinese&#x27;</span>, <span class="hljs-string">&#x27;CHI&#x27;</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>另一种策略是，在训练中加入一个“字符串开头”标记，并让网络选择自己的起始字母，而不是给它一个起始字母。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>random库的使用！☃️</title>
    <link href="/2024/02/16/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADrandom%E5%BA%93/"/>
    <url>/2024/02/16/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADrandom%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="random库的使用"><a href="#random库的使用" class="headerlink" title="random库的使用"></a>random库的使用</h1><h2 id="1-基本使用方法"><a href="#1-基本使用方法" class="headerlink" title="1.基本使用方法"></a>1.基本使用方法</h2><p><code>random</code> 是 Python 中的一个模块，提供了生成随机数的函数。以下是 <code>random</code> 模块中常用的一些函数的简要介绍：</p><ol><li><code>random()</code>: 返回一个在区间 <strong>[0.0, 1.0)</strong> 内的随机浮点数。</li><li><code>randint(a, b)</code>: 返回一个在区间 <strong>[a, b]</strong> 内的随机整数（包括边界值）。</li><li><code>choice(seq)</code>: 从非空序列 <code>seq</code> 中随机选择一个元素并返回。</li><li><code>shuffle(seq)</code>: 对序列 <code>seq</code> 中的元素进行原地打乱（随机排列）。</li><li><code>sample(population, k)</code>: 从总体 <code>population</code> 中随机选择 <code>k</code> 个不重复的元素组成列表并返回。</li><li><code>uniform(a, b)</code>: 返回一个在区间 <strong>[a, b)</strong> 内的随机浮点数。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 生成一个在 0 到 1 之间的随机浮点数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机浮点数:&quot;</span>, random.random())<br><br><span class="hljs-comment"># 生成一个在 1 到 100 之间的随机整数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;1 到 100 之间的随机整数:&quot;</span>, random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>))<br><br><span class="hljs-comment"># 从列表中随机选择一个元素</span><br>my_list = [<span class="hljs-string">&#x27;苹果&#x27;</span>, <span class="hljs-string">&#x27;香蕉&#x27;</span>, <span class="hljs-string">&#x27;橙子&#x27;</span>, <span class="hljs-string">&#x27;葡萄&#x27;</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;列表中的随机选择:&quot;</span>, random.choice(my_list))<br><br><span class="hljs-comment"># 打乱列表中的元素</span><br>random.shuffle(my_list)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;打乱后的列表:&quot;</span>, my_list)<br><br><span class="hljs-comment"># 从列表中随机选择两个不重复的元素</span><br>sampled_elements = random.sample(my_list, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;选取的元素:&quot;</span>, sampled_elements)<br><br><span class="hljs-comment"># 生成一个在 5.0 到 10.0 之间的随机浮点数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;5.0 到 10.0 之间的随机浮点数:&quot;</span>, random.uniform(<span class="hljs-number">5.0</span>, <span class="hljs-number">10.0</span>))<br></code></pre></td></tr></table></figure><h2 id="2-随机种子"><a href="#2-随机种子" class="headerlink" title="2.随机种子"></a>2.随机种子</h2><p>随机种子（random seed）在计算中是一个起始输入值，它用于初始化随机数生成器。在使用伪随机数生成器生成随机数时，如果给定了相同的随机种子，那么每次生成的随机数序列都将是相同的。这使得随机过程可重现，也就是说，如果你使用相同的随机种子，你将得到相同的结果，这在许多情况下都是非常有用的。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 设置随机种子</span><br>random.seed(<span class="hljs-number">123</span>)<br><br><span class="hljs-comment"># 生成随机数</span><br>random_number_1 = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br>random_number_2 = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br>random_number_3 = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># 输出随机数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机数1:&quot;</span>, random_number_1)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机数2:&quot;</span>, random_number_2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;随机数3:&quot;</span>, random_number_3)<br></code></pre></td></tr></table></figure><p>无论运行上述代码多少次，结果都是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">随机数<span class="hljs-number">1</span>: <span class="hljs-number">7</span><br>随机数<span class="hljs-number">2</span>: <span class="hljs-number">35</span><br>随机数<span class="hljs-number">3</span>: <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch中nn模块！🍧</title>
    <link href="/2024/02/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E4%B8%ADnn%E6%A8%A1%E5%9D%97/"/>
    <url>/2024/02/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E4%B8%ADnn%E6%A8%A1%E5%9D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="pytorch中nn模块"><a href="#pytorch中nn模块" class="headerlink" title="pytorch中nn模块"></a>pytorch中nn模块</h1><h2 id="0-nn-Module"><a href="#0-nn-Module" class="headerlink" title="0.nn.Module"></a>0.nn.Module</h2><h3 id="0-1-register-buffer"><a href="#0-1-register-buffer" class="headerlink" title="0.1 register_buffer"></a>0.1 register_buffer</h3><p><code>register_buffer</code> 是 PyTorch 中 <code>Module</code> 类的方法之一，用于向模型注册持久性缓冲区。持久性缓冲区是一种特殊的张量，其数值在<strong>训练过程中不会更新</strong>，但会被<strong>保存到模型的状态字典中</strong>（state_dict），从而可以被保存和加载。</p><p>具体语法为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">register_buffer(name, tensor)<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>name</code>：缓冲区的名称，用于在模型中标识缓冲区。</li><li><code>tensor</code>：要注册为缓冲区的张量。</li></ul><p>以下是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        <br>        self.register_buffer(<span class="hljs-string">&#x27;my_buffer&#x27;</span>, torch.zeros(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><br>model = MyModel()<br><span class="hljs-built_in">print</span>(model.state_dict())<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">OrderedDict([(<span class="hljs-string">&#x27;my_buffer&#x27;</span>, tensor([[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>                                   [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>                                   [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]]))])<br></code></pre></td></tr></table></figure><p>可以看到，在模型中注册了一个名称为 <code>&#39;my_buffer&#39;</code> 的缓冲区，并且初始值为全零张量。注册的缓冲区会出现在模型的状态字典中，因此在保存和加载模型时会被自动处理。</p><p><code>register_buffer</code> 方法通常用于将模型中需要持久存储的固定参数（如平均值、标准差等）注册为缓冲区。</p><h2 id="1-nn-LogSoftmax"><a href="#1-nn-LogSoftmax" class="headerlink" title="1.nn.LogSoftmax"></a>1.nn.LogSoftmax</h2><p>在PyTorch中，<code>nn.LogSoftmax</code>是一个用于计算对数softmax的模块。softmax函数用于将一个向量变换成概率分布，而log softmax函数则是在softmax的基础上取对数。log softmax函数的输出通常用作神经网络输出层的激活函数，特别是在多类别分类任务中。</p><p><code>nn.LogSoftmax</code>模块的输入是一个张量，通常是网络的原始输出（未经softmax处理），输出是一个张量，其中包含对数softmax的结果。</p><p>下面是一个简单的示例，演示如何使用<code>nn.LogSoftmax</code>模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 假设原始输出为 raw_output，形状为 (batch_size, num_classes)</span><br>raw_output = torch.randn(<span class="hljs-number">32</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 假设批量大小为32，类别数为10</span><br><br><span class="hljs-comment"># 创建 LogSoftmax 模块</span><br>log_softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 对原始输出进行对数softmax计算</span><br>log_probs = log_softmax(raw_output)<br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-built_in">print</span>(log_probs)<br></code></pre></td></tr></table></figure><p>在这个示例中，我们首先创建了一个具有随机值的原始输出张量 <code>raw_output</code>。然后，我们创建了一个 <code>LogSoftmax</code> 模块，并在 <code>dim=1</code> 的维度上对原始输出进行了对数softmax计算。最后，我们打印了对数softmax的结果 <code>log_probs</code>。</p><p>需要注意的是，对数softmax的输出是经过对数处理的概率分布，因此它的每个元素都是一个负数。通常在训练分类模型时，将对数softmax的输出与标签进行比较，计算损失函数，例如交叉熵损失。</p><p><strong>tips：</strong></p><p>取对数有几个好处：</p><ol><li><strong>数值稳定性</strong>：在计算概率时，通常会涉及到多个小概率的相乘，这可能会导致数值下溢（即结果接近于零）。通过取对数，可以将相乘转换为相加，避免了数值下溢的问题。同时，取对数也可以减少数值溢出的风险，特别是在计算指数时。</li><li><strong>简化计算</strong>：取对数可以将复杂的指数运算转换为加法运算，从而简化了计算过程。这在机器学习和深度学习中尤为重要，因为许多优化算法（如梯度下降）都涉及到对数似然或对数损失的计算。</li><li><strong>解释性</strong>：在某些情况下，对数可以提供更直观和易解释的结果。例如，在对数尺度下，乘法操作变成了加法操作，这使得数据的变化更容易理解。</li><li><strong>统计性质</strong>：在统计学中，对数变换可以使数据更符合正态分布或者更接近线性关系，从而使得一些统计分析更加有效。</li></ol><p>总的来说，取对数可以提高数值稳定性，简化计算，并在某些情况下提供更好的解释和统计性质，因此在实际应用中经常被使用。</p><h2 id="2-nn-NLLLoss"><a href="#2-nn-NLLLoss" class="headerlink" title="2.nn.NLLLoss"></a>2.nn.NLLLoss</h2><p><code>nn.NLLLoss</code> 是PyTorch中的一个损失函数，用于多分类问题中的负对数似然损失（Negative Log Likelihood Loss）。在PyTorch中，通常与LogSoftmax层结合使用，用于训练一个分类器，该分类器的输出是经过LogSoftmax处理的原始输出。</p><p>具体来说，<code>nn.NLLLoss</code> 期望输入是经过LogSoftmax处理后的对数概率分布的张量。它的计算方式是根据目标标签和模型预测的对数概率分布来计算损失值，然后返回平均损失值。</p><p>以下是 <code>nn.NLLLoss</code> 的一些主要参数和实现细节：</p><ul><li><strong>参数</strong>：<ul><li><code>weight</code>：可选参数，可以指定一个张量作为损失函数的权重，用于在某些类别上放大或减小损失。</li><li><code>ignore_index</code>：可选参数，指定一个类别索引，忽略该索引对应的预测值和目标值，不计入损失计算中。</li><li><code>reduction</code>：可选参数，指定损失的计算方式，可选值有<code>&#39;none&#39;</code>（不进行降维，返回每个样本的损失值）、<code>&#39;mean&#39;</code>（对所有样本的损失值取平均）、<code>&#39;sum&#39;</code>（对所有样本的损失值求和）。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.NLLLoss()<br>loss = criterion(output, target)<br></code></pre></td></tr></table></figure><p>其中，<code>output</code> 是经过LogSoftmax处理后的模型输出的张量，<code>target</code> 是对应的目标标签的张量。<code>output</code> 的形状一般是 <code>(batch_size, num_classes)</code>，<code>target</code> 的形状一般是 <code>(batch_size)</code>，其中 <code>batch_size</code> 是一个批次的样本数量，<code>num_classes</code> 是分类的类别数量。</p><p><code>nn.NLLLoss</code> 会将 <code>output</code> 中的每个样本的对数概率与 <code>target</code> 中对应样本的标签进行比较，并计算损失值。然后根据指定的 <code>reduction</code> 参数来进行降维操作，得到一个标量损失值，即最终的损失结果。</p><p>这个损失函数在训练分类器时非常常用，特别是在多分类问题中。 </p><p><strong>tips：</strong></p><p> <code>batch_size</code> 是一个批次的样本数量。每个元素表示对应样本的类别标签，通常是一个整数值，表示样本属于哪个类别。例如，如果一个批次有 32 个样本，每个样本的类别标签分别为 <code>[0, 1, 2, ..., 9]</code>，那么 <code>target</code> 的形状将是 <code>(32,)</code>。</p><h2 id="3-nn-Dropout"><a href="#3-nn-Dropout" class="headerlink" title="3.nn.Dropout"></a>3.nn.Dropout</h2><p>在 PyTorch 中，<code>nn.Dropout</code> 是一个用于实现 dropout 操作的模块。Dropout 是一种在神经网络中用于防止过拟合的正则化技术。其原理是在训练过程中，随机将神经元的输出设置为零，从而减少神经元之间的依赖性，以防止过拟合。</p><p><code>nn.Dropout</code> 模块在每次前向传播时以一定的概率（通常是0.5）将输入张量中的一些元素设置为零。这样做可以模拟在训练期间随机丢弃神经元的效果，从而使得网络更加健壮。</p><p>以下是一个简单的示例，展示了如何在 PyTorch 中使用 <code>nn.Dropout</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 定义一个简单的神经网络</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleNet, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>)<br>        self.dropout = nn.Dropout(p=<span class="hljs-number">0.5</span>)  <span class="hljs-comment"># 设置丢弃概率为0.5</span><br>        self.fc2 = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = torch.relu(self.fc1(x))<br>        x = self.dropout(x)  <span class="hljs-comment"># 在第一个全连接层的输出上应用dropout</span><br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 使用示例</span><br>model = SimpleNet()<br>input_tensor = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 输入张量大小为 [1, 10]</span><br>output = model(input_tensor)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><h2 id="4-nn-GRU"><a href="#4-nn-GRU" class="headerlink" title="4.nn.GRU"></a>4.nn.GRU</h2><p><code>nn.GRU</code> 是 PyTorch 深度学习框架中的一个模块，用于实现门控循环单元（Gated Recurrent Unit，GRU）的神经网络层。GRU 是一种循环神经网络（Recurrent Neural Network，RNN）的变体，用于处理序列数据，例如文本、时间序列等。</p><p>GRU 与传统的 RNN 不同之处在于其引入了门控机制，有助于缓解长期依赖问题，并且具有较少的参数，训练更快。在 GRU 中，有两个门控单元：更新门（Update Gate）和重置门（Reset Gate）。这些门控单元有助于网络决定在每个时间步应该保留多少过去的信息，并决定在当前时间步应该考虑多少新的信息。这种机制有助于 GRU 更好地捕获序列中的长期依赖关系。</p><p>在 PyTorch 中，<code>nn.GRU</code> 模块实现了这种 GRU 结构，并提供了一个方便的接口，使用户能够轻松地在自己的模型中使用 GRU 层。通常，你可以通过实例化 <code>nn.GRU</code> 类来创建一个 GRU 层，并将其用作神经网络模型的一部分，用于处理序列数据的建模任务。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 假设词汇表中有10个单词，每个单词用5维向量表示</span><br>vocab_size = <span class="hljs-number">10</span><br>embedding_dim = <span class="hljs-number">5</span><br><br><span class="hljs-comment"># 创建一个词嵌入层</span><br>embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)<br>gru = nn.GRU(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, batch_first=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 输入的索引序列</span><br>input_indices = torch.LongTensor([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>])<br><br><span class="hljs-comment"># 将输入索引传递给词嵌入层，得到对应的词嵌入向量</span><br>embeddings = embedding_layer(input_indices)<br>output, hidden = gru(embeddings)<br><br><br><span class="hljs-built_in">print</span>(embeddings)<br><span class="hljs-built_in">print</span>(output)<br><span class="hljs-built_in">print</span>(hidden)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[-<span class="hljs-number">1.7065</span>,  <span class="hljs-number">1.4895</span>, -<span class="hljs-number">1.4307</span>, -<span class="hljs-number">1.3842</span>, -<span class="hljs-number">0.7688</span>],<br>        [-<span class="hljs-number">1.4263</span>, -<span class="hljs-number">0.1287</span>,  <span class="hljs-number">0.2118</span>, -<span class="hljs-number">0.1879</span>,  <span class="hljs-number">1.4776</span>],<br>        [ <span class="hljs-number">0.5036</span>, -<span class="hljs-number">1.5243</span>, -<span class="hljs-number">1.3386</span>, -<span class="hljs-number">1.5916</span>, -<span class="hljs-number">0.6122</span>],<br>        [-<span class="hljs-number">0.2163</span>,  <span class="hljs-number">1.0274</span>,  <span class="hljs-number">0.4618</span>,  <span class="hljs-number">0.6996</span>,  <span class="hljs-number">2.0424</span>],<br>        [-<span class="hljs-number">1.5138</span>,  <span class="hljs-number">1.0113</span>, -<span class="hljs-number">0.9857</span>,  <span class="hljs-number">0.2578</span>,  <span class="hljs-number">0.1028</span>]],<br>       grad_fn=&lt;EmbeddingBackward0&gt;)<br>tensor([[ <span class="hljs-number">0.1186</span>, -<span class="hljs-number">0.3294</span>,  <span class="hljs-number">0.6707</span>,  <span class="hljs-number">0.2636</span>,  <span class="hljs-number">0.0757</span>],<br>        [ <span class="hljs-number">0.3987</span>, -<span class="hljs-number">0.3611</span>,  <span class="hljs-number">0.6153</span>,  <span class="hljs-number">0.1641</span>, -<span class="hljs-number">0.4888</span>],<br>        [ <span class="hljs-number">0.0880</span>,  <span class="hljs-number">0.0423</span>,  <span class="hljs-number">0.6707</span>,  <span class="hljs-number">0.2705</span>, -<span class="hljs-number">0.0653</span>],<br>        [ <span class="hljs-number">0.3424</span>,  <span class="hljs-number">0.0956</span>,  <span class="hljs-number">0.4108</span>, -<span class="hljs-number">0.0138</span>, -<span class="hljs-number">0.6475</span>],<br>        [ <span class="hljs-number">0.4621</span>, -<span class="hljs-number">0.3295</span>,  <span class="hljs-number">0.6419</span>,  <span class="hljs-number">0.0566</span>, -<span class="hljs-number">0.5258</span>]],<br>       grad_fn=&lt;SqueezeBackward1&gt;)<br>tensor([[ <span class="hljs-number">0.4621</span>, -<span class="hljs-number">0.3295</span>,  <span class="hljs-number">0.6419</span>,  <span class="hljs-number">0.0566</span>, -<span class="hljs-number">0.5258</span>]],<br>       grad_fn=&lt;SqueezeBackward1&gt;)<br></code></pre></td></tr></table></figure><p>输入的词的个数为5，则output的第一个维度也为5，因为gru输出的是每个词的output。</p><h2 id="5-nn-Embedding"><a href="#5-nn-Embedding" class="headerlink" title="5.nn.Embedding"></a>5.nn.Embedding</h2><p><code>nn.Embedding</code> 是 PyTorch 中的一个类，用于创建一个可训练的词嵌入层。在自然语言处理任务中，词嵌入是将单词映射到高维实数向量的技术，它可以将单词表示为连续的向量空间中的点，从而捕捉单词之间的语义相似性和关系。</p><p><code>nn.Embedding</code> 接受两个参数：</p><ol><li><code>num_embeddings</code>：表示词汇表的大小，即词汇表中唯一单词的数量。</li><li><code>embedding_dim</code>：表示词嵌入的维度，即每个单词将被映射到的向量的维度。</li></ol><p>在创建 <code>nn.Embedding</code> 实例时，PyTorch 会随机初始化词嵌入矩阵，大小为 <code>(num_embeddings, embedding_dim)</code>。在训练过程中，模型会通过反向传播自动学习这些词嵌入参数，以最小化损失函数。</p><p><code>nn.Embedding</code> 的输入是一个整数张量，其中的每个整数代表词汇表中的一个单词的索引。它的输出是根据输入索引对应的词嵌入向量。这使得模型能够在训练过程中动态地学习单词的分布式表示，从而更好地理解语义和上下文信息。</p><p>以下是一个简单的示例，说明如何使用 <code>nn.Embedding</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 假设词汇表中有10个单词，每个单词用5维向量表示</span><br>vocab_size = <span class="hljs-number">10</span><br>embedding_dim = <span class="hljs-number">5</span><br><br><span class="hljs-comment"># 创建一个词嵌入层</span><br>embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)<br><br><span class="hljs-comment"># 输入的索引序列</span><br>input_indices = torch.LongTensor([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>])<br><br><span class="hljs-comment"># 将输入索引传递给词嵌入层，得到对应的词嵌入向量</span><br>embeddings = embedding_layer(input_indices)<br><br><span class="hljs-built_in">print</span>(embeddings)<br></code></pre></td></tr></table></figure><p>这会输出每个索引对应的词嵌入向量。注意，输出的形状为 <code>(5, 5)</code>，其中 <code>5</code> 是输入索引序列的长度，而 <code>5</code> 是词嵌入的维度。</p><p><strong>tips:</strong></p><p>在 PyTorch 中，<code>nn.Embedding</code> 是一个用于实现词嵌入（Word Embedding）的模块，用于将整数索引映射到密集向量表示。这些向量通常被用作神经网络的输入。</p><p><code>nn.Embedding</code> 模块的参数是可以被学习的，这意味着它们在模型训练的过程中会被优化器所更新。具体来说，<code>nn.Embedding</code> 的参数是每个词嵌入向量的初始值，它们在训练过程中会根据模型的损失函数进行调整以提高模型的性能。</p><p><code>nn.Embedding</code> 和 Word2Vec 都是用于表示词嵌入（Word Embedding）的技术，但它们有一些关键的区别：</p><ol><li><strong>实现方式</strong>：<ul><li><code>nn.Embedding</code> 是 PyTorch 中的一个模块，用于将整数索引映射到密集向量表示。它是作为神经网络的一部分，在模型中被优化器所更新。</li><li>Word2Vec 是一种基于神经网络的词嵌入模型，它由两种不同的架构组成：Skip-gram 和 CBOW（Continuous Bag of Words）。这些模型通过在大规模文本语料库上进行训练，学习将词语表示为密集向量。</li></ul></li><li><strong>训练方式</strong>：<ul><li><code>nn.Embedding</code> 的参数是在模型的训练过程中与其他神经网络参数一起优化的，通常作为整个神经网络的一部分。</li><li>Word2Vec 是通过在大规模文本语料库上进行训练来学习词嵌入。Skip-gram 模型通过预测上下文词语来学习词嵌入，而 CBOW 模型则通过预测目标词语来学习。</li></ul></li><li><strong>上下文考虑</strong>：<ul><li><code>nn.Embedding</code> 并不考虑词语的上下文信息，它只是简单地将每个词语映射到一个固定长度的向量。</li><li>Word2Vec 考虑了词语的上下文信息，通过在训练过程中利用上下文词语来学习词嵌入。</li></ul></li><li><strong>适用场景</strong>：<ul><li><code>nn.Embedding</code> 通常作为神经网络的一部分，用于在文本分类、语言建模等任务中学习端到端的表示。</li><li>Word2Vec 可以独立训练并用于生成词嵌入，然后可以在各种自然语言处理任务中使用这些预训练的词嵌入。</li></ul></li></ol><h2 id="6-nn-CrossEntropyLoss"><a href="#6-nn-CrossEntropyLoss" class="headerlink" title="6.nn.CrossEntropyLoss"></a>6.nn.CrossEntropyLoss</h2><p><code>nn.CrossEntropyLoss</code> 是PyTorch中的一个损失函数，用于多分类任务。CrossEntropyLoss 计算了模型的输出与目标标签之间的交叉熵损失。在神经网络的训练过程中，通过最小化交叉熵损失，可以使得模型的输出尽可能接近于真实的标签，从而提高模型的分类性能。</p><p>交叉熵损失的计算公式如下：</p><p><img src="/2024/02/14/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E4%B8%ADnn%E6%A8%A1%E5%9D%97/1.png"></p><p>其中，x 是模型的原始输出（也称为 logits），class 是正确的类别标签，j 是所有类别的索引。</p><p>在 PyTorch 中，<code>nn.CrossEntropyLoss</code> <strong>会自动将 logits 传入 softmax 函数</strong>，然后计算交叉熵损失。此外，它还可以处理标签的软性编码（one-hot 编码）或整数形式的标签。</p><p>简而言之，<code>nn.CrossEntropyLoss</code> 可以帮助我们定义一个目标函数，通过最小化该函数，我们的模型可以更好地适应多分类任务。</p><p><strong>tips:</strong></p><p>在使用<code>nn.CrossEntropyLoss</code>时，通过设置<code>ignore_index</code>参数为特定的类别索引，可以实现忽略该类别的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 模拟的模型输出张量</span><br><span class="hljs-comment"># 假设有3个样本，每个样本的预测值是一个包含4个类别的概率分布</span><br>predictions = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1</span>],<br>                            [<span class="hljs-number">0.7</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.1</span>],<br>                            [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.9</span>]])<br><br><span class="hljs-comment"># 目标张量</span><br><span class="hljs-comment"># 假设这是每个样本的真实类别索引</span><br>targets = torch.tensor([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><span class="hljs-comment"># 定义损失函数，并设置ignore_index参数为2</span><br>loss_fn = nn.CrossEntropyLoss(ignore_index=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 计算损失</span><br>loss = loss_fn(predictions, targets)<br><span class="hljs-built_in">print</span>(loss)<br><br><span class="hljs-comment"># 设置ignore_index=2的输出为 tensor(0.8289)，若去掉2的标签，即</span><br>predictions = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1</span>],<br>                            [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.9</span>]])<br><br>targets = torch.tensor([<span class="hljs-number">3</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 输出结果 tensor(0.8289)，也就是说ignore_index等价于不计算设置标签的损失</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>os库的使用！☃️</title>
    <link href="/2024/02/14/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADos%E5%BA%93/"/>
    <url>/2024/02/14/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADos%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="os库的使用"><a href="#os库的使用" class="headerlink" title="os库的使用"></a>os库的使用</h1><h2 id="1-os-path"><a href="#1-os-path" class="headerlink" title="1.os.path"></a>1.os.path</h2><h3 id="1-1-splitext"><a href="#1-1-splitext" class="headerlink" title="1.1 splitext"></a>1.1 splitext</h3><p><code>os.path.splitext()</code> 是 <code>os.path</code> 模块中的一个函数，用于分离文件名中的文件名和扩展名。具体用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">os.path.splitext(path)<br></code></pre></td></tr></table></figure><p>其中，<code>path</code> 是文件路径字符串。</p><p>这个函数返回一个元组，包含分离后的文件名和扩展名。如果文件路径中没有扩展名，则第二个元素为空字符串。</p><p>下面是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>path1 = <span class="hljs-string">&quot;/path/to/file.txt&quot;</span><br>path2 = <span class="hljs-string">&quot;/path/to/another_file&quot;</span><br><br><span class="hljs-comment"># 分离文件名和扩展名</span><br>name1, ext1 = os.path.splitext(path1)<br>name2, ext2 = os.path.splitext(path2)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;File 1:&quot;</span>, name1)  <span class="hljs-comment"># 输出 /path/to/file</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Extension 1:&quot;</span>, ext1)  <span class="hljs-comment"># 输出 .txt</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;File 2:&quot;</span>, name2)  <span class="hljs-comment"># 输出 /path/to/another_file</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Extension 2:&quot;</span>, ext2)  <span class="hljs-comment"># 输出 空字符串</span><br></code></pre></td></tr></table></figure><h3 id="1-2-basename"><a href="#1-2-basename" class="headerlink" title="1.2 basename"></a>1.2 basename</h3><p><code>os.path.basename()</code> 是 <code>os.path</code> 模块中的一个函数，用于返回路径中的最后一个组成部分，即基本文件名部分。具体用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">os.path.basename(path)<br></code></pre></td></tr></table></figure><p>其中，<code>path</code> 是一个字符串，表示文件路径。</p><p>这个函数会返回路径中的最后一个组成部分，通常是<strong>文件名</strong>或<strong>目录名</strong>。</p><p>下面是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>path1 = <span class="hljs-string">&quot;/path/to/file.txt&quot;</span><br>path2 = <span class="hljs-string">&quot;/path/to/directory/&quot;</span><br><br><span class="hljs-comment"># 获取文件名或目录名</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Path 1 basename:&quot;</span>, os.path.basename(path1))  <span class="hljs-comment"># 输出 file.txt</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Path 2 basename:&quot;</span>, os.path.basename(path2))  <span class="hljs-comment"># 输出 directory</span><br></code></pre></td></tr></table></figure><h3 id="1-3-realpath"><a href="#1-3-realpath" class="headerlink" title="1.3 realpath"></a>1.3 realpath</h3><p><code>os.path.relpath</code> 是 Python 中用于计算相对路径的函数，它有两个参数：</p><ol><li><code>path</code>：要计算相对路径的目标路径。</li><li><code>start</code>：相对路径的起始点（可选参数）。如果指定了 <code>start</code>，则 <code>path</code> 将相对于 <code>start</code> 计算相对路径；如果未指定 <code>start</code>，则相对路径将相对于当前工作目录计算。</li></ol><p>示例用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 目标路径</span><br>path = <span class="hljs-string">&#x27;/Users/example/folder/file.txt&#x27;</span><br><br><span class="hljs-comment"># 起始点（可选）</span><br>start = <span class="hljs-string">&#x27;/Users/example/&#x27;</span><br><br><span class="hljs-comment"># 计算相对路径</span><br>relative_path = os.path.relpath(path, start)<br><span class="hljs-built_in">print</span>(relative_path)<br></code></pre></td></tr></table></figure><p>在这个示例中，<code>relative_path</code> 将是 <code>&#39;folder/file.txt&#39;</code>，因为文件 <code>&#39;file.txt&#39;</code> 相对于起始点 <code>&#39;/Users/example/&#39;</code> 是位于 <code>&#39;folder/&#39;</code> 目录下的。</p><h3 id="1-4-dirname"><a href="#1-4-dirname" class="headerlink" title="1.4 dirname"></a>1.4 dirname</h3><p><code>os.path.dirname()</code>: 这是 <code>os.path</code> 模块中的一个函数，用于获取指定路径的目录名部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-built_in">print</span>(os.path.realpath(__file__))<br><span class="hljs-built_in">print</span>(os.path.dirname(os.path.realpath(__file__)))<br></code></pre></td></tr></table></figure><p>对比输出为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">D:\Python\try_pytorch\try_file.py<br>D:\Python\try_pytorch<br></code></pre></td></tr></table></figure><h3 id="1-5-join"><a href="#1-5-join" class="headerlink" title="1.5 join"></a>1.5 join</h3><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model_config_file = os.path.join(<span class="hljs-built_in">dir</span>, <span class="hljs-string">&quot;../properties/model/&#123;&#125;.json&quot;</span>.<span class="hljs-built_in">format</span>(model_name))<br></code></pre></td></tr></table></figure><p>将dir和后面的字符串结合起来，其中<code>..</code>表示<strong>上一级目录</strong>。</p><h3 id="1-6-isabs"><a href="#1-6-isabs" class="headerlink" title="1.6 isabs"></a>1.6 isabs</h3><p><code>os.path.isabs()</code> 是 Python 中 <code>os.path</code> 模块提供的一个函数，用于检查给定的路径是否是绝对路径。</p><ul><li>如果路径是绝对路径，则返回 <code>True</code>。</li><li>如果路径是相对路径，则返回 <code>False</code>。</li></ul><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>path1 = <span class="hljs-string">&#x27;/usr/local/bin/python&#x27;</span><br>path2 = <span class="hljs-string">&#x27;scripts/my_script.py&#x27;</span><br><br><span class="hljs-built_in">print</span>(os.path.isabs(path1))  <span class="hljs-comment"># 输出 True，因为 &#x27;/usr/local/bin/python&#x27; 是绝对路径</span><br><span class="hljs-built_in">print</span>(os.path.isabs(path2))  <span class="hljs-comment"># 输出 False，因为 &#x27;scripts/my_script.py&#x27; 是相对路径</span><br></code></pre></td></tr></table></figure><p><code>os.path.isabs()</code> 函数对于确定给定路径是相对路径还是绝对路径很有用，这在处理文件路径时经常会用到。</p><h2 id="2-getcwd"><a href="#2-getcwd" class="headerlink" title="2.getcwd"></a>2.getcwd</h2><p><code>os.getcwd()</code>是Python中<code>os</code>模块提供的函数，用于获取当前工作目录（Current Working Directory）。在Python程序中调用<code>os.getcwd()</code>将返回一个字符串，表示当前Python程序所处的工作目录的路径。</p><p>例如，在Python中可以这样使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br>current_directory = os.getcwd()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Current working directory:&quot;</span>, current_directory)<br></code></pre></td></tr></table></figure><p>这将输出当前Python程序所在的工作目录的路径。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>string库的使用！☃️</title>
    <link href="/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADstring%E5%BA%93/"/>
    <url>/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADstring%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="string库的使用"><a href="#string库的使用" class="headerlink" title="string库的使用"></a>string库的使用</h1><h2 id="1-基本使用方法"><a href="#1-基本使用方法" class="headerlink" title="1.基本使用方法"></a>1.基本使用方法</h2><h3 id="1-1-字符串常量"><a href="#1-1-字符串常量" class="headerlink" title="1.1 字符串常量"></a>1.1 字符串常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> string<br><br><span class="hljs-comment"># 所有小写字母</span><br><span class="hljs-built_in">print</span>(string.ascii_lowercase)<br><br><span class="hljs-comment"># 所有大写字母</span><br><span class="hljs-built_in">print</span>(string.ascii_uppercase)<br><br><span class="hljs-comment"># 所有字母</span><br><span class="hljs-built_in">print</span>(string.ascii_letters)<br><br><span class="hljs-comment"># 所有数字</span><br><span class="hljs-built_in">print</span>(string.digits)<br><br><span class="hljs-comment"># 所有标点符号</span><br><span class="hljs-built_in">print</span>(string.punctuation)<br><br><span class="hljs-comment"># 所有可打印字符</span><br><span class="hljs-built_in">print</span>(string.printable)<br><br><span class="hljs-comment"># 所有空白字符</span><br><span class="hljs-built_in">print</span>(string.whitespace)<br></code></pre></td></tr></table></figure><h3 id="1-2-基本使用"><a href="#1-2-基本使用" class="headerlink" title="1.2 基本使用"></a>1.2 基本使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> string<br><br><span class="hljs-comment"># 检查字符串是否只包含字母</span><br>s = <span class="hljs-string">&quot;HelloWorld&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">all</span>(c <span class="hljs-keyword">in</span> string.ascii_letters <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s))  <span class="hljs-comment"># 输出 True</span><br><br><span class="hljs-comment"># 删除字符串中的标点符号</span><br>s = <span class="hljs-string">&quot;Hello, World!&quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span>.join(c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s <span class="hljs-keyword">if</span> c <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> string.punctuation))  <span class="hljs-comment"># 输出 HelloWorld</span><br><br><span class="hljs-comment"># 格式化字符串</span><br>name = <span class="hljs-string">&quot;Alice&quot;</span><br>age = <span class="hljs-number">30</span><br>formatted_string = string.Template(<span class="hljs-string">&#x27;$name is $age years old.&#x27;</span>)<br><span class="hljs-built_in">print</span>(formatted_string.substitute(name=name, age=age))  <span class="hljs-comment"># 输出 Alice is 30 years old.</span><br><br><span class="hljs-comment"># 使用模板字符串</span><br><span class="hljs-keyword">from</span> string <span class="hljs-keyword">import</span> Template<br><br>name = <span class="hljs-string">&quot;Alice&quot;</span><br>age = <span class="hljs-number">30</span><br>t = Template(<span class="hljs-string">&#x27;$name is $age years old.&#x27;</span>)<br><span class="hljs-built_in">print</span>(t.substitute(name=name, age=age))  <span class="hljs-comment"># 输出 Alice is 30 years old.</span><br><br><span class="hljs-comment"># 字符串模板替换</span><br>s = <span class="hljs-string">&quot;$who likes $what&quot;</span><br>d = &#123;<span class="hljs-string">&#x27;who&#x27;</span>: <span class="hljs-string">&#x27;Alice&#x27;</span>, <span class="hljs-string">&#x27;what&#x27;</span>: <span class="hljs-string">&#x27;Python&#x27;</span>&#125;<br><span class="hljs-built_in">print</span>(string.Template(s).safe_substitute(d))  <span class="hljs-comment"># 输出 Alice likes Python</span><br></code></pre></td></tr></table></figure><h2 id="2-具体方法"><a href="#2-具体方法" class="headerlink" title="2.具体方法"></a>2.具体方法</h2><h3 id="2-1-join"><a href="#2-1-join" class="headerlink" title="2.1 join"></a>2.1 join</h3><p><code>join()</code> 方法是 Python 中字符串对象的一个方法，用于将可迭代对象（如列表、元组等）中的元素连接成一个字符串。具体用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">separator_string.join(iterable)<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>separator_string</code> 是用于连接的字符串，它将插入到可迭代对象中的每个元素之间。</li><li><code>iterable</code> 是一个可迭代的对象，包含需要连接的元素。</li></ul><p>下面是一些示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用 join 方法将列表中的字符串连接成一个新的字符串</span><br>my_list = [<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot;World&quot;</span>, <span class="hljs-string">&quot;Python&quot;</span>]<br>result = <span class="hljs-string">&quot; &quot;</span>.join(my_list)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 Hello World Python</span><br><br><span class="hljs-comment"># 使用 join 方法将元组中的字符串连接成一个新的字符串</span><br>my_tuple = (<span class="hljs-string">&quot;apple&quot;</span>, <span class="hljs-string">&quot;banana&quot;</span>, <span class="hljs-string">&quot;cherry&quot;</span>)<br>result = <span class="hljs-string">&quot;, &quot;</span>.join(my_tuple)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 apple, banana, cherry</span><br><br><span class="hljs-comment"># 使用 join 方法将集合中的字符串连接成一个新的字符串</span><br>my_set = &#123;<span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-string">&quot;green&quot;</span>, <span class="hljs-string">&quot;blue&quot;</span>&#125;<br>result = <span class="hljs-string">&quot;; &quot;</span>.join(my_set)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 green; blue; red</span><br><br><span class="hljs-comment"># 使用 join 方法将字典中的键连接成一个新的字符串</span><br>my_dict = &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Alice&quot;</span>, <span class="hljs-string">&quot;age&quot;</span>: <span class="hljs-number">30</span>&#125;<br>result = <span class="hljs-string">&quot;, &quot;</span>.join(my_dict)<br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 name, age</span><br></code></pre></td></tr></table></figure><h3 id="2-2-find"><a href="#2-2-find" class="headerlink" title="2.2 find"></a>2.2 find</h3><p><code>find()</code> 方法是 Python 字符串对象的一个方法，用于在字符串中查找子字符串，并返回第一次出现的索引位置。如果子字符串不存在，则返回 -1。具体用法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">str</span>.find(sub[, start[, end]])<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>str</code> 是原始字符串。</li><li><code>sub</code> 是要查找的子字符串。</li><li><code>start</code> 是可选参数，指定查找的起始位置，默认为 0。</li><li><code>end</code> 是可选参数，指定查找的结束位置，默认为字符串的长度。</li></ul><p>下面是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">my_string = <span class="hljs-string">&quot;hello world&quot;</span><br><br><span class="hljs-comment"># 查找子字符串</span><br><span class="hljs-built_in">print</span>(my_string.find(<span class="hljs-string">&quot;world&quot;</span>))  <span class="hljs-comment"># 输出 6</span><br><span class="hljs-built_in">print</span>(my_string.find(<span class="hljs-string">&quot;python&quot;</span>))  <span class="hljs-comment"># 输出 -1，因为子字符串不存在</span><br><br><span class="hljs-comment"># 从指定位置开始查找</span><br><span class="hljs-built_in">print</span>(my_string.find(<span class="hljs-string">&quot;o&quot;</span>, <span class="hljs-number">5</span>))  <span class="hljs-comment"># 输出 7，从索引 5 开始查找子字符串 &quot;o&quot;</span><br><br><span class="hljs-comment"># 在指定范围内查找</span><br><span class="hljs-built_in">print</span>(my_string.find(<span class="hljs-string">&quot;l&quot;</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>))  <span class="hljs-comment"># 输出 3，在索引 3 到 6 的范围内查找子字符串 &quot;l&quot;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>unicodedata库的使用!☃️</title>
    <link href="/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADunicode%E5%BA%93/"/>
    <url>/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADunicode%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="unicodedata库的使用"><a href="#unicodedata库的使用" class="headerlink" title="unicodedata库的使用"></a>unicodedata库的使用</h1><h2 id="1-基本使用"><a href="#1-基本使用" class="headerlink" title="1.基本使用"></a>1.基本使用</h2><p><code>unicodedata</code> 是 Python 标准库中的一个模块，用于处理 Unicode 字符数据。它提供了许多函数来查询和处理 Unicode 字符属性。以下是 <code>unicodedata</code> 库的一些常见用法：</p><h3 id="1-1-获取字符的-Unicode-名称："><a href="#1-1-获取字符的-Unicode-名称：" class="headerlink" title="1.1 获取字符的 Unicode 名称："></a>1.1 <strong>获取字符的 Unicode 名称：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;A&#x27;</span><br>name = unicodedata.name(char)<br><span class="hljs-built_in">print</span>(name)  <span class="hljs-comment"># 输出 &#x27;LATIN CAPITAL LETTER A&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="1-2-获取字符的-Unicode-分类："><a href="#1-2-获取字符的-Unicode-分类：" class="headerlink" title="1.2 获取字符的 Unicode 分类："></a>1.2 <strong>获取字符的 Unicode 分类：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;A&#x27;</span><br>category = unicodedata.category(char)<br><span class="hljs-built_in">print</span>(category)  <span class="hljs-comment"># 输出 &#x27;Lu&#x27; (表示大写字母)</span><br></code></pre></td></tr></table></figure><h3 id="1-3-获取字符的-Unicode-编码点："><a href="#1-3-获取字符的-Unicode-编码点：" class="headerlink" title="1.3 获取字符的 Unicode 编码点："></a>1.3 <strong>获取字符的 Unicode 编码点：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;A&#x27;</span><br>code_point = <span class="hljs-built_in">ord</span>(char)<br><span class="hljs-built_in">print</span>(code_point)  <span class="hljs-comment"># 输出 65</span><br></code></pre></td></tr></table></figure><h3 id="1-4-将-Unicode-字符规范化："><a href="#1-4-将-Unicode-字符规范化：" class="headerlink" title="1.4 将 Unicode 字符规范化："></a>1.4 <strong>将 Unicode 字符规范化：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;é&#x27;</span><br>normalized_char = unicodedata.normalize(<span class="hljs-string">&#x27;NFKD&#x27;</span>, char)<br><span class="hljs-built_in">print</span>(normalized_char)  <span class="hljs-comment"># 输出 &#x27;é&#x27; (组合字符)</span><br></code></pre></td></tr></table></figure><h3 id="1-5-检查字符是否是数字、字母、空格等："><a href="#1-5-检查字符是否是数字、字母、空格等：" class="headerlink" title="1.5 检查字符是否是数字、字母、空格等："></a>1.5 <strong>检查字符是否是数字、字母、空格等：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;5&#x27;</span><br>is_digit = unicodedata.isdigit(char)<br><span class="hljs-built_in">print</span>(is_digit)  <span class="hljs-comment"># 输出 True</span><br></code></pre></td></tr></table></figure><h3 id="1-6-获取字符的大小写变体："><a href="#1-6-获取字符的大小写变体：" class="headerlink" title="1.6 获取字符的大小写变体："></a>1.6 <strong>获取字符的大小写变体：</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> unicodedata<br><br>char = <span class="hljs-string">&#x27;a&#x27;</span><br>upper_case_char = unicodedata.toupper(char)<br>lower_case_char = unicodedata.tolower(char)<br><span class="hljs-built_in">print</span>(upper_case_char)  <span class="hljs-comment"># 输出 &#x27;A&#x27;</span><br><span class="hljs-built_in">print</span>(lower_case_char)  <span class="hljs-comment"># 输出 &#x27;a&#x27;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>glob库的使用！☃️</title>
    <link href="/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADglob%E5%BA%93/"/>
    <url>/2024/02/13/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADglob%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="glob库的使用"><a href="#glob库的使用" class="headerlink" title="glob库的使用"></a>glob库的使用</h1><h2 id="1-glob基础使用方法"><a href="#1-glob基础使用方法" class="headerlink" title="1.glob基础使用方法"></a>1.glob基础使用方法</h2><p>在Python中，<code>glob</code>模块用于查找文件路径名匹配特定模式的文件。下面是一个简单的示例，演示了如何使用<code>glob</code>库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以.py结尾的文件</span><br>python_files = glob.glob(<span class="hljs-string">&#x27;*.py&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的Python文件:&quot;</span>, python_files)<br><br><span class="hljs-comment"># 查找当前目录及子目录下所有的.txt文件</span><br>txt_files = glob.glob(<span class="hljs-string">&#x27;**/*.txt&#x27;</span>, recursive=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的txt文件:&quot;</span>, txt_files)<br><br><span class="hljs-comment"># 查找当前目录及子目录下所有名为test的文件或目录</span><br>test_files = glob.glob(<span class="hljs-string">&#x27;**/test&#x27;</span>, recursive=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的test文件或目录:&quot;</span>, test_files)<br><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以.py结尾的文件</span><br>python_files = glob.glob(<span class="hljs-string">&#x27;*.py&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的Python文件:&quot;</span>, python_files)<br><br><span class="hljs-comment"># 查找当前目录及子目录下所有的.txt文件</span><br>txt_files = glob.glob(<span class="hljs-string">&#x27;**/*.txt&#x27;</span>, recursive=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的txt文件:&quot;</span>, txt_files)<br><br><span class="hljs-comment"># 查找当前目录及子目录下所有名为test的文件或目录</span><br>test_files = glob.glob(<span class="hljs-string">&#x27;**/test&#x27;</span>, recursive=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;所有的test文件或目录:&quot;</span>, test_files)<br></code></pre></td></tr></table></figure><h2 id="2-更多的使用方式"><a href="#2-更多的使用方式" class="headerlink" title="2.更多的使用方式"></a>2.更多的使用方式</h2><h3 id="2-1-匹配单个字符："><a href="#2-1-匹配单个字符：" class="headerlink" title="2.1 匹配单个字符："></a>2.1 <strong>匹配单个字符</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以a开头，b结尾的文件</span><br>files = glob.glob(<span class="hljs-string">&#x27;a*b&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-2-匹配多个字符："><a href="#2-2-匹配多个字符：" class="headerlink" title="2.2 匹配多个字符："></a>2.2 <strong>匹配多个字符</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以a开头，b结尾的文件，并且中间有1到3个任意字符</span><br>files = glob.glob(<span class="hljs-string">&#x27;a???b&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-3-匹配指定范围的字符："><a href="#2-3-匹配指定范围的字符：" class="headerlink" title="2.3 匹配指定范围的字符："></a>2.3 <strong>匹配指定范围的字符</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以a开头，b结尾，并且中间有一个数字的文件</span><br>files = glob.glob(<span class="hljs-string">&#x27;a[0-9]b&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-4-排除特定模式："><a href="#2-4-排除特定模式：" class="headerlink" title="2.4 排除特定模式："></a>2.4 <strong>排除特定模式</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有不以test开头的文件</span><br>files = glob.glob(<span class="hljs-string">&#x27;[!test]*&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-5-获取目录下所有子目录："><a href="#2-5-获取目录下所有子目录：" class="headerlink" title="2.5 获取目录下所有子目录："></a>2.5 <strong>获取目录下所有子目录</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录及子目录下所有的目录</span><br>directories = glob.glob(<span class="hljs-string">&#x27;*/&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-6-获取指定扩展名的文件："><a href="#2-6-获取指定扩展名的文件：" class="headerlink" title="2.6 获取指定扩展名的文件："></a>2.6 <strong>获取指定扩展名的文件</strong>：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-comment"># 查找当前目录下所有以.txt结尾的文件</span><br>txt_files = glob.glob(<span class="hljs-string">&#x27;*.txt&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RNN介绍！💐</title>
    <link href="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/RNN/"/>
    <url>/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/RNN/</url>
    
    <content type="html"><![CDATA[<h1 id="RNN介绍"><a href="#RNN介绍" class="headerlink" title="RNN介绍"></a>RNN介绍</h1><h2 id="1-图示"><a href="#1-图示" class="headerlink" title="1.图示"></a>1.图示</h2><p>对于字符级分类RNN：</p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/RNN/1.png"></p><p>对于字符级生成RNN：</p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/RNN/3.png"></p><h2 id="2-具体代码"><a href="#2-具体代码" class="headerlink" title="2.具体代码"></a>2.具体代码</h2><p><strong>对于字符级分类RNN</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(RNN, self).__init__()<br><br>        self.hidden_size = hidden_size<br><br>        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)<br>        self.h2o = nn.Linear(hidden_size, output_size)<br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden</span>):<br>        combined = torch.cat((<span class="hljs-built_in">input</span>, hidden), <span class="hljs-number">1</span>)<br>        hidden = self.i2h(combined)<br>        output = self.h2o(hidden)<br>        output = self.softmax(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initHidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, self.hidden_size)<br></code></pre></td></tr></table></figure><p>上面为基本网络。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">category_tensor, line_tensor</span>):<br>    hidden = rnn.initHidden()<br><br>    rnn.zero_grad()<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(line_tensor.size()[<span class="hljs-number">0</span>]):<br>        output, hidden = rnn(line_tensor[i], hidden)<br><br>    loss = criterion(output, category_tensor)<br>    loss.backward()<br><br>    <span class="hljs-comment"># Add parameters&#x27; gradients to their values, multiplied by learning rate</span><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> rnn.parameters():<br>        p.data.add_(p.grad.data, alpha=-learning_rate)<br></code></pre></td></tr></table></figure><p>上面为具体训练步骤。</p><p>其中，<img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/NLP/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/NLP%E6%A8%A1%E5%9E%8B/RNN/1.png">是RNN核心步骤。</p><p><strong>对于字符级生成RNN</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(RNN, self).__init__()<br>        self.hidden_size = hidden_size<br><br>        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)<br>        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)<br>        self.o2o = nn.Linear(hidden_size + output_size, output_size)<br>        self.dropout = nn.Dropout(<span class="hljs-number">0.1</span>)<br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, category, <span class="hljs-built_in">input</span>, hidden</span>):<br>        input_combined = torch.cat((category, <span class="hljs-built_in">input</span>, hidden), <span class="hljs-number">1</span>)<br>        hidden = self.i2h(input_combined)<br>        output = self.i2o(input_combined)<br>        output_combined = torch.cat((hidden, output), <span class="hljs-number">1</span>)<br>        output = self.o2o(output_combined)<br>        output = self.dropout(output)<br>        output = self.softmax(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initHidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, self.hidden_size)<br></code></pre></td></tr></table></figure><p>上面为具体网络。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">category_tensor, input_line_tensor, target_line_tensor</span>):<br>    target_line_tensor.unsqueeze_(-<span class="hljs-number">1</span>)<br>    hidden = rnn.initHidden()<br><br>    rnn.zero_grad()<br><br>    loss = torch.Tensor([<span class="hljs-number">0</span>]) <span class="hljs-comment"># you can also just simply use ``loss = 0``</span><br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(input_line_tensor.size(<span class="hljs-number">0</span>)):<br>        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)<br>        l = criterion(output, target_line_tensor[i])<br>        loss += l<br><br>    loss.backward()<br><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> rnn.parameters():<br>        p.data.add_(p.grad.data, alpha=-learning_rate)<br></code></pre></td></tr></table></figure><p>上面为具体训练步骤。</p>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>NLP</category>
      
      <category>NLP基础知识</category>
      
      <category>NLP模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>字符级RNN分类！🌞</title>
    <link href="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/"/>
    <url>/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="使用字符级RNN对名称进行分类"><a href="#使用字符级RNN对名称进行分类" class="headerlink" title="使用字符级RNN对名称进行分类"></a>使用字符级RNN对名称进行分类</h1><h2 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1.准备数据"></a>1.准备数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> <span class="hljs-built_in">open</span><br><span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">findFiles</span>(<span class="hljs-params">path</span>): <span class="hljs-keyword">return</span> glob.glob(path)<br><br><span class="hljs-built_in">print</span>(findFiles(<span class="hljs-string">&#x27;data/names/*.txt&#x27;</span>))<br><br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">import</span> string<br><br>all_letters = string.ascii_letters + <span class="hljs-string">&quot; .,;&#x27;&quot;</span><br>n_letters = <span class="hljs-built_in">len</span>(all_letters)<br><br><span class="hljs-comment"># Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">unicodeToAscii</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(<br>        c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> unicodedata.normalize(<span class="hljs-string">&#x27;NFD&#x27;</span>, s)<br>        <span class="hljs-keyword">if</span> unicodedata.category(c) != <span class="hljs-string">&#x27;Mn&#x27;</span><br>        <span class="hljs-keyword">and</span> c <span class="hljs-keyword">in</span> all_letters<br>    )<br><br><span class="hljs-built_in">print</span>(unicodeToAscii(<span class="hljs-string">&#x27;Ślusàrski&#x27;</span>))<br><br><span class="hljs-comment"># Build the category_lines dictionary, a list of names per language</span><br>category_lines = &#123;&#125;<br>all_categories = []<br><br><span class="hljs-comment"># Read a file and split into lines</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">readLines</span>(<span class="hljs-params">filename</span>):<br>    lines = <span class="hljs-built_in">open</span>(filename, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    <span class="hljs-keyword">return</span> [unicodeToAscii(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br><br><span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> findFiles(<span class="hljs-string">&#x27;data/names/*.txt&#x27;</span>):<br>    category = os.path.splitext(os.path.basename(filename))[<span class="hljs-number">0</span>]<br>    all_categories.append(category)<br>    lines = readLines(filename)<br>    category_lines[category] = lines<br><br>n_categories = <span class="hljs-built_in">len</span>(all_categories)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/2.png"></p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/1.png"></p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/3.png"></p><h2 id="2-将名称转换为张量"><a href="#2-将名称转换为张量" class="headerlink" title="2.将名称转换为张量"></a>2.将名称转换为张量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">letterToIndex</span>(<span class="hljs-params">letter</span>):<br>    <span class="hljs-keyword">return</span> all_letters.find(letter)<br><br><span class="hljs-comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">letterToTensor</span>(<span class="hljs-params">letter</span>):<br>    tensor = torch.zeros(<span class="hljs-number">1</span>, n_letters)<br>    tensor[<span class="hljs-number">0</span>][letterToIndex(letter)] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br><br><span class="hljs-comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span><br><span class="hljs-comment"># or an array of one-hot letter vectors</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lineToTensor</span>(<span class="hljs-params">line</span>):<br>    tensor = torch.zeros(<span class="hljs-built_in">len</span>(line), <span class="hljs-number">1</span>, n_letters)<br>    <span class="hljs-keyword">for</span> li, letter <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(line):<br>        tensor[li][<span class="hljs-number">0</span>][letterToIndex(letter)] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br><br><span class="hljs-built_in">print</span>(letterToTensor(<span class="hljs-string">&#x27;J&#x27;</span>))<br><br><span class="hljs-built_in">print</span>(lineToTensor(<span class="hljs-string">&#x27;Jones&#x27;</span>).size())<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>这一步构建了两个方法，<code>letterToTensor</code>将单个字符转换为了一个二维张量，<code>lineToTensor</code>将一个单词转换为了三维张量，其中<code>torch.zeros(len(line), 1, n_letters)</code>中的1是因为 PyTorch 假设一切都是批量的 - 我们在这里只使用批处理大小 1。</p><h2 id="3-创建网络"><a href="#3-创建网络" class="headerlink" title="3.创建网络"></a>3.创建网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(RNN, self).__init__()<br><br>        self.hidden_size = hidden_size<br><br>        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)<br>        self.h2o = nn.Linear(hidden_size, output_size)<br>        self.softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden</span>):<br>        combined = torch.cat((<span class="hljs-built_in">input</span>, hidden), <span class="hljs-number">1</span>)<br>        hidden = self.i2h(combined)<br>        output = self.h2o(hidden)<br>        output = self.softmax(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initHidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, self.hidden_size)<br><br>n_hidden = <span class="hljs-number">128</span><br>rnn = RNN(n_letters, n_hidden, n_categories)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>该网络首先将输入层和隐藏层结合，然后通过线性层输出一个1*128的隐藏层，再将该层通过一个线性层转换为输出层，经过激活函数后输出。</p><p><img src="/2024/02/13/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/RNN%E5%88%86%E7%B1%BB/4.png"></p><p>为了运行这个网络的一个步骤，我们需要传递一个输入（在我们的例子中，是当前字母的张量）和一个之前的隐藏状态（我们首先将其初始化为零）。我们将返回输出（每种语言的概率）和下一个隐藏状态（我们保留该状态以备下一步使用）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = letterToTensor(<span class="hljs-string">&#x27;A&#x27;</span>)<br>hidden = torch.zeros(<span class="hljs-number">1</span>, n_hidden)<br><br>output, next_hidden = rnn(<span class="hljs-built_in">input</span>, hidden)<br></code></pre></td></tr></table></figure><p>为了提高效率，我们不想为每一步都创建一个新的 Tensor，所以我们将使用 <code>lineToTensor</code> slices 而不是 <code>letterToTensor</code> slices。这可以通过预先计算 Tensor 的批次来进一步优化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = lineToTensor(<span class="hljs-string">&#x27;Albert&#x27;</span>)<br>hidden = torch.zeros(<span class="hljs-number">1</span>, n_hidden)<br><br>output, next_hidden = rnn(<span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>], hidden)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><h2 id="4-训练"><a href="#4-训练" class="headerlink" title="4.训练"></a>4.训练</h2><p>在开始训练之前，我们应该做一些辅助功能。首先是解释网络的输出，我们知道这是每个类别的可能性。我们可以用来 <code>Tensor.topk</code> 获取最大值的索引：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">categoryFromOutput</span>(<span class="hljs-params">output</span>):<br>    top_n, top_i = output.topk(<span class="hljs-number">1</span>)<br>    category_i = top_i[<span class="hljs-number">0</span>].item()<br>    <span class="hljs-keyword">return</span> all_categories[category_i], category_i<br><br><span class="hljs-built_in">print</span>(categoryFromOutput(output))<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>topk返回值和索引。</p><p>我们还想要一种快速获取训练示例（名称及其语言）的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randomChoice</span>(<span class="hljs-params">l</span>):<br>    <span class="hljs-keyword">return</span> l[random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(l) - <span class="hljs-number">1</span>)]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randomTrainingExample</span>():<br>    category = randomChoice(all_categories)<br>    line = randomChoice(category_lines[category])<br>    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)<br>    line_tensor = lineToTensor(line)<br>    <span class="hljs-keyword">return</span> category, line, category_tensor, line_tensor<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    category, line, category_tensor, line_tensor = randomTrainingExample()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;category =&#x27;</span>, category, <span class="hljs-string">&#x27;/ line =&#x27;</span>, line)<br></code></pre></td></tr></table></figure><p>对于损失函数 <code>nn.NLLLoss</code> 是合适的，因为 RNN 的最后一层是 <code>nn.LogSoftmax</code> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.NLLLoss()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">learning_rate = <span class="hljs-number">0.005</span> <span class="hljs-comment"># If you set this too high, it might explode. If too low, it might not learn</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">category_tensor, line_tensor</span>):<br>    hidden = rnn.initHidden()<br><br>    rnn.zero_grad()<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(line_tensor.size()[<span class="hljs-number">0</span>]):<br>        output, hidden = rnn(line_tensor[i], hidden)<br><br>    loss = criterion(output, category_tensor)<br>    loss.backward()<br><br>    <span class="hljs-comment"># Add parameters&#x27; gradients to their values, multiplied by learning rate</span><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> rnn.parameters():<br>        p.data.add_(p.grad.data, alpha=-learning_rate)<br><br>    <span class="hljs-keyword">return</span> output, loss.item()<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p><code>rnn.zero_grad()</code>：在每个训练步骤之前清零模型参数的梯度。</p><p><code>p.data.add_(p.grad.data, alpha=-learning_rate)</code>：这行代码是针对循环神经网络（RNN）模型中的参数进行梯度下降更新的一种常见方式。</p><ol><li><p><code>for p in rnn.parameters():</code>：这个循环遍历了RNN模型中的所有参数。在PyTorch中，通过 <code>parameters()</code> 方法可以获取模型中所有需要进行学习的参数。</p></li><li><p><code>p.data.add_(p.grad.data, alpha=-learning_rate)</code>：这行代码是对每个参数进行更新的核心部分。让我们分解它：</p><ul><li><code>p.data</code>：表示参数 <code>p</code> 的数据值。</li><li><code>p.grad.data</code>：表示参数 <code>p</code> 的梯度值。</li><li><code>alpha=-learning_rate</code>：表示更新的步长，即学习率的负数。</li></ul><p>实际上，这行代码执行了以下操作：</p><ul><li>首先，它获取了参数 <code>p</code> 的数据值 <code>p.data</code>。</li><li>然后，它将参数的梯度值 <code>p.grad.data</code> 乘以学习率的负数 <code>-learning_rate</code>。</li><li>最后，它将这个乘以后的梯度值添加到参数的数据值中，实现了参数的更新。</li></ul></li></ol><p>这个过程基本上是梯度下降法的一步，其中学习率 <code>learning_rate</code> 控制着参数更新的步长。通常，这行代码会在优化器（如随机梯度下降优化器或Adam优化器）中的参数更新步骤中被使用。</p><p>值得注意的是，这种方式在更新参数时直接修改了参数的数据值，而没有通过优化器对象来处理。因此，在使用这种方式时需要手动设置学习率、考虑动量等优化技巧。一般情况下，更推荐使用PyTorch提供的优化器，例如 <code>torch.optim.SGD</code> 或 <code>torch.optim.Adam</code>，这些优化器会自动管理参数更新的细节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> math<br><br>n_iters = <span class="hljs-number">100000</span><br>print_every = <span class="hljs-number">5000</span><br>plot_every = <span class="hljs-number">1000</span><br><br><br><br><span class="hljs-comment"># Keep track of losses for plotting</span><br>current_loss = <span class="hljs-number">0</span><br>all_losses = []<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">timeSince</span>(<span class="hljs-params">since</span>):<br>    now = time.time()<br>    s = now - since<br>    m = math.floor(s / <span class="hljs-number">60</span>)<br>    s -= m * <span class="hljs-number">60</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;%dm %ds&#x27;</span> % (m, s)<br><br>start = time.time()<br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_iters + <span class="hljs-number">1</span>):<br>    category, line, category_tensor, line_tensor = randomTrainingExample()<br>    output, loss = train(category_tensor, line_tensor)<br>    current_loss += loss<br><br>    <span class="hljs-comment"># Print ``iter`` number, loss, name and guess</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % print_every == <span class="hljs-number">0</span>:<br>        guess, guess_i = categoryFromOutput(output)<br>        correct = <span class="hljs-string">&#x27;✓&#x27;</span> <span class="hljs-keyword">if</span> guess == category <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;✗ (%s)&#x27;</span> % category<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d %d%% (%s) %.4f %s / %s %s&#x27;</span> % (<span class="hljs-built_in">iter</span>, <span class="hljs-built_in">iter</span> / n_iters * <span class="hljs-number">100</span>, timeSince(start), loss, line, guess, correct))<br><br>    <span class="hljs-comment"># Add current loss avg to list of losses</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % plot_every == <span class="hljs-number">0</span>:<br>        all_losses.append(current_loss / plot_every)<br>        current_loss = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch项目实战</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用Tensor方法！🍧</title>
    <link href="/2024/02/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B8%B8%E7%94%A8%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/02/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B8%B8%E7%94%A8%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="常用Tensor方法"><a href="#常用Tensor方法" class="headerlink" title="常用Tensor方法"></a>常用Tensor方法</h1><h2 id="1-topk"><a href="#1-topk" class="headerlink" title="1.topk"></a>1.topk</h2><p><code>Tensor.topk</code> 是 PyTorch 中的一个函数，用于在张量（Tensor）中获取前 k 个最大值或最小值及其对应的索引。</p><p>具体而言，<code>Tensor.topk</code> 函数返回的是给定张量中的前 k 个最大值（或最小值）以及它们在张量中的位置索引。函数的签名通常如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">values, indices = torch.topk(<span class="hljs-built_in">input</span>, k, dim=<span class="hljs-literal">None</span>, largest=<span class="hljs-literal">True</span>, <span class="hljs-built_in">sorted</span>=<span class="hljs-literal">True</span>, out=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>input</code> 是输入的张量。</li><li><code>k</code> 是要获取的最大值或最小值的个数。</li><li><code>dim</code> 是在哪个维度上进行检索。如果不指定，则默认为整个张量。</li><li><code>largest</code> 是一个布尔值，用于指定是否获取最大值。如果为 True，则返回前 k 个最大值；如果为 False，则返回前 k 个最小值。</li><li><code>sorted</code> 也是一个布尔值，用于指定返回的结果是否按照大小顺序排列。</li><li><code>out</code> 是一个可选的输出张量。</li></ul><p>以下是一个示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个示例张量</span><br>tensor = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>])<br><br><span class="hljs-comment"># 获取前3个最大值及其索引</span><br>top_values, top_indices = tensor.topk(<span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(top_values)    <span class="hljs-comment"># 输出: tensor([5, 4, 3])</span><br><span class="hljs-built_in">print</span>(top_indices)   <span class="hljs-comment"># 输出: tensor([3, 4, 1])</span><br></code></pre></td></tr></table></figure><p>在这个示例中，<code>top_values</code> 包含了输入张量中的前 3 个最大值 <code>[5, 4, 3]</code>，而 <code>top_indices</code> 包含了这些值在原始张量中的索引 <code>[3, 4, 1]</code>。</p><h2 id="2-add"><a href="#2-add" class="headerlink" title="2.add_"></a>2.add_</h2><p><code>add_</code> 是PyTorch张量（Tensor）类的一个方法，用于将另一个张量的值加到当前张量上。这个方法是就地操作，即会修改调用它的张量，并且返回修改后的张量。</p><p>具体来说，<code>add_</code> 方法有几种不同的用法：</p><h3 id="2-1-张量相加"><a href="#2-1-张量相加" class="headerlink" title="2.1 张量相加"></a>2.1 <strong>张量相加</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor1.add_(tensor2)<br></code></pre></td></tr></table></figure><p>这会将张量 <code>tensor2</code> 的值加到张量 <code>tensor1</code> 上，并修改 <code>tensor1</code> 的值。如果 <code>tensor1</code> 和 <code>tensor2</code> 的形状不匹配，PyTorch会自动进行广播（broadcasting）操作，使得它们可以相加。</p><h3 id="2-2-标量相加"><a href="#2-2-标量相加" class="headerlink" title="2.2 标量相加"></a>2.2 <strong>标量相加</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.add_(scalar)<br></code></pre></td></tr></table></figure><h3 id="2-3-张量与标量相乘再相加"><a href="#2-3-张量与标量相乘再相加" class="headerlink" title="2.3 张量与标量相乘再相加"></a>2.3 <strong>张量与标量相乘再相加</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.add_(other_tensor, alpha=scalar)<br></code></pre></td></tr></table></figure><h2 id="3-unsqueeze"><a href="#3-unsqueeze" class="headerlink" title="3.unsqueeze_"></a>3.unsqueeze_</h2><p><code>unsqueeze_</code> 是 PyTorch 中的一个张量操作函数，用于在指定的维度上增加一个大小为 1 的维度。这个操作是 in-place 的，意味着它会修改原始张量而不是返回一个新的张量。</p><p>语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.unsqueeze_(dim)<br></code></pre></td></tr></table></figure><ul><li><code>tensor</code>: 要进行操作的张量。</li><li><code>dim</code>: 要在其前面插入维度的索引。如果 <code>dim</code> 是负数，则从末尾开始计数。</li></ul><p>例如，假设有一个形状为 (3, 4) 的张量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>tensor = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>                       [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>],<br>                       [<span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>]])<br></code></pre></td></tr></table></figure><p>如果我们想在第一个维度上增加一个大小为 1 的维度，可以使用 <code>unsqueeze_</code> 操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.unsqueeze_(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>这将使得张量的形状变为 (1, 3, 4)，因为在原来的维度 0 的位置上插入了一个维度大小为 1 的维度。</p><p>同样，我们也可以在其他维度上插入维度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.unsqueeze_(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>这将使得张量的形状变为 (1, 3, 1, 4)。</p><h2 id="4-squeeze"><a href="#4-squeeze" class="headerlink" title="4.squeeze"></a>4.squeeze</h2><p><code>tensor.squeeze()</code> 是一个用于删除尺寸为 1 的维度的 PyTorch 张量方法。在张量中，有时会存在维度大小为 1 的维度，这些维度可能是由于某些操作或者数据结构的需求而产生的，但是它们对于张量的计算没有实质性的影响。<code>squeeze()</code> 方法就是用来删除这些维度，从而使得张量更加紧凑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个具有维度大小为 1 的维度的张量</span><br>tensor = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量形状：&quot;</span>, tensor.shape)  <span class="hljs-comment"># 输出：torch.Size([1, 3, 1, 5])</span><br><br><span class="hljs-comment"># 删除维度大小为 1 的维度</span><br>squeezed_tensor = tensor.squeeze()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;删除维度后的张量形状：&quot;</span>, squeezed_tensor.shape)  <span class="hljs-comment"># 输出：torch.Size([3, 5])</span><br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><ul><li>需要注意的是，<code>squeeze()</code> 方法默认会删除所有维度大小为 1 的维度，但也可以通过传递参数指定删除某些特定的维度。</li><li>调用 <code>squeeze(-1)</code> 方法是针对张量的最后一个维度进行压缩，即删除最后一个维度中大小为 1 的维度。这在处理张量中的单例维度时非常有用，尤其是在处理很多卷积网络或循环神经网络的输出时。</li><li>如果指定的维度大小<strong>不为 1</strong>，那么 <code>squeeze(dim)</code> 方法会<strong>保持原样</strong>，不会删除任何维度。这个方法仅仅会删除大小为 1 的维度。</li></ul><h2 id="5-detach"><a href="#5-detach" class="headerlink" title="5.detach"></a>5.detach</h2><p><code>detach()</code> 是 PyTorch 中张量的一个方法，用于创建一个新的张量，该张量与原始张量共享数据，但是不再与计算图相关联。换句话说，它会将张量从当前的计算图中分离出来，使得我们可以在不影响梯度计算的情况下对其进行操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个需要梯度的张量</span><br>tensor = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 对张量进行操作</span><br>result = tensor * <span class="hljs-number">2</span><br><br><span class="hljs-comment"># 调用 detach() 方法，分离张量</span><br>detached_tensor = result.detach()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;result：&quot;</span>, result)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;detached_tensor：&quot;</span>, detached_tensor)<br></code></pre></td></tr></table></figure><p>在这个示例中，<code>result</code> 是通过对 <code>tensor</code> 进行乘法运算得到的新张量，它依赖于 <code>tensor</code>，因此也会有梯度。调用 <code>detach()</code> 方法后，<code>detached_tensor</code> 将会分离出来，不再与计算图相关联，因此不再具有梯度信息。</p><h2 id="6-fill"><a href="#6-fill" class="headerlink" title="6.fill_"></a>6.fill_</h2><p><code>fill_()</code> 是 PyTorch 张量的一个方法，用于将张量中的所有元素填充为指定的值。这个方法会修改原始张量，并且不会返回新的张量。下划线（<code>_</code>）表示这个方法会就地修改张量，而不是返回一个新的张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个形状为 2x3 的张量，所有元素初始化为 0</span><br>tensor = torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Original Tensor:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><br><span class="hljs-comment"># 使用 fill_ 方法将所有元素填充为 5</span><br>tensor.fill_(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nTensor after fill_ with 5:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Original Tensor:<br>tensor([[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]])<br><br>Tensor after fill_ <span class="hljs-keyword">with</span> <span class="hljs-number">5</span>:<br>tensor([[<span class="hljs-number">5.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">5.</span>],<br>        [<span class="hljs-number">5.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">5.</span>]])<br></code></pre></td></tr></table></figure><h2 id="7-permute"><a href="#7-permute" class="headerlink" title="7.permute"></a>7.permute</h2><p><code>permute</code> 是 PyTorch 中用于维度置换（dimension permutation）的函数。它可以重新排列张量的维度。假设你有一个张量 <code>tensor</code>，你可以使用 <code>permute</code> 函数来重新排列其维度，如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个示例张量</span><br>tensor = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment"># 形状为 (2, 3, 4)</span><br><br><span class="hljs-comment"># 使用 permute 函数重新排列维度</span><br>permuted_tensor = tensor.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># 将第一个维度移到最后，形状变为 (3, 4, 2)</span><br><br><span class="hljs-built_in">print</span>(permuted_tensor.shape)<br></code></pre></td></tr></table></figure><p>在这个示例中，原始张量的形状是 <code>(2, 3, 4)</code>，使用 <code>permute(1, 2, 0)</code> 将第一个维度移到最后，新的张量形状变为 <code>(3, 4, 2)</code>。</p><p><code>permute</code> 函数接受一个整数参数序列作为输入，表示重新排列后的维度顺序。</p><h2 id="8-view"><a href="#8-view" class="headerlink" title="8.view"></a>8.view</h2><p>在PyTorch中，<code>tensor.view()</code>是一个函数，用于调整张量的形状，但是不改变其数据。它可以用于在不复制数据的情况下改变张量的形状，这在深度学习中非常有用。</p><p>该函数的语法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">new_tensor = tensor.view(*shape)<br></code></pre></td></tr></table></figure><p>其中<code>tensor</code>是原始的张量，<code>shape</code>是一个元组，指定了新张量的形状。<code>*shape</code>的意思是将<code>shape</code>元组中的元素解包，作为独立的参数传递给<code>view()</code>函数。</p><p>值得注意的是，<code>tensor.view()</code>返回的新张量与原始张量共享数据存储空间，因此在某些情况下，修改新张量可能会影响原始张量，反之亦然。如果想要确保新张量和原始张量完全独立，可以使用<code>tensor.clone().view()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个4x4的张量</span><br>x = torch.arange(<span class="hljs-number">16</span>).reshape(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量：&quot;</span>, x)<br><br><span class="hljs-comment"># 改变形状为2x8</span><br>x_view = x.view(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;改变形状后的张量：&quot;</span>, x_view)<br><br><span class="hljs-comment"># 改变形状为2x2x4</span><br>x_view = x.view(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;改变形状后的张量：&quot;</span>, x_view)<br></code></pre></td></tr></table></figure><p><strong>tips:</strong></p><p><code>tensor.view()</code>和<code>reshape()</code>在功能上非常相似，都可以用于改变张量的形状，但它们在实现方式和一些细节上有所不同。</p><p><code>tensor.view()</code>和<code>reshape()</code>在功能上非常相似，都可以用于改变张量的形状，但它们在实现方式和一些细节上有所不同。</p><ol><li><strong>共享内存 vs 复制内存</strong>：<ul><li><code>tensor.view()</code>: 返回的新张量与原始张量共享相同的数据存储空间，因此在内存上没有额外的开销。但是需要确保新形状的元素数量与原张量相同，否则会报错。</li><li><code>reshape()</code>: 返回一个具有指定形状的新张量，如果新形状与原张量的元素数量相同，那么不会进行数据复制，否则会复制数据到一个新的内存空间中。</li></ul></li><li><strong>灵活性</strong>：<ul><li><code>tensor.view()</code>: 由于共享内存，对原始张量的修改可能会影响到新张量，反之亦然。</li><li><code>reshape()</code>: 返回一个新的张量，与原始张量完全独立，因此对新张量的修改不会影响原始张量，反之亦然。</li></ul></li><li><strong>适用范围</strong>：<ul><li><code>tensor.view()</code>: 通常用于在不改变数据的情况下改变张量的形状，例如在神经网络中进行形状变换。</li><li><code>reshape()</code>: 除了可以改变形状外，还可以用于在不同的内存布局之间转换张量，例如将行优先的张量转换为列优先的张量。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个4x4的张量</span><br>x = torch.arange(<span class="hljs-number">16</span>)<br><br><span class="hljs-comment"># 使用view改变形状</span><br>x_view = x.view(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)<br><br><span class="hljs-comment"># 使用reshape改变形状</span><br>x_reshape = x.reshape(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)<br><br><span class="hljs-comment"># 修改原始张量的一个元素</span><br>x[<span class="hljs-number">0</span>] = <span class="hljs-number">100</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用view改变形状后的张量：&quot;</span>, x_view)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;使用reshape改变形状后的张量：&quot;</span>, x_reshape)<br></code></pre></td></tr></table></figure><p>在上面的示例中，因为<code>view()</code>返回的张量与原始张量共享内存，所以对原始张量的修改会影响到<code>x_view</code>，而<code>reshape()</code>返回的是一个新的张量，因此<code>x_reshape</code>不受影响。</p><p>在PyTorch中，<code>.view(1, -1)</code>用于将张量重塑为具有1行的二维张量，并且该张量的列数由参数<code>-1</code>确定。这里的<code>-1</code>表示在给定的维度上由系统<strong>自动推断其大小</strong>，以确保原始张量中的元素数量与重塑后的张量中的元素数量保持一致。</p><p>例如，如果有一个形状为<code>(4, 4)</code>的张量，使用<code>.view(1, -1)</code>将会把它重塑为一个形状为<code>(1, 16)</code>的张量，其中有1行，列数由系统自动计算，即16列。这样做的效果是将原始张量中的所有元素都放入新的一行中。</p><p>这种操作通常在深度学习中用于将具有多个轴的张量（如多通道图像）转换为二维张量以便进行某些操作，比如全连接层的输入。</p><h2 id="9-reshape"><a href="#9-reshape" class="headerlink" title="9.reshape"></a>9.reshape</h2><p>在 PyTorch 中，<code>tensor.reshape()</code> 方法用于重新塑形张量，使其具有新的形状，而不改变其数据。具体语法为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor.reshape(*shape)<br></code></pre></td></tr></table></figure><p>其中，<code>*shape</code> 是新的张量形状。该方法返回一个具有指定形状的新张量，但不改变原始张量的数据。</p><p>以下是一个简单的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个大小为 (2, 3, 4) 的张量</span><br>tensor = torch.arange(<span class="hljs-number">24</span>).reshape(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量：&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量形状：&quot;</span>, tensor.shape)<br><br><span class="hljs-comment"># 重新塑形为 (4, 6)</span><br>reshaped_tensor = tensor.reshape(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;重新塑形后的张量：&quot;</span>)<br><span class="hljs-built_in">print</span>(reshaped_tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;重新塑形后的张量形状：&quot;</span>, reshaped_tensor.shape)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">原始张量：<br>tensor([[[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>         [ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>],<br>         [ <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br><br>        [[<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>],<br>         [<span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>],<br>         [<span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]]])<br>原始张量形状： torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>重新塑形后的张量：<br>tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],<br>        [ <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>],<br>        [<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>],<br>        [<span class="hljs-number">18</span>, <span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>]])<br>重新塑形后的张量形状： torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure><p>可以看到，原始张量是一个大小为 (2, 3, 4) 的三维张量，通过 <code>reshape</code> 方法重新塑形为大小为 (4, 6) 的二维张量。</p><h2 id="10-transpose"><a href="#10-transpose" class="headerlink" title="10.transpose"></a>10.transpose</h2><p><code>tensor.transpose(0, 1)</code> 是 PyTorch 中的一个函数调用，用于对张量进行转置操作。在这个特定的调用中，<code>0</code> 和 <code>1</code> 是维度索引，表示对张量的第一个和第二个维度进行转置操作。</p><p>假设有一个二维张量（2维数组）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>tensor = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                       [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br></code></pre></td></tr></table></figure><p>执行 <code>tensor.transpose(0, 1)</code> 操作将交换张量的第一个维度和第二个维度，因此结果将是原始张量的转置，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">transposed_tensor = tensor.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(transposed_tensor)<br><br>输出：<br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>],<br>        [<span class="hljs-number">3</span>, <span class="hljs-number">6</span>]])<br></code></pre></td></tr></table></figure><h2 id="11-masked-fill"><a href="#11-masked-fill" class="headerlink" title="11.masked_fill"></a>11.masked_fill</h2><p><code>masked_fill</code> 是 PyTorch 中张量的一个方法，用于根据掩码（mask）替换张量中的元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建一个原始张量</span><br>tensor = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>                       [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br><br><span class="hljs-comment"># 创建一个掩码张量</span><br>mask = torch.tensor([[<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>],<br>                     [<span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]])<br><br><span class="hljs-comment"># 将原始张量中掩码为 True 的位置替换为 0</span><br>result = tensor.masked_fill(mask, <span class="hljs-number">0</span>)<br><br><span class="hljs-built_in">print</span>(result)<br><br>输出：<br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>],<br>        [<span class="hljs-number">4</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>]])<br></code></pre></td></tr></table></figure><h2 id="12-expand-as"><a href="#12-expand-as" class="headerlink" title="12.expand_as"></a>12.expand_as</h2><p><code>expand_as</code> 是 PyTorch 中的一个方法，用于将一个张量扩展成与另一个张量具有相同大小的形状。具体来说，<code>expand_as</code> 方法会返回一个新的张量，该张量与指定的张量具有相同的形状，但是复制了当前张量的内容，以填充新张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建两个张量</span><br>tensor1 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br>                        [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>tensor2 = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>]])<br><br><span class="hljs-comment"># 使用 expand_as 方法将 tensor2 扩展成与 tensor1 相同的形状</span><br>expanded_tensor2 = tensor2.expand_as(tensor1)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量 tensor2:&quot;</span>)<br><span class="hljs-built_in">print</span>(tensor2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;扩展后的张量 expanded_tensor2:&quot;</span>)<br><span class="hljs-built_in">print</span>(expanded_tensor2)<br><br><span class="hljs-comment"># 输出</span><br>原始张量 tensor2:<br>tensor([[<span class="hljs-number">0.1000</span>, <span class="hljs-number">0.2000</span>]])<br><br>扩展后的张量 expanded_tensor2:<br>tensor([[<span class="hljs-number">0.1000</span>, <span class="hljs-number">0.2000</span>],<br>        [<span class="hljs-number">0.1000</span>, <span class="hljs-number">0.2000</span>]])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python不同文件格式!🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E4%B8%8D%E5%90%8C%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E4%B8%8D%E5%90%8C%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="python不同文件格式"><a href="#python不同文件格式" class="headerlink" title="python不同文件格式"></a>python不同文件格式</h1><h2 id="1-YAML"><a href="#1-YAML" class="headerlink" title="1.YAML"></a>1.YAML</h2><p>YAML（YAML Ain’t Markup Language或YAML是一种人类可读的数据序列化格式。它经常用于配置文件和数据交换格式，因为它与JSON类似，但具有更容易阅读的格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br><br><span class="hljs-comment"># 读取YAML文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;example.yaml&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    yaml_data = yaml.safe_load(file)<br><br><span class="hljs-comment"># yaml_data现在是包含YAML数据的Python对象（通常是字典或列表）</span><br><span class="hljs-built_in">print</span>(yaml_data)<br></code></pre></td></tr></table></figure><p>使用PyYAML生成YAML数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br><br><span class="hljs-comment"># 定义一个包含数据的Python对象</span><br>data = &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;John&#x27;</span>, <span class="hljs-string">&#x27;age&#x27;</span>: <span class="hljs-number">30</span>, <span class="hljs-string">&#x27;city&#x27;</span>: <span class="hljs-string">&#x27;New York&#x27;</span>&#125;<br><br><span class="hljs-comment"># 使用yaml.dump将Python对象转换为YAML字符串</span><br>yaml_string = yaml.dump(data)<br><br><span class="hljs-comment"># 打印生成的YAML字符串</span><br><span class="hljs-built_in">print</span>(yaml_string)<br></code></pre></td></tr></table></figure><p><strong>注意：</strong>PyYAML中的<code>yaml.safe_load</code>用于安全地加载YAML数据，以避免潜在的安全风险。在加载不受信任的YAML数据时，应使用<code>safe_load</code>而不是<code>load</code>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># example.yaml</span><br><span class="hljs-attr">name:</span> <span class="hljs-string">John</span><br><span class="hljs-attr">age:</span> <span class="hljs-number">30</span><br><span class="hljs-attr">city:</span> <span class="hljs-string">New</span> <span class="hljs-string">York</span><br></code></pre></td></tr></table></figure><p>为了增加安全性，自 PyYAML 版本 5.1.0 开始，它引入了默认的安全限制，不再允许加载任意类的对象。因此，在使用 <code>yaml.load</code> 时，为了避免潜在的安全风险，建议传递 <code>Loader=yaml.FullLoader</code> 参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br><br><span class="hljs-comment"># 使用 FullLoader 加载 YAML 文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;example.yaml&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    yaml_data = yaml.load(file, Loader=yaml.FullLoader)<br><br><span class="hljs-comment"># yaml_data 现在是包含 YAML 数据的 Python 对象（通常是字典或列表）</span><br><span class="hljs-built_in">print</span>(yaml_data)<br></code></pre></td></tr></table></figure><p>这样的做法防止了潜在的代码注入攻击，因为 <code>yaml.FullLoader</code> 不会加载任意类的对象，只会加载基本的 Python 数据类型。在加载不受信任的 YAML 数据时，使用 <code>yaml.FullLoader</code> 是一个很好的做法。</p><p>在较早的版本中，<code>yaml.load</code> 是不安全的，因为它可以加载任意 Python 对象，包括不安全的对象。因此，为了防止安全漏洞，建议在使用 PyYAML 时明确指定 <code>Loader</code> 参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br><br><span class="hljs-comment"># 使用 FullLoader 加载 YAML 文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;example.yaml&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    yaml_data = yaml.load(file, Loader=yaml.FullLoader)<br><br><span class="hljs-comment"># yaml_data 现在是包含 YAML 数据的 Python 对象（通常是字典或列表）</span><br><span class="hljs-built_in">print</span>(yaml_data)<br></code></pre></td></tr></table></figure><p>这样的做法防止了潜在的代码注入攻击，因为 <code>yaml.FullLoader</code> 不会加载任意类的对象，只会加载基本的 Python 数据类型。在加载不受信任的 YAML 数据时，使用 <code>yaml.FullLoader</code> 是一个很好的做法。</p><p>在较早的版本中，<code>yaml.load</code> 是不安全的，因为它可以加载任意 Python 对象，包括不安全的对象。因此，为了防止安全漏洞，建议在使用 PyYAML 时明确指定 <code>Loader</code> 参数。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python特殊语法！🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E7%89%B9%E6%AE%8A%E8%AF%AD%E6%B3%95/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E7%89%B9%E6%AE%8A%E8%AF%AD%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="python特殊语法"><a href="#python特殊语法" class="headerlink" title="python特殊语法"></a>python特殊语法</h1><h2 id="1-kwargs"><a href="#1-kwargs" class="headerlink" title="1.**kwargs"></a>1.**kwargs</h2><p>在Python中，<code>**kwargs</code>是用于传递关键字参数的特殊语法。它允许在函数调用时传递任意数量的关键字参数，并以字典的形式在函数内部接收这些参数。</p><p>在你提供的代码中，<code>**factory_kwargs</code>是将一个字典解包，并将其作为关键字参数传递给<code>torch.empty</code>函数。具体来说，<code>factory_kwargs</code>是一个字典，包含了用于初始化张量的一些额外的参数。</p><p>举个例子，假设 <code>factory_kwargs</code> 是这样一个字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">factory_kwargs = &#123;<span class="hljs-string">&#x27;dtype&#x27;</span>: torch.float32, <span class="hljs-string">&#x27;device&#x27;</span>: <span class="hljs-string">&#x27;cuda&#x27;</span>&#125;<br></code></pre></td></tr></table></figure><p>在调用时，<code>**factory_kwargs</code>会将这个字典解包，将其中的键值对作为关键字参数传递给<code>torch.empty</code>函数。所以实际上，<code>torch.empty</code>函数的调用类似于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.empty((out_features, in_features), dtype=torch.float32, device=<span class="hljs-string">&#x27;cuda&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这样可以方便地通过<code>factory_kwargs</code>参数传递额外的配置信息给<code>torch.empty</code>函数。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python关键字！🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%85%B3%E9%94%AE%E5%AD%97/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%85%B3%E9%94%AE%E5%AD%97/</url>
    
    <content type="html"><![CDATA[<h1 id="python关键字"><a href="#python关键字" class="headerlink" title="python关键字"></a>python关键字</h1><h2 id="1-assert"><a href="#1-assert" class="headerlink" title="1.assert"></a>1.assert</h2><p>assert 关键字在调试代码时使用。</p><p>assert 关键字使您可以测试代码中的条件是否返回 True，否则，程序将引发 AssertionError。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x = <span class="hljs-string">&quot;hello&quot;</span><br><br><span class="hljs-comment">#if condition returns False, AssertionError is raised:</span><br><span class="hljs-keyword">assert</span> x == <span class="hljs-string">&quot;goodbye&quot;</span>, <span class="hljs-string">&quot;x should be &#x27;hello&#x27;&quot;</span><br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">AssertionError: x should be <span class="hljs-string">&#x27;hello&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="2-global"><a href="#2-global" class="headerlink" title="2.global"></a>2.global</h2><p>global 关键字用于从非全局范围创建全局变量，例如在函数内部。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建函数：</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">myfunction</span>():<br>  <span class="hljs-keyword">global</span> x<br>  x = <span class="hljs-string">&quot;hello&quot;</span><br><br><span class="hljs-comment"># 执行函数：</span><br>myfunction()<br><br><span class="hljs-comment"># x 现在有关是全局变量，可以进行全局访问。</span><br><span class="hljs-built_in">print</span>(x)<br></code></pre></td></tr></table></figure><h2 id="3-lambda"><a href="#3-lambda" class="headerlink" title="3.lambda"></a>3.lambda</h2><p><strong>lambda 函数是一种小的匿名函数。</strong></p><p><strong>lambda 函数可接受任意数量的参数，但只能有一个表达式。</strong></p><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">myfunc</span>(<span class="hljs-params">n</span>):<br>  <span class="hljs-keyword">return</span> <span class="hljs-keyword">lambda</span> a : a * n<br><br>mydoubler = myfunc(<span class="hljs-number">2</span>)<br><br><span class="hljs-built_in">print</span>(mydoubler(<span class="hljs-number">11</span>))<br></code></pre></td></tr></table></figure><h2 id="4-yield"><a href="#4-yield" class="headerlink" title="4.yield"></a>4.yield</h2><p><code>yield</code> 是 Python 中的一个关键字，它用于定义生成器函数或者生成器表达式。生成器（Generator）是一种特殊的迭代器，它可以按需生成值，并且只在需要时才计算值，而不是一次性计算所有值并将它们存储在内存中。</p><p>生成器函数是包含 <code>yield</code> 关键字的函数。当调用生成器函数时，它不会像普通函数一样立即执行并返回结果，而是返回一个生成器对象，通过迭代这个生成器对象，可以逐个获取生成器函数中 <code>yield</code> 语句产生的值。</p><p>下面是一个简单的示例，展示了如何定义一个生成器函数和使用 <code>yield</code> 关键字：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">count_up_to</span>(<span class="hljs-params">n</span>):<br>    count = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> count &lt;= n:<br>        <span class="hljs-keyword">yield</span> count<br>        count += <span class="hljs-number">1</span><br><br><span class="hljs-comment"># 使用生成器函数创建一个生成器对象</span><br>counter = count_up_to(<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 迭代生成器对象并逐个获取值</span><br><span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> counter:<br>    <span class="hljs-built_in">print</span>(num)<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>count_up_to</code> 是一个生成器函数，它接受一个参数 <code>n</code>，然后使用 <code>while</code> 循环以及 <code>yield</code> 语句生成从 1 到 <code>n</code> 的整数序列。当调用 <code>count_up_to(5)</code> 时，它返回一个生成器对象 <code>counter</code>。然后，通过迭代 <code>counter</code>，可以逐个获取生成器函数中 <code>yield</code> 语句产生的值，并打印出来。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python处理命令行参数！🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="python处理命令行参数"><a href="#python处理命令行参数" class="headerlink" title="python处理命令行参数"></a>python处理命令行参数</h1><p><code>argparse</code> 是 Python 标准库中用于处理命令行参数的模块。它提供了一种简单而灵活的方式来解析命令行参数，并生成帮助信息。以下是 <code>argparse</code> 模块的基本用法示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-comment"># 创建 ArgumentParser 对象</span><br>    parser = argparse.ArgumentParser(description=<span class="hljs-string">&#x27;描述你的脚本的用途&#x27;</span>)<br><br>    <span class="hljs-comment"># 添加位置参数（Positional Arguments）</span><br>    parser.add_argument(<span class="hljs-string">&#x27;input_file&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;输入文件的路径&#x27;</span>)<br><br>    <span class="hljs-comment"># 添加可选参数（Optional Arguments）</span><br>    parser.add_argument(<span class="hljs-string">&#x27;-o&#x27;</span>, <span class="hljs-string">&#x27;--output&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;输出文件的路径&#x27;</span>)<br><br>    <span class="hljs-comment"># 添加一个布尔型标志参数</span><br>    parser.add_argument(<span class="hljs-string">&#x27;-v&#x27;</span>, <span class="hljs-string">&#x27;--verbose&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;显示详细信息&#x27;</span>)<br><br>    <span class="hljs-comment"># 解析命令行参数</span><br>    args = parser.parse_args()<br><br>    <span class="hljs-comment"># 使用解析后的参数</span><br>    input_file = args.input_file<br>    output_file = args.output<br>    verbose = args.verbose<br><br>    <span class="hljs-comment"># 在这里执行你的程序逻辑</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;输入文件: <span class="hljs-subst">&#123;input_file&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;输出文件: <span class="hljs-subst">&#123;output_file&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;详细信息: <span class="hljs-subst">&#123;verbose&#125;</span>&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>argparse.ArgumentParser</code> 用于创建一个解析器对象。然后，使用 <code>add_argument</code> 方法添加位置参数和可选参数。最后，通过调用 <code>parse_args</code> 方法解析命令行参数，并返回一个包含解析结果的对象。</p><p>运行脚本时，可以使用以下命令行参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">python script.py <span class="hljs-built_in">input</span>.txt -o output.txt -v<br></code></pre></td></tr></table></figure><p>解析后，<code>args.input_file</code> 将包含输入文件的路径，<code>args.output</code> 将包含输出文件的路径，而 <code>args.verbose</code> 将为 <code>True</code>，因为 <code>-v</code> 标志已经被指定。</p><p>使用 <code>python script.py -h</code> 或 <code>python script.py --help</code> 可以显示帮助信息，其中包含关于位置参数和可选参数的说明。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python包管理！🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="python包管理"><a href="#python包管理" class="headerlink" title="python包管理"></a>python包管理</h1><p><img src="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/1.png"></p><p>上图所示是文件的结构。每个包下都有一个__init__。</p><p><code>__init__.py</code>文件可以包含一些常用的初始化代码，例如：</p><ol><li><strong>定义模块级别的变量、常量或函数</strong>：在<code>__init__.py</code>中定义的内容可以在包的其他模块中直接使用，而不需要使用相对导入或绝对导入。</li><li><strong>导入子模块</strong>：通过在<code>__init__.py</code>中导入子模块，可以使得使用者只需要导入包，而不需要逐个导入包中的每个模块。</li><li><strong>执行一些初始化操作</strong>：例如加载配置、注册组件、设置环境等。</li><li><strong>指定导入行为</strong>：通过在<code>__init__.py</code>中定义<code>__all__</code>变量，可以指定使用<code>from &lt;package&gt; import *</code>语句导入时的行为。</li><li><strong>自定义包的行为</strong>：可以在<code>__init__.py</code>中重载一些特殊的魔术方法，从而自定义包的行为，例如<code>__getattr__</code>、<code>__setattr__</code>等。</li><li><strong>包版本号管理</strong>：可以在<code>__init__.py</code>中定义包的版本号，方便其他模块获取当前包的版本信息。</li></ol><p><img src="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/2.png"></p><p>上图所示是state包下的init文件，其中<code>.</code> 表示当前目录或模块。</p><p>我们将对state包下不同文件的类引用写入transit包下的init中。</p><p><img src="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/3.png"></p><p>上图是core包下的init文件，我们在引入state包下的文件中的类时，就可以直接用<code>.state</code>引用，这样做的目的是简化了引用的复杂度。</p><p><img src="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/4.png"></p><p>上图是mimic包下的init文件，我们在其中直接对core进行引用。</p><p><img src="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%8C%85%E7%AE%A1%E7%90%86/5.png"></p><p>如上图所示，我们可在<strong>mimic包外的包</strong>中用干净的方式实现对不同文件下类的引用。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python内置函数!🍩</title>
    <link href="/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"/>
    <url>/2024/02/01/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="python内置函数"><a href="#python内置函数" class="headerlink" title="python内置函数"></a>python内置函数</h1><h2 id="1-all"><a href="#1-all" class="headerlink" title="1.all"></a>1.all</h2><p>all() 函数用于判断给定的可迭代参数 iterable 中的所有元素是否都为 TRUE，如果是返回 True，否则返回 False。</p><p>元素除了是 0、空、None、False 外都算 True。</p><p>它的语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">all</span>(iterable)<br></code></pre></td></tr></table></figure><p>其中，<code>iterable</code> 是一个可迭代对象，例如列表、元组、集合等。</p><p><code>all()</code> 函数返回一个布尔值：</p><ul><li>如果可迭代对象中的所有元素都为真，返回 <code>True</code>。</li><li>如果可迭代对象中有至少一个元素为假，返回 <code>False</code>。</li></ul><h2 id="2-any"><a href="#2-any" class="headerlink" title="2.any"></a>2.any</h2><p>any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False，则返回 False，如果有一个为 True，则返回 True。</p><p>元素除了是 0、空、FALSE 外都算 TRUE。语法同<code>all</code>。</p><h2 id="3-getattr"><a href="#3-getattr" class="headerlink" title="3.getattr"></a>3.getattr</h2><p><code>getattr</code> 是一个内建函数，用于获取对象的属性值。其基本语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">getattr</span>(<span class="hljs-built_in">object</span>, name[, default])<br></code></pre></td></tr></table></figure><ul><li><code>object</code>: 要获取属性的对象。</li><li><code>name</code>: 属性的名称。</li><li><code>default</code> (可选): 如果属性不存在，返回的默认值。</li></ul><p>下面是一个简单的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, age</span>):<br>        self.name = name<br>        self.age = age<br><br><span class="hljs-comment"># 创建一个 Person 对象</span><br>person = Person(<span class="hljs-string">&quot;Alice&quot;</span>, <span class="hljs-number">25</span>)<br><br><span class="hljs-comment"># 使用 getattr 获取属性值</span><br>name_value = <span class="hljs-built_in">getattr</span>(person, <span class="hljs-string">&#x27;name&#x27;</span>)<br>age_value = <span class="hljs-built_in">getattr</span>(person, <span class="hljs-string">&#x27;age&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Name: <span class="hljs-subst">&#123;name_value&#125;</span>, Age: <span class="hljs-subst">&#123;age_value&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>getattr</code> 被用来获取 <code>person</code> 对象的 <code>name</code> 和 <code>age</code> 属性的值。当然，这只是一个简单的演示。在实际应用中，<code>getattr</code> 可能会更有用，例如，当你需要根据动态的属性名称来访问对象的属性时。</p><p>如果属性不存在，你可以提供一个默认值作为 <code>default</code> 参数。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">gender_value = <span class="hljs-built_in">getattr</span>(person, <span class="hljs-string">&#x27;gender&#x27;</span>, <span class="hljs-string">&#x27;Unknown&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Gender: <span class="hljs-subst">&#123;gender_value&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure><p>在这里，如果 <code>gender</code> 属性不存在，就会返回默认值 <code>&#39;Unknown&#39;</code>。</p><p>总的来说，<code>getattr</code> 是一个灵活的工具，特别适用于需要动态访问对象属性的情况。</p><p><code>getattr</code> 函数可用于获取对象的属性，并且可以结合括号 <code>()</code> 调用属性值，前提是该属性是可调用的（即是一个方法）。这样的使用情况通常在需要动态调用对象的方法时会比较有用。</p><p>下面是一个示例，假设 <code>state</code> 是一个对象，而 <code>st_k</code> 是该对象的一个方法的名称，你可以使用 <code>getattr(state, st_k)</code> 获取该方法，并通过 <code>()</code> 调用它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">State</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">method1</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;This is method 1&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">method2</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;This is method 2&quot;</span><br><br><span class="hljs-comment"># 创建一个 State 对象</span><br>state = State()<br><br><span class="hljs-comment"># st_k 是一个方法的名称，例如 &#x27;method1&#x27; 或 &#x27;method2&#x27;</span><br>st_k = <span class="hljs-string">&#x27;method1&#x27;</span><br><br><span class="hljs-comment"># 使用 getattr 获取对象的方法，并调用它</span><br>result = <span class="hljs-built_in">getattr</span>(state, st_k)()<br><br><span class="hljs-comment"># 打印方法的返回值</span><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>st_k</code> 是一个方法的名称，<code>getattr(state, st_k)</code> 获取对象 <code>state</code> 中名为 <code>st_k</code> 的方法，然后通过 <code>()</code> 调用它。这种做法可以使代码更加灵活，允许在运行时选择要调用的方法。</p><h2 id="4-enumerate"><a href="#4-enumerate" class="headerlink" title="4.enumerate"></a>4.enumerate</h2><p>在Python中，<code>enumerate()</code> 函数用于将可迭代对象的每个元素和其对应的索引组合成一个元组，然后返回一个包含这些元组的迭代器。这个函数常用于循环遍历列表时同时获取元素和索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 基本用法</span><br>my_list = [<span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>]<br><span class="hljs-keyword">for</span> index, value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(my_list):<br>    <span class="hljs-built_in">print</span>(index, value)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">0</span> apple<br><span class="hljs-number">1</span> banana<br><span class="hljs-number">2</span> orange<br></code></pre></td></tr></table></figure><p>除了基本用法外，<code>enumerate()</code> 函数还可以接受一个可选参数 <code>start</code>，用于指定起始的索引值。默认情况下，起始索引值为 0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 指定起始索引值</span><br>my_list = [<span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>]<br><span class="hljs-keyword">for</span> index, value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(my_list, start=<span class="hljs-number">1</span>):<br>    <span class="hljs-built_in">print</span>(index, value)<br></code></pre></td></tr></table></figure><h2 id="5-map"><a href="#5-map" class="headerlink" title="5.map"></a>5.map</h2><p>在Python中，<code>map()</code> 函数是一个内置函数，它接受一个函数和一个可迭代对象（比如列表）作为参数，并将该函数应用于可迭代对象中的每个元素，返回一个新的迭代器，该迭代器包含将该函数应用于每个元素后的结果。</p><p><code>map()</code> 函数的基本语法如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">map</span>(function, iterable, ...)<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>function</code>：表示要应用于每个元素的函数。</li><li><code>iterable</code>：表示一个或多个可迭代对象，如列表、元组等。</li></ul><p>下面是一些使用 <code>map()</code> 函数的示例：</p><blockquote><p>将列表元素平方</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">numbers = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>squared_numbers = <span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x**<span class="hljs-number">2</span>, numbers)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(squared_numbers))  <span class="hljs-comment"># 输出: [1, 4, 9, 16, 25]</span><br></code></pre></td></tr></table></figure><blockquote><p>将字符串列表中的字符转换为大写</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">strings = [<span class="hljs-string">&#x27;hello&#x27;</span>, <span class="hljs-string">&#x27;world&#x27;</span>, <span class="hljs-string">&#x27;python&#x27;</span>]<br>upper_strings = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">str</span>.upper, strings)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(upper_strings))  <span class="hljs-comment"># 输出: [&#x27;HELLO&#x27;, &#x27;WORLD&#x27;, &#x27;PYTHON&#x27;]</span><br></code></pre></td></tr></table></figure><blockquote><p>将两个列表对应元素相加</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">list1 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>list2 = [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]<br>sum_result = <span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x, y: x + y, list1, list2)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(sum_result))  <span class="hljs-comment"># 输出: [5, 7, 9]</span><br></code></pre></td></tr></table></figure><h2 id="6-sorted"><a href="#6-sorted" class="headerlink" title="6.sorted"></a>6.sorted</h2><p>在Python中，<code>sorted()</code>函数用于对可迭代对象进行排序操作，并返回一个新的已排序列表，而不改变原始对象。它的基本语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sorted</span>(iterable, key=<span class="hljs-literal">None</span>, reverse=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><ul><li><code>iterable</code>：表示要排序的可迭代对象，如列表、元组、字典的键或值等。</li><li><code>key</code>：可选参数，用于指定一个函数，该函数将应用于可迭代对象的每个元素，用于生成排序中的比较键。默认为 <code>None</code>，表示直接比较元素本身。</li><li><code>reverse</code>：可选参数，用于指定是否反向排序，默认为 <code>False</code>，表示升序排序；设置为 <code>True</code> 则表示降序排序。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">words = [<span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>, <span class="hljs-string">&#x27;grape&#x27;</span>]<br>sorted_words = <span class="hljs-built_in">sorted</span>(words, key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br><span class="hljs-built_in">print</span>(sorted_words)  <span class="hljs-comment"># Output: [&#x27;apple&#x27;, &#x27;grape&#x27;, &#x27;banana&#x27;, &#x27;orange&#x27;]</span><br></code></pre></td></tr></table></figure><h2 id="7-zip"><a href="#7-zip" class="headerlink" title="7.zip"></a>7.zip</h2><p><code>zip()</code> 是 Python 的一个内置函数，用于将多个可迭代对象中对应位置的元素打包成元组，并返回一个由这些元组组成的迭代器。如果传入的可迭代对象长度不一致，则 <code>zip()</code> 函数会以最短的可迭代对象为准，其他对象中超出部分的元素会被忽略。</p><p>以下是 <code>zip()</code> 函数的基本语法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">zip</span>(iterable1, iterable2, ...)<br></code></pre></td></tr></table></figure><ul><li><code>iterable1</code>, <code>iterable2</code>, …: 一个或多个可迭代对象，可以是列表、元组、集合、字符串等。</li></ul><p><code>zip()</code> 函数将返回一个迭代器，其中的每个元素都是输入可迭代对象中对应位置的元素组成的元组。</p><p>下面是一个简单的例子，演示了如何使用 <code>zip()</code> 函数将两个列表中的元素打包成元组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">list1 = [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>]<br>list2 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br><br>zipped = <span class="hljs-built_in">zip</span>(list1, list2)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(zipped))  <span class="hljs-comment"># 输出：[(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 3)]</span><br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p><code>zip(*iterables)</code> 是 <code>zip()</code> 函数的特殊用法，它可以用于将已经打包成元组的迭代器解包。</p><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">list1 = [<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>]<br>list2 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br><br>zipped = <span class="hljs-built_in">zip</span>(list1, list2)<br>unzipped = <span class="hljs-built_in">zip</span>(*zipped)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(unzipped))<br></code></pre></td></tr></table></figure><p>返回：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[(<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)]<br></code></pre></td></tr></table></figure><h2 id="8-print"><a href="#8-print" class="headerlink" title="8.print"></a>8.print</h2><p>1.使用格式化字符串：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">name = <span class="hljs-string">&quot;Alice&quot;</span><br>age = <span class="hljs-number">30</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;My name is <span class="hljs-subst">&#123;name&#125;</span> and I am <span class="hljs-subst">&#123;age&#125;</span> years old.&quot;</span>)<br></code></pre></td></tr></table></figure><p>2.使用 <code>end</code> 参数控制输出结束符，默认情况下是换行符 <code>\n</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello,&quot;</span>, end=<span class="hljs-string">&quot; &quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;World!&quot;</span>)<br></code></pre></td></tr></table></figure><p>3.使用 <code>sep</code> 参数控制多个参数之间的分隔符，默认情况下是空格：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;One&quot;</span>, <span class="hljs-string">&quot;Two&quot;</span>, <span class="hljs-string">&quot;Three&quot;</span>, sep=<span class="hljs-string">&quot;, &quot;</span>)<br></code></pre></td></tr></table></figure><p>4.控制浮点数的小数位数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">name = <span class="hljs-string">&quot;Alice&quot;</span><br>age = <span class="hljs-number">30.12345</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;My name is <span class="hljs-subst">&#123;name&#125;</span> and I am <span class="hljs-subst">&#123;age:<span class="hljs-number">.2</span>f&#125;</span> years old.&quot;</span>)<br><br>输出：<br>My name <span class="hljs-keyword">is</span> Alice <span class="hljs-keyword">and</span> I am <span class="hljs-number">30.12</span> years old.<br></code></pre></td></tr></table></figure><h2 id="9-set"><a href="#9-set" class="headerlink" title="9.set"></a>9.set</h2><p>Python中的<code>set</code>是一种<strong>无序且不重复的集合</strong>数据类型，它是由不同元素组成的集合，每个元素在集合中只能出现一次。<code>set</code>可以用于执行集合操作，如交集、并集、差集等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">set</span>(<span class="hljs-string">&quot; &quot;</span>.join(sentences).split()) <span class="hljs-comment"># 创建无重复的数据类型</span><br></code></pre></td></tr></table></figure><h2 id="10-round"><a href="#10-round" class="headerlink" title="10.round"></a>10.round</h2><p><code>round()</code> 是 Python 中的一个内置函数，用于对浮点数进行四舍五入操作。它的语法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">round</span>(number[, ndigits])<br></code></pre></td></tr></table></figure><p><code>round()</code> 是 Python 中的一个内置函数，用于对浮点数进行四舍五入操作。它的语法如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">pythonCopy <span class="hljs-selector-tag">code</span><br><span class="hljs-function"><span class="hljs-title">round</span><span class="hljs-params">(number[, ndigits])</span></span><br></code></pre></td></tr></table></figure><p>其中：</p><ul><li><code>number</code> 是要进行四舍五入的浮点数；</li><li><code>ndigits</code> 是可选参数，表示要保留的小数位数。如果省略 <code>ndigits</code>，则默认为 0，即对 <code>number</code> 进行到最近的整数的四舍五入。</li></ul><p><code>round()</code> 函数返回一个浮点数，表示四舍五入后的结果。</p><p>以下是 <code>round()</code> 函数的一些示例用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 四舍五入到整数</span><br>result1 = <span class="hljs-built_in">round</span>(<span class="hljs-number">3.6</span>)<br><span class="hljs-built_in">print</span>(result1)  <span class="hljs-comment"># 输出: 4</span><br><br><span class="hljs-comment"># 四舍五入到指定小数位数</span><br>result2 = <span class="hljs-built_in">round</span>(<span class="hljs-number">3.1415926</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(result2)  <span class="hljs-comment"># 输出: 3.14</span><br></code></pre></td></tr></table></figure><p>在第一个示例中，<code>round(3.6)</code> 将 3.6 四舍五入到最近的整数，结果是 4。在第二个示例中，<code>round(3.1415926, 2)</code> 将 3.1415926 四舍五入到两位小数，结果是 3.14。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyCharm使用技巧!🍩</title>
    <link href="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    <url>/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
    
    <content type="html"><![CDATA[<h1 id="PyCharm使用技巧"><a href="#PyCharm使用技巧" class="headerlink" title="PyCharm使用技巧"></a>PyCharm使用技巧</h1><h2 id="1-搜索"><a href="#1-搜索" class="headerlink" title="1.搜索"></a>1.搜索</h2><p>文件搜索：<code>Ctrl+F</code></p><p>全局搜索：<code>Ctrl+Shift+F</code></p><p><img src="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/1.png"></p><h2 id="2-替换"><a href="#2-替换" class="headerlink" title="2.替换"></a>2.替换</h2><p>文件替换：<code>Ctrl+R</code></p><p>全局替换：<code>Ctrl+Shift+R</code></p><p>正则替换如下图所示：</p><p><img src="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/2.png"></p><p><strong>tips：</strong></p><p>1.在替换模式中点击右上角的<code>.*</code>符号，切换到正则替换模式。</p><p>2.用<code>\</code>加字符来匹配文件中的字符。</p><p>3.用括号<code>()</code>将需要保留的内容括起来。</p><p>4.用<code>$</code>加数字表示被括号括起来的内容，可以在替换中复用。</p><p>5.<code>？</code>表示不使用贪婪搜索，而是尽可能少的匹配字符。</p><h2 id="3-Debug"><a href="#3-Debug" class="headerlink" title="3.Debug"></a>3.Debug</h2><p><img src="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/3.png"></p><p><strong>tips:</strong></p><p>从左到右依次是：</p><ul><li><strong>step over</strong>（<code>F8</code>）：在单步执行时，在函数内遇到子函数时不会进入子函数内单步执行，而是将子函数整个执行完再停止，也就是把子函数整个作为一步。在不存在子函数的情况下是和step into效果一样的。简单的说就是，<strong>程序代码越过子函数，但子函数会执行，且不进入。</strong></li><li><strong>step into</strong>（<code>F7</code>）：在单步执行时，遇到子函数就进入并且继续单步执行，有的会跳到源代码里面去执行。</li><li><strong>step into my code</strong>（<code>Alt+Shift+F7</code>）：在单步执行时，遇到子函数就进入并且继续单步执行，不会进入到源码中。</li><li><strong>step out</strong>（<code>Shift+F8</code>）：假如进入了一个函数体中，你看了两行代码，不想看了，跳出当前函数体内，返回到调用此函数的地方，即使用此功能即可。</li></ul><p><img src="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/4.png"></p><p>每一步调试的变量结果都会在代码和调试框中出现。</p><h2 id="4-追踪"><a href="#4-追踪" class="headerlink" title="4.追踪"></a>4.追踪</h2><p>PyCharm提供了查看特定变量在代码中使用情况的功能，包括查找其来源。</p><ol><li>在代码编辑器中选中想要追踪来源的变量。可以将光标放在变量上，然后按住 <code>Ctrl</code> 键并单击变量，或者右键单击变量并选择 “Find Usages”（查找用法）。</li><li>如果想要查找变量的定义处（即变量的来源），可以在查找用法结果面板中右键单击并选择 “Go to”（转到）&gt; “Declaration”（定义），或者使用快捷键 <code>Ctrl + B</code>。</li></ol><p>通过这种方式，可以在PyCharm中轻松追踪特定变量的来源并了解其在代码中的使用情况。</p><h2 id="5-包围代码块"><a href="#5-包围代码块" class="headerlink" title="5.包围代码块"></a>5.包围代码块</h2><p>快捷键:<code>Ctrl+Alt+T</code></p><p><img src="/2024/01/30/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/pycharm%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/5.png"></p><h2 id="6-多行位移"><a href="#6-多行位移" class="headerlink" title="6.多行位移"></a>6.多行位移</h2><p>同时<strong>右移</strong>快捷键：<code>Tab</code></p><p>同时<strong>左移</strong>快捷键：<code>Shift+Tab</code></p><h2 id="7-创建新项目"><a href="#7-创建新项目" class="headerlink" title="7.创建新项目"></a>7.创建新项目</h2><p><strong>python创建新项目时base conda和自定义环境的区别</strong></p><ol><li><strong>Base Conda 环境</strong>：<ul><li>Base conda 环境是 Miniconda 或 Anaconda 安装后默认创建的环境。</li><li>这个环境包含了 Conda 及其默认的 Python 解释器和一些常用的包。</li><li>在 base conda 环境中安装的软件包对所有项目都可见，因此可能存在版本冲突或依赖关系问题。</li><li>由于其包含的软件包较多，可能会占用较多的磁盘空间。</li></ul></li><li><strong>自定义环境</strong>：<ul><li>自定义环境是用户根据项目需求自行创建的环境，可以根据项目需求选择所需的 Python 版本和软件包。</li><li>可以使用 Conda 或者虚拟环境管理工具（如 venv 或 virtualenv）创建自定义环境。</li><li>在自定义环境中，您可以根据项目的需求选择特定版本的软件包，从而更好地管理依赖关系和避免冲突。</li><li>自定义环境可以减少磁盘空间占用，因为您只安装了项目所需的软件包。</li></ul></li></ol><p>总的来说，使用 base conda 环境可以方便快捷地开始新项目，但是可能会出现依赖冲突的问题。而使用自定义环境可以更好地管理项目依赖，避免冲突，并且可以根据具体需求精确控制软件包的版本。</p><p><strong>conda和 virtualenv的区别</strong></p><p><strong>依赖管理</strong>：</p><ul><li><strong>Conda</strong>：Conda 不仅可以管理 Python 软件包的依赖关系，还可以管理系统级别的依赖关系。此外，Conda 允许您<strong>创建包含不同版本 Python 的环境</strong>。</li><li><strong>virtualenv</strong>：virtualenv 只能管理 Python 软件包的依赖关系，并且<strong>每个环境只能包含一个 Python 版本</strong>。</li></ul>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基础!🍧</title>
    <link href="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/"/>
    <url>/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="Pytorch基础"><a href="#Pytorch基础" class="headerlink" title="Pytorch基础"></a>Pytorch基础</h1><h2 id="1-Tensors张量"><a href="#1-Tensors张量" class="headerlink" title="1.Tensors张量"></a>1.Tensors张量</h2><p>张量是一种专门的数据结构，与数组和矩阵非常相似。在 PyTorch 中，我们使用张量对模型的输入和输出以及模型的参数进行编码。</p><p>张量类似于 NumPy 的 ndarrays，不同之处在于张量可以在 GPU 或其他硬件加速器上运行。事实上，张量和 NumPy 数组通常可以共享相同的底层内存，从而消除了复制数据的需要。</p><h3 id="1-1-初始化张量"><a href="#1-1-初始化张量" class="headerlink" title="1.1 初始化张量"></a>1.1 初始化张量</h3><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><p>张量可以通过多种方式进行初始化。</p><blockquote><p><strong>直接来自数据</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = [[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]<br>x_data = torch.tensor(data)<br></code></pre></td></tr></table></figure><blockquote><p><strong>从 NumPy 数组</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)<br></code></pre></td></tr></table></figure><blockquote><p><strong>从另一个张量</strong></p></blockquote><p>新张量保留参数张量的属性（形状、数据类型），除非显式覆盖。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">x_ones = torch.ones_like(x_data) <span class="hljs-comment"># retains the properties of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Ones Tensor: \n <span class="hljs-subst">&#123;x_ones&#125;</span> \n&quot;</span>)<br><br>x_rand = torch.rand_like(x_data, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># overrides the datatype of x_data</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Random Tensor: \n <span class="hljs-subst">&#123;x_rand&#125;</span> \n&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Ones Tensor:<br> tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><br>Random Tensor:<br> tensor([[<span class="hljs-number">0.8823</span>, <span class="hljs-number">0.9150</span>],<br>        [<span class="hljs-number">0.3829</span>, <span class="hljs-number">0.9593</span>]])<br></code></pre></td></tr></table></figure><blockquote><p><strong>使用随机值或常量值</strong></p></blockquote><p><code>shape</code> 是张量维度的元组。在下面的函数中，它决定了输出张量的维数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">shape = (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,)<br>rand_tensor = torch.rand(shape)<br>ones_tensor = torch.ones(shape)<br>zeros_tensor = torch.zeros(shape)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Random Tensor: \n <span class="hljs-subst">&#123;rand_tensor&#125;</span> \n&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Ones Tensor: \n <span class="hljs-subst">&#123;ones_tensor&#125;</span> \n&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Zeros Tensor: \n <span class="hljs-subst">&#123;zeros_tensor&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong>在给定形状（shape）时，逗号在 Python 中通常用于表示元组。在这种情况下，<code>shape = (2, 3,)</code> 中的逗号实际上是一个元组的标志，即使在没有逗号的情况下，它也是一个合法的元组。</p><p>这种写法是为了确保在定义元组时即使只有一个元素也使用逗号，以<strong>避免与普通的括号运算符产生歧义</strong>。例如，如果写成 <code>shape = (2, 3)</code>，它将被解释为一个包含两个整数的表达式，而不是一个包含一个元组的表达式。</p><p>在 Python 中，单个元素的元组需要在元素后面添加逗号，以明确表示这是一个元组。这是为了区分元组和括号内的表达式。所以，<code>(2, 3,)</code> 和 <code>(2, 3)</code> <strong>在这里是等价</strong>的，都表示一个包含两个整数的元组。</p><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">Random Tensor:<br> tensor([[<span class="hljs-number">0.3904</span>, <span class="hljs-number">0.6009</span>, <span class="hljs-number">0.2566</span>],<br>        [<span class="hljs-number">0.7936</span>, <span class="hljs-number">0.9408</span>, <span class="hljs-number">0.1332</span>]])<br><br>Ones Tensor:<br> tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br>Zeros Tensor:<br> tensor([[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]])<br></code></pre></td></tr></table></figure><h3 id="1-2-张量的属性"><a href="#1-2-张量的属性" class="headerlink" title="1.2 张量的属性"></a>1.2 张量的属性</h3><p>张量属性描述它们的形状、数据类型和存储它们的设备。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Shape of tensor: <span class="hljs-subst">&#123;tensor.shape&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Datatype of tensor: <span class="hljs-subst">&#123;tensor.dtype&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Shape of tensor: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>Datatype of tensor: torch.float32<br>Device tensor <span class="hljs-keyword">is</span> stored on: cpu<br></code></pre></td></tr></table></figure><h3 id="1-3-张量操作"><a href="#1-3-张量操作" class="headerlink" title="1.3 张量操作"></a>1.3 张量操作</h3><p><a href="https://pytorch.org/docs/stable/torch.html">https://pytorch.org/docs/stable/torch.html</a></p><p>这里全面描述了 100 多种张量运算，包括算术、线性代数、矩阵操作（转置、索引、切片）、采样等。这些操作中的每一个都可以在 GPU 上运行（速度通常高于在 CPU 上）。</p><p>默认情况下，张量是在 CPU 上创建的。我们需要显式地将张量移动到 GPU using <code>.to</code> 方法（在检查 GPU 可用性之后）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We move our tensor to the GPU if available</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    tensor = tensor.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br></code></pre></td></tr></table></figure><blockquote><p><strong>索引和切片</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.ones(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First row: <span class="hljs-subst">&#123;tensor[<span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;First column: <span class="hljs-subst">&#123;tensor[:, <span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Last column: <span class="hljs-subst">&#123;tensor[..., -<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br>tensor[:,<span class="hljs-number">1</span>] = <span class="hljs-number">0</span><br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">First row: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>First column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>Last column: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure><p><strong>tips：</strong>省略符号的作用是<strong>省略掉其余的维度</strong>。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(tensor)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor[:,:,:,<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor[..., <span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p><code>...</code>等价于<code>:,:,:</code></p><p>连接张量 可用于 <code>torch.cat</code> 沿给定维度连接一系列张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(t1)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure><p><strong>tips：</strong>dim表示连接的维度。</p><p><strong>切片操作：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 假设 pos_embedding 是一个形状为 (5, 6) 的张量</span><br>pos_embedding = torch.arange(<span class="hljs-number">30</span>).reshape(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>)<br><br><span class="hljs-comment"># 对 pos_embedding 进行切片操作</span><br>sliced_pos_embedding = pos_embedding[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始张量：&quot;</span>)<br><span class="hljs-built_in">print</span>(pos_embedding)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;切片后的张量：&quot;</span>)<br><span class="hljs-built_in">print</span>(sliced_pos_embedding)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">原始张量：<br>tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>],<br>        [ <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>],<br>        [<span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>],<br>        [<span class="hljs-number">18</span>, <span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>],<br>        [<span class="hljs-number">24</span>, <span class="hljs-number">25</span>, <span class="hljs-number">26</span>, <span class="hljs-number">27</span>, <span class="hljs-number">28</span>, <span class="hljs-number">29</span>]])<br>切片后的张量：<br>tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">4</span>],<br>        [ <span class="hljs-number">6</span>,  <span class="hljs-number">8</span>, <span class="hljs-number">10</span>],<br>        [<span class="hljs-number">12</span>, <span class="hljs-number">14</span>, <span class="hljs-number">16</span>],<br>        [<span class="hljs-number">18</span>, <span class="hljs-number">20</span>, <span class="hljs-number">22</span>],<br>        [<span class="hljs-number">24</span>, <span class="hljs-number">26</span>, <span class="hljs-number">28</span>]])<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>若在维度上使用<code>0：3：2</code>，表示从索引 0 开始到索引 3 结束。举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">sequence = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]<br><br><span class="hljs-comment"># 对 sequence 进行切片操作</span><br>sliced_sequence = sequence[<span class="hljs-number">0</span>:<span class="hljs-number">3</span>:<span class="hljs-number">2</span>]<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;原始序列：&quot;</span>, sequence)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;切片后的序列：&quot;</span>, sliced_sequence)<br></code></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">原始序列： [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]<br>切片后的序列： [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><blockquote><p><strong>算术运算</strong></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value</span><br><span class="hljs-comment"># ``tensor.T`` returns the transpose of a tensor 转置矩阵</span><br>y1 = tensor @ tensor.T<br>y2 = tensor.matmul(tensor.T)<br><br>y3 = torch.rand_like(y1)<br>torch.matmul(tensor, tensor.T, out=y3)<br><br><br><span class="hljs-comment"># This computes the element-wise product. z1, z2, z3 will have the same value</span><br>z1 = tensor * tensor<br>z2 = tensor.mul(tensor)<br><br>z3 = torch.rand_like(tensor)<br>torch.mul(tensor, tensor, out=z3)<br></code></pre></td></tr></table></figure><ol><li><strong>矩阵乘法（Matrix Multiplication）</strong>：<ul><li><code>y1 = tensor @ tensor.T</code>：这是Python中使用<code>@</code>运算符进行<strong>矩阵乘法</strong>的简洁写法，它计算了<code>tensor</code>与其转置的矩阵相乘，并将结果存储在<code>y1</code>中。</li><li><code>y2 = tensor.matmul(tensor.T)</code>：这是<code>torch.Tensor</code>类的<code>matmul</code>方法的调用方式，实现了与<code>@</code>运算符相同的功能，将两个张量相乘。</li><li><code>y3 = torch.rand_like(y1)</code>和<code>torch.matmul(tensor, tensor.T, out=y3)</code>：这两行代码将矩阵乘法的结果存储在预先分配的张量<code>y3</code>中。</li></ul></li><li><strong>元素级乘法（Element-wise Multiplication）</strong>：<ul><li><code>z1 = tensor * tensor</code>：这是Python中进行元素级乘法的简洁写法，它将<code>tensor</code>中的每个元素与另一个<code>tensor</code>中<strong>对应位置的元素相乘</strong>，并将结果存储在<code>z1</code>中。</li><li><code>z2 = tensor.mul(tensor)</code>：这是<code>torch.Tensor</code>类的<code>mul</code>方法的调用方式，实现了与<code>*</code>运算符相同的功能，进行元素级乘法。</li><li><code>z3 = torch.rand_like(tensor)</code>和<code>torch.mul(tensor, tensor, out=z3)</code>：这两行代码将元素级乘法的结果存储在预先分配的张量<code>z3</code>中。</li></ul></li></ol><blockquote><p><strong>单元素张量</strong></p></blockquote><p>如果你有一个单元素张量，例如通过将张量的所有值聚合为一个值，你可以使用以下命令 <code>item()</code> 将其转换为 Python 数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">agg = tensor.<span class="hljs-built_in">sum</span>()<br>agg_item = agg.item()<br><span class="hljs-built_in">print</span>(agg_item, <span class="hljs-built_in">type</span>(agg_item))<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">12.0</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;float&#x27;</span>&gt;<br></code></pre></td></tr></table></figure><p><strong>tips：</strong>agg也是一个张量，为单元素张量。</p><blockquote><p><strong>就地操作</strong></p></blockquote><p>将结果存储到操作数中的操作称为就地操作。它们由 <code>_</code> 后缀表示。例如： <code>x.copy_(y)</code> 、、 <code>x.t_()</code> 将更改 <code>x</code> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;tensor&#125;</span> \n&quot;</span>)<br>tensor.add_(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(tensor)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br>tensor([[<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>]])<br></code></pre></td></tr></table></figure><p>常见的PyTorch就地操作：</p><ol><li>**add_、sub_、mul_、div_**：<ul><li><code>add_()</code>：就地执行张量的加法。</li><li><code>sub_()</code>：就地执行张量的减法。</li><li><code>mul_()</code>：就地执行张量的乘法。</li><li><code>div_()</code>：就地执行张量的除法。</li></ul></li><li><strong>其他数学函数</strong>：<ul><li><code>abs_()</code>：就地执行张量的绝对值操作。</li><li><code>neg_()</code>：就地执行张量的取负操作。</li><li><code>pow_()</code>：就地执行张量的指数操作。</li><li><code>clamp_()</code>：就地执行张量的截断操作。</li></ul></li><li><strong>归约操作</strong>：<ul><li><code>sum_()</code>：就地计算张量的元素之和。</li><li><code>mean_()</code>：就地计算张量的平均值。</li><li><code>max_()</code>：就地计算张量的最大值。</li><li><code>min_()</code>：就地计算张量的最小值。</li></ul></li><li><strong>其他操作</strong>：<ul><li><code>fill_()</code>：用指定的标量值填充张量。</li><li><code>zero_()</code>：将张量的所有元素设置为0。</li><li><code>fill_diagonal_()</code>：将张量的对角线元素填充为指定值。</li></ul></li></ol><p>这些就地操作都是在函数名后面添加下划线<code>_</code>来表示的，例如<code>add_()</code>、<code>mul_()</code>等。在使用时需要小心，因为它们会直接修改原始的张量，可能会导致不可预测的结果或难以调试的错误。</p><h3 id="1-4-使用-NumPy-桥接"><a href="#1-4-使用-NumPy-桥接" class="headerlink" title="1.4 使用 NumPy 桥接"></a>1.4 使用 NumPy 桥接</h3><p>CPU 上的张量和 NumPy 数组可以共享其底层内存位置，更改一个将更改另一个。</p><blockquote><h3 id="Tensor-到-NumPy-数组"><a href="#Tensor-到-NumPy-数组" class="headerlink" title="Tensor 到 NumPy 数组"></a>Tensor 到 NumPy 数组</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">t = torch.ones(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br>n = t.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])<br>n: [<span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span> <span class="hljs-number">1.</span>]<br></code></pre></td></tr></table></figure><p>张量的变化反映在 NumPy 数组中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">t.add_(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>])<br>n: [<span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span>]<br></code></pre></td></tr></table></figure><blockquote><h3 id="NumPy-数组转-Tensor"><a href="#NumPy-数组转-Tensor" class="headerlink" title="NumPy 数组转 Tensor"></a>NumPy 数组转 Tensor</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">n = np.ones(<span class="hljs-number">5</span>)<br>t = torch.from_numpy(n)<br></code></pre></td></tr></table></figure><p>NumPy 数组中的更改会反映在张量中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">np.add(n, <span class="hljs-number">1</span>, out=n)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;t: <span class="hljs-subst">&#123;t&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;n: <span class="hljs-subst">&#123;n&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t: tensor([<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>], dtype=torch.float64)<br>n: [<span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span> <span class="hljs-number">2.</span>]<br></code></pre></td></tr></table></figure><h2 id="2-Datasets-DataLoaders-数据集和数据加载器"><a href="#2-Datasets-DataLoaders-数据集和数据加载器" class="headerlink" title="2.Datasets &amp; DataLoaders 数据集和数据加载器"></a>2.<strong>Datasets &amp; DataLoaders</strong> 数据集和数据加载器</h2><p>用于处理数据样本的代码可能会变得混乱且难以维护;理想情况下，我们希望我们的<strong>数据集代码与模型训练代码解耦</strong>，以获得更好的可读性和模块化。PyTorch 提供了两个数据原语： <code>torch.utils.data.DataLoader</code>和<code>torch.utils.data.Dataset</code> 允许你使用预加载的数据集以及你自己的数据。</p><p>Dataset 存储样本及其相应的标签，而 DataLoader 则在 Dataset 周围封装了一个可迭代器，以方便访问样本。</p><h3 id="2-1-加载数据集"><a href="#2-1-加载数据集" class="headerlink" title="2.1 加载数据集"></a>2.1 加载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br>training_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">True</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor()<br>)<br><br>test_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">False</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor()<br>)<br></code></pre></td></tr></table></figure><ul><li><code>root</code> 是存储训练&#x2F;测试数据的路径，</li><li><code>train</code> 指定训练或测试数据集，</li><li><code>download=True</code> 如果数据在 上不可用 <code>root</code> ，则从 Internet 下载数据。</li><li><code>transform</code> 和 <code>target_transform</code> 指定要素和标注转换</li></ul><h3 id="2-2-数据加载器"><a href="#2-2-数据加载器" class="headerlink" title="2.2 数据加载器"></a>2.2 数据加载器</h3><p>检索 <code>Dataset</code> 数据集的特征，并一次标记一个样本。在训练模型时，我们通常希望以“小批量”的方式传递样本，在每个时期重新洗牌数据以减少模型过拟合，并使用 Python <code>multiprocessing</code> 来加快数据检索速度。</p><p><code>DataLoader</code> 是一个可迭代的对象，它通过一个简单的 API 为我们抽象了这种复杂性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(training_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br>test_dataloader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>我们已将该数据集加载到<code>DataLoader</code>中，并可以根据需要遍历该数据集。下面的每次迭代都会返回一批 <code>train_features</code> and <code>train_labels</code> （分别包含 <code>batch_size=64</code> 特征和标签）。因为我们指定 <code>shuffle=True</code> 了 ，在我们遍历所有批次后，数据会被洗牌。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Display image and label.</span><br>train_features, train_labels = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(train_dataloader))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Feature batch shape: <span class="hljs-subst">&#123;train_features.size()&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Labels batch shape: <span class="hljs-subst">&#123;train_labels.size()&#125;</span>&quot;</span>)<br>img = train_features[<span class="hljs-number">0</span>].squeeze()<br>label = train_labels[<span class="hljs-number">0</span>]<br>plt.imshow(img, cmap=<span class="hljs-string">&quot;gray&quot;</span>)<br>plt.show()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Label: <span class="hljs-subst">&#123;label&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong>tensor.shape和tensor.size()获取到的内容相同，但一个是属性，一个是方法。可以把tensor看成是一个类。</p><h2 id="3-构建神经网络"><a href="#3-构建神经网络" class="headerlink" title="3.构建神经网络"></a>3.构建神经网络</h2><p>神经网络由对数据执行操作的层&#x2F;模块组成。torch.nn 命名空间提供了构建自己的神经网络所需的所有构建块。PyTorch 中的每个模块都对 nn.模块。神经网络本身是由其他模块（层）组成的模块。这种嵌套结构允许轻松构建和管理复杂的架构。</p><h3 id="3-1-获取用于训练的设备"><a href="#3-1-获取用于训练的设备" class="headerlink" title="3.1 获取用于训练的设备"></a>3.1 获取用于训练的设备</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">device = (<br>    <span class="hljs-string">&quot;cuda&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;mps&quot;</span><br>    <span class="hljs-keyword">if</span> torch.backends.mps.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;device&#125;</span> device&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="3-2-定义类"><a href="#3-2-定义类" class="headerlink" title="3.2 定义类"></a>3.2 定义类</h3><p>我们通过子类化来定义我们的神经网络 <code>nn.Module</code> ，并在 <code>__init__</code> 中初始化神经网络层。每个 <code>nn.Module</code> 子类都实现对方法中输入数据的 <code>forward</code> 操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.flatten = nn.Flatten()<br>        self.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.flatten(x)<br>        logits = self.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> logits<br></code></pre></td></tr></table></figure><p>我们创建一个 <code>NeuralNetwork</code> 的实例，并将其移动到 <code>device</code> 中，并打印其结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = NeuralNetwork().to(device)<br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">NeuralNetwork(<br>  (flatten): Flatten(start_dim=<span class="hljs-number">1</span>, end_dim=-<span class="hljs-number">1</span>)<br>  (linear_relu_stack): Sequential(<br>    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">784</span>, out_features=<span class="hljs-number">512</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">1</span>): ReLU()<br>    (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>, bias=<span class="hljs-literal">True</span>)<br>    (<span class="hljs-number">3</span>): ReLU()<br>    (<span class="hljs-number">4</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">10</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br>)<br></code></pre></td></tr></table></figure><p>为了使用模型，我们将输入数据传递给它。这将执行模型的 <code>forward</code> ，以及一些后台操作。不要直接调用<code>model.forward()</code> ！</p><p><strong>tips：</strong></p><ul><li>在 PyTorch 中，实现了 <code>nn.Module</code> 的子类中的 <code>forward</code> 方法是一个特殊的约定。当您调用模型的实例（例如 <code>model</code>）时，PyTorch 会自动调用 <code>forward</code> 方法，而不需要显式地调用 <code>model.forward()</code>。</li><li>这是因为<code>torch.nn.Module</code>类中已经定义了<code>__call__</code>方法，而该方法内部实际上会调用<code>forward()</code>方法。</li><li>在Python中，<code>__call__</code>是一个特殊方法，允许类的实例像函数一样被调用。</li></ul><p>下面是一个简单的例子，演示了如何使用<code>__call__</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Multiplier</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, factor</span>):<br>        self.factor = factor<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.factor * x<br><br><span class="hljs-comment"># 创建一个Multiplier实例</span><br>double = Multiplier(<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 使用__call__方法调用实例，实际上就像调用一个函数一样</span><br>result = double(<span class="hljs-number">5</span>)  <span class="hljs-comment"># 相当于调用了double.__call__(5)</span><br><span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出 10</span><br></code></pre></td></tr></table></figure><p>在输入上调用模型将返回一个二维张量，其中 dim&#x3D;0 对应于每个类的 10 个原始预测值的每个输出，dim&#x3D;1 对应于每个输出的单个值。我们通过传递模块的 <code>nn.Softmax</code> 实例来获取预测概率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, device=device)<br>logits = model(X)<br>pred_probab = nn.Softmax(dim=<span class="hljs-number">1</span>)(logits)<br>y_pred = pred_probab.argmax(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Predicted class: <span class="hljs-subst">&#123;y_pred&#125;</span>&quot;</span>)[]()<br></code></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Predicted <span class="hljs-keyword">class</span>: tensor([<span class="hljs-number">7</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><ol><li><code>tensor.argmax(1)</code> 是对 PyTorch 张量进行操作，用于沿指定维度找到张量中最大值的索引。参数是0表示沿着列找最大值，1表示沿着行找最大值。</li><li><code>nn.Softmax(dim=1)</code> 是PyTorch等深度学习框架中常用的函数。该函数用于沿着指定的维度计算张量的 softmax 激活。在这里，<code>dim=1</code> 表示 softmax 沿着输入张量的第二个维度（从 0 开始索引）进行操作。</li></ol><h3 id="3-2-模型层"><a href="#3-2-模型层" class="headerlink" title="3.2 模型层"></a>3.2 模型层</h3><h4 id="nn-Flatten"><a href="#nn-Flatten" class="headerlink" title="nn.Flatten"></a>nn.Flatten</h4><p><code>nn.Flatten</code> 是 PyTorch 中的一个层（Layer），用于将输入的多维张量（例如，具有多个轴或维度的张量）转换为一个具有单个轴的张量（通常是一维张量）。其作用是将输入的数据“展平”成一个一维向量，以便于后续的神经网络层（如全连接层）处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br>input_tensor = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(input_tensor)<br><span class="hljs-comment"># 定义一个 Flatten 层</span><br>flatten_layer = nn.Flatten()<br><br><span class="hljs-comment"># 使用 Flatten 层将输入张量展平</span><br>output = flatten_layer(input_tensor)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/1.png"></p><p>在许多情况下，当将卷积层的输出传递给全连接层时，需要使用 <code>nn.Flatten</code> 来将卷积层的输出展平为一维张量，以便于后续的全连接层处理。</p><h4 id="nn-Linear"><a href="#nn-Linear" class="headerlink" title="nn.Linear"></a>nn.Linear</h4><p><code>nn.Linear</code> 是 PyTorch 中的一个线性层（Linear Layer），也称为全连接层（Fully Connected Layer）或仿射层（Affine Layer）。这个层<strong>将输入张量与权重矩阵相乘，然后加上偏置向量</strong>（可选），最后应用激活函数（也可选）。</p><p>在神经网络中，全连接层通常用于将输入数据与权重相乘，并加上偏置，从而产生新的特征表示，这些特征表示被传递给下一层。全连接层的作用是将输入数据映射到输出空间中。</p><p>以下是 <code>nn.Linear</code> 的基本用法示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">linear_layer = nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>)<br>output = linear_layer(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/2.png"></p><p>在训练神经网络时，权重矩阵和偏置向量是可学习的参数，它们会根据反向传播算法进行优化，以最小化损失函数。</p><p><strong>tips：</strong></p><p>权重矩阵和偏置向量是随机的。</p><p>nn.ReLU</p><p>非线性激活是在模型的输入和输出之间创建复杂映射的原因。它们在线性变换后应用以引入非线性，帮助神经网络学习各种现象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">output = nn.ReLU()(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/3.png"></p><p><strong>tips：</strong></p><ul><li>ReLU（Rectified Linear Unit）是一种常用的非线性激活函数，被广泛应用于深度神经网络中。ReLU函数定义为：<code>f(x)=max(0,x)</code>，即，当输入 <em>x</em> 大于等于0时，ReLU函数返回输入 <em>x</em>；当输入 <em>x</em> 小于0时，ReLU函数返回0。如上图结果所示。</li><li>常见的非线性激活函数包括：</li></ul><ol><li>Sigmoid函数：将输入映射到0到1之间的连续范围，常用于输出层的二分类问题。</li><li>Tanh函数：类似于Sigmoid函数，但将输入映射到-1到1之间的连续范围，也常用于隐藏层。</li><li>ReLU（Rectified Linear Unit）函数：对于正数输入，输出等于输入；对于负数输入，输出为0。ReLU函数在深度学习中得到了广泛应用，因为它的计算简单且在训练过程中可以加速收敛。</li><li>Leaky ReLU函数：与ReLU类似，但对负数输入有小的线性斜率，可以避免ReLU中的“死亡神经元”问题。</li><li>Softmax函数：常用于多分类问题的输出层，将输入转换成一个概率分布，使得输出的所有值都在0到1之间且总和为1。</li></ol><h4 id="nn-Sequential"><a href="#nn-Sequential" class="headerlink" title="nn.Sequential"></a>nn.Sequential</h4><p>nn.Sequential 是模块的有序容器。数据以与定义的相同的顺序传递到所有模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">linear_relu_stack = nn.Sequential(<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>),<br>            nn.ReLU(),<br>        )<br>output2 = linear_relu_stack(input_tensor)<br></code></pre></td></tr></table></figure><p>效果与之前的定义相同。</p><h4 id="nn-Softmax"><a href="#nn-Softmax" class="headerlink" title="nn.Softmax"></a>nn.Softmax</h4><p>Softmax函数是一种常用的激活函数，通常用于多分类问题的输出层，将原始的网络输出转换为表示概率分布的形式。Softmax函数将输入向量 <em>z</em> 的每个元素转换为一个介于0和1之间的实数，同时确保所有元素的总和为1，因此可以看作是对输入向量的归一化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">output = nn.Softmax(dim=<span class="hljs-number">1</span>)(output)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/4.png"></p><p><strong>tips：</strong></p><p>dim为1表示行的和为1，dim为0表示列的和为 1。</p><h3 id="3-3-模型参数"><a href="#3-3-模型参数" class="headerlink" title="3.3 模型参数"></a>3.3 模型参数</h3><p>神经网络中的许多层都是参数化的，即具有相关的权重和偏差，这些权重和偏差在训练过程中得到优化。子类 <code>nn.Module</code> 会自动跟踪模型对象中定义的所有字段，并使所有参数都可以使用模型 <code>parameters()</code> 或 <code>named_parameters()</code> 方法访问。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>],<br>                      [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>]])  <span class="hljs-comment"># 2个样本，3个特征</span><br><br><span class="hljs-comment"># 定义权重矩阵和偏置向量</span><br>weight = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>],   <span class="hljs-comment"># 2个输出特征，每个特征对应3个输入特征</span><br>                       [<span class="hljs-number">0.4</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.6</span>]])<br>bias = torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])  <span class="hljs-comment"># 2个输出特征，每个特征都有一个偏置</span><br><br><span class="hljs-comment"># 执行线性变换操作</span><br>output = F.linear(<span class="hljs-built_in">input</span>, weight, bias)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output after linear transformation:&quot;</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/5.png"></p><p><strong>tips：</strong></p><p>偏差会加在<strong>每一行</strong>上。</p><h2 id="4-torch-autograd自动微分"><a href="#4-torch-autograd自动微分" class="headerlink" title="4.torch.autograd自动微分"></a>4.torch.autograd自动微分</h2><p>在训练神经网络时，最常用的算法是反向传播。在该算法中，参数（模型权重）根据损失函数相对于给定参数的梯度进行调整。</p><p>为了计算这些梯度，PyTorch 有一个内置的微分引擎，称为 <code>torch.autograd</code> 。它支持自动计算任何计算图的梯度。</p><p>考虑最简单的单层神经网络，具有输入 <code>x</code> 、参数 <code>w</code> ， <code>b</code> 和一些损失函数。可以在 PyTorch 中按以下方式定义它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>x = torch.ones(<span class="hljs-number">5</span>)  <span class="hljs-comment"># input tensor</span><br>y = torch.zeros(<span class="hljs-number">3</span>)  <span class="hljs-comment"># expected output</span><br>w = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.randn(<span class="hljs-number">3</span>, requires_grad=<span class="hljs-literal">True</span>)<br>z = torch.matmul(x, w)+b<br>loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)<br></code></pre></td></tr></table></figure><p>PyTorch中实现自动计算梯度的机制是通过<strong>动态计算图</strong>实现的。当你在PyTorch中定义张量并进行操作时，PyTorch会构建一个计算图，该计算图描述了数据流经过的操作，并且知道每个操作涉及的张量之间的依赖关系。这个计算图是动态的，因为它在每次执行时都会重新构建。</p><p>此代码定义以下计算图：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/6.png"></p><p>为了优化神经网络中参数的权重，我们需要计算损失函数相对于参数的导数。为了计算这些导数，我们调用 <code>loss.backward()</code> ，然后从 <code>w.grad</code> 和 <code>b.grad</code> 中检索值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">loss.backward()<br><span class="hljs-built_in">print</span>(w.grad)<br><span class="hljs-built_in">print</span>(b.grad)<br></code></pre></td></tr></table></figure><p>简而言之，PyTorch实现自动计算梯度的主要步骤如下：</p><ol><li>定义张量，并在需要计算梯度的张量上设置<code>requires_grad=True</code>。</li><li>执行计算操作，PyTorch会跟踪这些操作并构建计算图。</li><li>当需要计算梯度时，调用<code>.backward()</code>方法。PyTorch会根据计算图自动计算梯度，并将梯度累积到相应的张量的<code>.grad</code>属性中。</li></ol><p><strong>tips：</strong></p><p>我们只能获取计算图的叶节点的属性，这些节点的 <code>grad</code> <code>requires_grad</code> 属性设置为 <code>True</code> 。对于图中的所有其他节点，梯度将不可用。</p><h2 id="5-优化模型参数"><a href="#5-优化模型参数" class="headerlink" title="5.优化模型参数"></a>5.优化模型参数</h2><p>现在我们有了模型和数据，是时候通过优化模型的参数来训练、验证和测试我们的模型了。训练模型是一个迭代过程;在每次迭代中，模型对输出进行猜测，计算其猜测中的误差（损失），收集误差相对于其参数的导数（如我们在上一节中看到的），<strong>并使用梯度下降优化这些参数</strong>。</p><h3 id="5-1-超参数"><a href="#5-1-超参数" class="headerlink" title="5.1 超参数"></a>5.1 超参数</h3><p>超参数是可调整的参数，可用于控制模型优化过程。不同的超参数值会影响模型训练和收敛率</p><p>我们定义以下用于训练的超参数：</p><ul><li><strong>Number of Epochs</strong>  - <strong>遍历数据集的次数</strong></li><li><strong>Batch Size</strong> 批量大小 - 在<strong>更新参数之前</strong>通过网络传播的<strong>数据样本数</strong>，参数.grad会<strong>累计一个batch的梯度</strong></li><li><strong>Learning Rate</strong> 学习率 - 在每个批次&#x2F;周期<strong>更新模型参数的程度</strong>。较小的值会导致学习速度较慢，而较大的值可能会导致训练期间出现不可预测的行为。</li></ul><h3 id="5-2-优化循环"><a href="#5-2-优化循环" class="headerlink" title="5.2 优化循环"></a>5.2 优化循环</h3><p>一旦我们设置了超参数，我们就可以使用优化循环来训练和优化我们的模型。优化循环的每次迭代称为一个纪元。</p><p>每个纪元由两个主要部分组成：</p><ul><li><strong>The Train Loop</strong> 训练循环 - 遍历训练数据集并尝试收敛到最佳参数。</li><li>**The Validation&#x2F;Test Loop **验证&#x2F;测试循环 - 遍历测试数据集，以检查模型性能是否正在提高。</li></ul><h3 id="5-3-损失函数"><a href="#5-3-损失函数" class="headerlink" title="5.3 损失函数"></a>5.3 损失函数</h3><p>当呈现一些训练数据时，我们未经训练的网络可能不会给出正确的答案。损失函数衡量获得的结果与目标值的差异程度，它是我们在训练过程中想要最小化的损失函数。为了计算损失，我们使用给定数据样本的输入进行预测，并将其与真实数据标签值进行比较。</p><h3 id="5-4-优化"><a href="#5-4-优化" class="headerlink" title="5.4 优化"></a>5.4 优化</h3><p>优化是调整模型参数以减少每个训练步骤中的模型误差的过程。优化算法定义了此过程的执行方式。所有优化逻辑都封装在对象中 <code>optimizer</code> 。在这里，我们使用 SGD 优化器;此外，PyTorch 中还有许多不同的优化器，例如 ADAM 和 RMSProp，它们更适合不同类型的模型和数据。</p><p>我们通过注册需要训练的模型参数并传入学习率超参数来初始化优化器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)<br></code></pre></td></tr></table></figure><p>在训练循环中，优化分三个步骤进行：</p><ul><li>调用 <code>optimizer.zero_grad()</code> 以重置模型参数的梯度。默认情况下，渐变相加;为了防止重复计算，我们在每次迭代时都明确地将它们归零。</li><li>通过调用  <code>loss.backward()</code> 反向传播预测损失。PyTorch 将损失的梯度与每个参数交汇。</li><li>一旦我们有了梯度，我们就会调用 <code>optimizer.step()</code> 通过向后传递中收集的梯度来调整参数。</li></ul><p><strong>tips:</strong></p><p>model.parameters()为每一层的<strong>权重和偏差</strong>。比如上述例子中的w，b</p><p>举例：</p><p><img src="/2024/01/24/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/pytorch%E5%9F%BA%E7%A1%80/7.png"></p><h3 id="5-5-全面实施"><a href="#5-5-全面实施" class="headerlink" title="5.5   全面实施"></a>5.5   全面实施</h3><p>我们在优化代码上定义 <code>train_loop</code> 循环，并 <code>test_loop</code> 根据我们的测试数据评估模型的性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_loop</span>(<span class="hljs-params">dataloader, model, loss_fn, optimizer</span>):<br>    size = <span class="hljs-built_in">len</span>(dataloader.dataset)<br>    <span class="hljs-comment"># Set the model to training mode - important for batch normalization and dropout layers</span><br>    <span class="hljs-comment"># Unnecessary in this situation but added for best practices</span><br>    model.train()<br>    <span class="hljs-keyword">for</span> batch, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        <span class="hljs-comment"># Compute prediction and loss</span><br>        pred = model(X)<br>        loss = loss_fn(pred, y)<br><br>        <span class="hljs-comment"># Backpropagation</span><br>        loss.backward()<br>        optimizer.step()<br>        optimizer.zero_grad()<br><br>        <span class="hljs-keyword">if</span> batch % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            loss, current = loss.item(), batch * batch_size + <span class="hljs-built_in">len</span>(X)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loss: <span class="hljs-subst">&#123;loss:&gt;7f&#125;</span>  [<span class="hljs-subst">&#123;current:&gt;5d&#125;</span>/<span class="hljs-subst">&#123;size:&gt;5d&#125;</span>]&quot;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_loop</span>(<span class="hljs-params">dataloader, model, loss_fn</span>):<br>    <span class="hljs-comment"># Set the model to evaluation mode - important for batch normalization and dropout layers</span><br>    <span class="hljs-comment"># Unnecessary in this situation but added for best practices</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    size = <span class="hljs-built_in">len</span>(dataloader.dataset)<br>    num_batches = <span class="hljs-built_in">len</span>(dataloader)<br>    test_loss, correct = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><br>    <span class="hljs-comment"># Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode</span><br>    <span class="hljs-comment"># also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> dataloader:<br>            pred = model(X)<br>            test_loss += loss_fn(pred, y).item()<br>            correct += (pred.argmax(<span class="hljs-number">1</span>) == y).<span class="hljs-built_in">type</span>(torch.<span class="hljs-built_in">float</span>).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= num_batches<br>    correct /= size<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test Error: \n Accuracy: <span class="hljs-subst">&#123;(<span class="hljs-number">100</span>*correct):&gt;<span class="hljs-number">0.1</span>f&#125;</span>%, Avg loss: <span class="hljs-subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)<br></code></pre></td></tr></table></figure><p>我们初始化损失函数和优化器，并将其传递给 <code>train_loop</code> 和 <code>test_loop</code> 。随意增加 epoch 的数量以跟踪模型的改进性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_fn = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)<br><br>epochs = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;t+<span class="hljs-number">1</span>&#125;</span>\n-------------------------------&quot;</span>)<br>    train_loop(train_dataloader, model, loss_fn, optimizer)<br>    test_loop(test_dataloader, model, loss_fn)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Done!&quot;</span>)<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p><code>model.train()</code> 和 <code>model.eval()</code> 是 PyTorch 中用于控制模型模式的两个方法，它们的主要区别在于模型处于不同的运行模式，具体如下：</p><ol><li><code>model.train()</code>: 调用 <code>model.train()</code> 将模型设置为训练模式。在训练模式下，模型中的一些特定层，比如 dropout 和 batch normalization，会以不同的方式处理输入数据。例如，dropout 在训练时会随机丢弃部分节点，以防止过拟合；而 batch normalization 在训练时会根据当前 mini-batch 的统计数据来标准化输入数据。因此，在训练模式下，这些层会执行相应的训练操作。</li><li><code>model.eval()</code>: 调用 <code>model.eval()</code> 将模型设置为评估模式。在评估模式下，模型的行为会发生变化。例如，dropout 层不再随机丢弃节点，而是将所有节点保留，以便获取更加稳定的预测结果；batch normalization 也会使用固定的统计数据进行标准化，而不是使用当前 mini-batch 的统计数据。评估模式下，模型的行为更接近于实际使用场景。</li></ol><p>总的来说，<code>model.train()</code> 将模型设置为训练模式，用于训练过程中；<code>model.eval()</code> 将模型设置为评估模式，用于测试、验证或推断过程中，以获得更稳定和可靠的输出结果。</p><h3 id="5-6-保存并加载模型"><a href="#5-6-保存并加载模型" class="headerlink" title="5.6  保存并加载模型"></a>5.6  保存并加载模型</h3><p>在本节中，我们将了解如何通过保存、加载和运行模型预测来持久化模型状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br></code></pre></td></tr></table></figure><p><strong>保存和加载模型权重</strong></p><p>PyTorch 模型将学习到的参数存储在名为 <code>state_dict</code> 的内部状态字典中。这些可以通过以下 <code>torch.save</code> 方法持久化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = models.vgg16(weights=<span class="hljs-string">&#x27;IMAGENET1K_V1&#x27;</span>)<br>torch.save(model.state_dict(), <span class="hljs-string">&#x27;model_weights.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>要加载模型权重，您需要先创建同一模型的实例，然后使用 <code>load_state_dict()</code> method 加载参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">model = models.vgg16() <span class="hljs-comment"># we do not specify ``weights``, i.e. create untrained model</span><br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;model_weights.pth&#x27;</span>))<br>model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure><p><strong>tips：</strong></p><p>请务必在推理前调用 <code>model.eval()</code> 方法，将 dropout 和 Batch 归一化层设置为评估模式。如果不这样做，将产生不一致的推理结果。</p><p><strong>Saving and Loading Models with Shapes</strong></p><p>在加载模型权重时，我们需要先实例化模型类，因为该类定义了网络的结构。我们可能希望将此类的结构与模型一起保存，在这种情况下，我们可以传递<code>model</code>（而不是 <code>model.state_dict()</code> ）到保存函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.save(model, <span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure><p>然后，我们可以像这样加载模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = torch.load(<span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
      <category>Pytorch</category>
      
      <category>Pytorch基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ieir2024网站搭建!🐧</title>
    <link href="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/"/>
    <url>/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="ieir2024网站搭建"><a href="#ieir2024网站搭建" class="headerlink" title="ieir2024网站搭建"></a>ieir2024网站搭建</h1><h2 id="1-域名"><a href="#1-域名" class="headerlink" title="1.域名"></a>1.域名</h2><p>在<a href="https://www.gname.com/user#/admin_ym">我的域名 - GNAME管理中心</a>进行域名的注册和管理</p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/1.png"></p><p>解析域名：</p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/2.png"></p><p>前两条为SSL证书的DCV配置，后两条是正常的域名解析，解析到对应的服务器地址。</p><h2 id="2-SSL证书"><a href="#2-SSL证书" class="headerlink" title="2.SSL证书"></a>2.SSL证书</h2><h3 id="2-1-证书申请"><a href="#2-1-证书申请" class="headerlink" title="2.1 证书申请"></a>2.1 证书申请</h3><p>在<a href="https://freessl.cn/">FreeSSL首页 - FreeSSL.cn一个提供免费HTTPS证书申请的网站</a>申请免费的证书</p><ul><li>Step1，输入域名</li><li>Step2，DCV配置：返回DNS配置页面，添加两条主机记录（带www和不带www），立即检测。</li></ul><p>检测通过后会进入部署阶段，得到acme.sh部署命令。</p><h3 id="2-2-证书下载"><a href="#2-2-证书下载" class="headerlink" title="2.2 证书下载"></a>2.2 证书下载</h3><p>首先创建证书目录，root&#x2F;ssl-cert&#x2F;ieir2024.org</p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/3.png"></p><p>运行FreeSSL部署命令（FreeSSL网站给出）</p><p>最后下载证书到上面创建的目录</p><p>acme.sh –install-cert -d ieir2024.org –cert-file      &#x2F;root&#x2F;ssl_cert&#x2F;ieir2024.org&#x2F;cert.pem  –key-file       &#x2F;root&#x2F;ssl_cert&#x2F;ieir2024.org&#x2F;key.pem  –fullchain-file &#x2F;root&#x2F;ssl_cert&#x2F;ieir2024.org&#x2F;fullchain.pem –ca-file        &#x2F;root&#x2F;ssl_cert&#x2F;ieir2024.org&#x2F;ca.pem </p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/4.png"></p><h3 id="2-3-配置ssl-conf"><a href="#2-3-配置ssl-conf" class="headerlink" title="2.3 配置ssl.conf"></a>2.3 配置ssl.conf</h3><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/5.png"></p><p>将其中所有去年的网站名称改成今年的内容。</p><p>DocumentRoot “&#x2F;var&#x2F;www&#x2F;html&#x2F;ieir2024”（修改这个路径下的文件夹名称）</p><h3 id="2-4-重启httpd服务"><a href="#2-4-重启httpd服务" class="headerlink" title="2.4 重启httpd服务"></a>2.4 重启httpd服务</h3><p><code>systemctl restart httpd</code></p><p><code>service httpd force-reload</code></p><h2 id="3-修改网站"><a href="#3-修改网站" class="headerlink" title="3.修改网站"></a>3.修改网站</h2><p>使用Xftp进入<code>/var/www/html/ieir2024</code>路径下的目录。</p><p><strong>Key Dates:</strong></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/6.png"></p><p><strong>News:</strong></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/7.png"></p><p><strong>Header:</strong></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/8.png"></p><h2 id="4-修改部分"><a href="#4-修改部分" class="headerlink" title="4.修改部分"></a>4.修改部分</h2><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/9.png"></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/10.png"></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/11.png"></p><p><img src="/2024/01/19/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E5%AE%9E%E4%BE%8B/ieir2024/ieir2024%E7%BD%91%E7%AB%99%E6%90%AD%E5%BB%BA/12.png"></p>]]></content>
    
    
    <categories>
      
      <category>网站 (✪㉨✪)</category>
      
      <category>网站实例</category>
      
      <category>ieir2024</category>
      
    </categories>
    
    
    <tags>
      
      <tag>网站</tag>
      
      <tag>实例</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>rust基础知识！🐖</title>
    <link href="/2024/01/18/%E7%AE%97%E6%B3%95/rust/rust%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2024/01/18/%E7%AE%97%E6%B3%95/rust/rust%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="rust基础知识"><a href="#rust基础知识" class="headerlink" title="rust基础知识"></a>rust基础知识</h1><h2 id="1-Cargo"><a href="#1-Cargo" class="headerlink" title="1.Cargo"></a>1.Cargo</h2><p>Cargo 是 Rust 的<code>构建系统</code>和<code>包管理器</code>。Rust 开发者常用 Cargo 来管理 Rust 工程和获取工程所依赖的库。</p><p><img src="/2024/01/18/%E7%AE%97%E6%B3%95/rust/rust%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1.png"></p><p>Cargo 除了创建工程以外还具备构建（build）工程、运行（run）工程等一系列功能，构建和运行分别对应以下命令：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust">cargo build <br>cargo run <br></code></pre></td></tr></table></figure><h2 id="2-输出到命令行"><a href="#2-输出到命令行" class="headerlink" title="2.输出到命令行"></a>2.输出到命令行</h2><p>Rust 输出文字的方式主要有两种：<code>println!()</code> 和 <code>print!()</code>。这两个”函数”都是向命令行输出字符串的方法，区别仅在于前者会在输出的最后附加输出一个<strong>换行符</strong>。当用这两个”函数”输出信息的时候，第一个参数是格式字符串，后面是一串可变参数，对应着格式字符串中的”占位符”，这一点与 C 语言中的 printf 函数很相似。但是，Rust 中格式字符串中的占位符不是 <strong>“% + 字母”</strong> 的形式，而是一对 <code>&#123;&#125;</code>。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">12</span>; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;a is &#123;&#125;&quot;</span>, a); <br>&#125;<br></code></pre></td></tr></table></figure><p>如果我想把 a 输出两遍：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;a is &#123;0&#125;, a again is &#123;0&#125;&quot;</span>, a); <br></code></pre></td></tr></table></figure><p>在 {}之间可以放一个数字，它将把之后的可变参数当作一个数组来访问，下标从 0 开始。</p><p>如果要输出 { 或 } 怎么办呢？格式字符串中通过  分别转义代表 { 和 }。但是其他常用转义字符与 C 语言里的转义字符一样，都是<strong>反斜杠开头</strong>的形式。</p><h2 id="3-变量"><a href="#3-变量" class="headerlink" title="3.变量"></a>3.变量</h2><p>Rust 是<strong>强类型语言</strong>，但具有自动判断变量类型的能力。这很容易让人与弱类型语言产生混淆。</p><p>如果要声明变量，需要使用 <strong>let</strong> 关键字。例如：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">123</span>;<br></code></pre></td></tr></table></figure><p>在这句声明语句之后，以下三行代码都是被禁止的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust">a = <span class="hljs-string">&quot;abc&quot;</span>;<br>a = <span class="hljs-number">4.56</span>; <br>a = <span class="hljs-number">456</span>;<br></code></pre></td></tr></table></figure><ul><li>第一行的错误在于当声明 a 是 123 以后，a 就被确定为整型数字，不能把字符串类型的值赋给它。</li><li>第二行的错误在于自动转换数字精度有损失，Rust 语言不允许精度有损失的自动数据类型转换。</li><li>第三行的错误在于 a 不是个可变变量。</li></ul><p>前两种错误很容易理解，但第三个是什么意思？难道 a 不是个变量吗？</p><p>这就牵扯到了 Rust 语言为了高并发安全而做的设计：在语言层面<strong>尽量少的让变量的值可以改变</strong>。所以 a 的值不可变。但这**不意味着 a 不是”变量”**（英文中的 variable），官方文档称 a 这种变量为”不可变变量”。</p><p>如果我们编写的程序的一部分在假设值永远不会改变的情况下运行，而我们代码的另一部分在改变该值，那么代码的第一部分可能就不会按照设计的意图去运转。由于这种原因造成的错误很难在事后找到。这是 Rust 语言设计这种机制的原因。</p><p>当然，使变量变得”可变”（mutable）只需一个 <strong>mut</strong> 关键字。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">a</span> = <span class="hljs-number">123</span>;<br>a = <span class="hljs-number">456</span>;<br></code></pre></td></tr></table></figure><blockquote><h3 id="常量与不可变变量的区别"><a href="#常量与不可变变量的区别" class="headerlink" title="常量与不可变变量的区别"></a>常量与不可变变量的区别</h3></blockquote><p>既然不可变变量是不可变的，那不就是常量吗？为什么叫变量？</p><p>变量和常量还是有区别的。在 Rust 中，以下程序是合法的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">123</span>;   <span class="hljs-comment">// 可以编译，但可能有警告，因为该变量没有被使用</span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">456</span>;<br></code></pre></td></tr></table></figure><p>但是如果 a 是常量就不合法：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">const</span> a: <span class="hljs-type">i32</span> = <span class="hljs-number">123</span>;<br><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">456</span>;<br></code></pre></td></tr></table></figure><p>变量的值可以”重新绑定”，但在”重新绑定”以前不能私自被改变，这样可以确保在每一次”绑定”之后的区域里编译器可以充分的推理程序逻辑。 虽然 Rust 有自动判断类型的功能，但有些情况下声明类型更加方便：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span>: <span class="hljs-type">u64</span> = <span class="hljs-number">123</span>;<br></code></pre></td></tr></table></figure><p>这里声明了 a 为无符号 64 位整型变量，如果没有声明类型，a 将自动被判断为有符号 32 位整型变量，这对于 a 的取值范围有很大的影响。</p><blockquote><h3 id="重影"><a href="#重影" class="headerlink" title="重影"></a>重影</h3></blockquote><p>重影的概念与其他面向对象语言里的”重写”（Override）或”重载”（Overload）是不一样的。重影就是刚才讲述的所谓”重新绑定”，之所以加引号就是为了在没有介绍这个概念的时候代替一下概念。</p><p>重影就是指变量的名称可以被重新使用的机制：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">5</span>;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = x + <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = x * <span class="hljs-number">2</span>;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;The value of x is: &#123;&#125;&quot;</span>, x);<br>&#125;<br></code></pre></td></tr></table></figure><p>这段程序的运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust">The value of x is: <span class="hljs-number">12</span><br></code></pre></td></tr></table></figure><p>重影与可变变量的赋值不是一个概念，<strong>重影是指用同一个名字重新代表另一个变量实体，其类型、可变属性和值都可以变化。但可变变量赋值仅能发生值的变化。</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">s</span> = <span class="hljs-string">&quot;123&quot;</span>;<br>s = s.<span class="hljs-title function_ invoke__">len</span>();<br></code></pre></td></tr></table></figure><p>这段程序会出错：不能给字符串变量赋整型值。</p><h2 id="4-数据类型"><a href="#4-数据类型" class="headerlink" title="4.数据类型"></a>4.数据类型</h2><p>Rust 语言中的基础数据类型有以下几种。</p><h3 id="4-1-整数型（Integer）"><a href="#4-1-整数型（Integer）" class="headerlink" title="4.1 整数型（Integer）"></a>4.1 整数型（Integer）</h3><p>整数型简称整型，按照比特位长度和有无符号分为以下种类：</p><table><thead><tr><th>位长度</th><th>有符号</th><th>无符号</th></tr></thead><tbody><tr><td>8-bit</td><td>i8</td><td>u8</td></tr><tr><td>16-bit</td><td>i16</td><td>u16</td></tr><tr><td>32-bit</td><td>i32</td><td>u32</td></tr><tr><td>64-bit</td><td>i64</td><td>u64</td></tr><tr><td>128-bit</td><td>i128</td><td>u128</td></tr><tr><td>arch</td><td>isize</td><td>usize</td></tr></tbody></table><p>isize 和 usize 两种整数类型是用来衡量数据大小的，它们的位长度取决于所运行的目标平台，如果是 32 位架构的处理器将使用 32 位位长度整型。</p><p>整数的表述方法有以下几种：</p><table><thead><tr><th>进制</th><th>例</th></tr></thead><tbody><tr><td>十进制</td><td>98_222</td></tr><tr><td>十六进制</td><td>0xff</td></tr><tr><td>八进制</td><td>0o77</td></tr><tr><td>二进制</td><td>0b1111_0000</td></tr><tr><td>字节(只能表示 u8 型)</td><td>b’A’</td></tr></tbody></table><p>很显然，有的整数中间存在一个<strong>下划线</strong>，这种设计可以让人们在输入一个很大的数字时更容易判断数字的值大概是多少。</p><h3 id="4-2-浮点数型（Floating-Point）"><a href="#4-2-浮点数型（Floating-Point）" class="headerlink" title="4.2 浮点数型（Floating-Point）"></a>4.2 浮点数型（Floating-Point）</h3><p>Rust 与其它语言一样支持 32 位浮点数（f32）和 64 位浮点数（f64）。默认情况下，64.0 将表示 64 位浮点数，因为现代计算机处理器对两种浮点数计算的速度几乎相同，但 64 位浮点数精度更高。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">2.0</span>; <span class="hljs-comment">// f64</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">y</span>: <span class="hljs-type">f32</span> = <span class="hljs-number">3.0</span>; <span class="hljs-comment">// f32</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-3-数学运算"><a href="#4-3-数学运算" class="headerlink" title="4.3 数学运算"></a>4.3 数学运算</h3><p>用一段程序反映数学运算：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">sum</span> = <span class="hljs-number">5</span> + <span class="hljs-number">10</span>; <span class="hljs-comment">// 加 </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">difference</span> = <span class="hljs-number">95.5</span> - <span class="hljs-number">4.3</span>; <span class="hljs-comment">// 减 </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">product</span> = <span class="hljs-number">4</span> * <span class="hljs-number">30</span>; <span class="hljs-comment">// 乘 </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">quotient</span> = <span class="hljs-number">56.7</span> / <span class="hljs-number">32.2</span>; <span class="hljs-comment">// 除 </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">remainder</span> = <span class="hljs-number">43</span> % <span class="hljs-number">5</span>; <span class="hljs-comment">// 求余</span><br>&#125;<br></code></pre></td></tr></table></figure><p>许多运算符号之后加上 &#x3D; 号是自运算的意思，例如：</p><p><strong>sum +&#x3D; 1</strong> 等同于 <strong>sum &#x3D; sum + 1</strong>。</p><p><strong>注意：</strong>Rust 不支持 <strong>++</strong> 和 **–**，因为这两个运算符出现在变量的前后会影响代码可读性，减弱了开发者对变量改变的意识能力。</p><h3 id="4-4-布尔型"><a href="#4-4-布尔型" class="headerlink" title="4.4 布尔型"></a>4.4 布尔型</h3><p>布尔型用 bool 表示，值只能为 true 或 false。</p><h3 id="4-5-字符型"><a href="#4-5-字符型" class="headerlink" title="4.5 字符型"></a>4.5 字符型</h3><p>字符型用 char 表示。</p><p>Rust的 char 类型大小为 4 个字节，代表 Unicode标量值，这意味着它可以支持中文，日文和韩文字符等非英文字符甚至表情符号和零宽度空格在 Rust 中都是有效的 char 值。</p><p>Unicode 值的范围从 U+0000 到 U+D7FF 和 U+E000 到 U+10FFFF （包括两端）。 但是，”字符”这个概念并不存在于 Unicode 中，因此您对”字符”是什么的直觉可能与Rust中的字符概念不匹配。所以一般推荐使用字符串储存 UTF-8 文字（非英文字符尽可能地出现在字符串中）。</p><p><strong>注意：</strong>由于中文文字编码有两种（GBK 和 UTF-8），所以编程中使用中文字符串有可能导致乱码的出现，这是因为源程序与命令行的文字编码不一致，所以<strong>在 Rust 中字符串和字符都必须使用 UTF-8 编码</strong>，否则编译器会报错。</p><h3 id="4-6-复合类型"><a href="#4-6-复合类型" class="headerlink" title="4.6 复合类型"></a>4.6 复合类型</h3><p><strong>元组</strong>是用一对 <strong>( )</strong> 包括的一组数据，可以包含不同种类的数据：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">tup</span>: (<span class="hljs-type">i32</span>, <span class="hljs-type">f64</span>, <span class="hljs-type">u8</span>) = (<span class="hljs-number">500</span>, <span class="hljs-number">6.4</span>, <span class="hljs-number">1</span>);<br><span class="hljs-comment">// tup.0 等于 500</span><br><span class="hljs-comment">// tup.1 等于 6.4</span><br><span class="hljs-comment">// tup.2 等于 1</span><br><span class="hljs-keyword">let</span> (x, y, z) = tup;<br><span class="hljs-comment">// y 等于 6.4</span><br></code></pre></td></tr></table></figure><p><strong>数组</strong>用一对 <strong>[ ]</strong> 包括的同类型数据。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>];<br><span class="hljs-comment">// a 是一个长度为 5 的整型数组</span><br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">b</span> = [<span class="hljs-string">&quot;January&quot;</span>, <span class="hljs-string">&quot;February&quot;</span>, <span class="hljs-string">&quot;March&quot;</span>];<br><span class="hljs-comment">// b 是一个长度为 3 的字符串数组</span><br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">c</span>: [<span class="hljs-type">i32</span>; <span class="hljs-number">5</span>] = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>];<br><span class="hljs-comment">// c 是一个长度为 5 的 i32 数组</span><br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">d</span> = [<span class="hljs-number">3</span>; <span class="hljs-number">5</span>];<br><span class="hljs-comment">// 等同于 let d = [3, 3, 3, 3, 3];</span><br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">first</span> = a[<span class="hljs-number">0</span>];<br><span class="hljs-keyword">let</span> <span class="hljs-variable">second</span> = a[<span class="hljs-number">1</span>];<br><span class="hljs-comment">// 数组访问</span><br><br>a[<span class="hljs-number">0</span>] = <span class="hljs-number">123</span>; <span class="hljs-comment">// 错误：数组 a 不可变</span><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">a</span> = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>];<br>a[<span class="hljs-number">0</span>] = <span class="hljs-number">4</span>; <span class="hljs-comment">// 正确</span><br></code></pre></td></tr></table></figure><h2 id="5-注释"><a href="#5-注释" class="headerlink" title="5.注释"></a>5.注释</h2><p>Rust 中的注释方式与其它语言（C、Java）一样，支持两种注释方式：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// 这是第一种注释方式</span><br><br><span class="hljs-comment">/* 这是第二种注释方式 */</span> <br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * 多行注释</span><br><span class="hljs-comment"> * 多行注释</span><br><span class="hljs-comment"> * 多行注释</span><br><span class="hljs-comment"> */</span><br></code></pre></td></tr></table></figure><h3 id="5-1-用于说明文档的注释"><a href="#5-1-用于说明文档的注释" class="headerlink" title="5.1 用于说明文档的注释"></a>5.1 用于说明文档的注释</h3><p>在 Rust 中使用 <strong>&#x2F;&#x2F;</strong> 可以使其之后到第一个换行符的内容变成注释。</p><p>在这种规则下，三个正斜杠 <strong>&#x2F;&#x2F;&#x2F;</strong> 依然是合法的注释开始。所以 Rust 可以用 <strong>&#x2F;&#x2F;&#x2F;</strong> 作为说明文档注释的开头：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Adds one to the number given. </span><br><span class="hljs-comment">/// </span><br><span class="hljs-comment">/// # Examples </span><br><span class="hljs-comment">/// </span><br><span class="hljs-comment">/// ``` </span><br><span class="hljs-comment">/// let x = add(1, 2); </span><br><span class="hljs-comment">/// </span><br><span class="hljs-comment">/// ``` </span><br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">add</span>(a: <span class="hljs-type">i32</span>, b: <span class="hljs-type">i32</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i32</span> &#123; <br>    <span class="hljs-keyword">return</span> a + b; <br>&#125; <br>    <br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>,<span class="hljs-title function_ invoke__">add</span>(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)); <br>&#125;<br></code></pre></td></tr></table></figure><p>程序中的函数 add 就会拥有一段优雅的注释，并可以显示：</p><p><img src="/2024/01/18/%E7%AE%97%E6%B3%95/rust/rust%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/2.png"></p><h2 id="6-函数"><a href="#6-函数" class="headerlink" title="6.函数"></a>6.函数</h2><p>函数在 Rust 语言中是普遍存在的。</p><p>通过之前的章节已经可以了解到 Rust 函数的基本形式：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> &lt;函数名&gt; ( &lt;参数&gt; ) &lt;函数体&gt;<br></code></pre></td></tr></table></figure><p>其中 Rust 函数名称的命名风格是<strong>小写字母以下划线分割</strong>：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, world!&quot;</span>);<br>    <span class="hljs-title function_ invoke__">another_function</span>();<br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">another_function</span>() &#123;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, runoob!&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust">Hello, world!<br>Hello, runoob!<br></code></pre></td></tr></table></figure><p>注意，我们在源代码中的 main 函数之后定义了another_function。 Rust<strong>不在乎您在何处定义函数</strong>，只需在某个地方定义它们即可。</p><h3 id="6-1-函数参数"><a href="#6-1-函数参数" class="headerlink" title="6.1 函数参数"></a>6.1 函数参数</h3><p>Rust 中定义函数如果需要具备参数必须声明参数名称和类型：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-title function_ invoke__">another_function</span>(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>);<br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">another_function</span>(x: <span class="hljs-type">i32</span>, y: <span class="hljs-type">i32</span>) &#123;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;x 的值为 : &#123;&#125;&quot;</span>, x);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;y 的值为 : &#123;&#125;&quot;</span>, y);<br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust">x 的值为 : <span class="hljs-number">5</span><br>y 的值为 : <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure><h3 id="6-2-函数体的语句和表达式"><a href="#6-2-函数体的语句和表达式" class="headerlink" title="6.2 函数体的语句和表达式"></a>6.2 函数体的语句和表达式</h3><p>Rust 函数体由一系列可以以表达式（Expression）结尾的语句（Statement）组成。到目前为止，我们仅见到了没有以表达式结尾的函数，但已经将表达式用作语句的一部分。</p><p>语句是执行某些操作且没有返回值的步骤。例如：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">6</span>;<br></code></pre></td></tr></table></figure><p>这个步骤没有返回值，所以以下语句不正确：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = (<span class="hljs-keyword">let</span> <span class="hljs-variable">b</span> = <span class="hljs-number">2</span>);<br></code></pre></td></tr></table></figure><p>表达式有计算步骤且有返回值。以下是表达式（假设出现的标识符已经被定义）：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust">a = <span class="hljs-number">7</span><br>b + <span class="hljs-number">2</span><br>c * (a + b)<br></code></pre></td></tr></table></figure><p>Rust 中可以在一个用 <strong>{}</strong> 包括的块里编写一个较为复杂的表达式：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">5</span>;<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">y</span> = &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">3</span>;<br>        x + <span class="hljs-number">1</span><br>    &#125;;<br><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;x 的值为 : &#123;&#125;&quot;</span>, x);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;y 的值为 : &#123;&#125;&quot;</span>, y);<br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust">x 的值为 : <span class="hljs-number">5</span><br>y 的值为 : <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>很显然，这段程序中包含了一个表达式块：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust">&#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">3</span>;<br>    x + <span class="hljs-number">1</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>而且在块中可以使用函数语句，最后一个步骤是表达式，此表达式的结果值是整个表达式块所代表的值。这种表达式块叫做函数体表达式。</p><p>注意：<strong>x + 1</strong> 之后没有分号，否则它将变成一条语句！</p><p>这种表达式块是一个合法的函数体。而且在 Rust 中，函数定义可以嵌套：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">five</span>() <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i32</span> &#123;<br>        <span class="hljs-number">5</span><br>    &#125;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;five() 的值为: &#123;&#125;&quot;</span>, <span class="hljs-title function_ invoke__">five</span>());<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="6-3-函数返回值"><a href="#6-3-函数返回值" class="headerlink" title="6.3 函数返回值"></a>6.3 函数返回值</h3><p>在上一个嵌套的例子中已经显示了 Rust 函数声明返回值类型的方式：在参数声明之后用 <strong>-&gt;</strong> 来声明函数返回值的类型（不是 <strong>:</strong> ）。</p><p>在函数体中，随时都可以以 return 关键字结束函数运行并返回一个类型合适的值。这也是最接近大多数开发者经验的做法：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">add</span>(a: <span class="hljs-type">i32</span>, b: <span class="hljs-type">i32</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i32</span> &#123;<br>    <span class="hljs-keyword">return</span> a + b;<br>&#125;<br></code></pre></td></tr></table></figure><p>但是 Rust 不支持自动返回值类型判断！如果没有明确声明函数返回值的类型，函数将被认为是”纯过程”，不允许产生返回值，return 后面不能有返回值表达式。这样做的目的是为了让公开的函数能够形成可见的公报。</p><p><strong>注意：</strong>函数体表达式并不能等同于函数体，它不能使用 <strong>return</strong> <strong>关键字。</strong></p><h2 id="7-条件语句"><a href="#7-条件语句" class="headerlink" title="7.条件语句"></a>7.条件语句</h2><p>在 Rust 语言中的条件语句是这种格式的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">number</span> = <span class="hljs-number">3</span>; <br>    <span class="hljs-keyword">if</span> number &lt; <span class="hljs-number">5</span> &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;条件为 true&quot;</span>); <br>    &#125; <span class="hljs-keyword">else</span> &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;条件为 false&quot;</span>); <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>在上述程序中有条件 if 语句，这个语法在很多其它语言中很常见，但也有一些区别：首先，条件表达式 number &lt; 5 不需要用小括号包括（注意，不需要不是不允许）；但是 Rust 中的 if <strong>不存在单语句不用加 {} 的规则</strong>，<strong>不允许使用一个语句代替一个块</strong>。尽管如此，Rust 还是支持传统 else-if 语法的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">12</span>; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">b</span>; <br>    <span class="hljs-keyword">if</span> a &gt; <span class="hljs-number">0</span> &#123; <br>        b = <span class="hljs-number">1</span>; <br>    &#125;  <br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> a &lt; <span class="hljs-number">0</span> &#123; <br>        b = -<span class="hljs-number">1</span>; <br>    &#125;  <br>    <span class="hljs-keyword">else</span> &#123; <br>        b = <span class="hljs-number">0</span>; <br>    &#125; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;b is &#123;&#125;&quot;</span>, b); <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust">b 为 <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>Rust 中的条件表达式必须是 bool 类型，例如下面的程序是错误的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">number</span> = <span class="hljs-number">3</span>; <br>    <span class="hljs-keyword">if</span> number &#123;   <span class="hljs-comment">// 报错，expected `bool`, found integerrustc(E0308)</span><br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Yes&quot;</span>);<br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>虽然 C&#x2F;C++ 语言中的条件表达式用整数表示，非 0 即真，但这个规则在很多注重代码安全性的语言中是被禁止的。</p><p>结合之前章学习的函数体表达式我们加以联想：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">if</span> &lt;condition&gt; &#123; block <span class="hljs-number">1</span> &#125; <span class="hljs-keyword">else</span> &#123; block <span class="hljs-number">2</span> &#125; <br></code></pre></td></tr></table></figure><p>这种语法中的 <strong>{ block 1 }</strong> 和 <strong>{ block 2 }</strong> 可不可以是函数体表达式呢？</p><p>答案是肯定的！也就是说，在 Rust 中我们可以使用 if-else 结构实现类似于三元条件运算表达式 <strong>(A ? B : C)</strong> 的效果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = <span class="hljs-number">3</span>; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">number</span> = <span class="hljs-keyword">if</span> a &gt; <span class="hljs-number">0</span> &#123; <span class="hljs-number">1</span> &#125; <span class="hljs-keyword">else</span> &#123; -<span class="hljs-number">1</span> &#125;; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;number 为 &#123;&#125;&quot;</span>, number); <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust">number 为 <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>注意</strong>：两个函数体表达式的<strong>类型必须一样</strong>！且必须有一个 else 及其后的表达式块。</p><h2 id="8-循环"><a href="#8-循环" class="headerlink" title="8.循环"></a>8.循环</h2><h3 id="8-1-while-循环"><a href="#8-1-while-循环" class="headerlink" title="8.1 while 循环"></a>8.1 while 循环</h3><p>while 循环是最典型的条件语句循环：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">number</span> = <span class="hljs-number">1</span>; <br>    <span class="hljs-keyword">while</span> number != <span class="hljs-number">4</span> &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>, number); <br>        number += <span class="hljs-number">1</span>; <br>    &#125; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;EXIT&quot;</span>); <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br>EXIT<br></code></pre></td></tr></table></figure><p>Rust 语言到此教程编撰之日还没有 do-while 的用法，但是 do 被规定为保留字，也许以后的版本中会用到。</p><p>在 C 语言中 for 循环使用三元语句控制循环，但是 Rust 中没有这种用法，需要用 while 循环来代替：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> i; <br><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123; <br>    <span class="hljs-comment">// 循环体</span><br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">i</span> = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">while</span> i &lt; <span class="hljs-number">10</span> &#123; <br>    <span class="hljs-comment">// 循环体 </span><br>    i += <span class="hljs-number">1</span>; <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="8-2-for-循环"><a href="#8-2-for-循环" class="headerlink" title="8.2 for 循环"></a>8.2 for 循环</h3><p>for 循环是最常用的循环结构，常用来遍历一个线性数据结构（比如数组）。for 循环遍历数组：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>]; <br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> a.<span class="hljs-title function_ invoke__">iter</span>() &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;值为 : &#123;&#125;&quot;</span>, i); <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust">值为 : <span class="hljs-number">10</span><br>值为 : <span class="hljs-number">20</span><br>值为 : <span class="hljs-number">30</span><br>值为 : <span class="hljs-number">40</span><br>值为 : <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><p>这个程序中的 for 循环完成了对数组 a 的遍历。a.iter() 代表 a 的迭代器（iterator），在学习有关于对象的章节以前不做赘述。</p><p>当然，for 循环其实是可以通过下标来访问数组的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = [<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>, <span class="hljs-number">50</span>]; <br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..<span class="hljs-number">5</span> &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;a[&#123;&#125;] = &#123;&#125;&quot;</span>, i, a[i]); <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust">a[<span class="hljs-number">0</span>] = <span class="hljs-number">10</span><br>a[<span class="hljs-number">1</span>] = <span class="hljs-number">20</span><br>a[<span class="hljs-number">2</span>] = <span class="hljs-number">30</span><br>a[<span class="hljs-number">3</span>] = <span class="hljs-number">40</span><br>a[<span class="hljs-number">4</span>] = <span class="hljs-number">50</span><br></code></pre></td></tr></table></figure><h3 id="8-3-loop-循环"><a href="#8-3-loop-循环" class="headerlink" title="8.3 loop 循环"></a>8.3 loop 循环</h3><p>身经百战的开发者一定遇到过几次这样的情况：某个循环无法在开头和结尾判断是否继续进行循环，必须在循环体中间某处控制循环的进行。如果遇到这种情况，我们经常会在一个 while (true) 循环体里实现中途退出循环的操作。</p><p>Rust 语言有原生的无限循环结构 —— loop：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = [<span class="hljs-string">&#x27;R&#x27;</span>, <span class="hljs-string">&#x27;U&#x27;</span>, <span class="hljs-string">&#x27;N&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>]; <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">i</span> = <span class="hljs-number">0</span>; <br>    <span class="hljs-keyword">loop</span> &#123; <br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">ch</span> = s[i]; <br>        <span class="hljs-keyword">if</span> ch == <span class="hljs-string">&#x27;O&#x27;</span> &#123; <br>            <span class="hljs-keyword">break</span>; <br>        &#125; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;\&#x27;&#123;&#125;\&#x27;&quot;</span>, ch);<br>        i += <span class="hljs-number">1</span>; <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-string">&#x27;R&#x27;</span> <br><span class="hljs-string">&#x27;U&#x27;</span> <br><span class="hljs-string">&#x27;N&#x27;</span> <br></code></pre></td></tr></table></figure><p>loop 循环可以通过 break 关键字类似于 return 一样使整个循环退出并给予外部一个返回值。这是一个十分巧妙的设计，因为 loop 这样的循环常被用来当作查找工具使用，如果找到了某个东西当然要将这个结果交出去：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = [<span class="hljs-string">&#x27;R&#x27;</span>, <span class="hljs-string">&#x27;U&#x27;</span>, <span class="hljs-string">&#x27;N&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>]; <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">i</span> = <span class="hljs-number">0</span>; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">location</span> = <span class="hljs-keyword">loop</span> &#123; <br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">ch</span> = s[i];<br>        <span class="hljs-keyword">if</span> ch == <span class="hljs-string">&#x27;O&#x27;</span> &#123; <br>            <span class="hljs-keyword">break</span> i; <br>        &#125; <br>        i += <span class="hljs-number">1</span>; <br>    &#125;; <br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot; \&#x27;O\&#x27; 的索引为 &#123;&#125;&quot;</span>, location); <br>&#125;<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-string">&#x27;O&#x27;</span> 的索引为 <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h2 id="9-所有权"><a href="#9-所有权" class="headerlink" title="9.所有权"></a>9.所有权</h2><p>计算机程序必须在运行时管理它们所使用的内存资源。大多数的编程语言都有管理内存的功能：C&#x2F;C++ 这样的语言主要通过手动方式管理内存，开发者需要手动的申请和释放内存资源。但为了提高开发效率，只要不影响程序功能的实现，许多开发者没有及时释放内存的习惯。所以手动管理内存的方式常常造成资源浪费。</p><p>所有权对大多数开发者而言是一个新颖的概念，它是 Rust 语言为高效使用内存而设计的语法机制。所有权概念是为了让 Rust 在编译阶段更有效地分析内存资源的有用性以实现内存管理而诞生的概念。</p><h3 id="9-1-所有权规则"><a href="#9-1-所有权规则" class="headerlink" title="9.1 所有权规则"></a>9.1 所有权规则</h3><p>所有权有以下三条规则：</p><ul><li>Rust 中的每个值都有一个变量，称为其所有者。</li><li>一次只能有一个所有者。</li><li>当所有者不在程序运行范围时，该值将被删除。</li></ul><p>这三条规则是所有权概念的基础。</p><h3 id="9-2-变量范围"><a href="#9-2-变量范围" class="headerlink" title="9.2 变量范围"></a>9.2 变量范围</h3><p>我们用下面这段程序描述变量范围的概念：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust">&#123;<br>    <span class="hljs-comment">// 在声明以前，变量 s 无效</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">s</span> = <span class="hljs-string">&quot;runoob&quot;</span>;<br>    <span class="hljs-comment">// 这里是变量 s 的可用范围</span><br>&#125;<br><span class="hljs-comment">// 变量范围已经结束，变量 s 无效</span><br></code></pre></td></tr></table></figure><p>变量范围是变量的一个属性，其代表变量的可行域，默认从声明变量开始有效直到变量所在域结束。</p><p>我们把字符串样例程序用 C 语言等价编写：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">&#123;<br>    <span class="hljs-type">char</span> *s = strdup(<span class="hljs-string">&quot;runoob&quot;</span>);<br>    <span class="hljs-built_in">free</span>(s); <span class="hljs-comment">// 释放 s 资源</span><br>&#125;<br></code></pre></td></tr></table></figure><p>ust 之所以没有明示释放的步骤是因为在变量范围结束的时候，Rust 编译器自动添加了调用释放资源函数的步骤。</p><p>这种机制看似很简单了：它不过是帮助程序员在适当的地方添加了一个释放资源的函数调用而已。但这种简单的机制可以有效地解决一个史上最令程序员头疼的编程问题。</p><h3 id="9-3-变量与数据交互的方式"><a href="#9-3-变量与数据交互的方式" class="headerlink" title="9.3 变量与数据交互的方式"></a>9.3 变量与数据交互的方式</h3><p>变量与数据交互方式主要有移动（Move）和克隆（Clone）两种：</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>blender珍珠耳环少女！🐅</title>
    <link href="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/"/>
    <url>/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/</url>
    
    <content type="html"><![CDATA[<h1 id="珍珠耳环少女"><a href="#珍珠耳环少女" class="headerlink" title="珍珠耳环少女"></a>珍珠耳环少女</h1><h2 id="1-参考图"><a href="#1-参考图" class="headerlink" title="1.参考图"></a>1.参考图</h2><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/1.png"></p><p>如上图所示：<code>shift + A</code>新建菜单下选择需要加载的参考图。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/2.png"></p><p>点击右侧窗口的图像属性。</p><p><strong>tips：</strong>点击什么类型的物体就会出现相应的属性。</p><p>举例：点击摄像机后的图案如下所示</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/3.png"></p><p>勾选不透明度，调整透明度方便后续建模。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/4.png"></p><p>点击选择键，使参考图在视窗内无法被选择。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/5.png"></p><p>调整深度，可以将参考图看的更清楚。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/7.png"></p><h2 id="2-建模"><a href="#2-建模" class="headerlink" title="2.建模"></a>2.建模</h2><p>新建一个经纬球和三个环体</p><p>在如下所示的窗口中修改新建物体的参数</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/6.png"></p><p><strong>tips1：</strong><code>/键</code>可以独显某一物体。</p><p>其余部分同上。</p><p><strong>tips2：</strong>定位过程中可以切换正视图和侧视图（1&#x2F;3键）调整物体位置，<code>正视图确定x和z方向</code>，<code>侧视图确定y方向</code>。</p><p>同时对于旋转物体，可以先确定中心点，然后按x，y，z三个旋转轴方向对物体进行旋转定位。<strong>物体最多旋转三次即可达到指定的旋转位置。</strong></p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/8.png"></p><p>模型最终效果如上所示。</p><h2 id="3-摄像机"><a href="#3-摄像机" class="headerlink" title="3.摄像机"></a>3.摄像机</h2><p>小键盘<code>0</code>切换摄像机模式。</p><p>快捷键：<code>ctrl + alt + 0</code>让摄像机视角快速定位到视图位置。</p><p>或者按快捷键<code>N</code>调出视图选项栏，选择锁定摄像机，这样就可以直接调节物体的角度。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/9.png"></p><p>点击输出设置，修改分辨率，如图所示</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/10.png"></p><p>修改后的摄像机为一个正方形。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/11.png"></p><p>修改渲染输出的位置，如下图所示</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/12.png"></p><p>点击进入摄像机的属性，调整外边框的数值，可以屏蔽摄像机视角外的内容，方便观察。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/13.png"></p><h2 id="4-渲染器"><a href="#4-渲染器" class="headerlink" title="4.渲染器"></a>4.渲染器</h2><table><thead><tr><th align="center">Render Engines</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td align="center">EEVEE</td><td>快</td><td>没有光线追踪</td></tr><tr><td align="center">CYCLES</td><td>逼真，模拟物理世界 细节的光线阴影</td><td>慢，更耗硬件</td></tr></tbody></table><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/14.png"></p><p>如上图所示修改渲染引擎。</p><p>快捷键<code>F12</code>或者按如下图所示渲染模型。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/15.png"></p><p><strong>tips：</strong>将鼠标放在视图上方的工具栏，向下滑动鼠标中键，可以将隐藏的菜单选项调出来。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/16.png"></p><p>如上图所示是四种视图的预览方式。</p><blockquote><p>线框预览</p></blockquote><p>可以显示内部和背面的走线，建模常用。</p><blockquote><p>实体预览</p></blockquote><p>不显示颜色和材质，建模时候使用，不占资源。</p><blockquote><p>材质预览</p></blockquote><p>预览材质的颜色和简单的纹理，不计算光纤追踪细节，比渲染预览快。</p><blockquote><p>渲染预览</p></blockquote><p>最终渲染结果预览，占资源</p><p><strong>tips：</strong>可以修改渲染使用的gpu设备。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/22.png"></p><h2 id="5-灯光"><a href="#5-灯光" class="headerlink" title="5.灯光"></a>5.灯光</h2><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/17.png"></p><p>点击灯光属性，调节半径，半径越大灯光越柔和。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/18.png"></p><p>改变世界属性中的强度&#x2F;力度参数，可以更准确的布光。</p><blockquote><p>新建灯光</p></blockquote><p><code>shift + A</code>选择灯光类型。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/20.png"></p><p>在灯光属性中调整参数修改布光。</p><p><strong>tips：</strong>可以在物体属性中勾选自动光滑，设置光滑角度，来保持某些物体的角度。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/21.png"></p><h2 id="6-材质"><a href="#6-材质" class="headerlink" title="6.材质"></a>6.材质</h2><p>如下图所示新建材质</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/23.png"></p><p>修改下面的基础参数进行材质的修改。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/24.png"></p><p><strong>tips：</strong>可在右上角新建集合，管理文件资源。</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/25.png"></p><blockquote><p>关联材质</p></blockquote><p>快捷键：<code>ctrl + L</code></p><p>关联材质的目的是将未上材质的物体与已经上材质的物体进行关联，使该物体具有和已上材质的物体同样的材质。</p><p>最终效果如下图所示：</p><p><img src="/2023/12/09/%E5%BB%BA%E6%A8%A1/blender/%E8%AE%BE%E8%AE%A1/blender%E7%8F%8D%E7%8F%A0%E8%80%B3%E7%8E%AF%E5%B0%91%E5%A5%B3/26.png"></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blender界面认识！🥕</title>
    <link href="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/"/>
    <url>/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="界面认识"><a href="#界面认识" class="headerlink" title="界面认识"></a>界面认识</h1><h2 id="1-界面"><a href="#1-界面" class="headerlink" title="1.界面"></a>1.界面</h2><blockquote><p>窗口可替换</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/1.png"></p><p>如上图所示，每一个窗口都可以替换成不同的类型。</p><blockquote><p>窗口可拆分</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/2.png"></p><p>如上图所示，将鼠标放置在任一窗口的四角，往自己方向拖动可以新增一个窗口，往已存在的窗口拖动可以合并。</p><blockquote><p>窗口可恢复</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/3.png"></p><p>如上图所示，如果想要恢复到最初的窗口，可以按图示方法新建布局。</p><blockquote><p>最大化当前面板</p></blockquote><p>快捷键：<code>ctrl + space</code></p><p>再按一次返回。</p><h2 id="2-游标"><a href="#2-游标" class="headerlink" title="2.游标"></a>2.游标</h2><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/4.png"></p><p>点击上图的游标工具即可移动游标。或者在选择工具下<code>shift + 右键</code>进行移动。</p><blockquote><p>新建物体的位置</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/5.png"></p><p>如图所示，新建物体的位置会出现在游标所在的位置。</p><blockquote><p>模型定位</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/6.png"></p><p>如图所示，通过<code>shift + S</code>可以将模型的位置和游标进行联系。</p><p>游标回到原点快捷键：<code>shift + C</code></p><blockquote><p>物体旋转轴心点</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/7.png"></p><p>如图所示，改变物体变换轴心点为游标，物体的旋转则以游标为轴心</p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/8.png"></p><h2 id="3-原点"><a href="#3-原点" class="headerlink" title="3.原点"></a>3.原点</h2><p>物体的变换皆以原点为中心。</p><p>举例：如果不改变原点位置，则会进行下列变换</p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/9.png"></p><p>物体以原点为中心进行缩放。</p><blockquote><p>变换原点</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/10.png"></p><p>如图所示，使变换仅改变原点的位置。</p><p>在正视图的视角下，改变原点的位置，缩放将以该点为中心。</p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/11.png"></p><h2 id="4-偏好设置"><a href="#4-偏好设置" class="headerlink" title="4.偏好设置"></a>4.偏好设置</h2><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/12.png"></p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/13.png"></p><h2 id="5-变换轴心点"><a href="#5-变换轴心点" class="headerlink" title="5.变换轴心点"></a>5.变换轴心点</h2><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/14.png"></p><blockquote><p>边界框中心</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/15.png"></p><blockquote><p>各自的原点</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/16.png"></p><blockquote><p>质心点</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/17.png"></p><blockquote><p>活动元素</p></blockquote><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/18.png"></p><p>以最后一个选中的对象为中心，即中点为黄色的点。</p><h2 id="6-坐标"><a href="#6-坐标" class="headerlink" title="6.坐标"></a>6.坐标</h2><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/19.png"></p><blockquote><p>全局坐标</p></blockquote><p>世界坐标，即东南西北。</p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/20.png"></p><p>如图所示，全局坐标下，坐标轴不会随着物体的旋转而改变。</p><blockquote><p>局部坐标</p></blockquote><p>自身坐标，即上下左右。</p><p><img src="/2023/12/08/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Blender%E7%95%8C%E9%9D%A2%E8%AE%A4%E8%AF%86/21.png"></p><p>如图所示，局部坐标下，坐标轴随着物体方向的改变而改变。</p><blockquote><p>切换全局 &#x2F; 局部</p></blockquote><p>先按快捷键并选择固定轴，再按一次选择轴即可切换。</p><p>举例：<code>G + Z (局部) + Z (全局)</code></p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>迭代器和itertools库的使用！☃️</title>
    <link href="/2023/12/08/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%AD%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8Citertools%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/12/08/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%AD%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8Citertools%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="迭代器和itertools库的使用"><a href="#迭代器和itertools库的使用" class="headerlink" title="迭代器和itertools库的使用"></a>迭代器和itertools库的使用</h1><h2 id="1-迭代器"><a href="#1-迭代器" class="headerlink" title="1.迭代器"></a>1.迭代器</h2><p>在Python中，迭代器（Iterator）是一种对象，它可以用来遍历可迭代对象中的元素，如列表、元组、字典等。迭代器对象实现了两个方法：<code>__iter__()</code> 和 <code>__next__()</code>。</p><h3 id="1-自定义迭代器"><a href="#1-自定义迭代器" class="headerlink" title="1.自定义迭代器"></a>1.自定义迭代器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建一个简单的迭代器类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyIterator</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, start, end</span>):<br>        self.current = start<br>        self.end = end<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__next__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">if</span> self.current &lt; self.end:<br>            result = self.current<br>            self.current += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">return</span> result<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> StopIteration<br><br><span class="hljs-comment"># 使用迭代器遍历元素</span><br>my_iterator = MyIterator(<span class="hljs-number">1</span>, <span class="hljs-number">5</span>)<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> my_iterator:<br>    <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure><p>在上面的例子中，<code>MyIterator</code> 类实现了 <code>__iter__()</code> 和 <code>__next__()</code> 方法。<code>__iter__()</code> 方法返回迭代器对象本身，而 <code>__next__()</code> 方法用于返回迭代器的下一个元素。当没有元素可以返回时，抛出 <code>StopIteration</code> 异常，表示迭代结束。</p><h3 id="2-内置可迭代对象"><a href="#2-内置可迭代对象" class="headerlink" title="2.内置可迭代对象"></a>2.内置可迭代对象</h3><p>除了自定义迭代器类之外，Python内置了一些可迭代对象，比如列表、元组、字典等。你可以使用 <code>iter()</code> 函数获取这些对象的迭代器，然后使用 <code>next()</code> 函数逐个获取元素。</p><p>以下是一个使用内置函数的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">my_list = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>my_iterator = <span class="hljs-built_in">iter</span>(my_list)<br><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        item = <span class="hljs-built_in">next</span>(my_iterator)<br>        <span class="hljs-built_in">print</span>(item)<br>    <span class="hljs-keyword">except</span> StopIteration:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><p>注意：在实际编码中，通常使用 <code>for</code> 循环来遍历可迭代对象，而不是直接操作迭代器。<code>for</code> 循环会自动处理迭代器的创建和异常。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">my_list = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> my_list:<br>    <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure><h3 id="3-使用Iterator泛型来表示迭代器"><a href="#3-使用Iterator泛型来表示迭代器" class="headerlink" title="3.使用Iterator泛型来表示迭代器"></a>3.使用<code>Iterator</code>泛型来表示迭代器</h3><p>在Python中，<code>typing</code>模块提供了类型提示工具，但是它本身并不包含迭代器类型。迭代器类型通常用于表示可以迭代的对象，例如列表、元组和字典等。在<code>typing</code>模块中，你可以使用<code>Iterator</code>泛型来表示迭代器。</p><p>以下是一个简单的例子，演示如何在<code>typing</code>中使用<code>Iterator</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Iterator, <span class="hljs-type">List</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">iterate_list</span>(<span class="hljs-params">input_list: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; Iterator[<span class="hljs-built_in">int</span>]:<br>    <span class="hljs-comment"># 使用 iter() 函数将列表转换为迭代器</span><br>    iterator = <span class="hljs-built_in">iter</span>(input_list)<br>    <span class="hljs-keyword">return</span> iterator<br><br><span class="hljs-comment"># 示例用法</span><br>my_list = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<br>my_iterator = iterate_list(my_list)<br><br><span class="hljs-comment"># 使用迭代器遍历元素</span><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> my_iterator:<br>    <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure><p>在上述示例中，<code>iterate_list</code>函数接受一个<code>List[int]</code>类型的参数，并返回一个<code>Iterator[int]</code>类型的迭代器。在函数内部，我们使用<code>iter()</code>函数将传入的列表转换为迭代器，并将其返回。</p><p>需要注意的是，<code>Iterator</code>泛型只是一个类型提示，它在运行时并不会引入新的迭代器对象。它主要用于静态类型检查，以帮助开发者在编写代码时更好地理解和维护代码。</p><p>总的来说，<code>typing</code>模块提供了一些用于类型提示的工具，但在处理实际的迭代器时，主要还是使用Python标准库中的<code>iter</code>和<code>next</code>等迭代器相关的函数。</p><h2 id="2-itertools库的使用"><a href="#2-itertools库的使用" class="headerlink" title="2.itertools库的使用"></a>2.itertools库的使用</h2><p><code>itertools</code> 是 Python 中的一个标准库模块，提供了一组用于高效循环和迭代的工具函数。这些函数返回的是迭代器，而不是将所有元素一次性加载到内存中的序列。这对于处理大型数据集或者生成无限序列非常有用。</p><h3 id="1-itertools-count-start-0-step-1"><a href="#1-itertools-count-start-0-step-1" class="headerlink" title="1.itertools.count(start&#x3D;0, step&#x3D;1)"></a>1.<strong>itertools.count(start&#x3D;0, step&#x3D;1)</strong></h3><p><strong>用法：</strong> 从指定的起始值开始创建一个无限计数器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> count<br><br>counter = count(start=<span class="hljs-number">5</span>, step=<span class="hljs-number">2</span>)<br>result = [<span class="hljs-built_in">next</span>(counter) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]<br><span class="hljs-built_in">print</span>(result)<br><br>&gt;&gt;&gt;[<span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>, <span class="hljs-number">11</span>, <span class="hljs-number">13</span>]<br></code></pre></td></tr></table></figure><h3 id="2-itertools-cycle-iterable"><a href="#2-itertools-cycle-iterable" class="headerlink" title="2.itertools.cycle(iterable)"></a>2.<strong>itertools.cycle(iterable)</strong></h3><p><strong>用法：</strong> 创建一个无限循环的迭代器，重复迭代指定的可迭代对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> cycle<br><br>colors = cycle([<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>])<br>result = [<span class="hljs-built_in">next</span>(colors) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br><span class="hljs-built_in">print</span>(result)<br><br>&gt;&gt;&gt;[<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>, <span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>, <span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>]<br></code></pre></td></tr></table></figure><h3 id="3-itertools-chain-iterables"><a href="#3-itertools-chain-iterables" class="headerlink" title="3.itertools.chain(*iterables)"></a>3.<strong>itertools.chain(*iterables)</strong></h3><p><strong>用法：</strong> 将多个可迭代对象链接成一个迭代器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> chain<br><br>list1 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br>tuple1 = (<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>)<br>result = <span class="hljs-built_in">list</span>(chain(list1, tuple1))<br><span class="hljs-built_in">print</span>(result)<br><br>&gt;&gt;&gt;[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&#x27;c&#x27;</span>]<br></code></pre></td></tr></table></figure><h3 id="4-itertools-combinations-iterable-r"><a href="#4-itertools-combinations-iterable-r" class="headerlink" title="4.itertools.combinations(iterable, r)"></a>4.<strong>itertools.combinations(iterable, r)</strong></h3><p><strong>用法：</strong> 返回可迭代对象中所有长度为 <code>r</code> 的组合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> combinations<br><br>colors = [<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>]<br>result = <span class="hljs-built_in">list</span>(combinations(colors, <span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(result)<br><br>&gt;&gt;&gt;[(<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;green&#x27;</span>), (<span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>), (<span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;blue&#x27;</span>)]<br></code></pre></td></tr></table></figure><h3 id="5-itertools-product-iterables-repeat-1"><a href="#5-itertools-product-iterables-repeat-1" class="headerlink" title="5.itertools.product(*iterables, repeat&#x3D;1)"></a>5.<strong>itertools.product(*iterables, repeat&#x3D;1)</strong></h3><p><strong>用法：</strong> 返回可迭代对象的笛卡尔积，可选择重复元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> product<br><br>dice = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]<br>result = <span class="hljs-built_in">list</span>(product(dice, repeat=<span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(result)<br><br>&gt;&gt;&gt;[(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), ..., (<span class="hljs-number">6</span>, <span class="hljs-number">6</span>)]<br></code></pre></td></tr></table></figure><p>这些例子涵盖了一些常见的 <code>itertools</code> 函数，但该模块还提供了其他有用的工具，可以根据具体需求选择合适的函数。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ABC库的使用！☃️</title>
    <link href="/2023/12/08/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pythonABC%E5%BA%93/"/>
    <url>/2023/12/08/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/pythonABC%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="ABC库的使用"><a href="#ABC库的使用" class="headerlink" title="ABC库的使用"></a>ABC库的使用</h1><p>在Python中，<code>abc</code>库是Abstract Base Classes（抽象基类）的缩写。抽象基类是一种用于定义抽象数据类型或接口的方式，它们提供了一种机制来确保子类实现了特定的方法。<code>abc</code>模块提供了用于创建和使用抽象基类的工具。</p><p>以下是一些<code>abc</code>模块中常用的类和函数。</p><h2 id="1-ABC（Abstract-Base-Class）"><a href="#1-ABC（Abstract-Base-Class）" class="headerlink" title="1.ABC（Abstract Base Class）"></a>1.<strong>ABC（Abstract Base Class）</strong></h2><p><code>ABC</code>类是所有抽象基类的基类。通过继承<code>ABC</code>类，可以定义一个抽象基类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyAbstractClass</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_abstract_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><h2 id="2-abstractmethod-装饰器"><a href="#2-abstractmethod-装饰器" class="headerlink" title="2.@abstractmethod 装饰器"></a>2.<strong>@abstractmethod 装饰器</strong></h2><p>使用<code>@abstractmethod</code>装饰器可以标记一个方法为抽象方法，该方法必须在子类中实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyAbstractClass</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_abstract_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><h2 id="3-register-方法"><a href="#3-register-方法" class="headerlink" title="3.register 方法"></a>3.<strong>register 方法</strong></h2><p>使用<code>register</code>方法可以将一个类注册为抽象基类的虚拟子类，即使它并不直接继承自该抽象基类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyAbstractClass</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_abstract_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br><span class="hljs-comment"># Registering a class as a virtual subclass</span><br>MyConcreteClass = <span class="hljs-built_in">type</span>(<span class="hljs-string">&#x27;MyConcreteClass&#x27;</span>, (MyAbstractClass,), &#123;&#125;)<br>MyAbstractClass.register(MyConcreteClass)<br></code></pre></td></tr></table></figure><h2 id="4-实例检查"><a href="#4-实例检查" class="headerlink" title="4.实例检查"></a>4.<strong>实例检查</strong></h2><p>使用<code>isinstance</code>函数可以检查一个对象是否是特定抽象基类的实例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyAbstractClass</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_abstract_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyConcreteClass</span>(<span class="hljs-title class_ inherited__">MyAbstractClass</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">my_abstract_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Concrete class implementation&quot;</span>)<br><br>obj = MyConcreteClass()<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">isinstance</span>(obj, MyAbstractClass))  <span class="hljs-comment"># True</span><br></code></pre></td></tr></table></figure><p><strong>总结：</strong><code>abc</code>模块的主要目的是提供一种方式来定义和使用抽象基类，以确保在继承关系中正确地实现了必需的接口或方法。这有助于提高代码的可维护性和可读性。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python魔术方法使用！🍩</title>
    <link href="/2023/12/07/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%E5%A4%A7%E5%85%A8/"/>
    <url>/2023/12/07/%E7%AE%97%E6%B3%95/python/python%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7/python%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%E5%A4%A7%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="python魔术方法使用"><a href="#python魔术方法使用" class="headerlink" title="python魔术方法使用"></a>python魔术方法使用</h1><p>所谓魔法函数（Magic Methods），是Python的一种高级语法，允许你在类中自定义函数，并绑定到类的特殊方法中。比如在类A中自定义__str__()函数，则在调用str(A())时，会自动调用__str__()函数，并返回相应的结果。</p><p>Python 的类以其神奇的方法而闻名，通常称为 dunder（双下划线）方法。下面先列举Python里面的魔术方法，挑一些常用的魔术方法进行学习。</p><h2 id="1-魔术方法索引"><a href="#1-魔术方法索引" class="headerlink" title="1.魔术方法索引"></a>1.魔术方法索引</h2><h3 id="1-二元操作符"><a href="#1-二元操作符" class="headerlink" title="1.二元操作符"></a>1.二元操作符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">+<span class="hljs-built_in">object</span>.__add__(self, other)<br>-<span class="hljs-built_in">object</span>.__sub__(self, other)<br>*<span class="hljs-built_in">object</span>.__mul__(self, other)<br>//<span class="hljs-built_in">object</span>.__floordiv__(self, other)<br>/<span class="hljs-built_in">object</span>.__div__(self, other)<br>%<span class="hljs-built_in">object</span>.__mod__(self, other)<br>**<span class="hljs-built_in">object</span>.__pow__(self, other[, modulo])<br>&lt;&lt;<span class="hljs-built_in">object</span>.__lshift__(self, other)<br>&gt;&gt;<span class="hljs-built_in">object</span>.__rshift__(self, other)<br>&amp;<span class="hljs-built_in">object</span>.__and__(self, other)<br>^<span class="hljs-built_in">object</span>.__xor__(self, other)<br>|<span class="hljs-built_in">object</span>.__or__(self, other)<br></code></pre></td></tr></table></figure><h3 id="2-扩展二元操作符"><a href="#2-扩展二元操作符" class="headerlink" title="2.扩展二元操作符"></a>2.扩展二元操作符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">+=<span class="hljs-built_in">object</span>.__iadd__(self, other)<br>-=<span class="hljs-built_in">object</span>.__isub__(self, other)<br>*=<span class="hljs-built_in">object</span>.__imul__(self, other)<br>/=<span class="hljs-built_in">object</span>.__idiv__(self, other)<br>//=<span class="hljs-built_in">object</span>.__ifloordiv__(self, other)<br>%=<span class="hljs-built_in">object</span>.__imod__(self, other)<br>**=<span class="hljs-built_in">object</span>.__ipow__(self, other[, modulo])<br>&lt;&lt;=<span class="hljs-built_in">object</span>.__ilshift__(self, other)<br>&gt;&gt;=<span class="hljs-built_in">object</span>.__irshift__(self, other)<br>&amp;=<span class="hljs-built_in">object</span>.__iand__(self, other)<br>^=<span class="hljs-built_in">object</span>.__ixor__(self, other)<br>|=<span class="hljs-built_in">object</span>.__ior__(self, other)<br></code></pre></td></tr></table></figure><h3 id="3-一元操作符"><a href="#3-一元操作符" class="headerlink" title="3.一元操作符"></a>3.一元操作符</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">-<span class="hljs-built_in">object</span>.__neg__(self)<br>+<span class="hljs-built_in">object</span>.__pos__(self)<br><span class="hljs-built_in">abs</span>()<span class="hljs-built_in">object</span>.__abs__(self)<br>~<span class="hljs-built_in">object</span>.__invert__(self)<br><span class="hljs-built_in">complex</span>()<span class="hljs-built_in">object</span>.__complex__(self)<br><span class="hljs-built_in">int</span>()<span class="hljs-built_in">object</span>.__int__(self)<br>long()<span class="hljs-built_in">object</span>.__long__(self)<br><span class="hljs-built_in">float</span>()<span class="hljs-built_in">object</span>.__float__(self)<br><span class="hljs-built_in">oct</span>()<span class="hljs-built_in">object</span>.__oct__(self)<br><span class="hljs-built_in">hex</span>()<span class="hljs-built_in">object</span>.__hex__(self)<br><span class="hljs-built_in">round</span>()<span class="hljs-built_in">object</span>.__round__(self, n)<br>floor()object__floor__(self)<br>ceil()<span class="hljs-built_in">object</span>.__ceil__(self)<br>trunc()<span class="hljs-built_in">object</span>.__trunc__(self)<br></code></pre></td></tr></table></figure><h3 id="4-比较函数"><a href="#4-比较函数" class="headerlink" title="4.比较函数"></a>4.比较函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">&lt;<span class="hljs-built_in">object</span>.__lt__(self, other)<br>&lt;=<span class="hljs-built_in">object</span>.__le__(self, other)<br>==<span class="hljs-built_in">object</span>.__eq__(self, other)<br>!=<span class="hljs-built_in">object</span>.__ne__(self, other)<br>&gt;=<span class="hljs-built_in">object</span>.__ge__(self, other)<br>&gt;<span class="hljs-built_in">object</span>.__gt__(self, other)<br></code></pre></td></tr></table></figure><h3 id="5-类的表示、输出"><a href="#5-类的表示、输出" class="headerlink" title="5.类的表示、输出"></a>5.类的表示、输出</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">str</span>()<span class="hljs-built_in">object</span>.__str__(self) <br><span class="hljs-built_in">repr</span>()<span class="hljs-built_in">object</span>.__repr__(self)<br><span class="hljs-built_in">len</span>()<span class="hljs-built_in">object</span>.__len__(self)<br><span class="hljs-built_in">hash</span>()<span class="hljs-built_in">object</span>.__hash__(self) <br><span class="hljs-built_in">bool</span>()<span class="hljs-built_in">object</span>.__nonzero__(self) <br><span class="hljs-built_in">dir</span>()<span class="hljs-built_in">object</span>.__dir__(self)<br>sys.getsizeof()<span class="hljs-built_in">object</span>.__sizeof__(self)<br></code></pre></td></tr></table></figure><h3 id="6-类容器"><a href="#6-类容器" class="headerlink" title="6.类容器"></a>6.类容器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">len</span>()<span class="hljs-built_in">object</span>.__len__(self)<br>self[key]<span class="hljs-built_in">object</span>.__getitem__(self, key)<br>self[key] = value<span class="hljs-built_in">object</span>.__setitem__(self, key, value)<br><span class="hljs-keyword">del</span>[key] <span class="hljs-built_in">object</span>.__delitem__(self, key)<br><span class="hljs-built_in">iter</span>()<span class="hljs-built_in">object</span>.__iter__(self)<br><span class="hljs-built_in">reversed</span>()<span class="hljs-built_in">object</span>.__reversed__(self)<br><span class="hljs-keyword">in</span>操作<span class="hljs-built_in">object</span>.__contains__(self, item)<br>字典key不存在时<span class="hljs-built_in">object</span>.__missing__(self, key)<br></code></pre></td></tr></table></figure><h2 id="2-常用魔术方法"><a href="#2-常用魔术方法" class="headerlink" title="2.常用魔术方法"></a>2.常用魔术方法</h2><h3 id="1-init"><a href="#1-init" class="headerlink" title="1.__init__"></a>1.<code>__init__</code></h3><p>它是一个类初始化器。 每当创建一个类的实例时，都会调用其 <code>__init__()</code>方法。 例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GetTest</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Greetings!!&#x27;</span>)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">another_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;I am another method which is not automatically called&#x27;</span>)<br></code></pre></td></tr></table></figure><p>可以看到在实例在创建后会立即调用 <code>__init__</code>。 还可以在初始化期间将参数传递给类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GetTest</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Greetings!! &#123;0&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(name))<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">another_method</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;I am another method which is not automatically called&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="2-getitem"><a href="#2-getitem" class="headerlink" title="2.__getitem__"></a>2.<code>__getitem__</code></h3><p>在类中实现 <code>__getitem__</code> 允许其实例使用<code>[]</code>（索引器）运算符。这是一个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GetTest</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.info = &#123;<br>            <span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;Yasoob&#x27;</span>,<br>            <span class="hljs-string">&#x27;country&#x27;</span>:<span class="hljs-string">&#x27;Pakistan&#x27;</span>,<br>            <span class="hljs-string">&#x27;number&#x27;</span>:<span class="hljs-number">12345812</span><br>        &#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self,i</span>):<br>        <span class="hljs-keyword">return</span> self.info[i]<br>    <br><span class="hljs-meta">&gt;&gt;&gt; </span>foo = GetTest()<br><span class="hljs-meta">&gt;&gt;&gt; </span>foo[<span class="hljs-string">&#x27;name&#x27;</span>]<br><span class="hljs-string">&#x27;Yasoob&#x27;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>foo[<span class="hljs-string">&#x27;number&#x27;</span>]<br><span class="hljs-number">12345812</span><br></code></pre></td></tr></table></figure><p>如果没有<code>__getitem__</code>方法，我们会遇到以下错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>foo[<span class="hljs-string">&#x27;name&#x27;</span>]<br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>TypeError: <span class="hljs-string">&#x27;GetTest&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;__getitem__&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="3-del"><a href="#3-del" class="headerlink" title="3.__del__"></a>3.<code>__del__</code></h3><p><strong>del</strong>()是delete的缩写，这是析构魔术方法。当一块空间没有了任何引用时 默认执行__del__回收这个类地址，一般我们不自定义__del__ 有可能会导致问题。</p><p>触发时机：当对象被内存回收的时候自动触发，有下面两种情况：<br>页面执行完毕回收所有变量<br>当多个对象指向同一地址，所有对象被del的时候<br>功能：对象使用完毕后资源回收<br>参数：一个self接受对象<br>返回值：无</p><blockquote><p>注意：程序自动调用<code>__del__()</code>方法，不需要我们手动调用。</p></blockquote><p>来看例子：现在我们有一个类，在<code>__del__()</code>中打印一些信息，以便我们看到<code>__del__()</code>的调用时机。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cat</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eat</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;我嘎嘎能吃&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__del__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ohohoh，我被销毁了&quot;</span>)<br></code></pre></td></tr></table></figure><p>现在我们对类实例化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======start======&gt;&quot;</span>)<br>cat1 = Cat()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======ends======&gt;&quot;</span>)<br></code></pre></td></tr></table></figure><p>程序的输出为：</p><blockquote><p>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;<br>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;ends&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;<br>ohohoh，我被销毁了</p></blockquote><p>出现上面现象的原因是在没有手动执行<code>del</code>的情况下，程序执行结束后自动触发析构方法。</p><p>继续，现在加一个实例化，并且我们<code>del</code>cat1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">cat1 = Cat()<br>cat2 = cat1<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======start======&gt;&quot;</span>)<br><span class="hljs-keyword">del</span> cat1<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======ends======&gt;&quot;</span>)<br></code></pre></td></tr></table></figure><p>程序的输出为：</p><blockquote><p>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;<br>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;ends&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;<br>ohohoh，我被销毁了</p></blockquote><p>既然我们在start与end中间删除了cat1，为啥程序还是在执行完后触发析构方法？这主要是因为cat2还在继续占用cat1的内存地址，所以会在cat2执行完毕后触发析构方法。</p><p>只要同时删除cat1和cat2，内存地址没有指向的值，这块内存被释放就会触发析构方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">cat1 = Cat()<br>cat2 = cat1<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======start======&gt;&quot;</span>)<br><span class="hljs-keyword">del</span> cat1<br><span class="hljs-keyword">del</span> cat2<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&lt;=======ends======&gt;&quot;</span>)<br></code></pre></td></tr></table></figure><p>程序的输出为：</p><blockquote><p>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;start&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;<br>ohohoh，我被销毁了<br>&lt;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;ends&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;</p></blockquote><p><strong>注意</strong>：如果这个对象产生了循环引用，并且实现了<code>__del__</code>方法，那么这个对象将得不到释放，从而产生内存泄漏。</p><h3 id="4-call"><a href="#4-call" class="headerlink" title="4.__call__"></a>4.<code>__call__</code></h3><p><strong>call</strong>()方法可以让类的实例具有类似于函数的行为，这进一步模糊了函数和对象之间的概念。</p><p>触发时机：把对象当作函数调用的时候自动触发<br>功能：模拟函数化操作<br>参数：参数不固定，至少一个self参数<br>返回值：看需求<br>其使用方式为：对象后面加括号，触发执行。即：对象() 或者 类()()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, *args, **kwargs</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;call....&#x27;</span>)<br><br><br>a = A()<br>a()  <span class="hljs-comment"># 自动调用__call__()</span><br></code></pre></td></tr></table></figure><p>来看个例子：使用<code>__call__()</code>方法实现斐波那契数列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Fibonacci</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, num</span>):<br>        a, b = <span class="hljs-number">1</span>, <span class="hljs-number">1</span><br>        lst = []<br>        <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">2</span>:<br>            lst.append(a)<br>            lst.append(b)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):<br>                lst.append(a)<br>                a, b = b, a + b<br>        <span class="hljs-keyword">return</span> lst<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>f = Fibonacci()<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(f(<span class="hljs-number">5</span>))<br>[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>]<br></code></pre></td></tr></table></figure><h3 id="5-slots"><a href="#5-slots" class="headerlink" title="5.__slots__"></a>5.<code>__slots__</code></h3><p>Python是一门动态语言，这使得我们可以在程序运行的时候给对象绑定新的属性或方法，这就是动态语言的灵活性。</p><p>我们先定义一个类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, age</span>):<br>        self._name = name<br>        self._age = age<br></code></pre></td></tr></table></figure><p>然后创建一个实例并<strong>动态为这个实例绑定一个属性和方法</strong>，但是为实例绑定的属性和方法对另一个实例并不起作用，如果需要应用在多个实例上，则需要将其绑定到类上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> types <span class="hljs-keyword">import</span> MethodType<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fly</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;I can fly~&#x27;</span>)<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1 = Person(<span class="hljs-string">&#x27;王大锤&#x27;</span>, <span class="hljs-number">18</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>p2 = Person(<span class="hljs-string">&#x27;爱丽丝&#x27;</span>, <span class="hljs-number">16</span>)<br>&gt;&gt;&gt;<br><span class="hljs-comment"># 动态绑定属性和方法</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.fly = MethodType(fly, p1)<br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.fly()<br>I can fly~<br>&gt;&gt;&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span>p2.fly()  <span class="hljs-comment"># p1绑定的属性和方法对p2无效</span><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;D:\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py&quot;</span>, line <span class="hljs-number">3331</span>, <span class="hljs-keyword">in</span> run_code<br>    <span class="hljs-built_in">exec</span>(code_obj, self.user_global_ns, self.user_ns)<br>  File <span class="hljs-string">&quot;&lt;ipython-input-31-07b12cf8c526&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    p2.fly()<br>AttributeError: <span class="hljs-string">&#x27;Person&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;fly&#x27;</span><br></code></pre></td></tr></table></figure><p>动态绑定确实方便，但是如果我们需要限定自定义类型的对象只能绑定某些属性要怎么办呢？<code>__slots__</code>可以解决这个需求。</p><p>定义类的时候，可以定义一个特殊的<code>__slots__</code>变量，来限制该类实例能添加的属性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    __slots__ = (<span class="hljs-string">&#x27;_name&#x27;</span>, <span class="hljs-string">&#x27;_age&#x27;</span>, <span class="hljs-string">&#x27;_gender&#x27;</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, age</span>):<br>        self._name = name<br>        self._age = age<br></code></pre></td></tr></table></figure><p>实例就不能再添加不在限定范围内的属性了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>p = Person(<span class="hljs-string">&#x27;陆七岁&#x27;</span>, <span class="hljs-number">7</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>p._gender = <span class="hljs-string">&#x27;男&#x27;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p._gender<br><span class="hljs-string">&#x27;男&#x27;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p._school = <span class="hljs-string">&#x27;Q小学&#x27;</span><br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;D:\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py&quot;</span>, line <span class="hljs-number">3331</span>, <span class="hljs-keyword">in</span> run_code<br>    <span class="hljs-built_in">exec</span>(code_obj, self.user_global_ns, self.user_ns)<br>  File <span class="hljs-string">&quot;&lt;ipython-input-36-c90af696bffa&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    p._school = <span class="hljs-string">&#x27;Q小学&#x27;</span><br>AttributeError: <span class="hljs-string">&#x27;Person&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;_school&#x27;</span><br></code></pre></td></tr></table></figure><p>但要注意的是，<strong>限制只是针对实例</strong>，<strong>类本身并不会被限制</strong>。怎么理解能？就是我们仍然可以通过类去添加属性或方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>Person._school = <span class="hljs-string">&#x27;Q小学&#x27;</span> <br><span class="hljs-meta">&gt;&gt;&gt; </span>Person._school<br><span class="hljs-string">&#x27;Q小学&#x27;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1._school<br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;D:\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py&quot;</span>, line <span class="hljs-number">3331</span>, <span class="hljs-keyword">in</span> run_code<br>    <span class="hljs-built_in">exec</span>(code_obj, self.user_global_ns, self.user_ns)<br>  File <span class="hljs-string">&quot;&lt;ipython-input-38-f12357d4471f&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    p1._school<br>AttributeError: <span class="hljs-string">&#x27;Person&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;_school&#x27;</span><br></code></pre></td></tr></table></figure><p>总结：</p><p>__slots__是针对类实例的限制，要添加属性或方法仍可以通过类去添加；<br>__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的。</p><h3 id="6-str"><a href="#6-str" class="headerlink" title="6.__str__"></a>6.<code>__str__</code></h3><p><code>__str__()</code>方法可以改变对象的字符串显示。在打印某个对象的时候，会调用这个对象的<code>__str__</code>方法，打印这个方法的返回值。</p><ul><li>触发时机：使用<code>print(对象)</code>或<code>str(对象)</code>时触发。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cat</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, sex</span>):<br>        self.name = name<br>        self.sex = sex<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__str__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;我是一只可爱的小<span class="hljs-subst">&#123;self.sex&#125;</span>猫咪，我的名字是<span class="hljs-subst">&#123;self.name&#125;</span>&quot;</span><br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>cat = Cat(<span class="hljs-string">&quot;小白&quot;</span>, <span class="hljs-string">&quot;公&quot;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(cat)<br>我是一只可爱的小公猫咪，我的名字是小白<br></code></pre></td></tr></table></figure><h3 id="7-repr"><a href="#7-repr" class="headerlink" title="7.__repr__"></a>7.<code>__repr__</code></h3><p><strong>repr</strong>()方法可以改变对象的字符串显示。__repr__魔术方法是用来表述某个对象在内存中的展示形式。如果在终端直接输入一个对象，然后按回车，那么将会执行这个对象的__repr__方法。</p><ul><li>此方法是<code>__str__()</code>的“备胎”，如果找不到<code>__str__()</code>就会找<code>__repr__()</code>方法。</li><li><code>%r</code>默认调用的是<code>__repr__()</code>方法，<code>%s</code>调用<code>__str__()</code>方法</li><li><code>repr()</code>方法默认调用<code>__repr__()</code>方法</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, age</span>):<br>        self.name = name<br>        self.age = age<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__str__</span>(<span class="hljs-params">self</span>):<br>        msg = <span class="hljs-string">&#x27;name:&#123;&#125;,age:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(self.name, self.age)<br>        <span class="hljs-keyword">return</span> msg<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        msg = <span class="hljs-string">&#x27;name---&gt;&#123;&#125;,age---&gt;&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(self.name, self.age)<br>        <span class="hljs-keyword">return</span> msg<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>a = A(<span class="hljs-string">&#x27;za&#x27;</span>, <span class="hljs-number">34</span>)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%s&#x27;</span> % a) <br>name:za, age:<span class="hljs-number">34</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%r&#x27;</span> % a)  <span class="hljs-comment"># 用 %r,默认调用__repr__()方法</span><br>name--&gt;za, age--&gt;<span class="hljs-number">34</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(a)  <span class="hljs-comment"># 有__str__()方法就会调用__str__()方法，没有就调用__repr__()方法</span><br>name:za, age:<span class="hljs-number">34</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">repr</span>(a))  <span class="hljs-comment"># repr()方法默认调用__repr__()方法</span><br>name--&gt;za, age--&gt;<span class="hljs-number">34</span><br></code></pre></td></tr></table></figure><p>注意：如果将几个对象扔到一个容器中（比如：列表），那么在打印这个容器的时候，会依次调用这个容器中的元素的<code>__repr__</code>方法。如果没有实现这个<code>__repr__</code>方法，那么得到的将是一个类名+地址的形式，这种形式的是不好理解的。</p><h3 id="8-new"><a href="#8-new" class="headerlink" title="8.__new__"></a>8.<code>__new__</code></h3><p>触发时机： 在实例化对时触发<br>参数：至少一个cls 接收当前类<br>返回值：必须返回一个对象实例<br>作用：实例化对象</p><blockquote><p>注意：实例化对象是<code>Object</code>类底层实现，其他类继承了<code>Object</code>的<code>__new__</code>才能够实现实例化对象。</p></blockquote><p>第一个例子：查看<code>__new__</code>方法的执行时机。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;__init__(): 我也被调用啦~&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__new__</span>(<span class="hljs-params">cls, *args, **kwargs</span>):  <span class="hljs-comment"># 重写后,不再创建对象</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;__new__(): 哈哈我被调用啦~&#x27;</span>)<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>per = Person()<br>__new__(): 哈哈我被调用啦~<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(per)<br><span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p><code>None</code>说明没有创建对象，因为我们重写了<code>__new__</code>方法，<code>__new__</code>方法不再具有创建对象的功能，只有打印的功能。</p><p>第二个例子：调用父类的<code>__new__</code>方法，创建当前对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;__init__(): 我也被调用啦~&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__new__</span>(<span class="hljs-params">cls, *args, **kwargs</span>): <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;__new__(): 哈哈我被调用啦~&#x27;</span>)<br>        ret = <span class="hljs-built_in">super</span>().__new__(cls)  <span class="hljs-comment"># 调用父类object的__new__方法创建对象</span><br>        <span class="hljs-keyword">return</span> ret<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>per = Person()<br>__new__(): 哈哈我被调用啦~<br>__init__(): 我也被调用啦~<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(per)<br>&lt;__main__.Person <span class="hljs-built_in">object</span> at <span class="hljs-number">0x0000020FA3892848</span>&gt;<br></code></pre></td></tr></table></figure><h3 id="9-eq"><a href="#9-eq" class="headerlink" title="9.__eq__"></a>9.<code>__eq__</code></h3><p>说到<code>__eq__()</code>魔法方法，就必须提到Python中的<code>is</code>和<code>==</code>。先来看看这两者的区别：</p><ul><li><code>is</code> 比较两个对象的 <code>id </code>值是否相等，是否指向同一个内存地址；</li><li><code>==</code> 比较的是两个对象的内容是否相等，即内存地址可以不一样，内容一样就可以了。</li></ul><p><code>==</code>在比较类时，会默认调用<code>object.__eq__</code>方法，默认比较两个对象的地址（id）。</p><p>第一个例子：<code>list1</code>和<code>list2</code>的值相同，但<code>id</code>不同，来看看<code>is</code>和<code>==</code>的区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>list1 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>list2 = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">id</span>(list1)) <br><span class="hljs-number">1759352803720</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">id</span>(list2))<br><span class="hljs-number">1759352804232</span><br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(list1 == list2)  <br><span class="hljs-literal">True</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(list1 <span class="hljs-keyword">is</span> list2)  <br><span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>第二个例子：类的比较：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cat</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, sex</span>):<br>        self.name = name<br>        self.sex = sex<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>c1 = Cat(<span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>c2 = Cat(<span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1.__dict__)  <br>&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-string">&#x27;sex&#x27;</span>: <span class="hljs-number">2</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c2.__dict__) <br>&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-string">&#x27;sex&#x27;</span>: <span class="hljs-number">2</span>&#125;<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1 == c2)  <span class="hljs-comment"># ==比较时默认调用object.__eq__方法，默认比较两个对象的地址</span><br><span class="hljs-literal">False</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1 <span class="hljs-keyword">is</span> c2) <br><span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>重写<code>__eq__()</code>方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cat</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, sex</span>):<br>        self.name = name<br>        self.sex = sex<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__eq__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> self.__dict__ == other.__dict__<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>c1 = Cat(<span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>c2 = Cat(<span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1.__dict__)  <br>&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-string">&#x27;sex&#x27;</span>: <span class="hljs-number">2</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c2.__dict__) <br>&#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;小白&#x27;</span>, <span class="hljs-string">&#x27;sex&#x27;</span>: <span class="hljs-number">2</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1 == c2)  <span class="hljs-comment"># ==比较时默认调用object.__eq__方法，默认比较两个对象的地址</span><br><span class="hljs-literal">True</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(c1 <span class="hljs-keyword">is</span> c2) <br><span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><h3 id="10-bool"><a href="#10-bool" class="headerlink" title="10.__bool__"></a>10.<code>__bool__</code></h3><ul><li>触发时机：使用<code>bool(对象)</code>的时候自动触发</li><li>功能：强转对象</li><li>参数：一个<code>self</code>接受当前对象</li><li>返回值：必须是布尔类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Cat</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, sex</span>):<br>        self.name = name<br>        self.sex = sex<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__bool__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>cat = Cat(<span class="hljs-string">&quot;小白&quot;</span>, <span class="hljs-string">&quot;公&quot;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">bool</span>(cat))<br><span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><h3 id="11-add"><a href="#11-add" class="headerlink" title="11.__add__"></a>11.<code>__add__</code></h3><p><code>__add__</code>与<code>__radd__</code>都是做加法，只是加法的顺序不一样，会调用不同的魔法函数。</p><ul><li>触发时机：使用对象进行运算相加的时候自动触发</li><li>功能：对象运算</li><li>参数：两个对象参数</li><li>返回值：运算后的值</li></ul><p>对象在加号的左侧时，自动调用<code>__add__()</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sum</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num</span>):<br>        self.num = num<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__add__</span>(<span class="hljs-params">self, other</span>):  <span class="hljs-comment"># 对象在加号+的左侧时,自动触发</span><br>        <span class="hljs-keyword">return</span> self.num + other<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>value = Sum(<span class="hljs-number">7</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>res = value + <span class="hljs-number">8</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(res)<br><span class="hljs-number">15</span><br></code></pre></td></tr></table></figure><p>对象在加号的右侧时，自动调用<code>__radd__()</code>函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sum</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num</span>):<br>        self.num = num<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__radd__</span>(<span class="hljs-params">self, other</span>):  <br>        <span class="hljs-keyword">return</span> self.num + other<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>value = Sum(<span class="hljs-number">7</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>res = <span class="hljs-number">10</span> + value<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(res)<br><span class="hljs-number">17</span><br></code></pre></td></tr></table></figure><p>举例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sum1</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num</span>):<br>        self.num = num<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__add__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> self.num + other<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Sum2</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num</span>):<br>        self.num = num<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__radd__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> self.num * <span class="hljs-number">2</span> + other<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>value1 = Sum1(<span class="hljs-number">10</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>value2 = Sum2(<span class="hljs-number">7</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>res = value1 + value2<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><p>分析：首先将<code>res=value1+value2</code>传入<code>Sum1</code>中，得出值<code>res=10+value2</code>，再将<code>res=10+value2</code>传入<code>Sum2</code>中，所以<code>res=14+10=24</code>。</p><h3 id="12-len"><a href="#12-len" class="headerlink" title="12.__len__"></a>12.<code>__len__</code></h3><ul><li>触发时机：使用len对象的时候自动触发</li><li>功能：用于检测对象中或者类中成员个数</li><li>参数：一个self接收当前对象</li><li>返回值：必须是<strong>整型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">List</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.num = []<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, x</span>):<br>        self.num.append(x)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.num)<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>l = <span class="hljs-type">List</span>()<br><span class="hljs-meta">&gt;&gt;&gt; </span>l.add(<span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(l))<br></code></pre></td></tr></table></figure><h3 id="13-dict"><a href="#13-dict" class="headerlink" title="13.__dict__"></a>13.<code>__dict__</code></h3><p>获取类或对象的的<strong>内部成员结构</strong>。主要用来获取用户自定义的属性，以及这个属性对应的值。返回的是一个<strong>字典</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>():<br>    name1 = <span class="hljs-string">&quot;Lsir&quot;</span><br>    name2 = <span class="hljs-string">&quot;Wsir&quot;</span><br>    name3 = <span class="hljs-string">&quot;Zsir&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">task1</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;task1&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">task2</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;tesk2&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">task3</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;task3&quot;</span>)<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(MyClass.__dict__)<br>&#123;<span class="hljs-string">&#x27;__module__&#x27;</span>: <span class="hljs-string">&#x27;__main__&#x27;</span>, <span class="hljs-string">&#x27;name1&#x27;</span>: <span class="hljs-string">&#x27;Lsir&#x27;</span>, <span class="hljs-string">&#x27;name2&#x27;</span>: <span class="hljs-string">&#x27;Wsir&#x27;</span>, <span class="hljs-string">&#x27;name3&#x27;</span>: <span class="hljs-string">&#x27;Zsir&#x27;</span>, <span class="hljs-string">&#x27;task1&#x27;</span>: &lt;function MyClass.task1 at <span class="hljs-number">0x0000020C16385558</span>&gt;, <span class="hljs-string">&#x27;task2&#x27;</span>: &lt;function MyClass.task2 at <span class="hljs-number">0x0000020C16385D38</span>&gt;, <span class="hljs-string">&#x27;task3&#x27;</span>: &lt;function MyClass.task3 at <span class="hljs-number">0x0000020C16385708</span>&gt;, <span class="hljs-string">&#x27;__dict__&#x27;</span>: &lt;attribute <span class="hljs-string">&#x27;__dict__&#x27;</span> of <span class="hljs-string">&#x27;MyClass&#x27;</span> objects&gt;, <span class="hljs-string">&#x27;__weakref__&#x27;</span>: &lt;attribute <span class="hljs-string">&#x27;__weakref__&#x27;</span> of <span class="hljs-string">&#x27;MyClass&#x27;</span> objects&gt;, <span class="hljs-string">&#x27;__doc__&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br></code></pre></td></tr></table></figure><p>和<code>dir</code>函数做一个区分。<code>dir</code>函数返回的是这个对象上拥有的所有属性，包括Python内置的属性和用户自己添加的，并且只是获取属性名字，不会获取这个属性对应的值。</p><h3 id="14-doc"><a href="#14-doc" class="headerlink" title="14.__doc__"></a>14.<code>__doc__</code></h3><p>获取类或对象内部文档。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        我是一个类，这里说明一些有用的信息</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-built_in">print</span>(MyClass.__doc__)<br><br>        我是一个类，这里说明一些有用的信息<br>    <br></code></pre></td></tr></table></figure><h3 id="15-name"><a href="#15-name" class="headerlink" title="15.__name__"></a>15.<code>__name__</code></h3><p>获取类名或函数名</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Class1</span>:<br>    <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">task1</span>(<span class="hljs-params">self, func1</span>):<br>        <span class="hljs-built_in">print</span>(func1.__name__)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;我是func1函数&quot;</span>)<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>obj = MyClass()<br><span class="hljs-meta">&gt;&gt;&gt; </span>obj.task1(func)<br>func<br><span class="hljs-meta">&gt;&gt;&gt; </span>obj.task1(Class1)<br>Class1<br></code></pre></td></tr></table></figure><h3 id="16-class"><a href="#16-class" class="headerlink" title="16.__class__"></a>16.<code>__class__</code></h3><p>获取当前对象获取的类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Class1</span>:<br>    <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>obj = Class1()<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(obj.__class__)<br>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;__main__.Class1&#x27;</span>&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(obj.__class__.__name__)<br>Class1<br></code></pre></td></tr></table></figure><h3 id="17-bases"><a href="#17-bases" class="headerlink" title="17.__bases__"></a>17.<code>__bases__</code></h3><p>获取一个类直接继承的所有父类，返回元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Class1</span>:<br>    <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Class2</span>:<br>    <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>(Class1, Class2):<br>    <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(MyClass.__bases__)<br>(&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;__main__.Class1&#x27;</span>&gt;, &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;__main__.Class2&#x27;</span>&gt;)<br></code></pre></td></tr></table></figure><h3 id="18-getattr"><a href="#18-getattr" class="headerlink" title="18.__getattr__"></a>18.<code>__getattr__</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Base</span>:<br>    n = <span class="hljs-number">0</span><br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Point</span>(<span class="hljs-title class_ inherited__">Base</span>):<br>    z = <span class="hljs-number">6</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.x = x<br>        self.y = y<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">show</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(self.x, self.y)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getattr__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">return</span> item<br>    <br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.x<br><span class="hljs-number">4</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.z<br><span class="hljs-number">6</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.n<br><span class="hljs-number">0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.t<br><span class="hljs-string">&#x27;t&#x27;</span><br></code></pre></td></tr></table></figure><p>实例属性会按照<strong>继承关系</strong>寻找，如果找不到，就会执行<code>__getattr__()</code>方法，如果没有这个方法，就会抛出<code>AttributeError</code>异常标识找不到属性。</p><h3 id="19-setattr"><a href="#19-setattr" class="headerlink" title="19.__setattr__"></a>19.<code>__setattr__</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Base</span>:<br>    n = <span class="hljs-number">0</span><br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Point</span>(<span class="hljs-title class_ inherited__">Base</span>):<br>    z = <span class="hljs-number">6</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.x = x<br>        self.y = y<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">show</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(self.x, self.y)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getattr__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">return</span> item<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__setattr__</span>(<span class="hljs-params">self, key, value</span>):<br>        <span class="hljs-built_in">print</span>(key, value)<br>        <br><span class="hljs-comment"># --------------------------------------------------</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1 = Point(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>x <span class="hljs-number">4</span><br>y <span class="hljs-number">5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.x)<br>x<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.z)<br><span class="hljs-number">6</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.n)<br><span class="hljs-number">0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.t)<br>t<br><span class="hljs-comment"># --------------------------------------------------</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.x = <span class="hljs-number">50</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.x)<br>x<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.__dict__)<br>&#123;&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.__dict__[<span class="hljs-string">&#x27;x&#x27;</span>] = <span class="hljs-number">60</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.__dict__)<br>&#123;<span class="hljs-string">&#x27;x&#x27;</span>: <span class="hljs-number">60</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span>p1.x<br><span class="hljs-number">60</span><br></code></pre></td></tr></table></figure><p>实例通过<code>.</code>点号设置属性，例如<code>self.x=x</code>，就会调用<code>__setattr__()</code>，属性要加到实例的<code>__dict__</code>中，就需要自己完成。</p><p><code>setattr()</code>方法，可以拦截堆实例属性的增加，修改操作，如果要设置生效，需要自己操作实例的<code>__dict__</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Base</span>:<br>    n = <span class="hljs-number">200</span><br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span>(<span class="hljs-title class_ inherited__">Base</span>):<br>    z = <span class="hljs-number">100</span><br>    d = &#123;&#125;<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.x = x<br>        <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;y&#x27;</span>, y)<br>        self.__dict__[<span class="hljs-string">&#x27;a&#x27;</span>] = <span class="hljs-number">5</span><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getattr__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-built_in">print</span>(item)<br>        <span class="hljs-keyword">return</span> self.d[item]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__setattr__</span>(<span class="hljs-params">self, key, value</span>):<br>        <span class="hljs-built_in">print</span>(key, value)<br>        self.d[key] = value<br>        <br><span class="hljs-meta">&gt;&gt;&gt; </span>a = A(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>x <span class="hljs-number">4</span><br>y <span class="hljs-number">5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(a.__dict__)<br>&#123;<span class="hljs-string">&#x27;a&#x27;</span>: <span class="hljs-number">5</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(A.__dict__)<br>A.__dict__<br>mappingproxy(&#123;<span class="hljs-string">&#x27;__module__&#x27;</span>: <span class="hljs-string">&#x27;__main__&#x27;</span>,<br>              <span class="hljs-string">&#x27;z&#x27;</span>: <span class="hljs-number">100</span>,<br>              <span class="hljs-string">&#x27;d&#x27;</span>: &#123;<span class="hljs-string">&#x27;x&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;y&#x27;</span>: <span class="hljs-number">5</span>&#125;,<br>              <span class="hljs-string">&#x27;__init__&#x27;</span>: &lt;function __main__.A.__init__(self, x, y)&gt;,<br>              <span class="hljs-string">&#x27;__getattr__&#x27;</span>: &lt;function __main__.A.__getattr__(self, item)&gt;,<br>              <span class="hljs-string">&#x27;__setattr__&#x27;</span>: &lt;function __main__.A.__setattr__(self, key, value)&gt;,<br>              <span class="hljs-string">&#x27;__doc__&#x27;</span>: <span class="hljs-literal">None</span>&#125;)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(a.x, a.y)<br>x<br>y<br><span class="hljs-number">4</span> <span class="hljs-number">5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(a.a)<br><span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><h3 id="20-delattr"><a href="#20-delattr" class="headerlink" title="20.__delattr__"></a>20.<code>__delattr__</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Point</span>:<br>    z = <span class="hljs-number">5</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.x = x<br>        self.y = y<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__delattr__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-built_in">print</span>(item)<br>        p = Point(<span class="hljs-number">14</span>, <span class="hljs-number">5</span>)<br><br>        <br><span class="hljs-meta">&gt;&gt;&gt; </span>p = Point(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> p.x<br>x<br><span class="hljs-meta">&gt;&gt;&gt; </span>p.z=<span class="hljs-number">15</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> p.z<br>z<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> p.Z        <br>Z<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(Point.__dict__)<br>&#123;<span class="hljs-string">&#x27;__module__&#x27;</span>: <span class="hljs-string">&#x27;__main__&#x27;</span>, <span class="hljs-string">&#x27;z&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;__init__&#x27;</span>: &lt;function Point.__init__ at <span class="hljs-number">0x0000019E93B01318</span>&gt;, <span class="hljs-string">&#x27;__delattr__&#x27;</span>: &lt;function Point.__delattr__ at <span class="hljs-number">0x0000019E93B013A8</span>&gt;, <span class="hljs-string">&#x27;__dict__&#x27;</span>: &lt;attribute <span class="hljs-string">&#x27;__dict__&#x27;</span> of <span class="hljs-string">&#x27;Point&#x27;</span> objects&gt;, <span class="hljs-string">&#x27;__weakref__&#x27;</span>: &lt;attribute <span class="hljs-string">&#x27;__weakref__&#x27;</span> of <span class="hljs-string">&#x27;Point&#x27;</span> objects&gt;, <span class="hljs-string">&#x27;__doc__&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br></code></pre></td></tr></table></figure><h3 id="21-getattribute"><a href="#21-getattribute" class="headerlink" title="21.__getattribute__"></a>21.<code>__getattribute__</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Base</span>:<br>    n = <span class="hljs-number">0</span><br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Point</span>(<span class="hljs-title class_ inherited__">Base</span>):<br>    z = <span class="hljs-number">6</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x, y</span>):<br>        self.x = x<br>        self.y = y<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getattr__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">return</span> item<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getattribute__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">return</span> item<br>     <br><span class="hljs-meta">&gt;&gt;&gt; </span>p1 = Point(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.__dict__)<br>__dict__<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.x)<br>x<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.z)<br>z<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.n)<br>n<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(p1.t)<br>t<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(Point.__dict__)<br>&#123;<span class="hljs-string">&#x27;__module__&#x27;</span>: <span class="hljs-string">&#x27;__main__&#x27;</span>, <span class="hljs-string">&#x27;z&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;__init__&#x27;</span>: &lt;function Point.__init__ at <span class="hljs-number">0x000001F5EB7063A8</span>&gt;, <span class="hljs-string">&#x27;__getattr__&#x27;</span>: &lt;function Point.__getattr__ at <span class="hljs-number">0x000001F5EB706558</span>&gt;, <span class="hljs-string">&#x27;__getattribute__&#x27;</span>: &lt;function Point.__getattribute__ at <span class="hljs-number">0x000001F5EB706168</span>&gt;, <span class="hljs-string">&#x27;__doc__&#x27;</span>: <span class="hljs-literal">None</span>&#125;<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(Point.z)<br><span class="hljs-number">6</span><br></code></pre></td></tr></table></figure><p>实例的所有的属性访问，第一个都会调用__getattribute__方法，它阻止了属性的查找，该方法应该返回值或者抛出一个AttributeError异常。</p><ul><li>该方法的返回值将作为属性查找的结果。</li><li>如果抛出<code>AttributeError</code>异常，则会直接调用<code>__getattr__</code>方法，因为属性没有找到，<code>__getattribute__</code>方法中为了避免在该方法中无限递归，它的实现应该永远调用基类的同名方法以访问需要的任何属性。</li></ul><p>需要注意的是，除非明确知道__getattrtbute__方法用来做什么，否则不要使用。</p><h2 id="3-实例"><a href="#3-实例" class="headerlink" title="3.实例"></a>3.实例</h2><h3 id="3-1-setitem和getitem"><a href="#3-1-setitem和getitem" class="headerlink" title="3.1 setitem和getitem"></a>3.1 setitem和getitem</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.data = &#123;&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__setitem__</span>(<span class="hljs-params">self, key, value</span>):<br>        self.data[key] = value<br><br><span class="hljs-comment"># 创建 MyClass 实例</span><br>obj = MyClass()<br><br><span class="hljs-comment"># 使用 square bracket notation 进行赋值</span><br>obj[<span class="hljs-string">&#x27;name&#x27;</span>] = <span class="hljs-string">&#x27;John&#x27;</span><br>obj[<span class="hljs-string">&#x27;age&#x27;</span>] = <span class="hljs-number">30</span><br><br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-built_in">print</span>(obj.data)<br></code></pre></td></tr></table></figure><p>在这个例子中，<code>__setitem__</code> 方法允许我们使用类似字典赋值的语法（<code>obj[&#39;name&#39;] = &#39;John&#39;</code>）将数据存储到 <code>MyClass</code> 实例中。在这里，<code>obj.data</code> 将包含键值对 <code>&#123;&#39;name&#39;: &#39;John&#39;, &#39;age&#39;: 30&#125;</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.data = &#123;<span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;John&#x27;</span>, <span class="hljs-string">&#x27;age&#x27;</span>: <span class="hljs-number">30</span>&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">return</span> self.data.get(item, <span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># 创建 MyClass 实例</span><br>obj = MyClass()<br><br><span class="hljs-comment"># 使用方括号表示法获取元素</span><br>name = obj[<span class="hljs-string">&#x27;name&#x27;</span>]<br>age = obj[<span class="hljs-string">&#x27;age&#x27;</span>]<br>unknown_key = obj[<span class="hljs-string">&#x27;unknown_key&#x27;</span>]<br><br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-built_in">print</span>(name)  <span class="hljs-comment"># 输出: John</span><br><span class="hljs-built_in">print</span>(age)   <span class="hljs-comment"># 输出: 30</span><br><span class="hljs-built_in">print</span>(unknown_key)  <span class="hljs-comment"># 输出: None，因为键 &#x27;unknown_key&#x27; 在 data 中不存在</span><br></code></pre></td></tr></table></figure><p>在这个例子中，<code>__getitem__</code> 方法允许我们使用方括号表示法获取 <code>MyClass</code> 实例中的元素。如果请求的键在 <code>self.data</code> 字典中存在，则返回对应的值；否则返回 <code>None</code>。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python方法和技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>dataclasses库的使用！☃️</title>
    <link href="/2023/12/07/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADDataclasses%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/12/07/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADDataclasses%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="dataclasses库的使用"><a href="#dataclasses库的使用" class="headerlink" title="dataclasses库的使用"></a>dataclasses库的使用</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p><code>Dataclasses</code>是一些适合于存储数据对象（data object）的Python类。</p><p>他们存储并表示特定的数据类型。例如：一个数字。</p><p>并且他们能够被用于和同类型的其他对象进行比较。</p><h2 id="2-用法"><a href="#2-用法" class="headerlink" title="2.用法"></a>2.用法</h2><p>Python3.7 提供了一个装饰器<code>dataclass</code>，用以把一个类转化为<code>dataclass</code>。</p><p>你需要做的就是把类包裹进装饰器里：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass<br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span>:<br> ...<br></code></pre></td></tr></table></figure><h2 id="3-初始化"><a href="#3-初始化" class="headerlink" title="3.初始化"></a>3.初始化</h2><p>正常的初始化过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val</span>):<br>        self.val = val<br><span class="hljs-meta">&gt;&gt;&gt; </span>one = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>one.val<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>用<code>dataclass</code>是这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val:<span class="hljs-built_in">int</span> <br><span class="hljs-meta">&gt;&gt;&gt; </span>one = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>one.val<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>以下是<code>dataclass</code>装饰器带来的变化：</p><ol><li>无需定义<code>__init__</code>，然后将值赋给<code>self</code>，<code>dataclass</code>负责处理它</li><li>我们以更加易读的方式预先定义了成员属性，以及<strong>类型提示</strong>。我们现在立即能知道<code>val</code>是<code>int</code>类型。这无疑比一般定义类成员的方式更具可读性。</li></ol><p>它也可以定义默认值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val:<span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><h2 id="4-表示"><a href="#4-表示" class="headerlink" title="4.表示"></a>4.表示</h2><p>对象表示指的是对象的一个有意义的字符串表示，它在调试时非常有用。</p><p>默认的 Python 对象表示不是很直观：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val = <span class="hljs-number">0</span></span>):<br>    self.val = val<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;__main__.Number <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7ff395b2ccc0</span>&gt;<br></code></pre></td></tr></table></figure><p>这让我们无法知悉对象的作用，并且会导致糟糕的调试体验。</p><p>一个有意义的表示可以通过在类中定义一个<code>__repr__</code>方法来实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-keyword">return</span> self.val<br></code></pre></td></tr></table></figure><p>现在我们得到这个对象有意义的表示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><code>dataclass</code>会自动添加一个<code>__repr__</code>函数，这样我们就不必手动实现它了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br><span class="hljs-meta">&gt;&gt;&gt; </span>Number(val = <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h2 id="5-数据比较"><a href="#5-数据比较" class="headerlink" title="5.数据比较"></a>5.数据比较</h2><p>通常，数据对象之间需要相互比较。</p><p>两个对象<code>a</code>和<code>b</code>之间的比较通常包括以下操作：</p><ul><li>a &lt; b</li><li>a &gt; b</li><li>a &#x3D;&#x3D; b</li><li>a &gt;&#x3D; b</li><li>a &lt;&#x3D; b</li></ul><p>在 Python 中，能够在可以执行上述操作的类中定义方法。为了简单起见，只展示<code>==</code>和<code>&lt;</code>的实现。</p><p>通常这样写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"> self, val = <span class="hljs-number">0</span></span>):<br>       self.val = val<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__eq__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> self.val == other.val<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__lt__</span>(<span class="hljs-params">self, other</span>):<br>        <span class="hljs-keyword">return</span> self.val &lt; other.val<br></code></pre></td></tr></table></figure><p>使用<code>dataclass</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">order = <span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>我们不需要定义<code>__eq__</code>和<code>__lt__</code>方法，因为当<code>order = True</code>被调用时，<code>dataclass 装饰器</code>会自动将它们添加到我们的类定义中。</p><p>当你使用<code>dataclass</code>时，它会在类定义中添加函数<code>__eq__</code>和<code>__lt__</code>。</p><p>生成<code>__eq__</code>函数的 dataclass 类会比较两个属性构成的元组，一个由自己属性构成的，另一个由同类的其他实例的属性构成。在我们的例子中，自动生成的<code>__eq__</code>函数相当于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__eq__</span>(<span class="hljs-params">self, other</span>):<br>    <span class="hljs-keyword">return</span> (self.val,) == (other.val,)<br></code></pre></td></tr></table></figure><p>让我们来看一个更详细的例子：</p><p>我们会编写一个<code>dataclass</code>类<code>Person</code>来保存<code>name</code>和<code>age</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">order = <span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:<br>    name: <span class="hljs-built_in">str</span><br>    age:<span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>自动生成的<code>__eq__</code>方法等同于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__eq__</span>(<span class="hljs-params">self, other</span>):<br>    <span class="hljs-keyword">return</span> (self.name, self.age) == ( other.name, other.age)<br></code></pre></td></tr></table></figure><p>请注意属性的顺序。它们总是按照你在<code>dataclass</code>类中定义的顺序生成。</p><p>同样，等效的<code>__le__</code>函数类似于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__le__</span>(<span class="hljs-params">self, other</span>):<br>    <span class="hljs-keyword">return</span> (self.name, self.age) &lt;= (other.name, other.age)<br></code></pre></td></tr></table></figure><h2 id="6-dataclass-作为一个可调用的装饰器"><a href="#6-dataclass-作为一个可调用的装饰器" class="headerlink" title="6.dataclass 作为一个可调用的装饰器"></a>6.dataclass 作为一个可调用的装饰器</h2><p>定义所有的<strong>魔法方法</strong>（下一篇详细介绍）并不总是值得的。你的用例可能只包括存储值和检查相等性。因此，你只需定义<code>__init__</code>和<code>__eq__</code>方法。如果我们可以告诉装饰器不生成其他方法，那么它会减少一些开销，并且我们将在数据对象上有正确的操作。</p><p>幸运的是，这可以通过将<code>dataclass</code>装饰器作为可调用对象来实现。</p><p>装饰器可以用作具有如下参数的可调用对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">init=<span class="hljs-literal">True</span>, <span class="hljs-built_in">repr</span>=<span class="hljs-literal">True</span>, eq=<span class="hljs-literal">True</span>, order=<span class="hljs-literal">False</span>, unsafe_hash=<span class="hljs-literal">False</span>, frozen=<span class="hljs-literal">False</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">C</span>:<br> …<br></code></pre></td></tr></table></figure><ul><li><code>init</code>：默认将生成<code>__init__</code>方法。如果传入<code>False</code>，那么该类将不会有<code>__init__</code>方法。</li><li><code>repr</code>：<code>__repr__</code>方法默认生成。如果传入<code>False</code>，那么该类将不会有<code>__repr__</code>方法。</li><li><code>eq</code>：默认将生成<code>__eq__</code>方法。如果传入<code>False</code>，那么<code>__eq__</code>方法将不会被<code>dataclass</code>添加，但默认为<code>object.__eq__</code>。</li><li><code>order</code>：默认将生成<code>__gt__</code>、<code>__ge__</code>、<code>__lt__</code>、<code>__le__</code>方法。如果传入<code>False</code>，则省略它们。<br>我们在接下来会讨论<code>frozen</code>。由于<code>unsafe_hash</code>参数复杂的用例，它值得单独发布一篇文章。</li></ul><p>现在回到我们的用例，以下是我们需要的：</p><ol><li><strong>init</strong></li><li><strong>eq</strong></li></ol><p>默认会生成这些函数，因此我们需要的是不生成其他函数。那么我们该怎么做呢？很简单，只需将相关参数作为<code>false</code>传入给生成器即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params"><span class="hljs-built_in">repr</span> = <span class="hljs-literal">False</span></span>) </span><span class="hljs-comment"># order, unsafe_hash and frozen are False</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;__main__.Number <span class="hljs-built_in">object</span> at <span class="hljs-number">0x7ff395afe898</span>&gt;<br><span class="hljs-meta">&gt;&gt;&gt; </span>b = Number(<span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>c = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a == b<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-literal">False</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a &lt; b<br><span class="hljs-comment">#下列错误表示 &lt; 操作没有实现</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>Traceback (most recent call last):<br> File “&lt;stdin&gt;”, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>TypeError: ‘&lt;’ <span class="hljs-keyword">not</span> supported between instances of ‘Number’ <span class="hljs-keyword">and</span> ‘Number’<br></code></pre></td></tr></table></figure><h2 id="7-Frozen（不可变）-实例"><a href="#7-Frozen（不可变）-实例" class="headerlink" title="7.Frozen（不可变） 实例"></a>7.Frozen（不可变） 实例</h2><p>Frozen 实例是在初始化对象后无法修改其属性的对象。</p><blockquote><p>无法创建真正不可变的 Python 对象</p></blockquote><p>以下是我们期望不可变对象能够做到的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">10</span>) <span class="hljs-comment">#Assuming Number class is immutable</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.val = <span class="hljs-number">10</span> <span class="hljs-comment"># Raises Error</span><br></code></pre></td></tr></table></figure><p>有了<code>dataclass</code>，就可以通过使用<code>dataclass</code>装饰器作为可调用对象配合参数<code>frozen=True</code>来定义一个<code>frozen</code>对象。</p><p>当实例化一个<code>frozen</code>对象时，任何企图修改对象属性的行为都会引发<code>FrozenInstanceError</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">frozen = <span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Number</span>:<br>    val: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a.val<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.val = <span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>Traceback (most recent call last):<br> File “&lt;stdin&gt;”, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br> File “&lt;string&gt;”, line <span class="hljs-number">3</span>, <span class="hljs-keyword">in</span> __setattr__<br>dataclasses.FrozenInstanceError: cannot assign to field ‘val’<br></code></pre></td></tr></table></figure><p>因此，一个<code>frozen 实例</code>是一种很好方式来存储：</p><ul><li>常数</li><li>设置<br>这些通常不会在应用程序的生命周期内发生变化，任何企图修改它们的行为都应该被禁止。</li></ul><h2 id="8-后期初始化处理"><a href="#8-后期初始化处理" class="headerlink" title="8.后期初始化处理"></a>8.后期初始化处理</h2><p>有了<code>dataclass</code>，需要定义一个<code>__init__</code>方法来将变量赋给<code>self</code>这种初始化操作已经得到了处理。但是我们失去了在变量被赋值之后立即需要的函数调用或处理的灵活性。</p><p>让我们来讨论一个用例，在这个用例中，我们定义一个<code>Float</code>类来包含浮点数，然后在初始化之后立即计算整数和小数部分。</p><p>通常是这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Float</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, val = <span class="hljs-number">0</span></span>):<br>        self.val = val<br>        self.process()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">process</span>(<span class="hljs-params">self</span>):<br>        self.decimal, self.integer = math.modf(self.val)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Float( <span class="hljs-number">2.2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a.decimal<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.2000</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.integer<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2.0</span><br></code></pre></td></tr></table></figure><p>幸运的是，使用<strong>post_init</strong>方法已经能够处理后期初始化操作。</p><p>生成的<code>__init__</code>方法在返回之前调用<code>__post_init__</code>返回。因此，可以在函数中进行任何处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FloatNumber</span>:<br>    val: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">self</span>):<br>        self.decimal, self.integer = math.modf(self.val)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = Number(<span class="hljs-number">2.2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a.val<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2.2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.integer<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2.0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.decimal<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.2</span><br></code></pre></td></tr></table></figure><h2 id="9-继承"><a href="#9-继承" class="headerlink" title="9.继承"></a>9.继承</h2><p><code>Dataclasses</code>支持继承，就像普通的<code>Python</code>类一样。</p><p>因此，父类中定义的属性将在子类中可用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:<br>    age: <span class="hljs-built_in">int</span> = <span class="hljs-number">0</span><br>    name: <span class="hljs-built_in">str</span><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Student</span>(<span class="hljs-title class_ inherited__">Person</span>):<br>    grade: <span class="hljs-built_in">int</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>s = Student(<span class="hljs-number">20</span>, <span class="hljs-string">&quot;John Doe&quot;</span>, <span class="hljs-number">12</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>s.age<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">20</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>s.name<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-string">&quot;John Doe&quot;</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>s.grade<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">12</span><br></code></pre></td></tr></table></figure><p>请注意，<code>Student</code>的参数是在类中定义的字段的顺序。</p><p>继承过程中<code>__post_init__</code>的行为是怎样的？</p><p>由于<code>__post_init__</code>只是另一个函数，因此必须以传统方式调用它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span>:<br>    a: <span class="hljs-built_in">int</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;A&quot;</span>)<br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span>(<span class="hljs-title class_ inherited__">A</span>):<br>    b: <span class="hljs-built_in">int</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;B&quot;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = B(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>B<br></code></pre></td></tr></table></figure><p>在上面的例子中，只有<code>B</code>的<code>__post_init__</code>被调用，那么我们如何调用<code>A</code>的<code>__post_init__</code>呢？</p><p>因为它是父类的函数，所以可以用<code>super</code>来调用它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span>(<span class="hljs-title class_ inherited__">A</span>):<br>    b: <span class="hljs-built_in">int</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__post_init__() <span class="hljs-comment"># 调用 A 的 post init</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;B&quot;</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = B(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>A<br>    B<br></code></pre></td></tr></table></figure><h2 id="10-field"><a href="#10-field" class="headerlink" title="10.field"></a>10.field</h2><p>我们已经知道<code>Dataclasses</code>会生成他们自身的<code>__init__</code>方法。它同时把初始化的值赋给这些字段。</p><ul><li>变量名</li><li>数据类型</li></ul><p>这些内容仅给我们有限的<code>dataclass</code>字段使用范围。让我们讨论一下这些局限性，以及它们如何通过<code>dataclass.field</code>被解决。</p><h3 id="1-复合初始化"><a href="#1-复合初始化" class="headerlink" title="1.复合初始化"></a>1.复合初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_random_marks</span>():<br>    retun [random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Student</span>:<br>    marks:<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__post_init__</span>(<span class="hljs-params">seif</span>):<br>    self.marks = get_random_marks() <span class="hljs-comment">#Assign random speeds</span><br><br>&gt;&gt;&gt;a= Student()<br>&gt;&gt;&gt;a.marks<br>&gt;&gt;&gt;[<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">9</span>]<br></code></pre></td></tr></table></figure><p>数据类<code>Student</code>产生了一个名为<code>marks</code>的列表。我们不传递<code>marks</code>的值，而是使用<code>__post_init__</code>方法初始化。这是我们定义的单一属性。此外，我们必须在<code>__post_init__</code>里调用<code>get_random_marks</code>函数。这些工作是额外的。</p><p>辛运的是，<code>Python</code>为我们提供了一个解决方案。我们可以使用<code>dataclasses.field</code>来定制化<code>dataclass</code>字段的行为以及它们在<code>dataclass</code>的影响。</p><p>仍然是上述的使用情形，让我们从<code>__post_init__</code>里去除<code>get_random_marks</code>的调用。以下是使用<code>dataclasses.field</code>的情形：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> field<br><span class="hljs-meta">@dataclass</span><br>c1ass Student:<br>marks:<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]= field(default_factory=get_random_marks)<br>&gt;&gt;&gt;s = Student()<br>&gt;&gt;&gt;s.marks<br>&gt;&gt;&gt;[<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">9</span>]<br></code></pre></td></tr></table></figure><p><code>dataclasses.field</code>接受了一个名为<code>default_factory</code>的参数，它的作用是：如果在创建对象时没有赋值，则使用该方法初始化该字段。</p><p><code>default_factory</code>必须是一个可以调用的无参数方法（通常为一个函数）。</p><h3 id="2-使用全部字段进行数据比较"><a href="#2-使用全部字段进行数据比较" class="headerlink" title="2.使用全部字段进行数据比较"></a>2.使用全部字段进行数据比较</h3><p>我们了解到，<code>dataclass</code>能够自动生成<code>&lt;</code>,<code>=,&gt;</code>,<code>&lt;=</code>和<code>&gt;=</code>这些比较方法。但是这些比较方法的一个缺陷是，它们使用类中的所有字段进行比较，而这种情况往往不常见。更经常地，这种比较方法会给我们使用<code>dataclasses</code>造成麻烦。</p><p>考虑以下的使用情形：你有一个数据类用于存放用户的信息。现在，它可能存在以下字段：</p><ul><li>姓名</li><li>年龄</li><li>身高</li><li>体重</li></ul><p>你仅想比较用户对象的年龄、身高和体重。你不想比较姓名。这是后端开发者经常会遇到的使用情景。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">order=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>:<br>    name:<span class="hljs-built_in">str</span><br>    age：<span class="hljs-built_in">int</span><br>    height:<span class="hljs-built_in">float</span><br>weight:<span class="hljs-built_in">float</span><br></code></pre></td></tr></table></figure><p>自动生成的比较方法会比较以下的数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">(self.name，self.agerself.height， self.weight)<br></code></pre></td></tr></table></figure><p>这将会破坏我们的意图。我们不想让姓名<code>（name）</code>用于比较。那么，如何使用<code>dataclasses.field</code>来实现我们的想法呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">orde=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>:<br>name:<span class="hljs-built_in">str</span>=field(compare=<span class="hljs-literal">False</span>)<br>age:<span class="hljs-built_in">int</span><br>weight:<span class="hljs-built_in">float</span><br>height:<span class="hljs-built_in">float</span><br>&gt;&gt;&gt;user_1=User(<span class="hljs-string">&quot;John Doe&quot;</span>,<span class="hljs-number">23</span>,<span class="hljs-number">70</span>,<span class="hljs-number">1.70</span>)<br>&gt;&gt;&gt;user_2=User(<span class="hljs-string">&quot;Adam&quot;</span>,<span class="hljs-number">24</span>,<span class="hljs-number">65</span>,<span class="hljs-number">1.60</span>)<br>&gt;&gt;&gt;user_1&lt;user_2<br>&gt;&gt;&gt;<span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><p>默认情况下，所用的字段都用于比较，因此我们仅仅需要指定哪些字段用于比较，而实现方法是直接把不需要的字段定义为<code>filed（compare=False）</code>。</p><h3 id="3-使用全部字段进行数据表示"><a href="#3-使用全部字段进行数据表示" class="headerlink" title="3.使用全部字段进行数据表示"></a>3.使用全部字段进行数据表示</h3><p>自动生成的<code>__repr__</code>方法使用所有的字段用于表示。当然，这也不是大多数情形下的理想选择，尤其是当你的数据类有大量的字段时。单个对象的表示会变得异常臃肿，对调试来说也不利。</p><p>我们也能够个性化这种行为。考虑一个类似的使用场景，也许最合适的用于表示的属性是姓名（name）。那么对<code>__repr__</code>，我们仅使用它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass(<span class="hljs-params">order=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>:<br>name:<span class="hljs-built_in">str</span>=field(compare=false)<br>age:<span class="hljs-built_in">int</span>= field(<span class="hljs-built_in">repr</span>=<span class="hljs-literal">False</span>)<br>height:<span class="hljs-built_in">float</span>= field(<span class="hljs-built_in">repr</span>=<span class="hljs-literal">False</span>)<br>weight:<span class="hljs-built_in">float</span>= field(<span class="hljs-built_in">repr</span>=<span class="hljs-literal">False</span>)<br>city:<span class="hljs-built_in">str</span>=field(<span class="hljs-built_in">repr</span>=<span class="hljs-literal">False</span>,compare=<span class="hljs-literal">False</span>)<br>country:<span class="hljs-built_in">str</span>=field(<span class="hljs-built_in">repr</span>=<span class="hljs-literal">False</span>,compare=<span class="hljs-literal">False</span>)<br><br>&gt;&gt;&gt;a=User(<span class="hljs-string">&quot;john Doe&quot;</span>,<span class="hljs-number">24</span>,<span class="hljs-number">1.7</span>,<span class="hljs-number">70</span>,<span class="hljs-string">&quot;Massachusetts&quot;</span>,<span class="hljs-string">&quot;United States ofAmerica&quot;</span>)<br>&gt;&gt;&gt;b=User(<span class="hljs-string">&quot;Adam&quot;</span>,<span class="hljs-number">24</span>,<span class="hljs-number">1.6</span>,<span class="hljs-number">65</span>,<span class="hljs-string">&quot;San Jose&quot;</span>,<span class="hljs-string">&quot;United Statesof America&quot;</span>)<br><br>&gt;&gt;&gt;a<br>&gt;&gt;&gt;User(name=<span class="hljs-string">&#x27;john Doe&#x27;</span>)<br>&gt;&gt;&gt;b<br>&gt;&gt;&gt;User(name=<span class="hljs-string">&#x27;Adam&#x27;</span>)<br>&gt;&gt;&gt;b&gt;a<br>&gt;&gt;&gt;<span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><h3 id="4-从初始化中省略字段"><a href="#4-从初始化中省略字段" class="headerlink" title="4.从初始化中省略字段"></a>4.从初始化中省略字段</h3><p>目前为止我们看到的所有例子，都有一个共同特点——即我们需要为所有被声明的字段传递值，除了有默认值之外。在那种情形下（指有默认值的情况下），我们可以选择传递值，也可以不传递。</p><p>但是，还有一种情形：我们可能不想在初始化时设定某个字段的值。这也是一种常见的使用场景。也许你在追踪一个对象的状态，并且希望它在初始化时一直被设为<code>False</code>。更一般地，这个值在初始化时不能够被传递。</p><p>那么，我们如何实现上述想法呢？以下是具体内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span>:<br>email:<span class="hljs-built_in">str</span>= field(<span class="hljs-built_in">repr</span>= <span class="hljs-literal">True</span>)<br>verified:<span class="hljs-built_in">bool</span>=field(<span class="hljs-built_in">repr</span> = <span class="hljs-literal">False</span>,init=<span class="hljs-literal">False</span>,default=<span class="hljs-literal">False</span>)<br><span class="hljs-comment">#Omit verified from representation as well as __init__</span><br><br><br>&gt;&gt;&gt;a = User(<span class="hljs-string">&quot;a@test.com&quot;</span>)<br>&gt;&gt;&gt;User(email=<span class="hljs-string">&#x27;a@test.com&#x27;</span>)<br>&gt;&gt;&gt;a.verified<br>&gt;&gt;&gt;<span class="hljs-literal">False</span><br>        <br>        <br>&gt;&gt;&gt;b= User(<span class="hljs-string">&quot;betest.com&quot;</span>,<span class="hljs-literal">True</span>)<span class="hljs-comment">#Let us try to pass the value of verified</span><br>&gt;&gt;&gt;Traceback(most recent cal1 last):<br>    File<span class="hljs-string">&quot;&lt;stdin&gt;&quot;</span>,line1,<span class="hljs-keyword">in</span>&lt;module&gt;<br>TypeError:__init__()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>typing库的使用！☃️</title>
    <link href="/2023/12/06/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADtyping%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/12/06/%E7%AE%97%E6%B3%95/python/python%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/python%E4%B8%ADtyping%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="typing库的使用"><a href="#typing库的使用" class="headerlink" title="typing库的使用"></a>typing库的使用</h1><h2 id="1-基本介绍"><a href="#1-基本介绍" class="headerlink" title="1.基本介绍"></a>1.基本介绍</h2><ul><li><strong>typing模块的作用：</strong></li></ul><ol><li>类型检查，防止运行时出现参数和返回值类型不符合。</li><li>作为开发文档附加说明，方便使用者调用时传入和返回参数类型。</li><li>该模块加入后并不会影响程序的运行，不会报正式的错误，只有提醒。</li></ol><ul><li><strong>下面说说typing模块常用的方式：</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Tuple</span>, <span class="hljs-type">Dict</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a:<span class="hljs-built_in">int</span>, string:<span class="hljs-built_in">str</span>, f:<span class="hljs-built_in">float</span>, b:<span class="hljs-built_in">bool</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">List</span>, <span class="hljs-type">Tuple</span>, <span class="hljs-type">Dict</span>, <span class="hljs-built_in">bool</span>]:<br>    list1 = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(a))<br>    tup = (string, string, string)<br>    d = &#123;<span class="hljs-string">&quot;a&quot;</span>:f&#125;<br>    bl = b<br>    <span class="hljs-keyword">return</span> list1, tup, d,bl<br><span class="hljs-built_in">print</span>(add(<span class="hljs-number">5</span>,<span class="hljs-string">&quot;hhhh&quot;</span>, <span class="hljs-number">2.3</span>, <span class="hljs-literal">False</span>))<br><span class="hljs-comment"># 结果：([0, 1, 2, 3, 4], (&#x27;hhhh&#x27;, &#x27;hhhh&#x27;, &#x27;hhhh&#x27;), &#123;&#x27;a&#x27;: 2.3&#125;, False)</span><br></code></pre></td></tr></table></figure><ul><li><strong>说明：</strong></li><li>在传入参数时通过“参数名:类型”的形式声明参数的类型；</li><li>返回结果通过”-&gt; 结果类型”的形式声明结果的类型。</li><li>在调用的时候如果参数的类型不正确pycharm会有提醒，但不会影响程序的运行。</li><li>对于如list列表等，还可以规定得更加具体一些，如：“-&gt; List[str]”,规定返回的是列表，并且元素是字符串。</li><li><strong>由于python天生支持多态，迭代器中的元素可能多种，如下：</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">func</span>(<span class="hljs-params">a:<span class="hljs-built_in">int</span>, string:<span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">str</span>]:<br>    list1 = []<br>    list1.append(a)<br>    list1.append(string)<br>    <span class="hljs-keyword">return</span> list1<br><br><span class="hljs-comment"># 使用or关键字表示多种类型</span><br></code></pre></td></tr></table></figure><ul><li><strong>typing常用的类型：</strong></li><li>int,long,float: 整型,长整形,浮点型;</li><li>bool,str: 布尔型，字符串类型；</li><li>List, Tuple, Dict, Set:列表，元组，字典, 集合;</li><li>Iterable,Iterator:可迭代类型，迭代器类型；</li><li>Generator：生成器类型；</li></ul><h2 id="2-具体案例"><a href="#2-具体案例" class="headerlink" title="2.具体案例"></a>2.具体案例</h2><h3 id="2-1-typing的使用范围"><a href="#2-1-typing的使用范围" class="headerlink" title="2.1 typing的使用范围"></a>2.1 typing的使用范围</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataLoader</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;docstring for FileToProblemText.&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, user_config: UserConfig</span>):<br>        self.file_path = user_config.get_dataset_path()<br>        self.file_type = user_config.get_dataset_type()<br>        self.chunk_size = user_config.get_dataset_size()<br></code></pre></td></tr></table></figure><p>这段代码中的<code>user_config: UserConfig</code>不需要导入typing库，在Python 3.5及更高版本中，类型提示已经成为一种标准的语言特性。同时，对于返回值的类型提示<code>—&gt;</code>也不需要导入。</p><p>只有在泛型提示，即准确知道列表或字典中的数据类型时，才需要用到Typing库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Dict</span>, <span class="hljs-type">Any</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SolvingEngine</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.logger = logging.getLogger(self.__class__.__module__)<br>        self.graph: GraphOfStates = GOS_generator()<br>        self.shared_state_data: SharedStateData = SharedStateData()<br>        self.run_states: <span class="hljs-type">List</span>[State] = []<br>        self.result: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>] = &#123;&#125;<br>        self.executed: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>对于具体的类型，使用<code>List</code>或者<code>Dict</code>来表示。</p><h3 id="2-2-Union的使用"><a href="#2-2-Union的使用" class="headerlink" title="2.2 Union的使用"></a>2.2 Union的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Type</span>, <span class="hljs-type">Union</span><br><br><span class="hljs-comment"># 这个类型提示表示一个类型，该类型可以是以下类之一的实例：</span><br><span class="hljs-comment"># DatasetMultiEncDec, DatasetEPT, DatasetHMS, DatasetGPT2,</span><br><span class="hljs-comment"># PretrainDataset, SingleEquationDataset, MultiEquationDataset, AbstractDataset</span><br>DatasetType = <span class="hljs-type">Type</span>[<span class="hljs-type">Union</span>[<br>    DatasetMultiEncDec, DatasetEPT, DatasetHMS, DatasetGPT2,<br>    PretrainDataset, SingleEquationDataset, MultiEquationDataset, AbstractDataset<br>]]<br><br></code></pre></td></tr></table></figure><p>这个类型提示使用了 <code>Union</code> 类型，表示被注解的对象可以是其中列举的多个类型中的任意一个。同时，使用 <code>Type</code> 类型表示这是一个类对象的类型提示。因此，<code>DatasetType</code> 表示一个类，该类是上述列举的多个类之一。</p>]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
      <category>Python</category>
      
      <category>Python库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Live2d基础知识!🍹</title>
    <link href="/2023/12/06/live2d/%E6%8A%80%E5%B7%A7/live2d%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2023/12/06/live2d/%E6%8A%80%E5%B7%A7/live2d%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Live2d ʕʽɞʼʔ</category>
      
      <category>Live2d制作技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Live2d</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blender视图和物体控制!🥕</title>
    <link href="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="视图和物体控制"><a href="#视图和物体控制" class="headerlink" title="视图和物体控制"></a>视图和物体控制</h1><h2 id="1-控制视图和视角"><a href="#1-控制视图和视角" class="headerlink" title="1.控制视图和视角"></a>1.控制视图和视角</h2><blockquote><p>观察3D空间</p></blockquote><p><code>鼠标中键</code>或者点击视图窗口右上角的<code>小球图标</code><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/2.png"></p><blockquote><p>平移3D空间</p></blockquote><p><code>shift+鼠标中键</code>或者点击视图窗口右上角的<code>小手图标</code><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1.png"></p><blockquote><p>缩放3D空间</p></blockquote><p><code>滚动鼠标中键</code>或者点击视图窗口右上角的<code>放大镜图标</code><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/3.png"></p><blockquote><p>摄像机视角和正交 &#x2F; 透视视角切换</p></blockquote><p><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/4.png"></p><h2 id="2-控制物体模型"><a href="#2-控制物体模型" class="headerlink" title="2.控制物体模型"></a>2.控制物体模型</h2><blockquote><p>新建物体</p></blockquote><p><code>shift + A</code></p><blockquote><p>正常的移动 &#x2F; 旋转 &#x2F; 缩放工具</p></blockquote><p><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/5.png"></p><blockquote><p>移动</p></blockquote><p>移动快捷键：<code>G</code></p><p>移动且具有所有固定轴：<code>G + 鼠标中键</code>，选择轴后松开鼠标中键即会保留选择轴。</p><p>固定轴移动：<code>G + X/Y/Z</code></p><p>撤销移动（恢复到原点）：<code>alt + G</code></p><p>吸附移动：<code>G + ctrl</code></p><blockquote><p>旋转</p></blockquote><p>旋转快捷键：<code>R</code></p><p>旋转且具有所有固定轴：<code>R + 鼠标中键</code>，选择轴后松开鼠标中键即会保留选择轴。</p><p>固定轴旋转：<code>R + X/Y/Z</code></p><p>撤销旋转：<code>alt + R</code></p><blockquote><p>缩放</p></blockquote><p>缩放快捷键：<code>S</code></p><p>缩放且具有所有固定轴：<code>S + 鼠标中键</code>，选择轴后松开鼠标中键即会保留选择轴。</p><p>固定轴缩放：<code>S + X/Y/Z</code></p><p>撤销缩放：<code>alt + S</code></p><blockquote><p>删除</p></blockquote><p>删除快捷键：<code>Del</code> 或者  <code>X</code></p><blockquote><p>隐藏 &#x2F; 显示</p></blockquote><p>隐藏选中物体快捷键：<code>H</code></p><p>隐藏未选中物体快捷键：<code>shift + H</code></p><p>显示快捷键：<code>alt + H</code></p><p>或者右上角<code>眼睛图标</code></p><p><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/6.png"></p><blockquote><p>复制</p></blockquote><p>移动并复制快捷键：<code>shift + D</code></p><p><strong>注意：</strong>ctrl + Z撤回的话只是撤回移动部分，物体仍然被复制。</p><blockquote><p>选择</p></blockquote><p>长按左上角箭头，出现四个选项</p><p><img src="/2023/12/06/%E5%BB%BA%E6%A8%A1/blender/%E6%8A%80%E5%B7%A7/blender%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/blender%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/7.png"></p><p>调整：单选并移动物体。</p><p>框选：选框的方式进行多选。</p><p>刷选：移动鼠标进行多选。</p><p>套索：套索的方式进行多选。</p><p>切换选择工具：<code>W</code></p><h2 id="3-切换视图"><a href="#3-切换视图" class="headerlink" title="3.切换视图"></a>3.切换视图</h2><blockquote><p>方法一</p></blockquote><p>直接点击右上角小圆球的红蓝绿三个键</p><blockquote><p>方法二</p></blockquote><p>小键盘的数字键：</p><p>0 摄像机视角</p><p>1 &#x2F; 3 &#x2F; 7 &#x2F; 9 调整视图</p><p>2 &#x2F; 4 &#x2F; 6 &#x2F; 8 偏移视角，每按一次转15°</p><p>5 调整正交和透视</p><p>点击<code>.</code>，点击物体可将对象放大至视图中心</p><blockquote><p>方法三</p></blockquote><p>长按<code>~</code>键，选择视图</p><blockquote><p>方法四</p></blockquote><p><code>alt + 鼠标中键</code>改变视图</p>]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Blender</category>
      
      <category>Blender建模技巧</category>
      
      <category>Blender基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Blender</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>maya建模基础知识！🍒</title>
    <link href="/2023/12/06/%E5%BB%BA%E6%A8%A1/maya/%E6%8A%80%E5%B7%A7/maya%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2023/12/06/%E5%BB%BA%E6%A8%A1/maya/%E6%8A%80%E5%B7%A7/maya%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
      <category>Maya</category>
      
      <category>Maya建模技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Maya</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VFX魔法球特效！🎈</title>
    <link href="/2023/11/19/%E6%B8%B8%E6%88%8F/VFX/%E8%AE%BE%E8%AE%A1/Unity-VFX-MagicBall/"/>
    <url>/2023/11/19/%E6%B8%B8%E6%88%8F/VFX/%E8%AE%BE%E8%AE%A1/Unity-VFX-MagicBall/</url>
    
    <content type="html"><![CDATA[<p><img src="/2023/11/19/%E6%B8%B8%E6%88%8F/VFX/%E8%AE%BE%E8%AE%A1/Unity-VFX-MagicBall/1.gif"></p>]]></content>
    
    
    <categories>
      
      <category>Unity ᶘ ᵒᴥᵒᶅ</category>
      
      <category>VFX</category>
      
      <category>VFX设计案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Unity</tag>
      
      <tag>设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ai翻书特效！🌞</title>
    <link href="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/"/>
    <url>/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/</url>
    
    <content type="html"><![CDATA[<h1 id="Ai翻书特效"><a href="#Ai翻书特效" class="headerlink" title="Ai翻书特效"></a>Ai翻书特效</h1><p>效果如下图所示：</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/13.png"></p><p>实现该效果需要用到三个步骤：</p><p>1.文字工具</p><p>2.混合工具</p><p>3.变形工具</p><p>4.阴影工具</p><h2 id="1-文字工具创造轮廓"><a href="#1-文字工具创造轮廓" class="headerlink" title="1.文字工具创造轮廓"></a>1.文字工具创造轮廓</h2><p>首先用文字工具创造希望产生特效的文字</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/1.png"></p><p>然后对整体进行扩展</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/2.png"></p><p>扩展后文字将按照形状产生相应的路径，并形成一个编组</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/3.png"></p><p>最后将其解组，形成一个个单独的文字路径</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/4.png"></p><h2 id="2-混合工具产生基本的效果"><a href="#2-混合工具产生基本的效果" class="headerlink" title="2.混合工具产生基本的效果"></a>2.混合工具产生基本的效果</h2><p>首先复制一个文字，并改变其颜色</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/5.png"></p><p>然后使用混合工具指定步数产生混合后的效果</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/6.png"></p><h2 id="3-变形工具调整角度"><a href="#3-变形工具调整角度" class="headerlink" title="3.变形工具调整角度"></a>3.变形工具调整角度</h2><p>使用变形工具调整角度，使其更加立体</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/7.png"></p><p>调整后的效果如下图所示</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/8.png"></p><h2 id="4-添加阴影效果"><a href="#4-添加阴影效果" class="headerlink" title="4.添加阴影效果"></a>4.添加阴影效果</h2><p>首先将混合后的文字进行扩展并解组，扩展会让其每一层都具有路径</p><p>解组后每一层都可以自由移动</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/10.png"></p><p>然后在效果中添加阴影</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/9.png"></p><p>添加阴影后再对所有图层编组</p><p><strong>注意：</strong>编组快捷键为Ctrl+G</p><p>最后为第一层添加渐变效果，产生光泽感</p><p><img src="/2023/11/18/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E7%BF%BB%E4%B9%A6%E7%89%B9%E6%95%88/12.png"></p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>Ai</category>
      
      <category>Ai设计案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ai</tag>
      
      <tag>设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ai混合工具的使用！🌸</title>
    <link href="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Ai混合工具的使用"><a href="#Ai混合工具的使用" class="headerlink" title="Ai混合工具的使用"></a>Ai混合工具的使用</h1><p>Ai混合主要由混合选项中三个不同的参数控制</p><p>进入方式为：<strong>对象—-&gt;混合</strong></p><p>1.平滑的颜色</p><p>2.指定的步数</p><p>3.指定的距离</p><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/1.png"></p><p>初始图如下所示：</p><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/2.png"></p><h2 id="1-平滑的颜色"><a href="#1-平滑的颜色" class="headerlink" title="1.平滑的颜色"></a>1.平滑的颜色</h2><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/3.png"></p><h2 id="2-指定的步数"><a href="#2-指定的步数" class="headerlink" title="2.指定的步数"></a>2.指定的步数</h2><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/4.png"></p><h2 id="3-指定的距离"><a href="#3-指定的距离" class="headerlink" title="3.指定的距离"></a>3.指定的距离</h2><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/5.png"></p><h2 id="4-混合的原因"><a href="#4-混合的原因" class="headerlink" title="4.混合的原因"></a>4.混合的原因</h2><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/6.png"><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/7.png"></p><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/8.png"></p><p><img src="/2023/11/18/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E6%B7%B7%E5%90%88%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/9.png"></p><p>如上图所示我们可以观察到，改变图层的顺序会改变混合的方式</p><p>哪一个图层在上面，哪一个图层在混合图层中也会在最上方</p><p>而另一个图层在最下方</p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>Ai</category>
      
      <category>Ai矢量图设计技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Ai</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ai作图的操作顺序！🌸</title>
    <link href="/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
    <url>/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="Ai作图的操作顺序"><a href="#Ai作图的操作顺序" class="headerlink" title="Ai作图的操作顺序"></a>Ai作图的操作顺序</h1><p>如下图所示是一张用Ai画的矢量人脸图：</p><p><img src="/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/1.png"></p><p>因为Ai填色需要对闭合的钢笔线圈进行操作，所以面对上图中带有勾线的图形，需要分层进行操作。</p><h2 id="1-画出底色"><a href="#1-画出底色" class="headerlink" title="1.画出底色"></a>1.画出底色</h2><p>先用钢笔画出图像最底层的图形，如下图所示：</p><p><img src="/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/2.png"></p><p><strong>注意：</strong>画底色时，选择没有描边的钢笔</p><h2 id="2-逐层上色"><a href="#2-逐层上色" class="headerlink" title="2.逐层上色"></a>2.逐层上色</h2><p>如下图所示画出图形分层的色彩：</p><p><img src="/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/3.png"></p><p>每一层画出闭合的钢笔线圈</p><h2 id="3-画出勾线"><a href="#3-画出勾线" class="headerlink" title="3.画出勾线"></a>3.画出勾线</h2><p>在将底色画完之后，选择有描边的钢笔进行描边，最终呈现完整的图形</p><p><img src="/2023/11/16/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E5%9B%BE%E5%83%8F%E7%9A%84%E6%93%8D%E4%BD%9C/4.png"></p><p>线框图如上所示</p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>Ai</category>
      
      <category>Ai矢量图设计技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Ai</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第十章 · 乌鹊绕南枝❤️‍🔥</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%8D%81%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%8D%81%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="乌鹊绕南枝"><a href="#乌鹊绕南枝" class="headerlink" title="乌鹊绕南枝"></a>乌鹊绕南枝</h1><p>  　　“咚！——————”</p><p>　　寺庙的钟声不知何时敲响，庄严而又带着悲悯。</p><p>　　“闻钟声，菩提生。”苏景回头瞄了一眼寺庙斑驳红墙上的蛛丝，有些好奇是谁在这座无人问津的寺庙里醒钟。</p><p>　　他的神识扫过来来往往的人群，将每个人脸上的表情和神色都瞧了个明白。</p><p>　　有身着布衣的妇人背着衣不遮体的婴儿愁容满面；也有满面书生气的文人秀才站在路旁发呆，神情木讷；而更多的是背着大刀长枪，或冷漠，或奸邪，或狠决地徘徊游荡在大街上的人。</p><p>　　菩萨好像都无动于衷地放弃了他们。</p><p>　　如今各地都不太平，边境处尤甚，这里的人们都抱着活一日是一日的念头。为何这里的寺庙门可罗雀，衰败地没有任何香火，苏景转念间便有了答案。</p><p>　　在活着都是奢望的地方，烧香拜佛就成了稀罕事儿。能救他们的不是日夜礼佛，也不是磕破了脑袋求菩萨保佑，而是握在他们手中的真刀实枪。</p><p>　　苏景还沉浸在思绪之中，就被不远处人群中传来的骚乱打断。他悄悄远转内力，正想收回神识，却发现骚乱处有一群蒙着面的武士大步流星地朝他们这边闯来。</p><p>　　苏景偏头望向苏野，正巧苏野也在回望着他。“他们好像是冲我们来的。”苏景指了指地上的草药，有些意料之中地摊手说道。</p><p>　　“嗯。”苏野沉声回应，“该来的总会来的。”说罢，他扭头看向了那些迎面而来的武士，往前半步将苏景护在身后，同时悄然运转血脉之力，劲风在周身鼓动，衣袂猎猎。</p><p>　　“看这架势，倒不像是小门小派的人。可为何要蒙着面，难道是…”苏景看向那群武士，又扫了一圈十步开外朝这边好奇张望的人群。虽然这些武士都在极力表现出莽撞，但他们相互之间的距离却时刻维持着一种微妙的平衡。</p><p>　　短短数息后，那十数名武士就将苏景和苏野呈环形包围起来。苏野低声对苏景说：“一会儿我来拦住他们，你带着药材先走。”说罢，不等苏景回答，玄青色狼影便以磅礴之势从苏野身后腾起，可怖的能量狂潮毫无保留地从苏野体内席卷而出。</p><p>　　为首的武士死死盯着苏野身后的狼影，金色面具背后的双眸之中似乎有森然的火焰在曳动。他缓缓握住腰间的刀柄，然后朝苏野开口说道：“交出药材，走；不交，死。”</p><p>　　话音刚落，一道裹挟着凛冽战意的拳风便朝为首的武士奔袭而去，随后传来苏野冷漠到极致的声音：“就凭你们，也配？”</p><p>　　为首的那名武士在感受到拳风之中蕴含的浩瀚能量之后，眸中显露了诧异之色。但他也没有表现出丝毫的慌乱，而是紧闭双眼，同时右脚向外迈出一步，脚下有朱红流光涌动。</p><p>　　在拳风离他仅有毫厘之差时，为首的武士陡然睁眼。朱红色的火焰宛如实质一般的在他双眸前肆意地燃烧，而苏野的拳风好像被禁锢住似的停滞不前，随后便同那沸腾后的水汽儿，在吞吐间便消融在空气之中。</p><p>　　周遭的声音突然安静了下来，只听得见那熊熊的火焰发出的“滋滋”声。突然，为首的那名武士向后退了一步，然后抬手朝前一挥，顿时所有武士都拔出了腰间的佩刀，拔刀的锵鸣声惊地树上的鸟儿都慌了翅膀逃走。</p><p>　　每一把刀的刀尖都直直地指向了苏野。</p><p>　　苏野却仿佛没看见那些刀尖上流转的血腥气，而是偏头望向苏景。在和苏景眼神交汇的一刹那，苏野自己都没发现他眉峰陡然地舒展。</p><p>　　尽管这个世界破烂不堪，但他回头仍能看到希望，这便够了。</p><p>　　“我数到三，你就往后跑。”苏野轻声对苏景说。不待苏景回答，苏野又补充道：“听话。”</p><p>　　苏景把没说的话咽进肚子里，有些无奈的摇摇头，心想着，苏野还是把他当小孩子哄。</p><p>　　“一。”苏野回头，那些武士已经提刀向这边冲来。他毫无保留的将体内的所有能量释放，身后的狼影顷刻间又暴涨了三分，巨大的玄青色狼影将身体弓起，寻找一击制敌的机会。</p><p>　　“左二进一，右五平三。”</p><p>　　“二。”</p><p>　　“三…”话音未落，正当苏野准备调动血脉下隐藏的凶煞之力时，却听到了苏景地大喊声。</p><p>　　“等一下！”</p><p>　　武士走进了身后的庙宇，苏景自顾自地喃喃道：“果然是他。”</p><p>　　苏景问：“二当家为何有心情在这醒钟？”</p><p>　　“有些装睡的人啊，也该醒醒了。”</p><p>　　回去的路上，苏景给一个生病的小孩药材。</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　　</p><p>　二当家逛了逛这里的寺庙，随意的在菩萨面前做着不正经的事情。</p><p>　　</p><p>　“我们啊，都是站在菩萨背后的人，菩萨哪瞧得见咱们？”</p><p>　　</p><p>　　</p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第九章 · 鸣蛩惊梧桐🤎</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B9%9D%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B9%9D%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="鸣蛩惊梧桐"><a href="#鸣蛩惊梧桐" class="headerlink" title="鸣蛩惊梧桐"></a>鸣蛩惊梧桐</h1><p> 　　栋宇相望，桑梓接连。怀桑殿中的桑树像是一夜之间耗尽了生气，连带着怀梓殿中的梓树也衰败了大半。它们像是流干了眼泪的孩童，眼底只剩下不仁的麻木。</p><p>　　没过几日，一则震惊整个白谷域，乃至整个大乌都有所耳闻的消息传了出来，白谷域域主的小儿子，因与长兄生嫌已久，遂在金鸾祭当晚手刃了兄长，域主大人一怒之下将其击杀，然后急火攻心昏倒在了殿中。</p><p>　　又过了好些时日，当苏景在饭桌上听到苏野提起此事时，不禁感慨道：“大乌的人可真够狠的。”苏野挑了挑眉，状若无意的回了一句：“假作真时真亦假，无为有处有还无。”然后两人对视一眼，继续吃饭了。</p><p>　　苏野几日前就跟苏景商量着去山谷的更深处寻些珍贵的草药，然后拿到城中去卖。最近战事颇多，大大小小的流寇扰的人心惶惶，需要药材的人应该也不少。</p><p>　　“那日王觋医离开前我曾问过，这片山谷里有一种极为罕见的玉麟草，可治百病，他曾在年少的时候遇过一株，之后便无迹可寻了。”苏野对苏景说道。</p><p>　　苏景坐在门口的青石上，望着不远处在枝桠间载飞载下的衔欢燕，撑着脑袋说：“这好办，我和你一块去寻。”苏野摇了摇头，皱眉道：“太危险了，我一个人去便可。”</p><p>　　苏景撇了撇嘴，仰头看着苏野，状似不满的说道：“苏野，你忘了我的看家本领是什么了吗？”苏野怔然，随后想起什么似的恍然大悟，略微思索了片刻后说：“那我们明早出发。”</p><p>　　苏景拍了拍自己的胸脯，自信非常的说道：“包在我身上！什么玉麟草，万年参我都能给你挖出来！”苏野微微点头，不置可否。</p><p>　　第二日天刚蒙蒙亮，一抹鱼肚白好似从山涧清淙中缓缓流淌而出。苏野在闭目凝神之际就听到耳边传来一阵窸窣，紧接着就听到苏景扯着嗓子喊：“起！床！…唔！”</p><p>　　苏野一手捂着苏景的嘴巴，一手揉了揉自己的耳朵，然后从被褥上仰身而起。苏景从狼爪下躲开，颇有些迫不及待地拉着苏野往外走，边走边说道：“早上我已经在附近探查了一番，跟我来！”</p><p>　　苏野就这么跟着苏景往山谷的深处走，苏景走在前面，眼眸虚张，在他身前还有星星点点的墨绿色荧光跃动着汇成一条蜿蜒的蛇线，似乎在指引着他们前行的方向。</p><p>　　苏野在距苏景身后一步之外的地方不紧不慢的跟随着，狼眸微眯，瞳孔里血色纹路若隐若现。当他们来到毫无人迹的地方后，每往山谷深处行进一里，苏野的神经便更紧绷一分。</p><p>　　走着走着，阳光好像变的越来越稀薄，两个人的步子放缓，苏景身前的绿色荧光突然突兀的四散开来，如惊弓之鸟般的消失在两人眼前。</p><p>　　苏景蓦地睁开眼，神识向周围释放而出，鎏色的金光将这方空间都照亮了几分。苏景微微皱眉，在稀薄的阳光下似乎有一层极淡的雾在游走着。</p><p>　　一缕似有若无的空气掠过苏景的鼻尖，霎时间滔天的火光在苏景的脑海里涌现，吞天坼地的轰鸣声让苏景的神识都变的摇摇欲坠。苏景赶紧运转神识，将扩散于外的神识聚拢在眉心，嘴里大喝：“苏野！屏气凝神！这里有妄气！”</p><p>　　妄气，言其虚妄之相随念而起也。它能唤起人心中最可怕的念头，神识孱弱者一个不慎便会在无尽的虚妄中沉沦。</p><p>　　苏景虽说没修炼心法，但神识能量极为庞大，在吸入妄气的刹那间便靠着磅礴的神识能量抑住了内心的妄念。可妄念在脑海里出现的那片刻，依旧让他的心神动荡不已。</p><p>　　苏景深呼了一口气，陡然听见了身后一声l悲戚的狼嚎。“不好！”苏景急忙转头，发现苏野双手抱着脑袋跪坐在地上，脖颈和额头的青筋暴起，猛烈的抽动着。</p><p>　　苏野死死咬着牙，面部的肌肉因为太过用力而不住地颤抖，紧锁的眉峰被血光和戾气笼罩在内，身后一张巨大的玄青色狼影也低伏着头颅，狼尾不安又狂躁的不断晃动。</p><p>　　苏野感觉血液里的那股能量要把他撕碎了，他好像置身在滚烫的沸水中，体内升腾的热浪将他一寸一寸的吞噬。脑子里是无穷无尽的尸山血海，无数凄厉的哀鸣声仿佛在撕扯着他的神经，势必要让他一同坠入血海。</p><p>　　苏景看到他这副模样，急忙双手结印，安神诀和神识如洪流般的朝苏野涌去，除了维持自己不被妄气侵袭的那一部分能量外，其余的能量尽数传向了苏野。</p><p>　　苏景的神识刚接触苏野的那一刻，苏野浑身暴动的能量有片刻的收敛，然而没过多久，苏景就发现无论是他的神识还是安神诀都没法减弱苏野的痛苦。</p><p>　　冷汗不断的自苏野额头滑落，背后也早已被汗水浸湿。他像是搁浅在岸的鱼，狼狈又无措的喘息着。苏景又尝试给苏野灌输自己的能量，仍是不起半分作用。</p><p>　　苏景毫不犹豫的右手化刃，正欲往自己左手动脉划下的时候，被一只颤抖却有力的手握住了手腕。</p><p>　　苏野微微侧头，眼神里是隐晦的坚持，他喉间微动，从牙缝间挤出几个字：“不…要…”，然后轻轻晃了晃苏景化刃的胳膊。</p><p>　　苏景反手就抓住了苏野的手掌，有些哽咽的细声说道：“别怕，我马上就带你回家。”说罢，便欲起身去背苏野。苏野摇了摇头，无力地说：“别让…奶奶知道…，我们还要…还要采药…”</p><p>　　他望着苏景，扯了扯干涩的嘴角，道：“你…能不能…转过去，陪我说说话…”语气里有极力遏制的痛苦。苏景盯了他片刻，然后在苏野带着哀求的目光中缓缓转身。</p><p>　　他双手死死攒着衣角，努力强迫自己沉浸在回忆里。</p><p>　　“小的时候，我不小心打碎了母亲留下的一对鸳鸯玉，那是父亲第一次，也是最后一次冲我发火…”</p><p>　　“在学堂上学，我交了很多好朋友，偶尔喜欢发呆的小和尚，总是想家的虎妞，还有嘴硬心软的…”<br>　　……</p><p>　　苏景不知道自己说了多久，他只能感觉到身后之人不断传来压抑的闷哼和身体摩擦地面的声音。</p><p>　　慢慢地，阳光抽丝剥茧般的褪去，连带着妄气也消失在阴影里。等空气中的妄气尽数退散后，苏景悬着的心才松了绳。他试探性地喊了一声：“苏野？”没有听到回答，他猛地回头，却落进了一双深邃的眸子里。</p><p>　　他从那眸子里看到了寥廓的山，凛冽的风，还有…愣神的自己。眸子里的山风就那么把他包裹着，裹得他的胸膛不受控制的起伏起来。</p><p>　　苏景的呼吸有些急促，刚欲开口就听到苏野弱弱喊了声：“冷。”他赶紧坐的离苏野近些，就见到苏野伸手紧紧环住了他的手臂，嘴里嘟囔着：“太阳是不是被你赶跑了？”</p><p>　　苏景不免有些好笑，哄小孩子一样的说：“太阳啊也要休息了，再等一会儿，等我们小狼睡着了，太阳就出来了。”苏野闭上眼，过了一会儿又皱着眉头说：“睡不着。”</p><p>　　“睡不着就数…”苏景刚想说数星星，却发现今晚的天空黑的没有任何光亮。耳边却传来苏野的声音：“一，二，三…”数着数着，苏野的声音慢慢变轻，直到“七十一。”苏野把这个数字念的格外清晰，然后便安静了下来。</p><p>　　第二日一早，苏野被阳光晒得眼皮发烫。他惺忪地睁开眼，就见到苏景站在光亮里，朝他伸出手，面带笑意的对他说：“回家吧。”</p><p>　　苏野愣在原地，阳光从头顶将苏景笼罩起来，然后慢慢的，一点点的，驱走了他身后的黑暗。</p><p>　　尘芥镇。鹿行扬尘，余舟一芥。</p><p>　　尘芥镇是大赢和大乾绵延万里的边界线中，较为出名的一座大镇。这里混杂着大赢和大乾各方势力的眼线，也是无数走途无路之人的避难所。</p><p>　　由于大赢和大乾经年累月的摩擦，逃离在此的流民不断壮大，逐渐发展成一些大大小小的集团势力，其中最出名的就是“雔帮”。</p><p>　　雔帮有两位帮主，大帮主是赢国的边防士兵，据说在一次和大乾的战争中，因为不战而退被将军全境捉拿，方才逃到此地。</p><p>　　二帮主的身份鲜有人知道，江湖谣传，大帮主在和其他帮派的斗争中，险些身亡，是二帮主在关键时刻挺身而出，救大帮主于危难。</p><p>　　苏景和苏野将这尘芥镇的大致情况了解后，便找了块靠近寺庙的干净地方，将药材分门别类的铺在地上。</p><p>　　上次苏野被妄气侵袭后，苏景便在周围发现了一小片玉麟草，约莫十数株。后来两人又在整片山群探查了一番，将好些珍稀罕见的药材都搜刮了个干净。</p><p>　　苏景找了个有树荫的地方靠着，来来往往的人群中有不少人的视线都会往这个方向打量。当他们发现地上的药材时，许多人眼睛里都冒着贪婪的光。</p><p>　　但是没多久他们就发现，站在药材堆旁的还有一位身材挺拔，目含血光的少年。少年背后玄青色狼影宛如实质，狼眸扫过每一位过路人时，都会散发狠厉的威压。<br>　　<br>　　今日的天气有些闷热，蝉鸣的流响从梧桐树梢间淌出，苏景听着，有些好奇地说：“今日这蝉声倒是比往日山间的更为清亮。”</p><p>　　苏野抬眼朝树上望去，说：“梧桐树高，而且枝叶繁疏，蝉居高处而鸣，这声音自然传的远些。”</p><p>　　不远处的一座楼阁上，一道清拔的身影坐在墨绿屏风旁，面前是红木茶台。他揭开台上的茶盏，热气袅袅升起。他对着杯沿轻轻吹了口气，就听到苏野的话音传入耳侧。那人手上的动作顿了顿，然后嗤笑了一声。</p><p>　　“居高声自远啊。”</p><p>　　他浅抿了一口杯中的茶水，然后随手朝梧桐树甩去一道绿色的劲风，蝉声顿时戛然而止。</p><p>　　“聒噪。”  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第八章 · 花灯掩晦影🤍</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%85%AB%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%85%AB%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="花灯掩晦影"><a href="#花灯掩晦影" class="headerlink" title="花灯掩晦影"></a>花灯掩晦影</h1><p>　　“想什么呢这么入神？”白橖还沉浸在那年的淅淅沥沥中，就听到前方一道带着关心的声音传来。“没什么。”白橖敛了敛嘴角，语气淡淡的地对师兄说道。</p><p>　　他放慢了脚步，无声地和人群脱离了些，然后侧头望向山外连绵呼啸地大雪。凚玉山就这么经年累月地被这片银装素裹覆盖着，像是沉睡在地底的墓棺，庄严又永无天日。</p><p>　　几瓣雪花带着醉意似的落在了白橖的水云袍上，像是那日抵在肩头的呵呢。白橖心神微动，目光在眼前的白茫茫上驻了许久，好一会儿方才挪动步子，往人群的方向走去。</p><p>　　而刚刚在白橖肩头小憩的那几瓣雪花们，在化成水汽儿前似乎听到了那人的低语。</p><p>　　“离恨胜似冬雪，更行更远不歇。”</p><p>　　苏景，你还好吗。</p><p>　　苏景在睡梦中不自觉地翻了身，盖在脸上的话本子顺着脸颊向下滑落，在快要砸到地面时被一只宽大的手稳稳地接住。苏野把话本子放到桌面上，又给苏景拢了拢被子，然后将床头的油灯吹灭了。</p><p>　　他把地上的被褥往苏景的方向挪了挪，看着熟睡中的人儿不安分地把被子踢来踢去，苏野又无奈又好笑地把他露在外面的肚子遮上，然后双手搁在脑后躺下了。</p><p>　　挨着苏景，苏野能闻到他身上浅浅地酒香。苏野觉着，这味道里面有冬日晨阳般的暖意，让他能看到寥廓的天空，孤旋的雄鹰，跃蹄的野马，也能让他每晚燥动难捱的心绪逐渐平复。</p><p>　　苏野想起来他们第一次来到奶奶这的场景。这里只有一间空着的屋子，屋里也只有一张单人的小床。苏景走进来的时候就对他说：“你睡床，我睡地上。我在外面睡习惯了，睡床还不太舒服。”</p><p>　　说罢，正想将多余的被褥往地上铺的时候，就被苏野扔到了床上。“？？？”苏景瞪着大眼睛看向若无其事收拾被褥的苏野，脑袋里盘算着他俩要是打一架谁的胜算更大。</p><p>　　没过一会儿苏景就认命地躺在了床上，嘴角却悄悄翘起了弧度。两个人就这么在这里住下了，一住便是三年。</p><p>　　苏野朝苏景的方向翻了个身，狼眸牢牢地注视着苏景，似乎要将他看进骨子里。耳畔边那道带着哭腔的声音不断重复着，一下一下触碰着苏野心里的那片柔软。</p><p>　　他摩挲着手上的戒指，心里却突兀地响起一道声音。</p><p>　　谁也别想抢走苏景。</p><p>　　长夜漫漫，星辰流转。月挂西山，宿鸟出林。</p><p>　　等苏景再次睁开眼睛的时候，房间里面除了他空无一人。巳时的阳光如山间清泉似的倾泻进屋子里，苏景有些迷糊地揉了揉眼睛，目光从眼缝间望见了桌上一只用竹子做的小奶猫。</p><p>　　“狼族都这么喜欢猫的吗？他们是有什么姻亲关系？”苏景有些费解的打了个哈欠，然后打量了一圈屋子里各式各样用竹子做的小猫们，每一个都栩栩如生。不得不说，苏野竹刻的手艺是越来越娴熟了。</p><p>　　苏景慢悠悠的晃荡到房门口，推开门就看到奶奶和苏野坐在桌前吃饭。门打开的前一刻苏野还在低头喝着粥，推开门的一刹那苏野就把目光锁在了苏景身上。</p><p>　　苏景和苏野对视一眼，然后有些担心的问奶奶：“奶奶，您的腰好些了么？”奶奶听到苏景的声音就乐的合不拢嘴，她朝苏景招招手，示意他坐下来吃饭，然后顺了顺苏景翘起来的头发，眼含笑意地慈声说道：“好多了。来，赶紧吃饭。”</p><p>　　话音刚落，苏野就递过来一碗刚盛的热粥。苏景冲着粥呼呼吹了几口气，然后三下五除二的就把粥喝的见了底。他把碗放下，看到苏野已经在等他了，于是对奶奶说：“奶奶，我们先去山下修炼了，晚上再给您抓条大鱼回来！”</p><p>　　奶奶微笑着点头应好，苏景就跟着苏野出门了。夏日温煦，无风无云，空气中带着新长出来的青草味儿，阳光混着水汽儿在山林间漾出一层一层细微的光圈。</p><p>　　苏景刚走到山林的一处拐角，神识就不自觉地泛起鎏光。他惬意地张开双臂，深吸了一口气，将自己包裹进阳光的怀抱，包裹进自然的摇篮。两个人顺着山路来到了一块空旷的平地，这是他们平时修炼的地方。</p><p>　　苏景有些迫不及待地盘腿坐在地上，轻轻闭上双眼，任凭神识向外扩散，跃动着的神识能量和空气中的自然因子悄然碰撞着，不断产生光芒流转的能量涟漪。</p><p>　　苏野看着苏景扩散的越来越远的神识，一丈，五丈，十丈…苏野凝眸，苏景的神识领域有接近十二丈的范围！放眼整个大赢，在十七岁就能到达这个领域范围的人，一般都是出自各大世家的嫡系子弟。</p><p>　　大赢的修炼体系分为心法和身法。心法修的是神识，身法是以身化刃。所谓神，精气不灭者何，多闻见而识乎至道者，至识也，故曰“神识”。如何判断一个人的神识是否强大，最直观的就是领域范围。</p><p>　　范围越大，说明修炼之人的神识能量越浩瀚，越能够支撑的起神识领域中的心法效果。可是，苏野眉峰微蹙，心中思索着，苏景的神识领域虽然很辽阔，但似乎并没有大赢任何一方派系心法的影子。</p><p>　　而且苏景的神识虽有抚人心神，平心静气的能力，却极易和领域内的生灵共情，如若控制不得当，就会遭到反噬。这倒是和大乌圣灵教的教术有异曲同工之效。</p><p>　　苏野心中这般想着，突然察觉到自己血脉中那股躁动不安的能量又开始隐隐肆虐。他阖眸运转内力，将血脉中那如附骨之蛆般的能量压制住。只要和苏景在一起，他压制那股能量的效率就要快上许多。</p><p>　　过了一会儿，苏野睁开眼，缓缓吐出一口浊气。他看向苏景，发现他仍沉浸在神识领域的能量潮汐中。苏野向四周环视一圈，狼眸中有暗红色血光闪烁，像是一头孤狼在审视自己的领地。</p><p>　　最终，他缓缓仰头，死死盯着今日刺眼的有些过头的太阳。他根本不在乎苏景的神识是否强大，有他在，就没人敢欺负他。</p><p>　　他只在乎，苏景是否羁在他的领地。</p><p>　　大乌•金阳域。<br>　　<br>　　每年的七月初九，是圣灵教最重要的日子，因为在这一日，教内会举行盛大的圣鸾祭。届时，太阳的无上荣光会降临在每一位圣教徒的身上。</p><p>　　大乌没有皇族，而是以两大教派为首，统治着这方地域。两大教派其一便是这圣灵教。圣灵教视太阳为信仰，据圣灵教教宗记载：“我教始立也，凤鸟适至，故纪於鸟，以治厉正。”</p><p>　　金阳域的最中心处，有一座富丽堂皇的殿宇，名金鸾殿。殿宇内外，梧桐耸立，殿宇上方，金凤盘栖。</p><p>　　殿内有数道人影，为首之人朝人群之中看了看，待所有人到齐之后，方才对着大殿上方拱手说道：“冕下，圣鸾祭的诸多事宜已经准备就绪，待到午时，便可降下圣谕了。”</p><p>　　大殿内最高处，一道慵懒的声音传来：“神巫教那边可有异常？”为首之人略作思考，方才回应道：“大祭司那边一切如常，几位神使也都没什么异样。”</p><p>　　突然，为首之人像是想起什么来的，又补充了一句：“山神使今日同雨神使一起前往凫更城了。”那最高处又是一道声音传来：“凫更？鸤鸠，是你们白谷域边境外的那座小城？”</p><p>　　名为鸤鸠的主教微微欠身，拱手回应道：“回冕下，正是靠着白谷域边境的一座小城。它在山神使的管辖范围内，最近倒是没听说有什么反常之处。”</p><p>　　“玄鸟，青鸟，你们二人在圣鸾祭之后，就随着鸤鸠一起去白谷域那看看吧。”</p><p>　　“是。”</p><p>　　大乌西南·白谷域。</p><p>　　白谷域内，家家户户的门前皆挂着带有圣鸟图案的花灯，尽管已经过了戌时，域内的每条街道巷陌依旧处于白昼一般。每年举行完圣鸾祭，夜晚的白谷域居民都会挂上花灯祈福作乐。</p><p>　　不止白谷域，圣灵教所管辖的九域中，皆是如此。如潮水般的教徒纷纷从小楼深巷里涌出，沐浴在祭典后热闹喧嚷的氛围之中。正所谓弦管万家沸此宵，花灯万里正迢迢。</p><p>　　有人在街上感慨道：“今日的圣鸾祭，凤鸿冕下当真是威仪万千，可谓是有画难描圣威态，无花可比圣尊容。”</p><p>　　旁边的人一边附和一边感叹道：“我白谷域域主鸤鸠大人也是儒雅风流，真乃我白谷之幸。”周围的人纷纷点头，就听到人群中有人振臂揭喉高呼：“圣灵不朽！光耀万世！”“圣灵不朽！圣灵不朽！”一呼而万众应。</p><p>　　白谷域中央，怀桑殿。</p><p>　　一位身着紫袍的少年坐在殿内的一棵桑树下，低垂着头，将脸埋在树影之中。树干周围零星散落着几片枯叶，不远处是落满灰尘的高墙。</p><p>　　院墙内灯影幢幢，如鬼魅一般摇曳着。蓦地，殿外高呼的声音透过厚重的围墙，落在了少年的耳畔。</p><p>　　“圣灵不朽么…”少年浅语了一声，突然笑了起来。他一边笑着，一边抬起头，狭长的眼尾里，藏着揉碎了的黑暗。他拾起一片地上的落叶，任凭鲜血顺着手指将其染红。</p><p>　　少年怀中还抱着一名男子，一把玉质匕首插在那人的胸口，只余下一小截在体外。少年伸手想拨开那人额前的碎发，却不忍心手上的血渍沾上那人分毫。</p><p>　　他深深地凝望着怀中人的脸，浅浅勾了勾嘴角，眼底却是满堂的衰枝败叶。好一会儿后，他才将怀中的那人抱起，将额头轻轻抵在那人的额上，用尽所有力气般的深吸了一口气，然后缓缓地说：</p><p>　　“哥哥，你解脱了。”  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第七章 · 玉鸟望云雀🖤</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%83%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%83%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="玉鸟望云雀"><a href="#玉鸟望云雀" class="headerlink" title="玉鸟望云雀"></a>玉鸟望云雀</h1><p> 　　岁聿云暮,一元复始。</p><p>　　苏景托着脑袋，望向窗外的鹅毛大雪，想起了一个多月前，那道站在漫天银霜下的身影。他就那么直直地看着阴阳眼两兄弟的眼睛，仿佛生死于他而言，皆是虚妄。</p><p>　　后来，就变成了…打群架。苏景一只手死死勒住林七寸的脖子，双脚钳住他的下半身，另一只手对着林七寸的脸就是一顿猛揍，嘴里还不忘冲着他嚷嚷：“叫你偷袭！叫你偷袭！”</p><p>　　再后来，苏景就被白橖抱走了。白橖像抱着一只炸了毛的小奶猫，小奶猫还在气呼呼的吱哇乱叫。白橖勾了勾手指，一团团冰蓝柔光便敷在了苏景流血的位置。</p><p>　　白橖低头看了看苏景说：“瞎逞什么强。”苏景听完委屈极了，闷闷地说：“那个林七寸他想偷袭你！”白橖心里想着，他刚刚就察觉到了林七寸的小动作，正要应对的时候，便看到一个猫似的身影扑了过去。</p><p>　　白橖眸中泛笑，嘴上却淡淡地说：“知道了。”</p><p>　　“想什么呢。”苏景正望着窗外出神，耳边传来一道清冷的声音。“我在想，在想…这雪下的可真好看。”苏景看着白橖，有些支吾地说到。</p><p>　　“过几日就是除夕了，明日起我就回寺里去看望师父。你们有什么打算？”小和尚看着其他三个人问道。“我爹爹也喊我回去，说给我做一大桌好吃的！”虎妞儿一边眨巴眨巴眼睛，一边流着口水。</p><p>　　“你呢？”苏景看向白橖，目光中似乎藏着期待。“我…就在这。”白橖思索了片刻，师父这个月要闭关，他索性就待在这了，正好没什么人打扰，耳根子清…“太好了！今年终于有人陪我了！”白橖还沉浸在思绪中，就被一阵兴奋地声音打断。</p><p>　　他望着苏景合不拢嘴的笑容，不知为何，原本有些紧绷的弦悄悄地松了下来。</p><p>　　除夕，千家笑语，万户灯火。</p><p>　　白橖正在学府的藏书阁中随意地翻阅着。早上苏景跑来跟他说，今日要带他去一个地方。他有些期许，却又刻意将这份期许压在心底，藏在无人知晓的角落。</p><p>　　这时，一股轻盈的柔风自窗外悄悄溜到了他的身侧。先是调皮地蹭过他的脸颊，鼻翼，唇瓣，然后又勾起了他额前的几缕发丝，最后悠哉地来到他的耳畔，像是有人在耳边呢喃低语。</p><p>　　“跟我走。”</p><p>　　白橖听到了熟悉的声音，目光转向窗台，就看到苏景正扑闪着大眼睛，朝他勾了勾手。白橖心口生热，那些埋在心底的期许，刬尽还生。</p><p>　　渔火镇。江枫渔火，游子思归。</p><p>　　“这个小镇有来自各个地域的旅人。每年除夕，在外未归的游子便会在这里点燃一盏渔船的灯火，以寄归思。”苏景望着江畔来往渔船上亮起的灯火，向白橖介绍到。</p><p>　　白橖向四周张望着，金柳摇风树树，系彩舫渔舟遥岸。如织如梭的旅中客，燕舞莺啼的欢愉声，都和他儿时的记忆大相径庭。记忆里那个独自站在院墙一角的男孩儿，好像只有影子陪着他。</p><p>　　“噔。”蓦地，白橖耳畔传来一道钟声。他从思绪中走出来，却被一双温热的手捂住了眼睛。“三，二，一…”耳边有人在轻轻数着，然后徐徐松开手，漫天华光就这么映入他的眼眸。</p><p>　　“新年快乐！”苏景跳到了白橖身前，开怀着送上了新年的第一声祝福。白橖望着苏景，任凭人群熙攘，任凭霓光满天，他却只想把目光落在苏景身上。</p><p>　　“新年快乐。”白橖小声回应着。不远处，火树拂云起，琪花落满地。</p><p>　　冷泉亭外。泉水渟渟，风声泠泠。</p><p>　　苏景抱着几坛梅花酒，拖着白橖到冷泉亭这歇着。“你看，从这里望下去，正好可以将整个渔火镇看个清楚。”苏景找了个檀木柱靠着，又拉了拉白橖的衣角，示意他也坐下来。</p><p>　　白橖挨着苏景坐下，抬眼望去，灯火阑珊。他其实已经有些看不太真切了，哪怕这座亭子可以将整个渔火镇尽收眼底，在他眼里也不过是隔雾观火。</p><p>　　可是，他却觉得，他从未像今日这般看地真切过。</p><p>　　“小的时候，每年过年我都是和隔壁家的阿翁阿嬷们一起过的，他们待我很好，可我却总想着，要是能和我爹还有我娘一起就好了。”苏景仰头灌了一大口酒，小脸微红。</p><p>　　“后来，我爹和我娘把我带到了这里，他们跟我说以后这里就是我的家，可是每年我都见不到他们。偶尔他们会托人给我寄信，可是…”苏景坐起身，把头埋在柱子后面，白橖只能看着一张红扑扑的侧脸。</p><p>　　白橖把苏景从柱子后面拽出来，就听到了苏景小声的说：“我很想他们。”他声音很低，好像声音再大一些就会被别人发现他藏的秘密。</p><p>　　“这些年都是我一个人来这，但是今年不一样了。”苏景又灌了一口，一坛子梅花酒就见了底。他抬眼望着白橖，白橖也回望着他，似乎在这冬日的料峭里，能望见苏景眸中溢满的春水。</p><p>　　苏景将下巴浅浅地抵在白橖的肩上，嘴里呵出的酒气儿在白橖耳边打着旋儿。“今年有你陪着，真好。”苏景阖上眼，嘴角勾起了月牙般的弧度。</p><p>　　白橖的手在苏景靠近的时候，就下意识地抓紧了衣角。苏景说话间耳朵传来的酥麻让他手足无措，呼吸都乱了节奏。他怔怔地偏过头，看着苏景像只猫儿似的趴在他身上，眼底寒霜尽褪，心口春草疯长。</p><p>　　“小的时候我总是一个人躲在院墙的一角，没有人愿意接近一个连家主都讨厌的孩子。”白橖望着远处，陷入了回忆。“我养过一只小野猫，可是没过三个月它就死了，我很难过，把它埋在了后院的榕树下。”</p><p>　　“后来，我又养过雪兔，养过灵狐，养过许多许多的活物。它们同样都没活过三个月。慢慢地，我就不再难过了。”白橖自嘲般地浅笑一声。“我不喜这种感觉，这种感觉让我觉得…害怕。”</p><p>　　“再后来，我遇到了师父，师父是第一个待我好的人。他交了我如今修炼的心法，只是这心法虽强，却会导致我的身体比常人更加…敏感。”白橖说完，喉间有些干涩。他低头看了眼苏景，却发现他早已经在和周公举杯对酌了。</p><p>　　“傻子。”白橖无奈地摇摇头，在心里默默喊了自己一声。不远处，几瓣红梅也悠悠沉沉地落入雪的怀抱。</p><p>　　春潮带雨，润物无声。</p><p>　　立春甫过，苏景便整日神龙不见尾地不知道在忙些什么。有时是一整个上午不见踪影，下午便回到阁中呼呼大睡。有时上午坐在阁中也是心不在焉，下午又偷跑了出去。</p><p>　　白橖在忍了好几日之后，终于忍不住开口问他：“你近日到底在忙些什么。”语气中略微有些愠气。苏景看着他，眼珠子转了转，似乎在思考。又过了一会儿，他才一脸真诚地说：“秘密。”</p><p>　　就这样又过了两日。天刚蒙蒙亮的时候，苏景就蹲在白橖每日来学府的路上。小雨疏疏，青山欲晓，白橖来时见到的便是这般光景。苏景不知道横在路中央傻笑些什么，细雨润湿了他的发梢。</p><p>　　白橖走近了些，脚步略比往常重了几分。苏景听到脚步声传来，微微侧头，看到来人时，眼里放光地起身大喊：“白橖！生辰吉乐！”他张开双手，将白橖抱了个满怀。</p><p>　　白橖蓦地睁大了双眸，唇瓣微启，似乎想要说些什么，却呆呆地愣在原地。过了好一会儿，方才对苏景说：“你…站在这，我去取伞。”然后步子有些慌乱地朝学府走去。</p><p>　　苏景在学府门口晃悠了一会儿，就看见白橖拿着油纸伞，有些恍惚地走了出来。他跑过去，抓住白橖的衣角说：“走，我带你去个地方。”说完，往学府后山方向指了指。</p><p>　　两人徐徐走过后山的一片桦树林，又拐过几个崖角，来到一片木槿花丛。白橖停下了脚步，遥遥地就听到了几声啁啾。他举着油纸伞，偏头望向苏景。</p><p>　　苏景快步向前走了几步，然后从一块木槿花丛后面拿了两个金丝笼，笼子里面各有一只橙黄，橘红的玉鸟在欢鸣腾跃。“我看你袍子上绣的皆是玉鸟图案，便想着给你弄了两只来。”<br>　　<br>　　白橖望着笼中鸟，沉默不语。苏景将白橖的脸色看了个明白，然后毫不犹豫地打开了笼子。笼中的玉鸟先是不解的晃了晃脑袋，然后仰头望着天空，正巧几只云雀悠哉地掠过，便也挥着翅膀飞走了。</p><p>　　“它们虽然待在笼子里久了些，可是只要望向天空，便又有了方向。”苏景朝天上看了看，转头对白橖笑到。白橖有片刻的失神，他盯着苏景手中空无一物的金丝笼，呼吸开始变得急促了些。</p><p>　　苏景又带着白橖向木槿花丛后走去，一湾漾着碧波的池塘赫然映入白橖的眼帘，露花倒影，烟芜蘸碧。池塘周围铺满了青石，无名的野花交错着盛开，突然间，池塘里露出了两个小小的脑袋。<br>　　<br>　　“这是玉虚龟，它们寿命悠久，且极通人性，无论你什么时候想起来它们，它们都会在那里陪着你。”苏景望着白橖说到。“盛旦欣逢，愿君千万岁，无岁不逢春。这礼物你可喜欢，喜欢的话就笑笑吧。”</p><p>　　苏景先是抬手抱拳，眉间带笑地向白橖送上了生辰祝福。然后又凝眸注视着白橖，用最真诚的语气说：“遇到你，我很欢喜。”</p><p>　　白橖在听到苏景说第一句话时，神识就有些不受控制地波动了。当他听到“我很欢喜”四个字的时候，那些潜藏在心底的不安，那些冰封在雪山下的无助，都被那四个字击的粉碎。</p><p>　　他紧握双拳，似乎鼓足了所有勇气般的凝望着苏景，刚欲开口，骤雨溅珠。苏景连忙将他拉到一棵桦树下避雨。他没听到白橖刚刚说了些什么，急忙又问了一遍。</p><p>　　白橖没再说话，他看着苏景，第一次笑了出来。那一刻，雪尽春出，白橖眼眸里是倒映着的连绵春雨。</p><p>　　师父，您说的真的都对吗，可我好像和一个油嘴滑舌的家伙成了朋友呢。</p><p>　　锁在金丝笼中的玉鸟，也会想要扑腾着翅膀去追逐笼外的云雀。</p><p>　　那我呢。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第六章 · 槐序起四时💜</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%85%AD%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%85%AD%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="槐序起四时"><a href="#槐序起四时" class="headerlink" title="槐序起四时"></a>槐序起四时</h1><p>　　仲夏的蝉鸣，将先生的讲学声拉的悠长。</p><p>　　苏景听着听着就打起了盹，梦里他正等着糖画师傅给他做一个玉鸟图案的糖画。一个胖乎乎的小手从后面拍了拍苏景的脑袋，将苏景的美梦赶走。苏景有些迷糊地揉了揉眼睛，就听见小和尚在他耳边大喊：“下学啦！！！”</p><p>　　苏景一激灵，一把将小和尚的嘴捂住。他看到白橖一直望着窗外，便问他：“今日天气这般好，要不要一起出去玩？”白橖没看他，只回了一个字：“热。”苏景非常理解地点了点头，拉着小和尚和虎妞儿出去了。</p><p>　　没过一会儿，正当白橖觉得耳根子清净了许多的时候，就看到窗外边一个火急火燎的身影朝他跑来，不一会儿就来到他跟前。他看着苏景从身后兴奋的掏出了一把竹制的油纸伞，然后用那双扑闪扑闪的大眼睛望着他说：“现在可以一起出去玩了吗？”</p><p>　　星霜荏苒，白橖就这样在学府待了近一个月。每天苏景都会变着法的给他带各种各样的新鲜玩意儿。尾生蓝光的水萤，吹不灭的永生火，能够听到潮汐声的清月螺，还有…苏景看着手里的含羞草，这东西和白橖简直一模一样。</p><p>　　两天前，虎妞儿和小和尚在追着玩，不小心撞翻了白橖桌上的茶水，茶水还冒着热气地淋在了白橖手上。苏景下意识的去握白橖的手，没成想，他刚刚碰到白橖的手指，就被推开了。</p><p>　　苏景有些委屈巴巴的把脑袋搁在桌子上。前段时间白橖心情好的时候还会和他出去走走，这几日因为那件事，白橖都不和他说话了。苏景发愁的叹了口气，突然又想起什么似的眼睛亮了起来，然后赶紧冲出门。</p><p>　　第二日，直到中午吃饭的时辰苏景都还没有出现。从早上苏景没来开始，白橖就时不时看向窗外。中午下学后，白橖朝小和尚看了一眼，还没开口，虎妞儿就抢着说：“苏景哥哥给你买东西去了！”</p><p>　　白橖微怔，过了好一会儿才说：“知道了。”小和尚奇怪地看了一眼白橖，不知为何，他总觉得白橖淡漠的语气里，藏着一分喜意。</p><p>　　午时，白橖照常用着一碗清粥。从小到大，他都以白粥为主，时蔬辅之。突然，一个雀跃的声音传来：“白橖！白橖！你看我给你带了什么！”白橖微微偏头，看到苏景猫似的蹿到他旁边，然后小心翼翼的拿出一个袋子。</p><p>　　苏景将白橖的碗挪到自己面前，然后从袋子里面倒入了一些暗红色的粉末，用木勺轻轻搅拌了之后，又挪到了白橖面前。白橖看着苏景一脸期待的眼神，又盯着自己的碗看了足足一盏茶的功夫，方才舀了一浅勺送入嘴里。</p><p>　　“咳！咳咳…！”白橖还未反应过来嘴里的味道，就被呛的咳出声来。苏景一脸惊慌失措，赶紧给他倒了一杯凉水，又轻轻的拍着他的背，担心的问到：“没事吧？”</p><p>　　白橖伸手去接苏景倒的水，食指不小心碰到了苏景的手背。他的手在空中静了片刻，然后继续面色镇定的拿过水，掩下喉间的灼热。苏景看着白橖咳地泛红的脸，有些心疼地解释到：“这是我从西蜀拿回来的辣椒粉，我看你每日喝清粥，就想着给你换换口味。是我考虑不周了。”</p><p>　　“无妨。”白橖将食指轻轻按在自己的唇瓣上，任凭灼烧感在唇齿间跃动。等这种感觉快要消退的时候，白橖又浅舀了一勺放入嘴中。就这么一勺，两勺…苏景看着他慢慢的将一碗粥吃到见了底，心中又惊又喜。</p><p>　　“你喜欢吗？喜欢的话我改日再给你拿一些来。”苏景像是自己吃到什么珍馐美味般的问到。“嗯。”白橖浅声应着。这是他第一次觉得，原来吃饭也会让他产生一丝期待。</p><p>　　金秋的麦浪，将少年的心一点点装的满满当当。</p><p>　　小和尚戳了戳眼皮子耷拉着的虎妞儿，神秘兮兮的问：“你有没有发现苏景和白橖最近有什么奇怪的地方？”虎妞儿用清澈的眼睛看了一眼他俩，然后说：“他俩越长越好看啦！”</p><p>　　小和尚翻了个白眼，然后指了指他俩的位置，悄咪咪的说：“他俩的椅子都要贴一块儿啦！”</p><p>　　十月十五，是学府进行比武切磋的日子。</p><p>　　学府后山，有一座巨大的比武场。苏景早早就拖着白橖和小和尚还有虎妞儿他们三个来到这里。苏景饶有兴致地冲他们三个说：“终于有机会好好教训那些眼高手低的家伙们了。”</p><p>　　白橖知道苏景嘴里的他们就是刚入学时出言讥讽他的那些人。从开学到现在，苏景已经明里暗里和他们较量许多次了。白橖眼眸含着一丝自己也不曾察觉的笑意，嘴上却说着：“幼稚。”</p><p>　　苏景看着越来越多的人往这边涌，便跟他们三个说：“我们往前凑凑，看的清楚些。”前段时间苏景发现白橖的眼睛似乎有些看不太清，他问过白橖是不是有哪里不舒服，白橖只回他没有，但他却在心里默默记了下来。</p><p>　　等所有人逐渐都到齐了，一位身着劲装的女子翻身上台，朗声喝到：“比武——开始！”</p><p>　　一名穿着朱红色袈裟，眼眸虚张，周身鸦青光晕沉浮的和尚立手走到台前，然后目光环视了一圈，最后停在了小和尚这里。“摈尘法师，请。”小和尚一脸嫌弃，但还是慢悠悠走上台，在离台还有六尺处停下时，明黄暗纹自脚底升腾。</p><p>　　“摒尘是普渡寺守真大师的小弟子，修的是梵钟普渡诀，梵音出，众生渡。”苏景向白橖介绍到。他又指了指小和尚对面的那个人说：“那是广济寺的慧远法师，师从宏悟大师。宏悟大师最拿手的便是大悲咒，不历大悲，不通极乐。”</p><p>　　白橖听完稍起了些兴致，只见小和尚周身笼罩在一个明黄古钟内，古钟上端是龙头钓手，下端有二个莲华形撞座。小和尚在古钟内紧锁双眸，左手持珠，随着嘴唇翕动的频率越来越快，一根龙型的钟椎赫然出现在古钟侧方，如巨龙吐息。</p><p>　　对面的慧远法师盘腿席地而坐，朱红色袈裟在肩侧环绕。他将胸口的紫金珠串取下，右手一下一下捻着，细看的话会发现紫金珠上有鸦青色纹路若明若昧。顷刻间，一位千手千眼的菩萨立于慧远身后，而其中一只手，遥遥对着小和尚的方向一指。</p><p>　　顿时，苏景听到了无数悲戚的声音在耳边萦绕，宛如杜鹃啼血的哀鸣。他立马运转神识，稳定心神。他又看向白橖，却发现白橖的眼睛里，平静无波，没有悲伤，也不曾欢喜。</p><p>　　小和尚没有坐以待毙，他突地睁开双眸，龙椎宛如巨龙咆哮似的撞上古钟。霎时间，震耳欲聋的梵音以小和尚为中心向四面八方扩散。明黄色的波纹和鸦青色的流光碰撞在一起，梵音与悲泣同鸣。</p><p>　　约莫半盏茶的功夫，笼罩着小和尚的古钟消失在虚空，立于慧远身后的菩萨像也变得若隐若现。“噗！”慧远法师在佛像消失的一刹那，捂着胸口，吐了一地暗沉的血。</p><p>　　小和尚用肉嘟嘟的手拍了拍自己的脸，摇摇晃晃的险些摔倒在地。苏景正准备去接他，突然眼神一凝，鎏色神识匿于虚空，一枚藏于阴影中的青针像是蛰伏在暗的毒蛇，随时准备给敌人致命一击。</p><p>　　“林七寸，收起你那些肮脏的手段。”苏景将小和尚扶起，目含鎏光的向人群中一处阴暗的角落说到。一道身着竹青色长袍，上面绣着蛇纹图案的男子缓步走上台，歪头朝苏景露出了一个轻蔑的笑容，他讥讽到：</p><p>　　“苏景啊苏景，你的神识除了能安抚两只阿猫阿狗，还能干嘛？”林七寸知道苏景还没有找到合适的心法，便处处踩着他的痛点。“臭扔针的！我拍死你！”苏景还未开口说话，就看见虎妞儿冲上了台。</p><p>　　一个巨大的月白色虚影遽然出现在虎妞儿身后，虎妞儿咆哮着向林七寸挥出拳头，身后的虎影也张开了血盆大口，虎掌带着排山之势向林七寸拍下。林七寸陡然瞪大了双眼，不敢有丝毫的分神，神识疯狂运转，竹青色浓雾向四周奔袭，无数青针藏于雾中。</p><p>　　虎掌拍向青雾时，只听雾中传来一声闷哼，接着便瞧见一道身影从雾中向后猛地退了好几步，方才堪堪稳住身形。虎妞儿双手叉腰，露着两颗小虎牙凶巴巴地冲林七寸喊到：“有本事你再叫啊！”</p><p>　　“你…！”林七寸正弯腰喘着粗气，听到虎妞儿的挑衅声，脸上有惊怒之色浮现。“别急，让我们兄弟俩来会会他们。”林七寸突然被一左一右两只手扶起，就见到开口说话之人朝他露出一个和善的笑容。</p><p>　　来的两人都只露出一只眼，另一只眼皆被黑布掩着。刚刚开口说话之人身着素衣，面容和善，而另一人全身裹在墨色长衫中，神情淡漠。</p><p>　　苏景见到上台的两个人后，目光一紧，旋即对虎妞儿说：“来的是阴阳眼两兄弟。哥哥执生，弟弟掌死。生死玄妙，皆藏于眼。你千万小心，不要看他们的眼睛。”虎妞儿听完，赶紧用两只小手把眼睛捂住。</p><p>　　苏景深吸一口气，眼帘虚掩，手掌翻转，金色暗纹自脚底浮现。正当他准备运转神识时，突然眼前出现了一道身影。白橖侧身站在他的身前，先是微微转头，用只有他听的见的声音对他说了句：“傻子。”然后又对着阴阳眼两兄弟用极其淡漠的语气吐出四个字：</p><p>　　“一起上吧。”</p><p>　　银霜漫天，雪虐风饕。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第五章 · 晨曦暖霜女❤️</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%BA%94%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%BA%94%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="晨曦暖霜女"><a href="#晨曦暖霜女" class="headerlink" title="晨曦暖霜女"></a>晨曦暖霜女</h1><p>  　　苏景和苏野一前一后走回房间。月光从窗外漫进屋内，留下一湾清浅。苏野借着月光将卷在地上的被褥收拾好，就看到苏景已经趴在床上翻他带回来的话本子了。他从桌前递过去一盏油灯，说：“少看一会儿。”</p><p>　　苏景嘟囔着应下。苏野又将他带回来的竹子在桌旁摆好，略微思索了片刻，便拿起小刀开始打磨竹子。没过多久，苏野就听到苏景“噗嗤”地笑出声来，他抬头望向苏景，就见他指着话本子里的一段话，摇头晃脑地念着：</p><p>　　“却说这两位少年，一位性格孤僻，一位直来直去。初识孤僻的少年还觉得直爽的少年惹人心烦，可是没过多久，两人却成了至交。欲知后事如何，且听下回分解。”苏景砸吧嘴，越读越觉得有些熟悉。</p><p>　　他翻了个身，一只手搁在脑后躺着，一只手将话本子盖在脸上。此时他的脑海里，出现了一位身穿水云绸缎，总是喜欢背着小手，一脸严肃的对他说：“别闹。”的人影。</p><p>　　大赢•凚玉山。</p><p>　　极北之地，雪山西来，横亘六合几千里。排云划雾，玉屑遮天，直控穹窿而特起。雪山尽头，凚玉山巅，一座殿宇巍峨耸立。</p><p>　　殿宇的西南角处，有一汪清泉，泉水上方暖雾缭绕，泉中有两只玉虚龟在慢悠悠扑腾。一名身着水云袍，头戴鹤羽冠的少年静坐在泉边的玉石上。少年用手指微微拨弄着泉水，冰蓝色的流光在指边跃动。</p><p>　　这里的温度极冷，一般人穿着狐裘大衣都会冻的直打哆嗦。可那池中的乌衣却似感受不到温度般地自在。少年听着泉中咕噜的气泡声，嘴角漾起一抹浅笑。</p><p>　　不远处传来一阵脚步声，一名年纪稍大的男子快步走到少年面前，对着少年说：“白橖小师弟，师尊唤我们过去。”名叫白橖的少年没有看他，仍旧冲着前方回应到：“师兄稍等。”</p><p>　　男子有些好奇的看了看暖泉，询问到：“这里面就是师弟寻了好久才找到的阳烁石？”白橖点了点头。“原来是置于这方泉水之下，有阳烁石在，这两个小家伙才能这般快活。”男子指了指泉中的乌衣，略作感慨。</p><p>　　白橖收拾好了自己的衣裳，正欲起身，男子连忙跑过去搀扶。白橖退了一步，清冷地说：“无妨。”男子有些担忧地说：“你的眼睛…”白橖摆了摆手，似乎是自言自语地说：“眼见不一定为实，心见才是。”说罢，便自己朝殿门外走去，眼底升起一片雾霭。</p><p>　　凚玉山有十二宫，从白橖居住的宫殿到师尊住的正殿要经过另外几座行宫，里面住的是其他师兄弟。刚刚唤白橖的那位师兄也陆续唤了其他人。他们三三俩俩的结伴而行，只有白橖独自一人走在最后。每次人一多起来，白橖就会想到那个人的身影。</p><p>　　那是崇宁十二年的夏天，同样的硝烟遍地，山河飘摇。</p><p>　　白橖的眼睛从那个时候就逐渐有些看不清了，可他却觉得正是从那时起，他才真正拥有过光明。</p><p>　　那一年，师傅将他送到了三国交汇处的一座山谷。谷里有一座学府，名“鼎泰”，有鼎立三足，三阳交泰之意。里面全是江湖各派送去的天赋异禀的孩童。因其独立于任何一方势力，方才能在这乱世中超脱于外。</p><p>　　鲜有人知道府主是谁，也很少有人知道府里的先生来自哪里，大家都心照不宣的将门中优秀子弟送来进修，因为这里不论国界，不论尊卑，只论天赋。</p><p>　　大赢的三教九流能和世家子弟同席而坐，乌人眼中的异教徒也能与圣灵教和巫神教同台论道，还有乾国数不清的小部落，在这里也能和二十八宿部的裔子们一决高下。</p><p>　　这里有失传已久的大赢心法和身法绝学，也有来自上古的乌族术式，还有乾国蛮荒时期的血脉秘术，原本这些握在各国勋贵手中的宝藏，却在这里被传授给来自不同背景的孩童。</p><p>　　三国的掌权者对此地虎视眈眈，却又因为厉害关系相互制肘，没有谁愿意率先打破这个微妙的平衡。一双无形的手悄悄藏于这座学府的背后，能托之，亦能覆之。</p><p>　　刚来此地的白橖并不关心这里有谁，也不关心为什么随处可见奇装异服的男女老少。师父他老人家在他下山前，苦口婆心的劝到：“橖儿，此次下山，为师希望你能多交些朋友回来。当然，油嘴滑舌的家伙除外！”白橖点点头，记下了师父的话。</p><p>　　苏景正带着一个胖胖的小和尚还有一个虎头虎脑的女娃娃准备去府外斗蛐蛐儿，就看见府门口一个粉雕玉琢的小男孩儿背着小手，默默凝视着府上的“鼎泰”二字。</p><p>　　苏景以为他不识字儿，就热心肠的跑过去，大声的冲小男孩儿说：“这两个字念‘鼎泰’，一言九鼎的鼎，否极泰来的泰。”说完，还不忘朝他眨了眨眼睛。苏景以为小男孩儿会对他投来崇拜的眼神，没成想，小男孩儿看都没看他一眼，只是微微吐出两个字：“傻子。”</p><p>　　苏景也不生气，他一脸好奇的问小男孩儿：“你叫什么名字。”男孩儿不做声。苏景又问：“你家在哪？”男孩沉默不语。苏景不屈不挠：“你要不要和我们一起斗蛐蛐？”话音刚落，男孩儿头也不回的走进学府，留给苏景一个冷漠的背影。</p><p>　　小和尚贼兮兮地凑过来，说：“依小僧看，他定是嫌你话多。”虎妞儿睁着大眼睛，望着小男孩儿离开的背影说：“他生的可真好看。”苏景灰溜溜的摸了摸鼻子，说：“可不是。”也不知道是在回复谁的话。</p><p>　　第二日清晨，学府的学生们坐在阁内，等着先生来上课。还未到时辰，底下叽叽喳喳的乱成一片。不一会儿一位须发皆白，精神矍铄的老者带着一位身穿水云袍的小男孩儿走到台前，清了清嗓子说：</p><p>　　“今日学府中来了位新门生。来跟大家做一下自我介绍。”说完，老者示意小男孩儿上台。小男孩儿略微有些拘谨的走到台前，一脸严肃的说：“我叫白橖，师从凚玉山寒丹尊者。”说完，又径直退到一旁。</p><p>　　苏景在白橖进入阁中的那一刻起，就一直悄悄注视着他。他的衣服上绣着精致的玉鸟图案，明明年纪和他一般大，却总是像个小大人似的一直皱着眉头。苏景觉得，他要是笑起来，一定比虎妞儿还漂亮。</p><p>　　他听到白橖的名字时，满脑子想的都是糖霜，糖人，糖画…虎妞儿露着两颗小虎牙，憨态可掬的望着白橖…流口水。旁边的小和尚看到苏景在白橖介绍完后莫名其妙的傻笑起来，又看到虎妞儿发呆的样子，摇了摇头，捻了捻手里的珠子，低头念了句：“阿弥陀佛。”</p><p>　　突然，阁内传来一声冷哼，接着便听到有人讥讽到：“我当是谁，原来是寒丹尊者的爱徒，大赢白家的少主啊。”阁中其他人先是一愣，在听到白家少主几个字后，面色皆古怪了起来。</p><p>　　大赢白家，数年前因为“卖国求荣”的罪名，家主被下到昭狱。“白家子怎么还敢有脸上这里来丢人现眼了？”又是一道不屑的声音从阁中响起。白橖似是没听到那些个嘲讽，衣服的一角却被小手轻轻的抓起，空气中有寒霜悄然凝结。</p><p>　　阁中霎时间静的出奇。突然，“我叫苏景，同你一般大，来自西蜀苏家。”苏景突然站起身，朝白橖露出了一个盎然的笑意。“咱们这不论出身，只比拳头。谁拳头更硬，谁就是老大。”</p><p>　　苏景有意无意的朝阁中的某一个角落看去，又朝白橖招了招手，说：“来我这儿坐！我这边靠窗，凉快！”白橖淡淡地朝苏景望了一眼，在心里吐了两个字：“傻子。”他环视了阁中一圈，似乎只有苏景旁边看着稍微有些顺眼，便径直朝他那走去。</p><p>　　苏景赶紧将旁边位置上画的木槿图收拾了干净。白橖没有看苏景，自顾自的越过苏景坐在窗户旁边。他将椅子往窗边又挪了挪，开始闭目养神。苏景把椅子也往白橖那挪了挪，看似有模有样地望着先生，眼睛却不住往窗边瞟。</p><p>　　白橖眼眸微闭，神识却泛着冰蓝的柔光。他想起师父临行前告诫他的话，略微思索着，想必苏景就是师父口中那种油嘴滑舌的家伙吧。</p><p>　　窗外，晨曦东升，万物尽苏。昨夜青女带来的凝霜和寒意在此时悄然化成了水汽儿。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第四章 · 总角孝古稀🧡</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%9B%9B%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E5%9B%9B%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="总角孝古稀"><a href="#总角孝古稀" class="headerlink" title="总角孝古稀"></a>总角孝古稀</h1><p>  　　苏景和苏野两个人在王爷爷家门口等了一会儿，月光温柔的将两个人的影子拉的纤长。苏景往前挪了挪步子，让他的影子悄悄盖过了苏野的头顶。他又伸出手往左边拍了拍，苏野就看着苏景影子里的手拍上了自己影子的脑袋。</p><p>　　苏景自顾自地在旁边傻笑着，没过一会儿就听到屋里传来一个中气十足的声音：“走了小兔崽子们！”未见其人先闻其声。眨眼间的功夫，一位鹤发童颜的老者就迈着大步走了出来。</p><p>　　这位老者先是盯着苏野看了一看，然后随手取下腰间挂着的一个小葫芦瓶，扔给苏野说：“你小子今日目萦厉煞，周身血气浮动，我这瓶子里有三十六颗清心丸，你每日卯时服下一颗，足月方可除煞。”</p><p>　　苏野接过葫芦瓶子，微微点了点头。老者又望向苏景，发现苏景正略带期待的看着他，便从药盒里取出两颗丹药，神色严肃地说：“小小年纪就不好生养胃！整日吃辛辣喝烈酒，胃早晚给你折腾坏了！回去以后，将这枚养胃丹用温水化开，早晚各服一次，不许再喝酒了！”</p><p>　　苏景连忙点了点头，嘴里一边说着：“谢谢王爷爷！我保证滴酒不沾！”一边冲苏野使了个眼色。苏野心领神会，将拎着酒罐子的手往身后背了背。王爷爷这才满意的说；“走吧，去瞧瞧你们奶奶的病。”</p><p>　　苏野跟在苏景身后三个步子的距离，看着苏景像只小麻雀似的和王爷爷唠着嗑。经过四五个拐角，又辗转了几条野路，一个翠竹环绕的的竹楼出现在三个人的眼前。</p><p>　　苏野快步上前去把门打开，点燃起厅堂的蜡烛，然后领着王爷爷进到屋子里。苏景三步作两步地跑进来，大喊着：“奶奶，我们回来了！我们还把王爷爷请来了！”</p><p>　　里屋传来一个慈蔼的老妇人的声音，略带笑意的回应着：“回来就好，回来就好，快进来坐。”苏景和苏野便带着王爷爷往里屋走。刚进门，苏景就看到奶奶准备起身。他赶紧跑过去将奶奶扶起来，苏野也从背后递来一个枕头放在奶奶的腰后。</p><p>　　奶奶先是冲着苏野和苏景笑了笑，然后转头对王爷爷略带歉意地说：“王觋医，又要麻烦你了。”王爷爷摆了摆手，轻轻捻了捻自己的山羊胡子，说：“不麻烦。两个小兔崽子，在外面侯着去！”</p><p>　　苏景乖巧的眨了眨眼睛，对奶奶说：“奶奶，我和苏野今日给您抓了条大鱼！我们现在去做给您吃！”奶奶宠溺地对苏景点了点头，又对苏野说：“看着他点，别让他把厨房掀了。”苏野浅笑着应了好，就拉着苏景出去了。</p><p>　　两个人一起来到厨房，等苏野将厨房里的火烛亮起的时候，就见到苏景在门边徘徊着。苏野知道苏景在想什么，便对他说：“你去把酒和牛乳温着，其他的事情我来。”说罢便将竹篓里的彩鳞鲭拿了出来。</p><p>　　苏景赶紧应了苏野的话，然后跑出去温东西了。苏野知道苏景的神识有共情万物的能力，虽然彩鳞鲭灵智微乎其微，可是苏景仍然可以感受到它的痛苦。所以一般杀生的事情都是他来做。</p><p>　　苏野想到有一次他和苏景上山采灵药，路过一片灌木丛时他不小心踩死了一只木栖虫，身后的苏景几不可闻的发出了一声闷哼。尽管苏景连神情都没有变化，但是苏野还是敏锐的捕捉到了苏景的感受。</p><p>　　苏野娴熟的将彩鳞鲭处理好，然后下锅煮沸。苏野其实不喜欢吃鱼，他吃惯了牛羊肉这种粗肉，鱼这种细肉他吃的不自在。苏景也不喜欢吃鱼，他生性好动，吃鱼对他来说太麻烦了，好几次险些被卡住。</p><p>　　但是奶奶喜欢吃鱼，所以每隔一段时间两人就会捉一条鱼回来做给奶奶吃。所以苏野在做鱼这块也是相当熟练的。等鱼做好了，他又给苏景炒了两盘小菜，然后准备去叫苏景。</p><p>　　苏景在竹楼外升起了一堆柴火，他小心翼翼将装牛乳的罐子固定好，然后拿着个蒲扇轻轻扇着火。晚风阵阵，火光曳曳，苏景没来由的生出些困意。他扇风的手越来越低，速度越来越缓，在快要停下的时候，听到有人轻唤了声“苏景。”</p><p>　　苏景反应了片刻，猛的抬起头，拿扇子的手不小心碰到了烧的发红的罐子。苏景被烫的下意识缩回了手，却将那罐子晃荡了起来，洁白的牛乳随着晃动洒了些许。苏景又想伸手去稳住晃悠悠的罐子，却看到有双手从身后伸了过来，稳稳的拿起罐子放在了地上。</p><p>　　苏景转头，看着苏野面色不虞地盯着他。他有些不好意思地挠了挠头说：“对不起，我不小心睡着了，牛乳撒了一些…”话音刚落，苏野就将苏景的双手握住，然后低头在泛红的地方吹了吹。</p><p>　　苏景刚想说他没什么事，就听到苏野有些闷闷的质问他：“手不想要了是不是。”接着没等他回答又问道：“酒呢？”苏景指了指放在火堆后的酒罐子说：“没事，我喝冷的就行。奶奶那应该弄的差不多了，我把鱼给送过去。”</p><p>　　“菜我已经送过去了。酒我给你温，不着急。”苏野拉住想要起身的苏景，然后去将酒罐子架在火堆上放好，又新添了几根柴火，最后默默坐回苏景身边，没有说话。</p><p>　　苏景有些不自在地拨弄着手边的杂草。一盏茶的功夫后，苏景看到王爷爷背着药箱出来了。他赶忙起身询问道：“爷爷，奶奶的腰怎么样了。”苏野也站了起来，拍了拍苏景背上的灰尘。</p><p>　　“腰痛暂时是不会发作了，但她早年间从山崖下摔下来摔的太狠，年轻的时候又没有好好治疗，导致现在成了隐疾。我这段时间先封住了她的痛感，不过想要更好的缓解她的腰伤，需要到镇上去买些药材。”王爷爷解释到，然后递了张药单给苏野。</p><p>　　苏野将药单收好，对苏景说：“你先回去吃饭，我去送送爷爷。”话音刚落，就看到王爷爷自己自顾自的往外走，嘴里念叨着：“老头子我好得很，不用你送！你俩都饿坏了吧，赶紧去吃饭！快去快去！”</p><p>　　苏野和苏景对视一眼，都看到了对方眼里的笑意。他俩一人拿起一个罐子，朝屋里走去。进门的时候看到奶奶正好从里屋走出来，他俩放下罐子，将奶奶扶到桌子边上坐好。</p><p>　　苏野去厨房里准备拿两副碗筷。苏景问奶奶：“奶奶，鱼好吃吗？”奶奶眼睛里溢满了笑容，她止不住的夸赞着：“好吃！小野的手艺是越来越好了！将来娶的媳妇儿定是个有福气的！”</p><p>　　苏野从厨房出来的时候正好听到了奶奶的话。他先是递给了苏景一副碗筷，然后无奈的说到：“奶奶，您就别打趣我了。”说完，眼睛有意无意地瞟了苏景一眼。苏景没有说话，只是望着奶奶浅浅地笑。</p><p>　　苏野给苏景倒了碗梅花酒，又盛了两碗牛乳。苏景喜欢喝酒，越烈越兴奋。苏野却喜欢牛乳，越纯粹越合口。奶奶笑着接过苏野递的牛乳，对他俩说：“你俩都是好孩子。当初我从山上将你们带回来，一晃眼就是五年。”</p><p>　　“你俩当时见着我，一个眼睛水汪汪的，一个像头小狼崽子，凶得狠。当时我就在想，我的孙子要是还活着，也和你俩一般大了吧。”奶奶笑着说到，眼里却噙着泪。</p><p>　　“我看着你俩身上全都是伤，心里啊就跟揪着似的。两个这么小的娃娃，到底是吃了多少苦。”奶奶一边说一边抹着泪，苏野没说话，他静静地看着苏景把头低的越来越下，眼睛没进了阴影。</p><p>　　“我说带你们去治病，小野还不情愿。最后还是小景拖着拽着你走我才把你俩带到了王觋医那。”“王觋医看过你俩的伤，偷偷跟我说，要不是这俩孩子命大，就凭他俩身上的伤，不死也要没了半条命。那时我就下定决心，要让你俩在我这里住着，住到我老了，哪都去不了的时候，就换你们来照顾我。”</p><p>　　“三年了，我早就把你们当成了我自己的孩子。我不知道你们有没有把这当成自己的家，但是只要奶奶我还在这里一天，这里就永远是你们的家。”说完，奶奶缓缓起身，先拍了拍苏野的手，又顺了顺苏景的头发。“时辰不早了，早点回房歇息吧。”</p><p>　　苏野起身将奶奶扶回了房间。再次回到桌前的时候，发现苏景正红着眼眶，用一双湿漉漉的眼睛看着他。苏野走到苏景旁边，蹲下身子，抬头捏了捏苏景的脸，柔声说：“我会一直陪着你的。”</p><p>　　苏景看着苏野，没有说话。苏野知道他刚刚听了奶奶的那番话，心里一定酸楚的厉害。苏野也不好受，默默在心里盘算着要怎么去镇上给奶奶买药。他站起身，计划着明天就去深山里找些珍稀的灵药，再拿到镇上去换。</p><p>　　就在此时，一道带着哭腔的声音认真地对他说：“我也会一直陪着你的。”苏野心下一怔，然后直勾勾地望着苏景的眼睛，胸口发烫。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第三章 · 芳醴入暖酥💛</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%89%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%89%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="芳醴入暖酥"><a href="#芳醴入暖酥" class="headerlink" title="芳醴入暖酥"></a>芳醴入暖酥</h1><p>  　　苏野站在一片乾阔的竹林内，这里生长着两种截然不同的竹子，骨竹和绵竹。骨竹叶繁而节疏，色苍而气凛。棉竹猗猗，叠干龙回，攒根凤峙。每次苏野心情不好的时候，便会到这里砍些竹子回去做些小玩意儿。</p><p>　　这些年苏野一直试图寻找能够清除疤痕的药材。可是附近的村庄只有几位年迈的觋医和巫妪，治伤可以，却没办法让苏景彻底恢复。他想起苏景腿上成片的烧伤，还有手臂上密密麻麻的刀痕，五年前的记忆纷沓而至。</p><p>　　他记不清那是白天还是夜晚，也不记得自己在那里趴了多久，他只记得全身不断传来的疼痛一点点摧毁着他的意志，内心深处有一片深渊试图将他拽入无尽的黑暗。夏日天气燥的不行，可他还是觉得冷，冷的骨头发颤。</p><p>　苏野觉得自己快死了，他从大乾北部一路逃到了这里，从尸山血海逃到了青山碧谷。这里只有他一个人，溪流涓涓的声音好像离他越来越远。模模糊糊中他似乎听到了熟悉的声音在唤他：“小野…小野…”</p><p>　　突然，一股夜交藤的清香钻入他的鼻翼，耳畔边也传来一串串风铃似的低吟声。苏野的神识稍微清醒了几分，感觉自己仿佛置身于温泉暖池当中。“是谁在麻痹自己的五感？”苏野心道，可是他没有多余的力气去探个究竟，只能任凭来人摆弄。</p><p>　　又过了一会儿，当苏野再次感受到睡意如潮水般涌来时，一根微凉的手指覆上了他的唇瓣。他还未来得及琢磨唇上的凉意，就发现这根手指试图撬开他的嘴。苏野心中有些好笑，第一次有人主动把手伸进狼嘴里，不怕他一口给咬断吗。</p><p>　　苏野起了逗弄的心思，任凭那根手指如何使劲儿，苏野都紧抿着唇瓣。正当他以为那人没招的时候，耳边忽的传来一阵温热，还没反应过来话中的含义，腹部便被轻飘飘的打了一拳。</p><p>　　苏野明白过来，心中轻笑，假装吃痛地张开嘴，好奇来人要对他做些什么。张开嘴的瞬间便感觉到一滴滴带着血腥味的液体落入唇缝。苏野不明所以，可是没过一会，苏野就惊愕的发现自己竟然可以控制身体的内力了，再然后他就陷入了梦中。</p><p>　　浑浑噩噩之间，他感觉到有人想要带他离开。他慌慌张张地将右手用力的插进泥土里，不想让藏起来的戒指被人发现。这时，右手上又传来一阵熟悉的凉意。苏野有些意外，却也由着他背着自己离开。离开前，他似乎感觉到那人不着痕迹的抖了一下，嘴角泛起一丝笑意。</p><p>　　他由着那人将自己带到溪边，又由着他给自己处理伤口。他感觉到那人在看到他的后背时，指尖微微的颤抖。“吓着他了吗？”苏野心里想着，却发现那人有条不紊的清洗着他的伤口。</p><p>　　再然后…苏野记不清了，只记得自己被那人弄的浑身痒痒，伴随着溪水潺潺的声音睡过去了。又不知过了几日，迷糊中他想起了自己小时候珍藏的猎物，他喜欢抱着他们睡觉，那是属于他自己的战利品。他下意识的轻咬着身旁软软的东西，心满意足的酣睡着。</p><p>　　在一阵窸窣声中，他惊醒过来。这是他这么长时间以来，第一次有力气睁开眼睛。映入眼帘的是一张少年的脸，少年白皙的脸上满是…害怕？苏野不理解的看着他捂着脖子，突然想起来自己昨天晚上似乎咬着什么。</p><p>　　他默默地走到少年身边，假装什么都没发生似的轻轻咬了咬他的手臂，然后倒下去装睡。似乎是在暗示少年自己不会伤害他。少年没有挣扎，而是默默坐在自己身边，哼着小曲儿。苏野感到从未有过的放松，但是心底却升起一股不安。</p><p>　　又过了好几日，半梦半醒间苏野好像回到了一片血泊之中。血泊中一个男人双目猩红，周身血光弥散，他凄厉的地对着自己喊：“小野！小野！”苏野猛的惊醒，想要找到自己带着的那枚戒指。</p><p>　　他发了疯似的满地寻找着，指甲掀起一层又一层的泥土，鲜血顺着手指汩汩流进土壤里。突然他听到了一阵急促的脚步声，一只握着戒指的手伸到了他面前。他焦急的把戒指抢了过来，恶狠狠的盯着抢走戒指的那个人。</p><p>　　当他回过神看到来的人是谁时，才陡然清醒。他有些局促和不安的将自己蜷缩起来，闭上眼睛想要甩掉脑子里的血泊，却怎么也忘不掉。他烦躁的喘息着，却发现有只手一下一下的轻拍着自己的后背，好像知道自己没睡似的不停安慰着。</p><p>　　他的心霎时平静下来，等着那人的手拍的越来越轻，直到搭在他的肩上睡着了。苏野睁开眼睛，起身仔细打量着眼前这个人。他先是被那人满身的破烂衣裳吸引，衣裳上的花纹繁冗华贵，如今却如粗麻烂布似的挂在那人身上。</p><p>　　苏野视线往下，看到那人的腿被包裹的严严实实。只有脚踝处的地方，微微露出来一小片肌肤。苏野面色微沉，他看得出来那露出来的一小部分已经是烧伤过刚长出来的新肉，可想而知，整个腿部应该都伤的不轻。</p><p>　　苏野又低头看着搭在自己身上的手臂，上面是一条一条带着血痕的刀口。苏野想起了自己嘴巴里的血腥味，便猜到了这些伤痕的缘由。他用拇指的指肚来回拭过那些刀口，像是在拭着白瓷上的裂痕。“七十一道。”苏野默默的把这个数字藏在心底。</p><p>　　最后，苏野望向那人的脸。乱糟糟的头发下面是和羊脂玉一般白皙的脸。他的睫毛让苏野想到了枝繁叶茂的蓝花丹，鼻梁让苏野想到了壁立千仞的九嶷山，嘴唇让苏野想到了…咳，苏野收回自己越飘越远的思绪，开始仰头数着天上的星星。</p><p>　　“一，二，三，五，六，十…不对，一，二，四，五，七…不对不对…”苏野望着天上的星星，不耐烦的胡乱数着。他从小就讨厌数算，如今心里燥热，更是没法好好数了。</p><p>　　就在这时，一道细微的闷哼声传入苏野的耳朵。紧接着就听到那人带着哭腔小声喊着“爹爹…娘…白糖…”苏野低头看着那人有些颤抖的身体，长长的睫毛上面挂着泪星子，像是清晨悬在叶上的露珠，颤巍巍的。</p><p>　　苏野从来没有安慰过人。他学着那人之前拍他一样，也略带僵硬地轻轻拍着那人的肚子，嘴里念叨着：“没事了，都没事了…”他不知道自己为何要这么做，但他现在就是想这么拍拍他，又像拍着自己。</p><p>　　就这样又过了两日。那日的阳光格外明媚，亮的那人睡觉都不太安稳。苏野看着那人在阳光下微皱的眉头和被阳光晒的红扑扑的脸蛋，鬼使神差的伸出手，替他遮挡着脸上的阳光。</p><p>　　苏野就这么静静地遮了两个时辰，直到那人的眼皮颤了颤，他才回过神似的慌忙收回自己的手，眼睛却来不及从那人脸上挪开。于是，那人睁眼的刹那，他直勾勾的看向那人的眼眸深处，像是望见了天上的骄阳，腾的在他心里燃起了一片烈火。</p><p>　　苏野从未如此渴望的想要了解一个人。他深吸了一口气，缓缓低下头，伏在那人耳侧，努力压下喉中的那股燥热，问到：“你是谁，为什么要救我。”他想知道一个答案，哪怕只是那个人的名字。</p><p>　　“我叫苏景，我想救你。”只听那人毫不犹豫的回答着他。又听他反问：“你叫什么名字？”苏景没有问他为什么会来这里，只是好奇他叫什么。“我叫…苏野。”“你也姓苏？！那我们就都是苏家的人了！”苏景高兴的喊道。“…嗯。”苏野不置可否，眼底也含着笑。</p><p>　　竹子砍的差不多了，苏野从回忆里面抽离出来，天空悄悄地泼了墨。他一手抱着竹子，一手拎着竹篓，用最快的速度疾驰回家。回家的路上，他经过了两家铺子，然后往王爷爷的方向奔去。</p><p>　　当苏野赶到王爷爷家门口的时候，他突然停下了脚步。眼前的石凳上，苏景背对着他坐着，两条腿悬在空中一下下的摆动着。听到他的脚步声，苏景转过身来，对着他露出了一个大大的笑容，然后举起手向他这边晃了晃，对他说：“苏野！我在这！”</p><p>　　苏景从石凳上跳下来，边跑边跟他说：“我已经跟王爷爷说了奶奶的事儿。爷爷现在在收拾东西，我们等他一会儿。”等苏景跑到他身边，苏野瞧着他从身后拿出了一个罐子，略微有些得意的跟他说：“你瞧我买了什么。新鲜的牛乳！还温着，咱们一会儿回家喝！”</p><p>　　苏野心头微热，也从背后伸过手，拿出一个装着梅花酒的酒壶，又从兜里掏出一个话本子。他盯着苏景认真地说：“我们回家。”</p><p>　　蝉鸣几许，繁星明灭。奶味儿混着酒香，纯真与热烈碰撞。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第二章 · 朱阳煜微烛💚</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="朱阳煜微烛"><a href="#朱阳煜微烛" class="headerlink" title="朱阳煜微烛"></a>朱阳煜微烛</h1><p>  　　苏景的神识直到看着苏野转身朝竹林的方向离开后才暗自收回，夕阳的余晖将他回家的路照的金黄。他知道苏野要去竹林做什么，可他现在也想为苏野做点什么。</p><p>　　太阳是最富有的神明，他慷慨的将晨曦，将暮色，将晚霞赐给每一片山林。山林亦是毫无保留的将这份恩赐传递给生长在这里的一花一草，传递给行走在其间的每一位有缘人。</p><p>　　苏景就是这样的有缘人。他喜欢走在日暮下的山林，不，他也喜欢清晨的山林，雨后的山林，槐序的山林，岁馀的山林。他喜欢一切的山林，也喜欢山林的一切。</p><p>　　往常回家的时候，苏景总是会不自觉的在这片林子里多待上一会儿。仲春的朱顶红，槐序的虞美人，金秋的迷迭香，岁馀的蝴蝶兰，都是苏景的玩伴。前些日子天气好，苏景每天都要待到晚饭的时辰才回去。</p><p>　　今日的天气比前几日的天气还要好上几分。夏风骀荡，苏景觉得自己应该更高兴些才对，可是苏野背后的疤痕在他脑子里面挥之不去。他一遍遍的回想着，没心情去管今天的天气如何，更没心思去想他的话本子。</p><p>　　回去的路上要经过三十六道弯，而在最后曲径通幽的地方，有一片村庄，那里就是苏景的家，也是苏野的家。苏景有个习惯，经过了多少道弯就在心里反复念叨着这个数，数越大苏景走的越快，数到三十六的时候苏景已经是连走带跑的往家里赶了。</p><p>　　但是今日的苏景已经记不得他数到几了。他的步子迈的比往日都要慢上一些，将脚底的树叶残枝踩的吱呀呀响，神思涌动，脑海里面回忆起了他和苏野第一次相遇的场景。</p><p>　　三年前的一个晌午，苏景一个人在望日峰上待了许久。大半个月以来，他每日都要花好几个时辰的功夫坐在望日峰最高的那棵千年龙柏的树冠上，看飞鸟缱绻在云缕，看池鱼氤氲在碧涧，看薰风吹拂新绿，看露雨泽润青茵。</p><p>　　苏景喜欢这般的日子。他轻轻阖上眼睛，鎏色的光晕在眉目间流转，神识慢慢的从眉宇向四周蔓延。神识所过之处，空气中弥漫的燥热皆被抚平退散。</p><p>　　他的心念随着神识漫无目的地闲逛着，在快要溜达到这片林子外的时候，突然觉察出一道近乎微弱的喘息。苏景心中隐隐感到一丝不对劲，立刻将散漫开的神识向那道喘息声的方向聚拢。</p><p>　　当苏景的神识拢在喘息声传来的那处地方时，他看到了一个和他年纪相仿的少年浑身是血的趴在地上。少年眉头紧锁，眼帘低垂，嘴唇苍白，身体似乎因为太过疼痛而轻微的颤抖着，那一道道似有若无的喘息声让苏景觉得他随时都有可能被灌下两大碗孟婆汤。</p><p>　　苏景赶紧从龙柏上跳下来，火急火燎的朝受伤的少年那赶去。他的鞋不太合脚，跑起来总是有些磕磕绊绊。途中苏景的肚子不争气的叫了一声又一声。苏景管不了那么多，顺手摘了几个看起来能吃的果子就揣进自己身上唯一一块儿还称得上干净的地方。</p><p>　　等苏景赶到的时候，少年的气息已然又微弱了几分。苏景意外的看到，少年原本空荡的尾骨处不知何时生出了一条玄青色狼尾，只是这尾巴也同他主人一般，像霜打的茄子，软塌塌的倒在一旁。</p><p>　　“这是…狼族？连人形都已经没法完全维持了，看来伤势真的挺严重。”心念及此，苏景顾不得多想，眉头微蹙，赶紧释放神识将少年笼罩在其中，同时心中密词默念，一道裹挟着夜交藤香的软风自苏景处落向了少年的眉心。于此同时，一串如江南小调般的低吟声传进了少年的耳畔。</p><p>　　苏景一边维持着“安神诀”，一边分神仔细观察着少年的反应。只见少年颤抖的身体随着耳畔的低吟声逐渐平静下来，紧锁的眉宇也舒展了几分。他的呼吸声不再断断续续，而是浅浅的起伏着。</p><p>　　苏景看着少年浑身上下没有一处完整的衣料，露在外面的身体满是凝固的血痂和数不尽的刀口子，狰狞的刀口上沾满了污泥和血垢。苏景不知道少年经历了什么炼狱般的痛苦，但他能感觉到自己的心被一只无形的手紧紧攥住。</p><p>　　苏景轻吐了口气，他的神识具有宁心静气的作用，“安神诀”也能帮助缓解疼痛。然而无论是苏景的神识还是“安神诀”都只能起到镇痛宁神的效果，这种治标不治本的法子虽可以短暂缓解少年的痛苦，但想要把他从鬼门关拽回来，只能…</p><p>　　想到此处，苏景毫不犹豫地伸出左臂，拢起袖子固定好。右手幻化出一道风刃，在左臂的动脉处深深地划了一道豁口，豁口裂开的瞬间，鲜红的血液随着苏景倒吸一口凉气的声音缓缓流出。</p><p>　　苏景小的时候养过一只奶猫，有一次它不小心误食了一种致命的毒果子，苏景发现的时候它腹痛的在地上不停的翻滚。苏景将它抱在怀里，正准备动用神识，不料手掌传来一阵刺痛。苏景看到小奶猫不小心划破了他的掌心，又将渗出来的血舐了干净。</p><p>　　接下来发生的一幕让小苏景瞪大了眼睛。他惊讶的发现，原本已经快要不行的小奶猫竟然恢复了精神，乖乖的躺在他怀里睡着了。苏景用神识探查了它的状况，虽然还是虚弱的很，但是已然没有大碍。</p><p>　　小苏景愣愣地看着自己的手掌，聪明的他立刻意识到，他的血液里有什么了不得的东西。他有些兴奋，却没有把这件事告诉任何人。他知道一旦让其他人发现了端倪，必然会给他自己带来大麻烦。</p><p>　　苏景怕疼，自那以后也没有机会再动用他身体的能力。他小心翼翼地挤了挤自己的伤口，想让血流的更多更快些。他蹲下身子，将左臂悬在少年的额头上，让血滴落的位置正好在少年嘴唇的上方。他又把右手在自己身上干净的地方擦了擦，然后用食指试探性地想要撬开少年紧抿的唇瓣。</p><p>　　少年不知道是痛的牙关紧闭还是不喜欢嘴巴被人触碰，苏景试探了好几次依旧没能让他把嘴巴张开。他动脉处的血滴在少年的唇瓣上，像是红梅落入冬雪。</p><p>　　苏景灵光一闪，低头在少年的耳畔悄声说了句“对不住了。”然后右手不轻不重地给少年的腹部来了一拳。平日里这种力度打在少年身上就如同隔靴搔痒，但他伤的实在太重，苏景一拳下去，少年就痛的忍不住张嘴抽气。</p><p>　　苏景瞅准机会，下意识的用力掐了掐自己的伤口，鲜血像山间细流似的落进少年的唇缝。苏景目不转睛的看着他，心里也有些紧张。这是他第一次主动给别人喂血，效果如何他自己也不太清楚。</p><p>　　不多久，只见少年的狼尾动了动，十数息的功夫之后就消失在虚空中，唇瓣也悄悄泛起了些微血色。“有效果了！”苏景心中大喜，紧绷的弦稍微松了些。</p><p>　　只是…苏景用神识探查了他的身体，生命体征微弱的像是一颗随时会熄灭的火苗，更别说风吹雨淋了。苏景叹了口气，默默把自己的袖子拉的更高些，然后又划了两道口子，一股脑的全喂进少年的嘴里。</p><p>　　苏景像是一位不断给火苗添柴的人，期望着火苗能越烧越旺。他就这么直愣愣的举着胳膊，等到手臂酸的快要抬不起来的时候，才用手边的野草给自己的伤口随意的处理了一下。</p><p>　　苏景看着少年刀口周围的污泥和血垢，便想着背他去山脚边的溪流。正当他试图抬起少年的手臂时，却发现他右手的五个手指全都微蜷着插在泥土当中。</p><p>　　苏景把手覆在少年的手背上，掌心发力，一点点地将少年的手从泥土里分开。当他再次抬起少年的胳膊时，一枚暗红的狼牙戒指从少年的手掌心滑落。</p><p>　　苏景估摸着这是对他很重要的物品，便从身上扯下一块料子，将戒指小心翼翼的包好，然后带在身上。他背起少年的时候才发现，少年比他要高出半个额头，而且…苏景感受到自己的小腿在微微的颤抖，心里嘀咕道：“狼族都这么重的吗！”</p><p>　　到了溪边，苏景将少年安放在一棵青柏旁，将一直带在身上的野果子拿到溪边冲洗干净，又将包果子的布料来回洗了好几遍，方才回到少年身边，清理着他身上化脓的血口子。</p><p>　　清理的时候苏景才知道什么叫触目惊心。岂止是刀口子，他背上有五处被穿喉箭中伤的痕迹，箭矢上有防止伤口愈合的药，到现在还在血流不止。腰背上还有数道被刮骨鞭鞭笞的痕迹，血肉模糊，伤口之深可见白骨。尤其是心口处的那几道口子…苏景每清理一处心便俞沉一分。</p><p>　　等苏景将所有的伤口处理完毕时，天空已是墨色。他轻轻拭去少年面上的尘土，露出一张棱角分明的脸。少年还未清醒，双目紧闭，眉宇间却带着戾气。苏景本以为自己长的够俊了，却不得不承认眼前的少年比他要更多几分峻朗。</p><p>　　苏景坐在少年的身侧，又在自己右臂上划了几刀。他一边给少年喂血，一边阖上眼准备休息。但是手臂不时传来的疼痛让他毫无睡意，便强睁着大眼睛数天上的星星。数着数着，便模模糊糊的睡着了。</p><p>　　就这么过了一日，两日…苏景看着少年身上的伤口正在逐渐愈合，估摸着再有个十几日的功夫，他就可以宣布他从阎王爷手中把人给抢回来了。</p><p>　　等到第三日早晨，苏景在睡梦中被脖颈处的一阵酥麻弄醒。他迷迷糊糊睁开眼睛，看到了一颗玄青色的狼脑袋。小狼还没有醒，嘴巴似乎咬着…自己的脖子？！</p><p>　　苏景瞬间清醒，他慢慢的试图把自己的脖子从它嘴巴里面悄悄挪出来。正当苏景挪出来的一刹那，小狼猛地惊醒。“你你你别咬脖子，咬脖子我就会死掉，死掉的话我就不能救你了！”苏景没过脑子的冲小狼嚷嚷着。</p><p>　　小狼歪头看着苏景，眼睛里面似乎透露着一种…看傻子的神情。它有气无力的咬住苏景的胳膊，又昏昏沉沉的睡了过去。苏景回过神来，摸了摸自己的脖子，没有任何的伤口。他意识到小狼没想伤害他，就由着他咬着自己的胳膊。</p><p>　　第七日的晚上，苏景去林子里找吃的。前几日小狼化成狼形，应该是妖族的自我保护机制，毕竟维持人形要消耗更多的能量，而狼形可以更好的恢复。他又找了一些野果子，准备等小狼化成人形的时候果腹。</p><p>　　正当他往回走的时候，发现少年模样的小狼在满地寻找着什么。苏景心领神会，赶紧跑到他身边，把自己身上一直带着的那枚戒指递给了小狼。小狼先是恶狠狠的盯着苏景看，后来想到什么似的，收起了眉宇间的戾气，自顾自的将自己蜷成一团，又沉沉的睡过去了。</p><p>　　苏景有些好笑的看着他这副模样，浅浅地对他说了句：“小白眼狼。”然后又娴熟的在自己手腕上划破几道口子，喂进小狼嘴里。他靠着小狼躺下，手有一搭没一搭的轻轻拍在小狼背上，嘴里念叨着：“没事的，都过去了，都过去了…”</p><p>　　第九日，苏景不知为何一觉睡到了正午。这两日他总觉得身体有些疲软，可能是流了太多的血，又或者是天气炎热了几分。苏景在睡梦中不断的翻身，试图逃离阳光的照射。恍惚间，有一道阴影蒙上了他的眼睛，为他隔绝了晃眼的光。</p><p>　　等苏景醒来时，正好和一双深邃的眸子对视，黑曜石般的瞳孔里，仿佛燃烧着熊熊的烈火。苏景还没回过神，就看到眼前的人低身伏于自己的耳畔边，用清冷又炙热的声音对他说：“你是谁，为什么要救我。”</p><p>　　朱阳当空，烛火燎原。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一章 · 池鱼覆清泥💙</title>
    <link href="/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2023/11/15/%E5%86%99%E4%BD%9C/%E5%8D%97%E5%86%A0%E6%AC%B2%E7%83%82%E6%9F%AF/%E5%8D%97%E5%86%A0-%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="池鱼覆清泥"><a href="#池鱼覆清泥" class="headerlink" title="池鱼覆清泥"></a>池鱼覆清泥</h1><p> 崇宁十七年，夏。</p><p>　　大赢和大乾边境交界处，有一片绵延万里的峰群，高低起伏的碧山翠峦间，有一座不起眼的山头。山头上满是扎根了数千年的烟松，四季常绿，他们像是风霜饱经后的老者，仍怀揣着一颗稚子之心，年年常乐。</p><p>　　远处几只结伴的闲云鹤悠悠飞来，在这片松林旁驻足小憩。闲云鹤性怯，喜静，寻常人一生都看不到他们的踪影，今日这座山头却能引得它们落脚歇息，想来是发觉这片林子没有人迹。</p><p>　　山脚边有一条小溪深深浅浅的流淌着，溪水中生活着一种独特的鱼，在太阳照射下其鳞生霓色，故而称其“彩鳞鲭”。阳光在水面铺开时，会有彩色的流光自水里晕染开来，像是把整个大赢的胭脂都倒进了溪水当中，故而这条溪水又被称作“彩粼溪”。</p><p>　　那几只闲云鹤正立在烟松边上闲散地整理着羽翼，突然从彩粼溪的方向传来了“扑通”的落水声，紧跟着又传来一声“哎呦——”。声音不算太大，却也惊的闲云鹤们如临大敌似的振翅而逃，仓皇间还能腾出空朝彩粼溪那边探个脑袋，隐约能瞧着溪边有两道模糊的人影。</p><p>　　其中一名头戴蓑笠帽的少年低坐在溪旁，不急不徐的将裤脚卷到及膝的位置，又拢了拢袖子，从身侧拿出一个竹篓，熟练的将篓中的衣物放入溪水中，帽檐将少年的脸尽数没入阴影，可水里倒映出的那张脸，连隔壁家的小奶猫见了都要羞的转身就跑。</p><p>　　少年浣衣的同时，眼睛不时瞟向一旁，别家的小奶猫跑不跑不知道，但自家这位…刚刚那声“哎哟”便是自家这位“小奶猫”抓鱼不成，反将自己扑空在水里湿了个满身发出来的哀嚎。</p><p>　　这位“小奶猫”也没有气馁，重新调整了姿势，深吸了一口气，然后屏住呼吸，将大半个身子都没在水中，只露出一双亮闪闪的眼睛，眨也不眨地盯着几条浑不知情的游鱼在水里交尾欢腾，其间虹芒交相辉映。</p><p>　　片刻过后，他猫似的缓缓弓起背，嘴唇翕动，水面腾的升起一层薄雾和光晕，光晕缓缓向鱼群拢去，原本在水中撒欢的鱼儿突然安静下来，只有尾巴还在轻微的摆动着。就在鱼群失神的瞬间，这位少年忽地向鱼群扑去，溅起巨大的水花和池底的青泥。</p><p>　　浣衣的少年正在抖落一件刚洗净的素色长衫上的水珠，耳畔边便传来了水花溅落的声响，还没反应过来声响的缘由，便见到青泥将手中的长衫又沾了个满怀。</p><p>　　少年的手顿时僵住，额头青筋猛跳，他闭上眼，努力长吸了一口气，试图压抑自己的情绪，好一会儿后方才咬着牙，睁开眼睛，冲着抓鱼的少年从牙缝中生生挤出几个字：“苏景！你能不能——”</p><p>　　话还没说到一半，苏景就从水里起了身，手里抓着一条活蹦乱跳的彩鳞鲭。夏日的阳光在这片茂密的山林里也只能堪堪从树叶的缝隙里漏出几片金纱，金纱似的光芒笼在苏景脸上，让人移不开眼。</p><p>　　浣衣少年盯着他怔了片刻，刚刚还作势要吓唬苏景的气焰被眼前的场景一下子打消了，顷刻间化作笑意，望着苏景那张被泥星子遮得严严实实的脸，只剩两只扑闪闪的大眼睛露在外面。</p><p>　　“苏野你快看！这条彩鳞鲭的个头比以往抓的那些都要大！”苏景一手叉着腰，一手举起刚抓的家伙朝苏野那边使劲儿晃了晃，泥星子也遮不住脸上的兴奋劲儿。</p><p>　　苏野象征性的朝苏景比了个大拇指，又从自己衣服里面掏出一条干净的帕子递过去，然后伸手接过他手里抓着的那条彩鳞鲭，声音淡淡，目光中却含着不易察觉的笑意说道：“把脸擦擦。”</p><p>　　待苏景将帕子在脸上胡乱抹了几下之后，苏野用手舀了勺清水，一把薅过苏景的脖子，他看似大力实则不轻不重的将苏景脸上的泥点子抹了个干干净净，而后捏了捏苏景被抹地有些发红的脸蛋，这才满意的将人放了回去。</p><p>　　“这人怎么擦脸也这么用力。”苏景小声嘟囔着，苏野站在一旁，将苏景的嘀咕听了个清楚。他看着苏景的脸，不知为何突然想将梅花酒倒进牛乳里面试试，看看是不是也会像苏景的脸这般，白里泛着红。</p><p>　　苏景一边拧了拧自己湿透的衣服，一边对苏野说道：“奶奶今天的腰伤又发作了，眼睛也看不太清楚，咱们回去的时候去趟王爷爷那，请他老人家再给奶奶瞧瞧，顺便再去趟——”，苏景话没说完，突然想起什么似的闭上了嘴，拧衣服的手速加快，余光却看向了苏野，好像在打量苏野有没有听到他那后半句话。</p><p>　　苏野嗯了一声，状似没听见后半句话地整理着篓中的衣物，心里却明白苏景的小算盘。前段日子苏景迷上了沈姨家从镇上寻来的话本子，吃饭也看，睡觉也看，连同他讲话时也总是想着话本子里的故事。</p><p>　　苏野气闷，担心他因为太过入迷而荒废了修炼，便将话本子还给了沈姨。苏景知道后去找苏野理论，苏野只回了他四个字：“为了你好。”苏景自知打不过苏野，但是又心心念念着话本子的后续，便盘算着再偷偷去趟沈姨那把话本子拿回来。</p><p>　　正当苏野将脏了的手帕和长衫重新放入溪水冲洗时，余光瞥见了一道准备溜走的身影。只见苏景偷偷摸摸的翻转手掌结了一印，脚尖轻点地面，脚底生成一股难以察觉的暗风，恍惚间便向林子里急掠而去。</p><p>　　“凌风步修的不错。”苏野望向苏景离开的方向，心中想道。他不慌不忙地将手里的帕子拧干，装进竹篓。等一切收拾好了以后，心念微动，凝神催发着体内的血脉之力，霎时间背后幻化出一道巨大的黑色虚影，周身暗红色的光芒跃动，同时脚掌发力，裹挟着劲风朝苏景离开的方向赶去。</p><p>　　苏景前行的过程中，心神凝聚，眸色变幻，目光含鎏。他将神识朝后方扩散开，一圈圈鎏色的能量波动以苏景为中心，悄悄隐匿在空气中跃动的微尘内，时刻关注着后方苏野的动静。</p><p>　　十数息后，一道苏景极为熟稔的能量潮和苏景的神识碰撞在一起，像是暴雨骤袭潭水，暗红和鎏金色的能量溅玉喷珠般的向四周迸裂。苏景心中一惊，没想到苏野这么快就追上来了，正欲催动内力加快速度，不料后颈处袭来一阵潮湿灼热之感，紧接着便被脖子处的拉力拖着往下栽。</p><p>　　苏野头快要着地的瞬间，眼前突然出现了一团毛茸茸的玄青色尾巴，将苏景稳稳当当地接住。钳住苏景后颈的力量松开后，苏景正想揉揉被弄的有些发痒的脖子，却又被两个厚重有力的爪子翻了个身，一张黑色的狼脸就这么出现在苏景的眸子里。</p><p>　　“苏野你快变回去，重死我了。”苏景被小狼压的没办法移动，大声嚷嚷。小狼没有理睬，低下头，使劲儿蹭了蹭苏景的脸，然后轻轻地将苏景从后颈舐到耳垂。</p><p>　　有时候苏景会想，狼形和人形的苏野到底是不是共用同一个神识，人形的苏野看上去正正经经，怎么狼形的苏野这么…苏景不知道怎么形容，只能任由小狼把他压着。</p><p>　　小狼看他一副任凭处置的躺在那，不由有些好笑。他抬起头颅，心念微动，赤色的流光闪烁间，钳住苏景的爪子骤然变成了两条孔武有力的胳膊。</p><p>　　夏日的天气炎热，即使在林中，追逐过后苏景也有些微汗涔涔。苏野正准备收回自己压着苏景的手，突然看到了苏景额头和脸颊渗出的汗珠。</p><p>　　苏野晃了晃神，脑子里不受控制的想到了刚温好的牛乳，又想到了十五的月亮……苏野摇摇头，觉得这些都不及苏景白。苏野又低头看了看自己黑黢黢的胳膊，暗叹太阳有点过于关照他了些。</p><p>　　苏景挣脱开苏野，活动了一下有些发酸的胳膊，袖口滑到了手肘。苏野一眼就注意到了苏景手臂上深浅不一，密密麻麻的划口，不由眉头微皱，心里沉了沉。</p><p>　　苏野心情急转直下间，没有发现，一道隐匿在背后的神识顺着他的领口溜到了后背。坐在一旁的苏景神情微变，心中一怔，他神识见到的，是一道道扭曲骇人的疤痕。如同一条条狰狞的千足之虫附着在苏野的背上。</p><p>　　两个人就这么静静的看着彼此，谁都没有开口说话。过了好一会儿，苏景才笑着说道：“愣着做什么，拉我起来，我腿麻了。”苏野这才回过神，一把扶起苏景，拍了拍他后背上的灰尘，轻声对他说：“你先回去，我去趟竹林。”苏景也没过问他去干什么，只是冲苏野笑了笑，然后往回家的方向走去了。</p><p>　　苏野看着苏景的背影逐渐消失在他的眼底，又盯了片刻，方才回头往竹林的方向走去。暮色悄悄地将整片林子没入橘黄，也悄悄地聆听着少年们的心事。</p><p>　　彩粼溪中两条游鱼追逐打闹着，不小心将池底的青泥翻了个痛快。又或许很多不堪的前尘往事也随着这些泥泞一起，被侵覆出水面了。  </p>]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>南冠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AE变形动画！🫧</title>
    <link href="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/"/>
    <url>/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="AE变形动画"><a href="#AE变形动画" class="headerlink" title="AE变形动画"></a>AE变形动画</h1><h2 id="1-人偶位置控点工具"><a href="#1-人偶位置控点工具" class="headerlink" title="1.人偶位置控点工具"></a>1.人偶位置控点工具</h2><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/1.png"></p><p><strong>效果：</strong></p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/2.png"></p><p>操纵黄色的点可对其进行变形。</p><h2 id="2-贝塞尔曲线"><a href="#2-贝塞尔曲线" class="headerlink" title="2.贝塞尔曲线"></a>2.贝塞尔曲线</h2><p>在创建形状图层时勾选贝塞尔曲线路径</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/3.png"></p><p>创建两个不同的贝塞尔曲线路径，路径之间可以相互复制粘贴</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/4.png"></p><p>创建两个关键帧，实现图形的变换</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/5.png"></p><h2 id="3-合并路径"><a href="#3-合并路径" class="headerlink" title="3.合并路径"></a>3.合并路径</h2><p>创建两条或多条路径，在添加处点击合并路径选项</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/6.png"></p><p>产生新的内容——<strong>合并路径</strong>，选择模式</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/7.png"></p><p>不同的模式会产生不同的效果，下图为相减时产生的效果</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/8.png"></p><p><strong>注意：</strong>路径的上下顺序会改变合并路径的效果</p><p><strong>❗️Tips：</strong>Ctrl+G可以对内容进行打组，如下图所示：</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/9.png"></p><h2 id="4-中继器"><a href="#4-中继器" class="headerlink" title="4.中继器"></a>4.中继器</h2><p>可将多个图形按照一定规则进行复制</p><p>同样在<strong>添加</strong>中找到中继器</p><p><strong>注意：</strong>中继器会对其位置上方的内容进行复制</p><p>若希望进行对称变换，可以调整中继器变换的比例属性</p><p><img src="/2023/11/14/Adobe/AE/%E6%8A%80%E5%B7%A7/AE%E5%8F%98%E5%BD%A2%E5%8A%A8%E7%94%BB/10.png"></p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>AE</category>
      
      <category>AE动画设计技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>AE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>毛茸茸字体！🌞</title>
    <link href="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/"/>
    <url>/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/</url>
    
    <content type="html"><![CDATA[<h1 id="毛茸茸字体"><a href="#毛茸茸字体" class="headerlink" title="毛茸茸字体"></a>毛茸茸字体</h1><p>效果如下图所示：</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/1.png"></p><p>实现该效果需要用到三个步骤：</p><p>1.混合工具</p><p>2.钢笔工具</p><p>3.效果</p><h2 id="1-混合工具构建基本样式"><a href="#1-混合工具构建基本样式" class="headerlink" title="1.混合工具构建基本样式"></a>1.混合工具构建基本样式</h2><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/2.png"></p><p>设定混合选项</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/3.png"></p><p>选择混合距离1.5px</p><p>再进行对象—-&gt;混合——&gt;建立</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/4.png"></p><p>效果如上所示</p><h2 id="2-钢笔工具画出想要的字体"><a href="#2-钢笔工具画出想要的字体" class="headerlink" title="2.钢笔工具画出想要的字体"></a>2.钢笔工具画出想要的字体</h2><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/5.png"></p><p><strong>注意：</strong>画好的字体必须是连接起来的字体</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/6.png"></p><p>替换混合轴后效果如下图所示</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/7.png"></p><h2 id="3-效果"><a href="#3-效果" class="headerlink" title="3.效果"></a>3.效果</h2><p>在粗糙化选项中进行属性编辑</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/8.png"></p><p>编辑属性如下</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/9.png"></p><p>最终效果如下所示：</p><p><img src="/2023/11/14/Adobe/Ai/%E8%AE%BE%E8%AE%A1/Ai%E8%AE%BE%E8%AE%A11/10.png"></p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>Ai</category>
      
      <category>Ai设计案例</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ai</tag>
      
      <tag>设计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ai钢笔工具的使用！🌸</title>
    <link href="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Ai钢笔工具的使用"><a href="#Ai钢笔工具的使用" class="headerlink" title="Ai钢笔工具的使用"></a>Ai钢笔工具的使用</h1><h2 id="1-找到凹凸曲线的交界点"><a href="#1-找到凹凸曲线的交界点" class="headerlink" title="1.找到凹凸曲线的交界点"></a>1.找到凹凸曲线的交界点</h2><p><img src="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/1.png"></p><p>如上图所示即是凹凸曲线的交界点</p><p>该临界点是钢笔落点的基本位置</p><h2 id="2-每条凹凸曲线的范围不超过180度"><a href="#2-每条凹凸曲线的范围不超过180度" class="headerlink" title="2.每条凹凸曲线的范围不超过180度"></a>2.每条凹凸曲线的范围不超过180度</h2><p><img src="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/2.png"></p><p>如图所示，曲线由两个端点所控制，而端点之间连城一条直线</p><p>直线是180度角</p><p>所以在选择两个钢笔的端点时，曲线角度不能超过180度</p><h2 id="3-控制凹凸曲线端点的手柄为切线"><a href="#3-控制凹凸曲线端点的手柄为切线" class="headerlink" title="3.控制凹凸曲线端点的手柄为切线"></a>3.控制凹凸曲线端点的手柄为切线</h2><p><img src="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/3.png"></p><p>如上图所示，在初始点的位置，控制左边手柄为左半边曲线的切线</p><p>然后按住<strong>Alt键</strong>改变右边手柄的方向和长度</p><p>使右边手柄为右半边曲线的切线</p><h2 id="4-端点手柄的长度决定曲线的倾斜程度"><a href="#4-端点手柄的长度决定曲线的倾斜程度" class="headerlink" title="4.端点手柄的长度决定曲线的倾斜程度"></a>4.端点手柄的长度决定曲线的倾斜程度</h2><p><img src="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/4.png"></p><p><img src="/2023/11/14/Adobe/Ai/%E6%8A%80%E5%B7%A7/Ai%E9%92%A2%E7%AC%94%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8/5.png"></p><p>如上图所示，控制右边手柄的长度，可以看到曲线的倾斜角度发生了改变</p><p>长度越长，倾斜角度越大</p>]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
      <category>Ai</category>
      
      <category>Ai矢量图设计技巧</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技巧</tag>
      
      <tag>Ai</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>算法整体认知思路！💁</title>
    <link href="/2023/11/01/%E7%AE%97%E6%B3%95/Algorithm-begin/"/>
    <url>/2023/11/01/%E7%AE%97%E6%B3%95/Algorithm-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>算法 ʕ≧ᴥ≦ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>思路</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《南冠欲烂柯》简介！👀</title>
    <link href="/2023/11/01/%E5%86%99%E4%BD%9C/Writing-begin/"/>
    <url>/2023/11/01/%E5%86%99%E4%BD%9C/Writing-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>写作 ʕ◉ᴥ◉ʔ</category>
      
      <category>《南冠欲烂柯》</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>大纲</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Adobe全家桶流程概览！🧟‍♀️</title>
    <link href="/2023/11/01/Adobe/Adobe-begin/"/>
    <url>/2023/11/01/Adobe/Adobe-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Adobe ʕ￫ᴥ￩ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>思路</tag>
      
      <tag>Adobe</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能的应用场景！🤹🏼‍♀️</title>
    <link href="/2023/11/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AI-begin/"/>
    <url>/2023/11/01/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AI-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>AI ʢᵕᴗᵕʡ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>思路</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>整体建模思路！🧝🏼‍♀️</title>
    <link href="/2023/11/01/%E5%BB%BA%E6%A8%A1/Maya-begin/"/>
    <url>/2023/11/01/%E5%BB%BA%E6%A8%A1/Maya-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>建模 ʕథ౪థʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>思路</tag>
      
      <tag>建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unity整体架构思路！🙇🏻‍♂️</title>
    <link href="/2023/11/01/%E6%B8%B8%E6%88%8F/Unity-begin/"/>
    <url>/2023/11/01/%E6%B8%B8%E6%88%8F/Unity-begin/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Unity ᶘ ᵒᴥᵒᶅ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>思路</tag>
      
      <tag>Unity</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>小杨来啦！🦸🏻‍♂️</title>
    <link href="/2023/10/31/%E5%B7%A5%E5%85%B7/kaixin/"/>
    <url>/2023/10/31/%E5%B7%A5%E5%85%B7/kaixin/</url>
    
    <content type="html"><![CDATA[<p>开心就好</p>]]></content>
    
    
    <categories>
      
      <category>工具 ʕ•ᴥ•ʔ</category>
      
    </categories>
    
    
    <tags>
      
      <tag>情绪</tag>
      
      <tag>发疯</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
